paperID,title,url,abstract,publisher,source,yearPublished
1,The Sustainable Personality: Values and Behaviors in Individual Sustainability.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iyCFjx0AAAAJ&citation_for_view=iyCFjx0AAAAJ:_FxGoFyzp5QC,"Meaningful societal change begins with individual change. One cannot do for a community what one cannot do for one's self. The topic of Individual Sustainability is a controversial one, as students often appear to be unable to align their demonstrated behaviors with their admirable values related to sustainability. Individual behavior creates the foundation for action in social, economic, and environmental sustainability, and potentially guides our ability to work with one another to make life-affirming decisions. In short, it is a matter of aligning our day-to-day behaviors with our well-stated values that will result in greater sustainable community action. The general objective of this research is to determine how an interactive website providing multisource feedback on personality motivates students to change their behaviors or values, or to align their behaviors and values. We believe that creating a ""cognitive dissonance"" between individuals' values and behaviors","Sciedu Press. 1120 Finch Avenue West Suite 701-309, Toronto Ontario, Canada M3J 3H7",,2015
2,Walking the walk: Conceptual foundations of the Sustainable Personality,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iyCFjx0AAAAJ&citation_for_view=iyCFjx0AAAAJ:UeHWp8X0CEIC,"Systems Theory in sustainability studies has normally not been extended beyond environmental, economic, and social contexts. The role of the individual is critical to the success of sustainability efforts across other contexts. Sustainable Personality explores the fundamental conceptual foundations for sustainable behavior and the role of the individual in environmental, social, and economic sustainability. This paper provides a broad historical foundation, starting with Greek philosophy, for the concept of Sustainable Personality. The authors' purpose is to demonstrate that our global sustainability problems stem largely from individual limitations, and that meaningful human change begins with individual change. In particular, the challenge of increasing sustainable action by empowering individuals to align their behaviors with their admirable values is explored.",Elsevier,,2015
3,The affective regulation of social interaction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iyCFjx0AAAAJ&citation_for_view=iyCFjx0AAAAJ:UebtZRa9Y70C,"The recent publication of David Heise's Expressive Order (2007) provides an occasion for discussing some of the key ideas in Affect Control Theory. The theory proposes that a few dimensions of affective meaning provide a common basis for interrelating personal identities and social actions. It holds that during interpersonal interactions, social behavior is continually regulated to maintain an affective tone compatible with whatever social roles or identities define the situation. We outline the intellectual history of the proposed dimensions and of the idea that each social action invites an action from the other that has a particular location along these dimensions. We also relate these ideas to the Affect-as-Information hypothesis, an approach that often guides research in psychology on the role of affect in regulating judgment and thought.",SAGE Publications,,2007
4,"Creative thinking, creative problem solving, and inventive design in the engineering curriculum: A review",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iyCFjx0AAAAJ&citation_for_view=iyCFjx0AAAAJ:roLk4NBRz8UC,"During the past decade, and especially over the last few years, engineering educators have been promoting, and implementing in their classrooms, an increased emphasis on student creativity, problem-solving ability, and inventiveness. At a growing number of universities, student engineers are studying the creative process, developing advanced thinking and problem-solving skills, and learning to design by experience. Successful programs, projects, and research at premier engineering schools around the country are equipping students with the advanced creative and cognitive abilities required to succeed as contemporary professionals. This paper is a review of the innovative, multi-disciplinary, educational methodology that is manifest in several types of new efforts, including: 1) Engineering design in a studio atmosphere; 2) Engineering courses for creative problem-solving; 3) Encouraging creativity and insight through journal writing; 4) The agenda for creativity at the UK Centre for Materials Education; and 5) A focus on the personal creative process. Research for this review inspired The Creativity, Innovation, and Design Report, a new national publication dedicated to fostering creativity and innovation in engineering and applied science education.",,2003 Annual Conference,2003
5,An evaluation of freshman engineering persistence using expectancy-value theory,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iyCFjx0AAAAJ&citation_for_view=iyCFjx0AAAAJ:YsMSGLbcyi4C,"As we engage in an increasingly complex and quickly progressing world, the development of science, technology, engineering, and mathematics (STEM) students will be increasingly important to the continuation of the United States' competitiveness. However, the overall number of STEM students earning a degree will not be able to meet the increasing demand for practicing professionals especially within historically underrepresented groups such as women and minorities. One way to tackle this problem is to increase the retention of STEM students by studying the processes that influence persistence to completion of a STEM degree. Retention is critically important to the field of engineering as over 10% of all engineering majors will switch to other STEM degrees and even more will not persist within STEM fields at all. The focus of this paper is to utilize Expectancy-Value Theory to determine how freshman …",IEEE,,2013
6,"Educating the Whole Engineer at Wake Forest Engineering: Using Cognitive Apprenticeship as an Effective Pedagogical Approach to Cultivate Design Learning, Team Effectiveness …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iyCFjx0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iyCFjx0AAAAJ:5nxA0vEk-isC,"To better serve the evolving needs of society through responsible design, we must better educate the next generation of engineers to continue innovating and advancing technological solutions for the betterment of humanity. Wake Forest Engineering was built on the mission to Educate the Whole Engineer with a vision for our graduates to make positive societal impact (For Humanity). In educating the whole engineer, we must recognize that the complexities of engineering practice involve not only technical domains of learning (e.g., technical engineering knowledge, processes and thinking, fundamental principles, advanced technological methods and tools, prototyping, testing) but also non-technical domains of learning (e.g., collaboration and teamwork, engagement with stakeholders, effective communication, project management, ethical decision making, entrepreneurial mindset, professionalism, character …",TEMPUS PUBLICATIONS,,2024
7,Social emotional learning in STEM higher education,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iyCFjx0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iyCFjx0AAAAJ:ufrVoPGSRksC,"This chapter provides an overview of social emotional learning in STEM higher education. The authors discuss SEL competencies within this context and examine underlying issues, such as professional demands and emotional challenges within the learning environment that motivate SEL in higher education STEM contexts. Existing gaps and promising models relevant to bringing SEL into the university curriculum are also highlighted. Current approaches highlight teaching strategies and extracurricular activities that support the development of emotional intelligence, social skills, and empathy. The chapter also presents key recommendations for improving SEL-based practices in STEM higher education.",IGI Global Scientific Publishing,,2023
8,Scoping review of character development pedagogies in engineering education,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iyCFjx0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iyCFjx0AAAAJ:zYLM7Y9cAGgC,"When preparing engineering students for professional practice, the importance of their engagement in global, social, and ethical dimensions of engineering cannot be overemphasized. The importance of ethics is well discussed in engineering education literature, but much less is known about how to effectively prepare graduates for the complex global, social, and ethical challenges of engineering practice. Studies have found that common challenges to engineering ethics education include lack of student interest, resistance from faculty, and a lack of consensus regarding topics and pedagogical methods to include in already saturated curricula.We believe a character-focused approach to engineering ethics education could address these challenges by providing language and tools that are easily accessible to students and faculty for engaging ethical challenges in engineering and addressing students' …",IEEE,2022 IEEE Frontiers in Education Conference (FIE),2022
9,Operationalizing Team Effectiveness with Evidence-based Practice,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iyCFjx0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iyCFjx0AAAAJ:Tyk-4Ss8FVUC,"The design team is at the core of the capstone ecosystem, so understanding team dynamics is essential to capstone design research and practice. Much has been learned in this domain, but operational (ie, practical) approaches to enhancing team effectiveness lag behind theoretical findings. At Wake Forest Engineering, the instructional team has adopted an integrative evidence-based practice approach that capitalizes on tools drawn from diverse academic and professional sources to augment team effectiveness. Developmental processes associated with this approach are briefly discussed, and a working toolset is demonstrated to provide a basis for other capstone instructional teams to explore the potential of evidence-based practice.",,,2022
10,Engineering Education Meets Organizational Science: Toward Best Practices for Strategic Change,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iyCFjx0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iyCFjx0AAAAJ:W7OEmFMy1HYC,"This Innovative Practice Full Paper explores how implementing best practices from organizational science can strengthen strategic change initiatives in engineering education. Transforming organizational culture has been a priority in engineering education for nearly four decades, but systemic change has not come easily, and long-standing goals remain elusive. Stagnant graduation and industry participation rates for women and underrepresented minorities have implications for establishing cultures of inclusion. Further, continued difficulty closing the research-to-practice gap in the engineering classroom points to faculty cultures that are resistant to, or unprepared for, change. Are such cultures immutable, or could our current interventional methods be improved? How much do we really know about planning and managing change, and could best practices from organizational science help catalyze the …",IEEE,,2021
11,Evaluation of ultra-high temperature ceramics foraeropropulsion use,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RiXqXbQAAAAJ&citation_for_view=RiXqXbQAAAAJ:u5HHmVD_uO8C,"Among the ultra-high temperature ceramics (UHTC) are a group of materials consisting of zirconium diboride or hafnium diboride plus silicon carbide, and in some instances, carbon. These materials offer a good combination of properties that make them candidates for airframe leading edges on sharp-bodied reentry vehicles. These UHTC perform well in the environment for such applications, i.e. air at low pressure. The purpose of this study was to examine three of these materials under conditions more representative of a propulsion environment, i.e. higher oxygen partial pressure and total pressure. Results of strength and fracture toughness measurements, furnace oxidation, and high velocity thermal shock exposures are presented for ZrB2 plus 20 vol.% SiC, ZrB2 plus 14 vol.% SiC plus 30 vol.% C, and SCS-9a SiC fiber reinforced ZrB2 plus 20 vol.% SiC. The poor oxidation resistance of UHTCs is the …",Elsevier,,2002
12,UHTCs: ultra-high temperature ceramic materials for extreme environment applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RiXqXbQAAAAJ&citation_for_view=RiXqXbQAAAAJ:0EnyYjriUFMC,"The Electrochemical Society Interface• Winter 2007 31 seconds, while the outer wall is still at room temperature. This∆ T generates a compressive stress on the inside (hot) surface, while the outside (cool) surface carries a tensile stress. Depending on the thickness of the nozzle, the thermal conductivity and strength will determine the success or failure of the part. A finite element model of thick and thin-walled cross-section (Fig. 2) shows the highest tensile loads in red. 8 With higher thermal conductivity, the borides can more readily transmit the heat through the part and equilibrate the temperature within the crosssection, thereby reducing the thermal stress.",IOP Publishing,,2007
13,Paralinear oxidation of CVD SiC in water vapor,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RiXqXbQAAAAJ&citation_for_view=RiXqXbQAAAAJ:u-x6o8ySG0sC,The oxidation kinetics of CVDSiC were monitored by thermogravimetric analysis (TGA) in a 50% H2O/50% O2 gas mixture flowing at 1.4 cm/s for temperatures between 1200” and 1400°C. Paralinear weight change kinetics were observed as the water vapor oxidized the SiC and simultaneously volatilized the silica scale. The long‐term degradation rate of SiC is determined by the volatility of the silica scale. Rapid SiC surface recession rates were estimated from these data for actual aircraft engine combustor conditions.,American Ceramics Society,,1997
14,Variation of the oxidation rate of silicon carbide with water‐vapor pressure,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RiXqXbQAAAAJ&citation_for_view=RiXqXbQAAAAJ:d1gkVwhDpl0C,"Chemically vapor deposited silicon carbide (CVD SiC) was oxidized at temperatures of 1000°‐1400°C in H2O/O2 gas mixtures with compositions of 10‐90 vol% water vapor at a total pressure of 1 atm. Additional experiments were conducted in H2O/argon mixtures at a temperature of 1100°C. Experiments were designed to minimize impurity and volatility effects, so that only intrinsic water‐vapor effects were observed. The oxidation kinetics increased as the water‐vapor content increased. The parabolic oxidation rates in the range of 10‐90 vol% water vapor (the balance being oxygen) were approximately one order of magnitude higher than the rates that were observed in dry oxygen for temperatures of 1200°‐1400°C. The power‐law dependence of the parabolic oxidation rate on the partial pressure of water vapor at all temperatures of the study indicated that the molecular species was not the sole rate‐limiting …",American Ceramics Society,,1999
15,"SiC Recession Caused by SiO2 Scale Volatility under Combustion Conditions: II, Thermodynamics and Gaseous‐Diffusion Model",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RiXqXbQAAAAJ&citation_for_view=RiXqXbQAAAAJ:9yKSN-GCB0IC,"In combustion environments, volatilization of SiO2 to Si‐O‐H(g) species is a critical issue. Available thermochemical data for Si‐O‐H(g) species were used in the present study to calculate boundary‐layer‐controlled fluxes from SiO2. Calculated fluxes were compared to volatilization rates of SiO2 scales grown on SiC, which were measured in a high‐pressure burner rig, as reported in Part I of this paper. Calculated volatilization rates also were compared to those measured in synthetic combustion gas furnace tests. Probable vapor species were identified in both fuel‐lean and fuel‐rich combustion environments, based on the observed pressure, temperature, and velocity dependencies, as well as on the magnitude of the volatility rate. Water vapor was responsible for the degradation of SiO2 in the fuel‐lean environment. SiO2 volatility in fuel‐lean combustion environments was attributed primarily to the formation of Si …",American Ceramics Society,,1999
16,Experimental investigation of fifth oxide effects on calcium–magnesium–aluminosilicate glass properties,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RiXqXbQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RiXqXbQAAAAJ:MhiOAD_qIWkC,"Molten calcium–magnesium–aluminosilicate (CMAS) containing debris is a leading threat to hot‐section components in air‐ingesting turbine engines. This study investigated common natural‐forming and coating‐derived oxide additions to CMXAS glasses—where X denotes a fifth oxide constituent. Glass property relationships are elucidated by cation size effects and allow inferences to glass structure to be made. Iron oxide content, Group IV metal, and rare‐earth metal cations—including one dual cation addition (Y3+ and Yb3+)—effects on CMAS viscosity, coefficient of thermal expansion (CTE), softening temperature, and glass transition temperature were explored. The baseline material, nominally a 33 CaO–9 MgO–13 AlO1.5–45 SiO2 (single cation oxide mol%) CMAS, was synthesized from constituent oxide powders. Natural‐forming additions consistently operated as network modifiers. However, coating …",,,2025
17,Mechanisms of rare‐earth monosilicate reaction with calcium–magnesium aluminosilicate,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RiXqXbQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RiXqXbQAAAAJ:MpfHP-DdYjUC,"Reactions of calcium–magnesium aluminosilicate (CMAS) with single‐cation rare‐earth monosilicates (REMS) at 1300°C for times up to 24 h were investigated to determine reaction mechanisms. Eight single‐cation REMSs were investigated: La2SiO5, Nd2SiO5, Gd2SiO5, Dy2SiO5, Y2SiO5, Er2SiO5, Yb2SiO5, and Lu2SiO5. REMS with the smallest and largest cations, from either end of the lanthanide series, produced denser layers of apatite and underwent less recession, whereas the middle of the rare‐earths experienced much more recession and produced thick, low density apatite product layers. These reaction morphologies are attributed to competition between rates of REMS dissolution and apatite precipitation, which govern the outcome of REMS + CMAS reactions. The relative differences between these rates produce the range of REMS degradation observed when investigated as a function of rare‐earth …",,,2025
18,Oxygen tracer diffusion in yttrium silicates,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RiXqXbQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RiXqXbQAAAAJ:cK4Rrx0J3m0C,"The diffusivity of oxygen in environmental barrier coating (EBC) materials must be sufficiently low to limit the oxidation of the underlying silicon bond coat and silicon carbide ceramic matrix composite (SiC CMC). Yttrium silicates have been proposed as candidate EBC materials however there are limited oxygen diffusivity data available. In this study, oxygen diffusion coefficients for polycrystalline Y2Si2O7 and Y2SiO5 were determined using the oxygen tracer diffusion technique. The 18O diffusion concentration profiles were measured after exposure at temperatures of 1000 – 1300°C using time-of-flight secondary ion mass spectrometry (ToF-SIMS). Oxygen tracer diffusion and surface exchange coefficients were obtained by fitting the semi-infinite solution of the diffusion equation to the concentration profiles. Oxygen diffusion and surface exchange coefficients in yttrium silicates ranged from 10−14 – 10−12 cm2/s …",Elsevier,,2025
19,Oxidation Behavior of Tantalum in High Temperature Molecular and Dissociated Oxygen,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RiXqXbQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RiXqXbQAAAAJ:IaI1MmNe2tcC,"Tantalum (Ta) was oxidized in a new resistive heating system equipped with a DC microplasma capable of heating samples to 2400°C via Joule heating in a molecular or dissociated oxygen environment. Oxidation was conducted at 1300°C, 1400°C, and 1500°C for 2.5 and 5 minutes in molecular or partially-dissociated 1% O2 – balance Ar. The presence of atomic oxygen is verified through emission spectroscopy and quantified via Kapton HN erosion studies. The degree of dissociation is estimated as ∼40%. In molecular oxygen, the thickness of the oxide grown on Ta decreased as temperature increased, suggesting the formation of a more protective scale. Gas-phase diffusion through cracks in the oxide is identified as the rate-limiting process. For oxidation in atomic oxygen at 1300°C and 1400°C, the highly cracked oxide provided no barrier to atomic oxygen ingress and the extent of oxidation increased ten …",Elsevier,,2025
20,Ab initio stability predictions for rare earth oxyphosphates and experimental confirmation of cerium (III) phases,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RiXqXbQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RiXqXbQAAAAJ:7BrZ7Jt4UNcC,"Rare earth oxyphosphates represent a large family of compounds with the general formula (RE2O3)x(REPO4), where RE refers to lanthanides and yttrium. At least four known stoichiometries have been established, each with distinct structures. These compounds have potential applications as refractory coatings, catalysts, and magnetic materials. We modeled the stability of RE3PO7 [RE3(PO4)O3] with respect to rare earth sesquioxides (RE2O3) and orthophosphates (REPO4) using DFT computations with the GGA-PBE and r2SCAN exchange-correlation functionals. Phase stability predictions were consistent between the two functionals, while r2SCAN calculations of formation enthalpies for REPO4 showed better agreement with experimental data. RE3PO7 phases for La–Dy were predicted to be stable at 0 K, with a space group change from Cm to C2/m starting with Sm. RE3PO7 phases for Y, Ho, and Er were …",National Academy of Sciences,,2025
21,Mental Health and Behavior of College Students During the Early Phases of the COVID-19 Pandemic: Longitudinal Smartphone and Ecological Momentary Assessment Study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7OC4jEUAAAAJ&citation_for_view=7OC4jEUAAAAJ:zYLM7Y9cAGgC,"Background The vast majority of people worldwide have been impacted by coronavirus disease (COVID-19). In addition to the millions of individuals who have been infected with the disease, billions of individuals have been asked or required by local and national governments to change their behavioral patterns. Previous research on epidemics or traumatic events suggests that this can lead to profound behavioral and mental health changes; however, researchers are rarely able to track these changes with frequent, near-real-time sampling or compare their findings to previous years of data for the same individuals. Objective By combining mobile phone sensing and self-reported mental health data among college students who have been participating in a longitudinal study for the past 2 years, we sought to answer two overarching questions. First, have the behaviors and mental health of the participants changed in response to the COVID-19 pandemic compared to previous time periods? Second, are these behavior and mental health changes associated with the relative news coverage of COVID-19 in the US media? Methods Behaviors such as the number of locations visited, distance traveled, duration of phone usage, number of phone unlocks, sleep duration, and sedentary time were measured using the StudentLife smartphone sensing app. Depression and anxiety were assessed using weekly self-reported ecological momentary assessments of the Patient Health Questionnaire-4. The participants were 217 undergraduate students, with 178 (82.0%) students providing data during the …","JMIR Publications Inc., Toronto, Canada",,2020
22,Differentiating higher and lower job performers in the workplace using mobile sensing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7OC4jEUAAAAJ&citation_for_view=7OC4jEUAAAAJ:u5HHmVD_uO8C,"Assessing performance in the workplace typically relies on subjective evaluations, such as, peer ratings, supervisor ratings and self assessments, which are manual, burdensome and potentially biased. We use objective mobile sensing data from phones, wearables and beacons to study workplace performance and offer new insights into behavioral patterns that distinguish higher and lower performers when considering roles in companies (i.e., supervisors and non-supervisors) and different types of companies (i.e., high tech and consultancy). We present initial results from an ongoing year-long study of N=554 information workers collected over a period ranging from 2-8.5 months. We train a gradient boosting classifier that can classify workers as higher or lower performers with AUROC of 0.83. Our work opens the way to new forms of passive objective assessment and feedback to workers to potentially provide …",ACM,,2019
23,GLOBEM: Cross-Dataset Generalization of Longitudinal Human Behavior Modeling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7OC4jEUAAAAJ&citation_for_view=7OC4jEUAAAAJ:aqlVkmm33-oC,"There is a growing body of research revealing that longitudinal passive sensing data from smartphones and wearable devices can capture daily behavior signals for human behavior modeling, such as depression detection. Most prior studies build and evaluate machine learning models using data collected from a single population. However, to ensure that a behavior model can work for a larger group of users, its generalizability needs to be verified on multiple datasets from different populations. We present the first work evaluating cross-dataset generalizability of longitudinal behavior models, using depression detection as an application. We collect multiple longitudinal passive mobile sensing datasets with over 500 users from two institutes over a two-year span, leading to four institute-year datasets. Using the datasets, we closely re-implement and evaluated nine prior depression detection algorithms. Our …",ACM,,2023
24,"Mental Health and Behavior of College Students During the COVID-19 Pandemic: Longitudinal Mobile Smartphone and Ecological Momentary Assessment Study, Part II",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7OC4jEUAAAAJ&citation_for_view=7OC4jEUAAAAJ:WF5omc3nYNoC,"Background Since late 2019, the lives of people across the globe have been disrupted by COVID-19. Millions of people have become infected with the disease, while billions of people have been continually asked or required by local and national governments to change their behavioral patterns. Previous research on the COVID-19 pandemic suggests that it is associated with large-scale behavioral and mental health changes; however, few studies have been able to track these changes with frequent, near real-time sampling or compare these changes to previous years of data for the same individuals. Objective By combining mobile phone sensing and self-reported mental health data in a cohort of college-aged students enrolled in a longitudinal study, we seek to understand the behavioral and mental health impacts associated with the COVID-19 pandemic, measured by interest across the United States in the search terms coronavirus and COVID fatigue. Methods Behaviors such as the number of locations visited, distance traveled, duration of phone use, number of phone unlocks, sleep duration, and sedentary time were measured using the StudentLife mobile smartphone sensing app. Depression and anxiety were assessed using weekly self-reported ecological momentary assessments, including the Patient Health Questionnaire-4. The participants were 217 undergraduate students. Differences in behaviors and self-reported mental health collected during the Spring 2020 term, as compared to previous terms in the same cohort, were modeled using mixed linear models …","JMIR Publications Inc., Toronto, Canada",,2021
25,Social Sensing: Assessing Social Functioning of Patients Living with Schizophrenia using Mobile Phone Sensing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7OC4jEUAAAAJ&citation_for_view=7OC4jEUAAAAJ:qjMakFHDy7sC,"Impaired social functioning is a symptom of mental illness (e.g., depression, schizophrenia) and a wide range of other conditions (e.g., cognitive decline in the elderly, dementia). Today, assessing social functioning relies on subjective evaluations and self assessments. We propose a different approach and collect detailed social functioning measures and objective mobile sensing data from N=55 outpatients living with schizophrenia to study new methods of passively accessing social functioning. We identify a number of behavioral patterns from sensing data, and discuss important correlations between social function sub-scales and mobile sensing features. We show we can accurately predict the social functioning of outpatients in our study including the following sub-scales: prosocial activities (MAE = 7.79, r = 0.53), which indicates engagement in common social activities; interpersonal behavior (MAE = 3.39, r = 0 …",,,2020
26,From User Surveys to Telemetry-Driven AI Agents: Exploring the Potential of Personalized Productivity Solutions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7OC4jEUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7OC4jEUAAAAJ:NhqRSupF_l8C,"Information workers increasingly struggle with productivity challenges in modern workplaces, facing difficulties in managing time and effectively utilizing workplace analytics data for behavioral improvement. Despite the availability of productivity metrics through enterprise tools, workers often fail to translate this data into actionable insights. We present a comprehensive, user-centric approach to address these challenges through AI-based productivity agents tailored to users' needs. Utilizing a two-phase method, we first conducted a survey with 363 participants, exploring various aspects of productivity, communication style, agent approach, personality traits, personalization, and privacy. Drawing on the survey insights, we developed a GPT-4 powered personalized productivity agent that utilizes telemetry data gathered via Viva Insights from information workers to provide tailored assistance. We compared its …",ACM,,2025
27,Passive sensing of anhedonia and amotivation in a transdiagnostic sample.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7OC4jEUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7OC4jEUAAAAJ:EUQCXRtRnyEC,"Anhedonia and avolition are core clinical features of schizophrenia, bipolar disorder, and major depressive disorder, which have been traditionally assessed using clinical rating scales. However, recent developments in mobile technology allow for measurement of anhedonia and amotivation using passive sensors (eg, global positioning system and actigraphy) and surveys completed in daily life (ie, ecological momentary assessment [EMA]). The current study examined associations between clinical rating scales assessing anhedonia and amotivation and passive sensing measures. We aimed to determine the added value of passive sensing measures in explaining variability in clinical interviews, compared to models using EMA alone. We recruited a transdiagnostic sample (schizophrenia= 41, bipolar disorder= 47, and major depressive disorder= 48) to complete an in-person assessment session, as well as a 2 …",American Psychological Association,,2025
28,Acute suicidal ideation in context: highlighting sentiment-based markers through the diary entries of a clinically depressed sample,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7OC4jEUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7OC4jEUAAAAJ:vV6vV6tmYwMC,"Background Despite major strides in conceptualizing and modeling the multifaceted nature of suicidal thought and behavior (STB) over the past few decades, the overall predictability of STB has not improved. This may be partly due to the dynamic nature of suicidal ideation (SI), which often fluctuates over hours, yet is largely overlooked in studies. Bolstered by the application and promise of natural language processing (NLP) across the mental health field, efforts toward richer operationalization of acute SI may include analyses on written data that occur alongside changes in SI, thus offering a better understanding of STB as it unfolds. Methods Ecological momentary assessment (EMA) data from 268 participants with major depressive disorder (MDD) were utilized to investigate acute changes in SI. Data consisted of thrice-daily SI severity scores measured through self-report responses to item 9 of the Patient Health …",BioMed Central,,2025
29,Semantic signals in self-reference: The detection and prediction of depressive symptoms from the daily diary entries of a sample with major depressive disorder.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7OC4jEUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7OC4jEUAAAAJ:9ZlFYXVOiuMC,"Individuals with major depressive disorder (MDD) experience fewer positive and more negative emotions and use fewer positive words to describe themselves. Natural language processing techniques have been used to predict depression, with pronoun and emotion usage being identified as important features. However, it is unclear how depressed individuals use positive and negative words when writing about themselves. Individuals with MDD (N= 258) completed ecological momentary assessments three times a day (including the Patient Health Questionnaire-9 [PHQ-9] and a free-text diary entry) and weekly ecological momentary assessments (including a free-text response to a life events prompt) over a 90-day study period. Using natural language processing techniques, we generated 20 model features to detect and predict averages of and changes in weekly depression from diary entries. Four regression …",American Psychological Association,,2025
30,Anhedonia in flux: Understanding the associations of emotion regulation and anxiety with anhedonia dynamics in a sample with major depressive disorder,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7OC4jEUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7OC4jEUAAAAJ:ldfaerwXgEUC,"Negative rumination and emotion regulation difficulties have been consistently linked with depression. Despite anhedonia—the lack of interest in pleasurable experiences—being a cardinal symptom of depression, emotion regulation of positive emotions, including dampening, are considered far less in the literature. Given that anhedonia may manifest through blunted responses to previously positive or enjoyable experiences, it is vital to understand how different positive emotion regulation strategies impact anhedonia symptom severity and how it can vary or change over time. Moreover, understanding the detrimental or protective nature of positive emotion regulation on anhedonia can aid with future anhedonia-focused treatments. Therefore, the current study examined the temporal association between anhedonia dynamics and two different emotion rumination strategies in response to positive emotions …",Elsevier,,2025
31,Guide to intrusion detection and prevention systems (idps),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aiI32MEAAAAJ&citation_for_view=aiI32MEAAAAJ:RGFaLdJalmkC,"The National Institute of Standards and Technology (NIST) developed this document in furtherance of its statutory responsibilities under the Federal Information Security Management Act (FISMA) of 2002, Public Law 107-347. NIST is responsible for developing standards and guidelines, including minimum requirements, for providing adequate information security for all agency operations and assets; but such standards and guidelines shall not apply to national security systems. This guideline is consistent with the requirements of the Office of Management and Budget (OMB) Circular A-130, Section 8b (3),“Securing Agency Information Systems,” as analyzed in A-130, Appendix IV: Analysis of Key Sections. Supplemental information is provided in A-130, Appendix III.",,,2007
32,Wireshark & Ethereal network protocol analyzer toolkit,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aiI32MEAAAAJ&citation_for_view=aiI32MEAAAAJ:IWHjjKOFINEC,"Ethereal is the# 2 most popular open source security tool used by system administrators and security professionals. This all new book builds on the success of Syngress' best-selling book Ethereal Packet Sniffing. Wireshark & Ethereal Network Protocol Analyzer Toolkit provides complete information and step-by-step Instructions for analyzing protocols and network traffic on Windows, Unix or Mac OS X networks. First, readers will learn about the types of sniffers available today and see the benefits of using Ethereal. Readers will then learn to install Ethereal in multiple environments including Windows, Unix and Mac OS X as well as building Ethereal from source and will also be guided through Ethereal's graphical user interface. The following sections will teach readers to use command-line options of Ethereal as well as using Tethereal to capture live packets from the wire or to read saved capture files. This section also details how to import and export files between Ethereal and WinDump, Snort, Snoop, Microsoft Network Monitor, and EtherPeek. The book then teaches the reader to master advanced tasks such as creating sub-trees, displaying bitfields in a graphical view, tracking requests and reply packet pairs as well as exclusive coverage of MATE, Ethereal's brand new configurable upper level analysis engine. The final section to the book teaches readers to enable Ethereal to read new Data sources, program their own protocol dissectors, and to create and customize Ethereal reports.-Ethereal is the# 2 most popular open source security tool, according to a recent study conducted by insecure. org-Syngress' first Ethereal book has consistently …",Elsevier,,2006
33,Technical guide to information security testing and assessment,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aiI32MEAAAAJ&citation_for_view=aiI32MEAAAAJ:9ZlFYXVOiuMC,"The National Institute of Standards and Technology (NIST) developed this document in furtherance of its statutory responsibilities under the Federal Information Security Management Act (FISMA) of 2002, Public Law 107-347. NIST is responsible for developing standards and guidelines, including minimum requirements, for providing adequate information security for all agency operations and assets; but such standards and guidelines shall not apply to national security systems. This guideline is consistent with the requirements of the Office of Management and Budget (OMB) Circular A-130, Section 8b (3),“Securing Agency Information Systems,” as analyzed in A-130, Appendix IV: Analysis of Key Sections. Supplemental information is provided in A-130, Appendix III.",,,2008
34,Information security continuous monitoring (ISCM) for federal information systems and organizations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aiI32MEAAAAJ&citation_for_view=aiI32MEAAAAJ:iH-uZ7U-co4C,"The purpose of this guideline is to assist organizations in the development of a continuous monitoring strategy and the implementation of a continuous monitoring program providing visibility into organizational assets, awareness of threats and vulnerabilities, and visibility into the effectiveness of deployed security controls. It provides ongoing assurance that planned and implemented security controls are aligned with organizational risk tolerance as well as the information needed to respond to risk in a timely manner should observations indicate that the security controls are inadequate.","Kelley L. Dempsey, L A. Johnson, Matthew A. Scholl, Kevin M. Stine, Alicia Clay Jones, Angela Orebaugh, Nirali S. Chawla, Ronald Johnston",,2011
35,Guide to IPsec VPNs:.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aiI32MEAAAAJ&citation_for_view=aiI32MEAAAAJ:Tyk-4Ss8FVUC,"The National Institute of Standards and Technology (NIST) developed this document in furtherance of its statutory responsibilities under the Federal Information Security Management Act (FISMA) of 2002, Public Law 107-347. NIST is responsible for developing standards and guidelines, including minimum requirements, for providing adequate information security for all agency operations and assets, but such standards and guidelines shall not apply to national security systems. This guideline is consistent with the requirements of the Office of Management and Budget (OMB) Circular A-130, Section 8b (3),—Securing Agency Information Systems,“as analyzed in A-130, Appendix IV: Analysis of Key Sections. Supplemental information is provided in A-130, Appendix III.","US Department of Commerce, Technology Administration, National Institute of Standards and Technology",,2005
36,Virginia Cyber Navigator Internship Program (VA-CNIP): Service Learning in Local Election Security,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aiI32MEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=aiI32MEAAAAJ:70eg2SAEIzsC,"A coalition of Virginia universities, in partnership with the Virginia Department of Elections (ELECT), launched the Virginia Cyber Navigator Internship Program (VA-CNIP) – an innovative educational program to develop future cybersecurity professionals to protect the election infrastructure. The program addresses the need for more skilled cybersecurity professionals, and those who are supporting public services such as elections. This paper provides an overview of the key components of the program: a full semester gateway course covering sociotechnical election topics, a two-day kickoff bootcamp to prepare students for their internship, an internship with an election office, and a one-day debrief and assessment at the end of the internship.",,,2023
37,NIST SP 800-115,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aiI32MEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=aiI32MEAAAAJ:L8Ckcad2t8MC,,,,2020
38,A study of security and privacy issues associated with the Amazon Echo,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aiI32MEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=aiI32MEAAAAJ:ULOm3_A8WrAC,"More than 11 million US consumers have an Amazon Echo installed in their homes (Gonzales, 2017). While many consumers view the Amazon Echo as a useful helper in the home to provide information, play music, and order items online, consumers underestimate the device's security and privacy impacts. Additionally, law enforcement officials are beginning to see how consumer internet of things (IoT) devices can provide crucial evidence in cases. This paper presents security and privacy issues with the Amazon Echo and recent cases in which law enforcement officials have employed the Amazon Echo in an investigation. Due to the Amazon Echo's privacy issues and potential uses in court, this paper analyses the fourth amendment in regard to the Amazon Echo. This paper concludes with suggested recommendations that Amazon Echo owners should employ for greater security and privacy.",Inderscience Publishers (IEL),,2018
39,What do we need to make IoT security a reality,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aiI32MEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=aiI32MEAAAAJ:-f6ydRqryjwC,,,,2014
40,Ethical Challenges of the Internet of Things,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aiI32MEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=aiI32MEAAAAJ:7PzlFSSx8tAC,,,,2014
41,A stochastic dynamic pricing model for the multiclass problems in the airline industry,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oA2j_v4AAAAJ&citation_for_view=oA2j_v4AAAAJ:d1gkVwhDpl0C,"In the airline industry, deciding the ticket price for each flight directly affects the number of people that in the future will try to buy a ticket. Depending on the willingness-to-pay of the customers the flight might take off with empty seats or seats sold at a lower price. Therefore, based on the behavior of the customers, a price must be fixed for each type of product in each period. We propose a stochastic dynamic pricing model to solve this problem, applying phase type distributions and renewal processes to model the inter-arrival time between two customers that book a ticket and the probability that a customer buys a ticket. We test this model in a real-world case where as a result the revenue is increased on average by 31 percent.",North-Holland,,2015
42,Optimal timing of airline promotions under dilution,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oA2j_v4AAAAJ&citation_for_view=oA2j_v4AAAAJ:qjMakFHDy7sC,"Offering promotions has become common practice in the airline industry as a strategy to boost the total revenue. An effective promotion campaign should be adequately priced and timed to attract sufficient extra demand and compensate for the markdown price. Diversion of demand from the regular fare to the markdown price is also a side-effect of offering promotions, which needs to be considered in designing successful campaigns. Demand dilution occurs when customers are attracted to the promotional fare from higher fare families, or from future purchases to the promotional time window. We propose a stochastic dynamic model for the optimal timing of promotions, considering both types of dilution and given fixed prices for the regular and promotional fares. We prove the existence of an optimal policy, and derive structural properties to find the minimum number of unsold seats that justifies the promotion under …",North-Holland,,2019
43,Using longitudinal health records to simulate the impact of national treatment guidelines for cardiovascular disease,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oA2j_v4AAAAJ&citation_for_view=oA2j_v4AAAAJ:Y0pCki6q_DkC,"Continuous tracking of patient's health data through electronic health records (EHRs) has created an opportunity to predict healthcare policies' long-term impacts. Despite the advances in EHRs, data may be missing or sparsely collected. In this article, we use EHR data to develop a simulation model to test multiple treatment guidelines for cardiovascular disease (CVD) prevention. We use our model to estimate treatment benefits in terms of CVD risk reduction and treatment harms due to side effects, based on when and how much medication the patients are exposed to over time. Our methodology consists of using the EM algorithm to fit sparse health data and a discrete-time Monte-Carlo simulation model to test guidelines for different patient demographics. Our results suggest that, among published guidelines, those that focus on reducing CVD risk are able to reduce treatment without increasing the risk of severe …",IEEE,,2021
44,Monitoring policy in the context of preventive treatment of cardiovascular disease,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oA2j_v4AAAAJ&citation_for_view=oA2j_v4AAAAJ:WF5omc3nYNoC,"Preventing chronic diseases is an essential aspect of medical care. To prevent chronic diseases, physicians focus on monitoring their risk factors and prescribing the necessary medication. The optimal monitoring policy depends on the patient’s risk factors and demographics. Monitoring too frequently may be unnecessary and costly; on the other hand, monitoring the patient infrequently means the patient may forgo needed treatment and experience adverse events related to the disease. We propose a finite horizon and finite-state Markov decision process to define monitoring policies. To build our Markov decision process, we estimate stochastic models based on longitudinal observational data from electronic health records for a large cohort of patients seen in the national U.S. Veterans Affairs health system. We use our model to study policies for whether or when to assess the need for cholesterol-lowering …",Springer US,,2022
45,"Uncovering Patterns in Overdose Deaths: An Analysis of Spike Identification in Fatal Drug Overdose Data in Massachusetts, 2017-2023",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oA2j_v4AAAAJ&citation_for_view=oA2j_v4AAAAJ:LkGwnXOMwfcC,"Objectives Yearly rolling aggregate trends or rates are commonly used to analyze trends in overdose deaths, but focusing on long-term trends can obscure short-term fluctuations (eg, daily spikes). We analyzed data on spikes in daily fatal overdoses and how various spike detection thresholds influence the identification of spikes. Materials and Methods We used a spike detection algorithm to identify spikes among 16 660 drug-related overdose deaths (from any drug) reported in Massachusetts’ vital statistics from 2017 through 2023. We adjusted the parameters of the algorithm to define spikes in 3 distinct scenarios: deaths exceeding 2 adjusted moving SDs above the 7-, 30-, and 90-day adjusted moving average. Results Our results confirmed the on-the-ground observation that there are days when many more people die of overdoses than would be expected based on fluctuations due to differences among people …",SAGE Publications,,2024
46,Drug involvement variations in overdose death spikes: county-level analysis in Massachusetts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oA2j_v4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oA2j_v4AAAAJ:UebtZRa9Y70C,"Background Communities often experience relatively quiet periods disrupted by sudden surges of drug overdoses, suggesting that the risk of death can change substantially in a short period. Multiple substances are often involved in overdoses, and it is crucial to understand which are more frequently observed in spikes. This study aimed to investigate the involvement of specific substances in overdose spikes at the state and county levels in Massachusetts.Methods We applied a spike detection method to identify daily spikes among 9915 overdose fatalities in Massachusetts from 2020 to 2023. A day was identified as a spike if the number of overdose deaths was over two SDs of the adjusted moving average with a lag of 30 days. We used a general linear mixed model to compare the presence of cocaine, psychostimulants, fentanyl, heroin and prescription opioids in overdose deaths between spike and typical days …",BMJ Publishing Group Ltd,,2025
47,Family dynamics and environmental factors influencing progression from alcohol experimentation to initiation in youth: Evidence from the Adolescent Brain Cognitive Development …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oA2j_v4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oA2j_v4AAAAJ:Se3iqnhoufwC,"Background and Aims Early alcohol initiation is linked to the later development of problem drinking and other negative health outcomes. While a growing body of research categorizes early drinking behaviors into experimentation (onset of sipping) and initiation (first full drink), the factors associated with the transition between these stages remain underexplored. This study aimed to evaluate the influence of individual, interpersonal, and environmental factors on the time from alcohol experimentation to initiation among preadolescent youth. Design We used data from the Adolescent Brain Cognitive Development (ABCD) Study (2016-2021). Participants who reported no baseline alcohol use and sipped before consuming a full drink during the study were included to ensure a clear temporal sequence from experimentation to initiation. Setting The ABCD Study is conducted across 21 research sites in the United States. Participants We included 1,213 youths in the final sample, whose ages ranged from 8 to 11 at baseline and 12 to 14 at the end of the study period. Measurementsx Experimentation was defined as the first instance of alcohol sipping, while initiation was defined as consuming at least one full drink during the study period. An extended Cox model was used to examine the effects of sociodemographic characteristics, alcohol expectancies, family and peer dynamics, and neighborhood-level factors on the likelihood of alcohol initiation following experimentation. Findings Among 1,213 youths, 87 (7.2%) participants had their first sip and later first drink by the 45th month after baseline. Older age at onset of sipping was associated with the highest …",Cold Spring Harbor Laboratory Press,,2025
48,Early adolescent substance use patterns and associated factors: A longitudinal analysis of the Adolescent Brain Cognitive Development Study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oA2j_v4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oA2j_v4AAAAJ:roLk4NBRz8UC,"Background Early substance use is associated with long-term negative health and behavioral outcomes. While extensive research has examined predictors of substance use in adolescents and adults, relatively little is known about the risk factors that drive substance use in younger children. Furthermore, most studies focus on individual substances in isolation, rather than exploring the use of multiple substances. This study aims to identify demographic, family, and peer-related factors associated with alcohol, nicotine, cannabis, and multiple substance use in children aged from 9 to 13. Methods We analyzed longitudinal data from 11,868 children enrolled in the Adolescent Brain and Cognitive Development (ABCD) Study (version 5.1), incorporating observations collected from baseline, annual follow-ups, and mid-year phone interviews. Substance use outcomes were categorized into five mutually exclusive groups: no use, alcohol only, nicotine only, cannabis only, and use of two or more substances. We applied a generalized estimating equation model to assess the associations between substance use outcomes and demographic, family, and peer characteristics. Results Peer substance use was consistently associated with all categories of child substance use, particularly for the use of two or more substances. Parental drug use, permissiveness toward alcohol, and lower parental education were also linked to increased risk. Older age was associated with alcohol, nicotine, and multiple substance use. Conclusions Findings highlight the importance of peer and family environments in shaping early substance use behaviors. Early prevention efforts …",Cold Spring Harbor Laboratory Press,,2025
49,Who Goes Next? Optimizing the Allocation of Adherence-Improving Interventions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oA2j_v4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oA2j_v4AAAAJ:_FxGoFyzp5QC,"Long-term adherence to medication is a critical factor in preventing chronic diseases, such as cardiovascular disease. To address poor adherence, physicians may recommend adherence-improving interventions; however, such interventions are costly and limited in their availability. Knowing which patients will stop adhering helps distribute the available resources more effectively. We developed a binary integer program (BIP) model to select patients for adherence-improving intervention under budget constraints. We further studied a long-term adherence prediction model using dynamic logistic regression (DLR) model that uses patients' claim data, medical health factors, demographics, and monitoring frequencies to predict the risk of future non-adherence. We trained and tested our predictive model to longitudinal data for cardiovascular disease in a large cohort of patients taking medication for cholesterol control seen in the national Veterans Affairs health system. Our study shows the importance of including past adherence to increase prediction accuracy. Finally, we assess the potential benefits of using the prediction model by proposing an algorithm that combines the DLR and BIP models to decrease the number of CVD events in a population.",,,2024
50,The effect of chemical residues on the physical and electrical properties of chemical vapor deposited graphene transferred to SiO2,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9jntG6wAAAAJ&citation_for_view=9jntG6wAAAAJ:2osOgNQ5qMEC,"The effects of residues introduced during the transfer of chemical vapor deposited graphene from a Cu substrate to an insulating (SiO 2) substrate on the physical and electrical of the transferred graphene are studied. X-ray photoelectron spectroscopy and atomic force microscopy show that this residue can be substantially reduced by annealing in vacuum. The impact of the removal of poly (methyl methacrylate) residue on the electrical properties of graphene field effect devices is demonstrated, including a nearly 2× increase in average mobility from 1400 to 2700 cm 2/Vs. The electrical results are compared with graphene doping measurements by Raman spectroscopy.",AIP Publishing,,2011
51,Defect-Dominated Doping and Contact Resistance in MoS2,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9jntG6wAAAAJ&citation_for_view=9jntG6wAAAAJ:HDshCWvjkbEC,"Achieving low resistance contacts is vital for the realization of nanoelectronic devices based on transition metal dichalcogenides. We find that intrinsic defects in MoS2 dominate the metal/MoS2 contact resistance and provide a low Schottky barrier independent of metal contact work function. Furthermore, we show that MoS2 can exhibit both n-type and p-type conduction at different points on a same sample. We identify these regions independently by complementary characterization techniques and show how the Fermi level can shift by 1 eV over tens of nanometers in spatial resolution. We find that these variations in doping are defect-chemistry-related and are independent of contact metal. This raises questions on previous reports of metal-induced doping of MoS2 since the same metal in contact with MoS2 can exhibit both n- and p-type behavior. These results may provide a potential route for achieving low …",American Chemical Society,,2014
52,MoS2 P-type Transistors and Diodes Enabled by High Work Function MoOx Contacts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9jntG6wAAAAJ&citation_for_view=9jntG6wAAAAJ:e5wmG9Sq2KIC,"The development of low-resistance source/drain contacts to transition-metal dichalcogenides (TMDCs) is crucial for the realization of high-performance logic components. In particular, efficient hole contacts are required for the fabrication of p-type transistors with MoS2, a model TMDC. Previous studies have shown that the Fermi level of elemental metals is pinned close to the conduction band of MoS2, thus resulting in large Schottky barrier heights for holes with limited hole injection from the contacts. Here, we show that substoichiometric molybdenum trioxide (MoOx, x < 3), a high work function material, acts as an efficient hole injection layer to MoS2 and WSe2. In particular, we demonstrate MoS2 p-type field-effect transistors and diodes by using MoOx contacts. We also show drastic on-current improvement for p-type WSe2 FETs with MoOx contacts over devices made with Pd contacts, which is the prototypical …",American Chemical Society,,2014
53,Hole Selective MoOx Contact for Silicon Solar Cells,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9jntG6wAAAAJ&citation_for_view=9jntG6wAAAAJ:iH-uZ7U-co4C,"Using an ultrathin (∼15 nm in thickness) molybdenum oxide (MoOx, x < 3) layer as a transparent hole selective contact to n-type silicon, we demonstrate a room-temperature processed oxide/silicon solar cell with a power conversion efficiency of 14.3%. While MoOx is commonly considered to be a semiconductor with a band gap of 3.3 eV, from X-ray photoelectron spectroscopy we show that MoOx may be considered to behave as a high workfunction metal with a low density of states at the Fermi level originating from the tail of an oxygen vacancy derived defect band located inside the band gap. Specifically, in the absence of carbon contamination, we measure a work function potential of ∼6.6 eV, which is significantly higher than that of all elemental metals. Our results on the archetypical semiconductor silicon demonstrate the use of nm-thick transition metal oxides as a simple and versatile pathway for dopant-free …",American Chemical Society,,2014
54,"2D materials advances: from large scale synthesis and controlled heterostructures to improved characterization techniques, defects and applications",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9jntG6wAAAAJ&citation_for_view=9jntG6wAAAAJ:rO6llkc54NcC,"The rise of two-dimensional (2D) materials research took place following the isolation of graphene in 2004. These new 2D materials include transition metal dichalcogenides, mono-elemental 2D sheets, and several carbide-and nitride-based materials. The number of publications related to these emerging materials has been drastically increasing over the last five years. Thus, through this comprehensive review, we aim to discuss the most recent groundbreaking discoveries as well as emerging opportunities and remaining challenges. This review starts out by delving into the improved methods of producing these new 2D materials via controlled exfoliation, metal organic chemical vapor deposition, and wet chemical means. We look into recent studies of doping as well as the optical properties of 2D materials and their heterostructures. Recent advances towards applications of these materials in 2D electronics are …",IOP Publishing,2D Materials,2016
55,Environmental Control of Ferroelectricity in Hafnia Films,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9jntG6wAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9jntG6wAAAAJ:UHK10RUVsp4C,"Ferroelectricity in hafnia films has triggered significant research interest over the past decade due to its immense promise for next‐generation memory devices. However, the origin of ferroic behavior at the nanoscale and the means to control it remain an open question, with the consensus being that it deviates from conventional ferroelectrics. In this work, a novel approach is presented to tune ferroelectric properties of hafnia through environmental control using piezoresponse force microscopy (PFM). A reversible transition from non‐ferroelectric to ferroelectric behavior by modulating the surrounding atmosphere is demonstrated. Notably, the domain relaxation dynamics exhibit striking sensitivity to environmental factors, including ambient conditions, specific gas compositions (N2, CO2, O2), and humidity levels. The critical role of surface water removal, gas molecule adsorption, and their interactions with near …",,,2025
56,Process temperature dependence of sputtered MgO/n-type GaN metal–oxide–semiconductor capacitors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9jntG6wAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9jntG6wAAAAJ:dQ2og3OwTAUC,"The temperature dependence of epitaxial growth of MgO on n-type (0001)-oriented GaN by radio frequency magnetron sputtering is investigated. Epitaxial growth is obtained for growth temperatures of 550 C and above, but polycrystalline films are observed for 500 C and below. For all process temperatures, it is demonstrated that an interfacial phase is present that ranges from 2 to 3 nm in thickness and does not increase in thickness with temperature. The presence of the interfacial phase is shown to originate from ion bombardment during the initial growth. The electronic properties of metal–oxide–semiconductor capacitor devices are measured. Wider hysteresis is seen in capacitance–voltage measurements for devices fabricated at lower deposition temperatures. The less stable electrical performance of films grown at lower temperatures is shown to be related to both interface and bulk defects.",AIP Publishing,,2025
57,Effect of Precursor Purge Time on Plasma-Enhanced Atomic Layer Deposition-Prepared Ferroelectric Hf0.5Zr0.5O2 Phase and Performance,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9jntG6wAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9jntG6wAAAAJ:PR6Y55bgFSsC,"Hafnium oxide-based thin films, in particular hafnium zirconium oxide (HZO), have potential for applications in nonvolatile memory and energy harvesting. Atomic layer deposition (ALD) is the most widely used method for HZO deposition due to its precise thickness control and ability to provide conformal coverage. Previous studies have shown the effects of different metal precursors, oxidizer precursors, and process temperatures on the ferroelectric properties of HZO. However, no mechanism has been identified to describe the different phase stabilities as the metal precursor purge time varies. This study investigates how varying the metal precursor purge time during plasma-enhanced ALD (PE-ALD) influences the phases and properties of the HZO thin films. Grazing incidence X-ray diffraction, Fourier transform infrared spectroscopy, and scanning transmission electron microscopy are used to study the changes in …",American Chemical Society,,2025
58,Electrodeposition of amorphous molybdenum sulfo-selenide as a low-cost catalyst,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9jntG6wAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9jntG6wAAAAJ:N5tVd3kTz84C,"Overall, the MoSx system has shown greater catalytic activity over the traditional MoS2 based systems due to the absence of discrete basal plane, and differing structural arrangements. This increases the overall catalytic site density alongside adequate electronic conductivity from short-range atomic arrangements that allow for use in electrochemical processes. Here we translate prior efforts to improve electrocatalysis via Se incorporation within the crystalline system to the polymeric system, as several of the active sites in the a-MoSx have similar motifs and bonding environments as those found in MoS2. We use a single-electrolyte electrodeposition synthesis technique in order to provide a scalable, low-cost material. We demonstrate the influence of the electrolyte conditions on the films physical, chemical, electronic, and catalytic properties as a function of selenium content through a comprehensive study via …",Pergamon,,2025
59,Properties of Electrodeposited Molybdenum Disulfide on Zinc Oxide and Zinc Oxide/Zinc Sulfide Nanowires,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9jntG6wAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9jntG6wAAAAJ:1yQoGdGgb4wC,"We developed a facile and scalable 3-step hydrothermal, electrodeposition, and annealing technique to synthesize a variety of nanowire heterostructures. The heterojunction catalysts of CP-ZnO-MoS2 and CP-ZnO-ZnS-MoS2 both saw an increase in catalytic activity in the acidic regime, with overpotentials to reach 10 mA/cm2 of 181 mV and 154 mV respectively, over their constituent materials. The CP-ZnO-ZnS-MoS2 catalysts also saw an increase in catalytic activity in the alkaline conditions, requiring only 209 mV to reach 10 mA/cm2. This has been attributed primarily to the synergistic properties of the band alignment structure and the increased surface area afforded by the nanowire structure. The 1T phase was also noted in the CP-ZnO-MoS2 sample, suggesting that this also played a role in increasing the catalytic activity of the sample. Overall, the synthesized nanowire heterostructures were found to be high-performing and gives insight into how the changing band alignment and morphology can play a significant role in increasing the catalytic performance towards HER.",,,2025
60,Design of low-emission and energy-efficient residential buildings using a multi-objective optimization algorithm,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oz5HKqgAAAAJ&citation_for_view=oz5HKqgAAAAJ:2osOgNQ5qMEC,"The improvement of energy efficiency and environmental performance of buildings is considered a major priority worldwide. New building regulations have an explicit orientation toward low-emission and energy-efficient designs. However, the optimal design of residential buildings should consider multiple, and usually competitive, objectives such as energy consumption optimization, financial costs reduction and decrease of environmental impacts. This makes it a challenging multi-objective optimization problem. The aim of this work is to develop a novel method to tackle the problem. A multi-objective optimization model based on harmony search algorithm (HS) is presented. This model is developed to minimize the life cycle cost (LCC) and carbon dioxide equivalent (CO2-eq) emissions of the buildings. Several building envelope parameters are taken as the design variables. To demonstrate the efficiency of the …",Pergamon,,2012
61,On the development of multi-linear regression analysis to assess energy consumption in the early stages of building design,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oz5HKqgAAAAJ&citation_for_view=oz5HKqgAAAAJ:3fE2CSJIrl8C,"Modeling of energy consumption in buildings is essential for different applications such as building energy management and establishing baselines. This makes building energy consumption estimation as a key tool to reduce energy consumption and emissions. Energy performance of building is complex, since it depends on several parameters related to the building characteristics, equipment and systems, weather, occupants, and sociological influences. This paper presents a new model to predict and quantify energy consumption in commercial buildings in the early stages of building design. Building simulation software including eQUEST and DOE-2 was used to build and simulate individual building configuration that were generated using Monte Carlo simulation techniques. Ten thousands simulations for seven building shapes were performed to create a comprehensive dataset covering the full ranges of …",Elsevier,,2014
62,A novel fusion-based deep learning model for sentiment analysis of COVID-19 tweets,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oz5HKqgAAAAJ&citation_for_view=oz5HKqgAAAAJ:oursBaop5wYC,"Undoubtedly, coronavirus (COVID-19) has caused one of the biggest challenges of all times. The ongoing COVID-19 pandemic has caused more than 150 million infected cases and one million deaths globally as of May 5, 2021. Understanding the sentiment of people expressed in their social media comments can help in monitoring, controlling, and ultimately eradicating the disease. This is a sensitive matter as the threat of infectious disease significantly affects the way people think and behave in various ways. In this study, we proposed a novel method based on the fusion of four deep learning and one classical supervised machine learning model for sentiment analysis of coronavirus-related tweets from eight countries. Also, we analyzed coronavirus-related searches using Google Trends to better understand the change in the sentiment pattern at different times and places. Our findings reveal that the coronavirus …",Elsevier,,2021
63,Evaluation of self-healing mechanisms in concrete with double-walled sodium silicate microcapsules,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oz5HKqgAAAAJ&citation_for_view=oz5HKqgAAAAJ:g5Ck-dwhA_QC,"The objective of this study is to evaluate a new generation of self-healing materials that hold promise for better durability and performance. The in situ polymerization method was used to develop double-walled microcapsules. The microcapsules were prepared in a single batch process containing sodium silicate as the healing agent encapsulated in double-walled polyurethane/urea-formaldehyde (PU/UF) microcapsules. Double-walled microcapsules provide enhanced durability at high temperatures compared with single-walled microcapsules while preserving adequate interfacial bonding of microcapsules. A parametric study was carried out to investigate the effect of different parameters such as agitation rate, pH, and temperature on the performance of the microcapsules and to determine the optimum microencapsulation procedure. The prepared microcapsules were then incorporated into self-healing concrete …",American Society of Civil Engineers,,2015
64,Dicyclopentadiene and sodium silicate microencapsulation for self-healing of concrete,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oz5HKqgAAAAJ&citation_for_view=oz5HKqgAAAAJ:_FxGoFyzp5QC,"Considerable interest has been directed in recent years toward the use of self-healing materials in concrete. The concept of microcapsule healing is based on a healing agent being encapsulated and embedded in the concrete. The objective of this study was to evaluate the effects of preparation parameters, namely, temperature, agitation rate, and pH on the shell thickness and size (diameter) of the microcapsules as well as to evaluate the self-healing mechanism in concrete through experimental testing performed in laboratory. Two healing agents were evaluated in this study, i.e., dicyclopentadiene (DCPD) and sodium silicate. Based on the results of the experimental program, it was determined that, as the pH was increased from 3.0 to 3.7, the shell thickness increased for sodium silicate, while the shell thickness reached a minimum at a pH value of 3.4 for DCPD. Sodium silicate shell thickness was almost twice …",American Society of Civil Engineers,,2014
65,A graph attention network framework for generalized-horizon multi-plant solar power generation forecasting using heterogeneous data,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oz5HKqgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oz5HKqgAAAAJ:htyGaKyDgHMC,"Accurate forecasting of solar power output from multiple photovoltaic plants simultaneously for different time horizons is crucial for their large-scale integration into the electric grid. Forecasting strategies for PV output power significantly vary depending on the forecasting horizons, quality, variety, resolution of data, and fields of application. While the researchers addressed many of these particular cases to achieve high forecasting accuracy, the literature lacks sufficient discussion on integrating strategies for various forecasting scenarios into a general framework. This article proposes such a framework facilitating PV power forecasting with variable time horizons and imparting data of various types and granularity by introducing a single adjustable module into the framework. Moreover, by proposing a geographic distance-based graph construction, ensuring minimal vertex connectivity and adjustable sparsity, the …",Pergamon,,2025
66,Investigating Instructors’ Experiences in a Neurodiversity-Focused AI Training Program,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oz5HKqgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oz5HKqgAAAAJ:IHkkN1K1AlAC,"In this paper, we examine the multifaceted challenges instructors encounter in a neurodiversity-focused AI summer training program for community college students. Our research draws on interview data from multiple instructors involved in the program's implementation to illuminate the complexities of teaching AI concepts to a diverse group of neurodivergent learners. Instructors faced timely challenges adapting to students' varied learning styles and preferences, particularly in balancing conceptual and technical instruction. For instance, some instructors adopted a code-focused approach, while others prioritized high-level understanding. This difference led to confusion among certain students who struggled to reconcile the varying levels of abstraction. Instructors grappled with managing the social and emotional dynamics of the classroom, including addressing students' social anxiety, facilitating effective communication, and navigating instances of interpersonal conflict. The compressed timeframe of the program, coupled with the demanding nature of the material, compounded these difficulties. The lack of robust assessment strategies for gauging student’s technical and social learning made it difficult for instructors to effectively tailor instruction to individual needs. In this paper, we highlight the evidence-based need for more comprehensive training programs and support systems for instructors tasked with teaching AI to neurodivergent learners. These programs should address pedagogical approaches for accommodating diverse learning, cognitive, and communication styles, strategies for managing the social-emotional complexities of inclusive …",,,2025
67,Navigating the Social-Emotional Landscape of Neurodiversity in AI Education,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oz5HKqgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oz5HKqgAAAAJ:j8pvxH-kN2QC,"In this paper, we address the critical need to explore the social and emotional dimensions of learning in Artificial Intelligence (AI) Education, ie, Computer Science Education with and about AI, for neurodivergent students. While AI holds immense potential to create inclusive learning environments, current pedagogical practices often fall short in addressing the unique social and emotional needs of neurodivergent learners. The research we present in this paper examines the experiences of project instructors and neurodivergent students enrolled in or graduated from two-year institutions in a neurodiversity-focused AI summer training program. In this work, we draw on interview data from multiple stakeholders on the project team. Our findings highlight challenges the instructors faced in navigating the social-emotional landscape of neurodiversity, including supporting students with social anxiety and facilitating effective communication among individuals with diverse communication styles. In this paper, we will examine the emotional work required of instructors to foster inclusive learning environments. We will emphasize the need for professional development opportunities that equip educators with the knowledge and skills to support the holistic needs of neurodivergent students in AI Education.",,,2025
68,Optimizing thermal insulation of waterborne acrylic coatings through controlled integration of hydrophobic silica aerogel: Experimental insights and advanced modeling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oz5HKqgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oz5HKqgAAAAJ:HqhvjgTjE9cC,,,,2025
69,Preparing Autistic Students for the AI Workforce,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oz5HKqgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oz5HKqgAAAAJ:ujxm2eEBZHIC,,https://doi.org/10.1145/3696630.372723,,2025
70,The robots are here: Navigating the generative ai revolution in computing education,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v9O0mDoAAAAJ&citation_for_view=v9O0mDoAAAAJ:5nxA0vEk-isC,"Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second …",,,2023
71,Compiler error messages considered unhelpful: The landscape of text-based programming error message research,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v9O0mDoAAAAJ&citation_for_view=v9O0mDoAAAAJ:LkGwnXOMwfcC,"Diagnostic messages generated by compilers and interpreters such as syntax error messages have been researched for over half of a century. Unfortunately, these messages which include error, warning, and run-time messages, present substantial difficulty and could be more effective, particularly for novices. Recent years have seen an increased number of papers in the area including studies on the effectiveness of these messages, improving or enhancing them, and their usefulness as a part of programming process data that can be used to predict student performance, track student progress, and tailor learning plans. Despite this increased interest, the long history of literature is quite scattered and has not been brought together in any digestible form. In order to help the computing education community (and related communities) to further advance work on programming error messages, we present a …",,,2019
72,Metacognitive difficulties faced by novice programmers in automated assessment tools,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v9O0mDoAAAAJ&citation_for_view=v9O0mDoAAAAJ:IjCSPb-OGe4C,"Most novice programmers are not explicitly aware of the problem-solving process used to approach programming problems and cannot articulate to an instructor where they are in that process. Many are now arguing that this skill, called metacognitive awareness, is crucial for novice learning. However, novices frequently learn in university CS1 courses that employ automated assessment tools (AATs), which are not typically designed to provide the cognitive scaffolding necessary for novices to develop metacognitive awareness. This paper reports on an experiment designed to understand what difficulties novice programmers currently face when learning to code with an AAT. We describe the experiences of CS1 students who participated in a think-aloud study where they were observed solving a programming problem with an AAT. Our observations show that some students mentally augmented the tool when it did …",,,2018
73,Metacognition and self-regulation in programming education: Theories and exemplars of use,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v9O0mDoAAAAJ&citation_for_view=v9O0mDoAAAAJ:roLk4NBRz8UC,"Metacognition and self-regulation are important skills for successful learning and have been discussed and researched extensively in the general education literature for several decades. More recently, there has been growing interest in understanding how metacognitive and self-regulatory skills contribute to student success in the context of computing education. This article presents a thorough systematic review of metacognition and self-regulation work in the context of computer programming and an in-depth discussion of the theories that have been leveraged in some way. We also discuss several prominent metacognitive and self-regulation theories from the literature outside of computing education—for example, from psychology and education—that have yet to be applied in the context of programming education. In our investigation, we built a comprehensive corpus of papers on metacognition and self …",ACM,,2022
74,First things first: Providing metacognitive scaffolding for interpreting problem prompts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v9O0mDoAAAAJ&citation_for_view=v9O0mDoAAAAJ:zYLM7Y9cAGgC,"When solving programming problems, novices are often not aware of where they are in the problem-solving process. For instance, students who misinterpret the problem prompt will most likely not form a valid conceptual model of the task and fail to make progress towards a working solution. Avoiding such errors, and recovering from them once they occur, requires metacognitive skills that enable students to reflect on their problem-solving processes. For these reasons, developing metacognitive awareness is crucially important for novice students. Previous research has shown that explicitly teaching key steps of programming problem-solving, and having students reflect on where they are in the problem-solving process, can help students complete future programming assignments. Such metacognitive awareness training can be done through personal tutoring, but can be difficult to implement without a high ratio of …",,,2019
75,GenAI Integration in Upper-Level Computing Courses,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v9O0mDoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=v9O0mDoAAAAJ:KlAtU1dfN6UC,"GenAI is playing an increasingly important role in computing courses at all levels, offering new opportunities to support teaching and learning. However, using GenAI effectively raises important concerns regarding trust, academic integrity, and broader social and ethical dimensions. This Working Group was formed to report on the current state of the art in using GenAI in upper-level computing courses to aid educators. The working group will undertake a methodological review of published work and solicit input from the computing educational community as part of the report.",,,2025
76,An International Examination of Non-Technical Skills and Professional Dispositions in Computing--Identifying the Present Day Academia-Industry Gap,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v9O0mDoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=v9O0mDoAAAAJ:3fE2CSJIrl8C,"Computing graduates are frequently reported by members of industry to lack in professional dispositions and/or non-technical skills (often referred to as ""soft skills""). In this work, we conduct a gap analysis of the alignment between academic preparation and industry expectations through a three-pronged study. First, a literature review explored the academic perspective of how fostering professional dispositions and non-technical skills occurs in tertiary computing education. Second, a literature review identifying industry's expectations of those dispositions and skills for entry-level computing professionals. Finally, a mixed-methods approach, combining a survey and structured interviews of computing industry professionals to identify their opinions on the relative importance of those skills and dispositions. In each of these prongs, we additionally consider whether and how Diversity, Equity, Inclusion, and Accessibility …",,,2025
77,Office Hours and Online Forum Engagement in Introductory CS Courses,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v9O0mDoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=v9O0mDoAAAAJ:kNdYIx-mwKoC,"This research full paper explores the connection between office hours use and online forum engagement in introductory computer science courses. Office hours (OH) and online question-and-answer (Q&A) forums provide a platform for students to interact with their classmates and instructors. We investigate the relationship between student engagement in an online discussion forum (Piazza) and utilization of office hours across 5 semesters of an introductory CS course. We explored the correlation between Piazza utilization and OH attendance, discerned disparities between in-person and online OH involvement, and analyzed the distinct approaches of men and women in engaging with course resources. We found that active Piazza users visit OH more than inactive Piazza users. More specifically, students who interact above average on Piazza in each metric observed - asks, answers, posts, and views - attend OH …",IEEE,,2024
78,"All for One and One for All-Collaboration in Computing Education: Policy, Practice, and Professional Dispositions",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v9O0mDoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=v9O0mDoAAAAJ:8k81kl-MbHgC,"The ITiCSE '23 final keynote raised teaching soft skills, or professional dispositions, to help students face challenges in modern programming. This project addresses helping computing students develop professional dispositions through collaborative learning (CL) since some in the industry observe entry-level engineers struggling due to their fragile professional dispositions. We are motivated to understand professional expectations from entry-level engineers and present the academia-industry gap to support practitioners and researchers in advancing CL in Computing Education, encouraging positive curricula and policy changes that promote DEIA. We will present CL practices alongside their supported professional dispositions to assist practitioners in adoption. We will present the academia-industry gap in CL for future research opportunities, helping researchers advance CL practices to integrate professional …",,,2024
79,"Performance, Workload, Emotion, and Self-Efficacy of Novice Programmers Using AI Code Generation",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v9O0mDoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=v9O0mDoAAAAJ:MXK_kJrjxJIC,"Artificial Intelligence-driven Development Environments (AIDEs) offer developers revolutionary computer programming assistance. There is great potential in incorporating AIDEs into Computer Science education; however, the effects of these tools should be fully examined before doing so. Here, a within-subjects study was conducted to compare the programming performance, workload, emotion, and self-efficacy of seventeen novices coding with and without use of the GitHub Copilot AIDE under time pressure. Results showed that using the AIDE significantly increased programming efficiency and reduced effort and mental workload but did not significantly impact emotion or self-efficacy. However, participants' performance improved with more experience using the AI, and their self-efficacy followed. The results suggest that students who try AIDEs will likely be tempted to use them for time-sensitive work. There is no …",,,2024
80,"Size, volume fraction, and nucleation of Stober silica nanoparticles",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gHrrwKwAAAAJ&citation_for_view=gHrrwKwAAAAJ:0EnyYjriUFMC,"29Si NMR, small-angle X-ray scattering (SAXS), and dynamic light scattering (DLS) are used to monitor the synthesis of silica nanoparticles from the base-catalyzed hydrolysis of TEOS in methanol and ethanol. The reactions are conducted at a [TEOS] =0.5 M, low concentrations of ammonia ([NH3] =0.01–0.1 M), and [H2O] =1.1–4.4 M to resolve the initial size of the first nuclei and to follow their structural evolution. It is found that after an induction period where there is a buildup of singly hydrolyzed monomer, the first nuclei are fractal and open in structure. Interestingly, the nuclei are twice as large in ethanol (Rg≈8 nm) as those in methanol (Rg≈4 nm). The data suggest that the difference in primary particle size is possibly caused by a higher supersaturation ratio of the singly hydrolyzed monomer in methanol than in ethanol if it is assumed that the surface energy of the first nuclei is the same in methanol and …",Academic Press,,2003
81,A phase diagram for polymer-grafted nanoparticles in homopolymer matrices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gHrrwKwAAAAJ&citation_for_view=gHrrwKwAAAAJ:LkGwnXOMwfcC,"We quantified the stability of polystyrene- (PS-) grafted silica nanoparticles (NPs) in PS matrices with ultrasmall angle X-ray scattering (USAXS) and transmission electron microscopy (TEM) and developed a phase diagram to predict NP dispersion based on the graft polymer density, σ, and the graft and free polymer molecular weights, or N and P, respectively. Using controlled/living polymerizations, polymer nanocomposites were formulated with silica NPs of radius, R = 9 nm where σ = 0.10–0.70 chains/nm2 at an essentially constant N = 61–68 kg/mol. The matrix molecular weight was varied from P = 37–465 kg/mol permitting us to vary the swelling ratio, P/N = 0.6–7.7. Using USAXS and TEM, we determined whether the PS-grafted NPs were stable and dispersed uniformly, or were unstable and aggregated within the matrix. From these measurements we developed a phase diagram for NP miscibility with respect …",American Chemical Society,,2012
82,Chemical reaction kinetics leading to the first Stober silica nanoparticles–NMR and SAXS investigation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gHrrwKwAAAAJ&citation_for_view=gHrrwKwAAAAJ:KlAtU1dfN6UC,"29Si-NMR and 13C-NMR were used in methanol and ethanol to monitor the intermediates or hydrolyzed monomers that lead to the formation of the first primary particles as detected by small angle X-ray scattering. This identification was facilitated by using initial NH3 and H2O levels at the lower end of those experienced in Stober synthesis to slow the reaction kinetics. We found that [NH3] and [H2O] control the balance between hydrolysis of tetraethylorthosilicate (TEOS) and the condensation of its hydrolyzed monomers. Transesterification between methanol and TEOS did occur; however, it was negligible compared to the production of hydrolyzed intermediates. The first nanostructures appear at a hydrolyzed monomer concentration around 0.1 M, indicating that formation of the primary structures is thermodynamically controlled by a supersaturation of the intermediate species. Differences in particle size between …",North-Holland,,2003
83,Photocatalytic oxidation of cadmium-EDTA with titanium dioxide,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gHrrwKwAAAAJ&citation_for_view=gHrrwKwAAAAJ:4DMP91E08xMC,"Ethylenediaminetetraacetic acid (EDTA) forms stable complexes with toxic metals such as cadmium. Metal-EDTA chelates are chemically stable and occur in a number of waste situations. The viability of using photocatalytic oxidation with titanium dioxide to degrade Cd-EDTA was examined at concentrations from 2 × 10-5 to 10-3 M at pH from 3 to 8. Initially a portion of the complex was adsorbed onto the TiO2 photocatalyst at low pH. However, independent of the degree of initial adsorption, Cd-EDTA was rapidly destroyed with little dependence on pH. Concurrently, in most cases cadmium was liberated as Cd2+ with no affiliation with organic reaction products; its fate depended on suspension pH. At low pH, Cdaq2+ was released into solution. Also, organic carbon was released into solution as oxidation of adsorbed EDTA occurred. At higher pH the Cd was adsorbed onto the TiO2 at adsorption equilibrium levels …",American Chemical Society,,1999
84,Connecting the wetting and rheological behaviors of poly (dimethylsiloxane)-grafted silica spheres in poly (dimethylsiloxane) melts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gHrrwKwAAAAJ&citation_for_view=gHrrwKwAAAAJ:IjCSPb-OGe4C,"Using dynamic light scattering, mechanical rheometry, and visual observation, the static wetting behavior of PDMS-grafted silica spheres (PDMS-g-silica) in PDMS melts is related to their rheology. A phase diagram is mapped out for a constant grafted chain length as a function of grafting density and free polymer chain length. The transition between stable and aggregated regions is determined optically and with dynamic light scattering. It is associated with a first-order wetting transition. In the stable region Newtonian behavior is observed for semidilute suspensions. The hydrodynamic brush thicknesses, deduced from viscosity measurements, correspond closely to values obtained from self-consistent field calculations for the various parameter values. At the transition, the brush collapses suddenly and shear-thinning and thixotropy appear. The rheology indicates a degree of aggregation that increases with …",American Chemical Society,,2006
85,Engineering Nanoparticle Surface Amphiphilicity: An Integrated Computational and Laser Desorption Ionization Study of Controlled Ligand Self-Assembly,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gHrrwKwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=gHrrwKwAAAAJ:QIV2ME_5wuYC,"Multiligand monolayers can self-organize into advantageous interfacial patterns that govern nanoparticle (NP) properties. Polyethylene glycol (PEG) is widely incorporated into self-assembled monolayers to enhance biocompatibility, particularly in drug delivery applications. Previous studies demonstrate that monolayer phase separation can be controlled by leveraging the energetic and entropic driving forces acting on ligands in the design of amphiphilic surfaces. In this work, we extend an integrated experimental and simulation framework to investigate the self-assembly of dodecanethiol (DDT), a long hydrophobic alkanethiol, with 2-ethoxyethane-1-thiol, a short hydrophilic PEG-thiol, as a function of their surface composition on ultrasmall gold NPs. The PEG-DDT Au NPs were synthesized via ligand exchange. Integrated MALDI-MS experiments and configurationally biased Monte Carlo simulations were used to …",American Chemical Society,,2025
86,REU Site: Advanced Materials Synthesis at the University of Virginia,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gHrrwKwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=gHrrwKwAAAAJ:qUcmZB5y_30C,"NON-TECHNICAL DESCRIPTION: This REU site offers unique opportunities for undergraduate students in the mid-Atlantic region to engage in research in advanced materials synthesis. The REU students, recruited heavily from historically black colleges and universities and two-year community colleges, include all populations that are underrepresented in science and engineering fields; thus, the students are diverse in gender, race, ethnicity, first-generation, socioeconomic status, disability, age, and sexual orientation. They work in interdisciplinary research teams and receive training in materials science and engineering, state-of-the-art research methods, science communication, responsible conduct, and career development during the ten-week summer program. Integrated throughout the REU are mentorship activities, workshops, and seminars that prepare students for successful careers in industry, national …",,,2021
87,Computational and Experimental Investigations of Phase-Separated Monolayers on Ultrasmall Noble Metal Nanoparticles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gHrrwKwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=gHrrwKwAAAAJ:ZeXyd9-uunAC,"Metal nanoparticles contain a small metallic core that might consist of just a few thousand atoms, surrounded by a layer of organic molecules, which determines its interaction with the environment. Layers made from two different types of molecules can form complex patterns such as strips or spots as they separate on the surface, like oil and water. The ability to manipulate these patterns could lead to new technologies that require precise control of the nanoparticle interaction with its surroundings. However, characterizing existing patterns is difficult due to the small size and curved shape of the metallic core. With support from the Macromolecular, Supramolecular and Nanochemistry Program in the Division of Chemistry, Professors David Green and Kateri DuBay at the University of Virginia are using a combination of experimental and computational techniques to study pattern formation on the nanoparticle surface …",,,2019
88,Straightforward one-pot syntheses of silylamides of magnesium and calcium via an in situ Grignard metalation method,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gHrrwKwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=gHrrwKwAAAAJ:mVmsd5A6BfQC,"Calcium bis[bis(trimethylsilyl)amide] (Ca(HMDS)2) is a widely used reagent in diverse stoichiometric and catalytic applications. These processes necessitate a straightforward and large-scale access of this complex. Calcium does not react with primary and secondary amines, but the addition of excess bromoethane to a mixture of calcium turnings and amines in THF at room temperature yields the corresponding calcium bis(amides), calcium bromide and ethane. This in situ Grignard metalation method (iGMM) allows the preparation of calcium bis(amides) from secondary and primary trialkylsilyl-substituted amines and anilines on a multigram scale. 1 Background 2 The In Situ Grignard Metalation Method (iGMM) 3 Properties of [(thf)2M(HMDS)2] 4 Applications and Perspective",Georg Thieme Verlag,,2019
89,The Effect of Solvent Viscosity on Production of Few-layer Graphene from Liquid-Phase Exfoliation of Graphite,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=gHrrwKwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=gHrrwKwAAAAJ:M3ejUd6NZC8C,"Prior research into the liquid-phase exfoliation of graphite to produce few-layer graphene has focused primarily on the surface energy matching between graphite and solvent; however, the effect of other solvent properties, such as liquid viscosity, have not been systematically explored. In principle, a higher viscosity solvent should enable the production of graphene and other graphitic nanomaterials by liquid-phase exfoliation at lower shear rates than traditionally used organic solvents of low viscosity, such as N-methyl-2-pyrrolidone (NMP). Thus, at a given shear rate, more material should be exfoliated in the higher viscosity solvent. Hence, graphite suspensions in NMP, benzyl benzoate, and propylene glycol were exfoliated at various shear rates in a rheometer. Exfoliant concentrations were measured by ultraviolet- visual (UV-vis) spectroscopy and quality characterization was performed by Raman spectroscopy …",,,2019
90,Adaptive control design and analysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YOZbkCEAAAAJ&citation_for_view=YOZbkCEAAAAJ:d1gkVwhDpl0C,"A systematic and unified presentation of the fundamentals of adaptive control theory in both continuous time and discrete time Today, adaptive control theory has grown to be a rigorous and mature discipline. As the advantages of adaptive systems for developing advanced applications grow apparent, adaptive control is becoming more popular in many fields of engineering and science. Using a simple, balanced, and harmonious style, this book provides a convenient introduction to the subject and improves one's understanding of adaptive control theory. Adaptive Control Design and Analysis features: Introduction to systems and control Stability, operator norms, and signal convergence Adaptive parameter estimation State feedback adaptive control designs Parametrization of state observers for adaptive control Unified continuous and discrete-time adaptive control L1+ a robustness theory for adaptive systems Direct and indirect adaptive control designs Benchmark comparison study of adaptive control designs Multivariate adaptive control Nonlinear adaptive control Adaptive compensation of actuator nonlinearities End-of-chapter discussion, problems, and advanced topics As either a textbook or reference, this self-contained tutorial of adaptive control design and analysis is ideal for practicing engineers, researchers, and graduate students alike.",John Wiley & Sons,,2003
91,Adaptive Control of Systems with Actuator and Sensor Nonlinearities,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YOZbkCEAAAAJ&citation_for_view=YOZbkCEAAAAJ:u-x6o8ySG0sC,"From the Publisher: An in-depth examination of intelligent approaches to increasing the accuracy of a variety of system components. Utilizing a unified, adaptive, inverse approach, the book offers electrical, mechanical, chemical, aeronautical and computer engineers methods for controlling many of the ""hard"" nonlinearities of frequently-employed control systems such as dead-zone, backlash and hysteresis. Discusses such nonlinearities at both the input and output points of a linear part and within both continuous time designs and discrete time designs.",John Wiley & Sons,,1996
92,"Feedback control real-time scheduling: Framework, modeling, and algorithms",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YOZbkCEAAAAJ&citation_for_view=YOZbkCEAAAAJ:u5HHmVD_uO8C,"This paper presents a feedback control real-time scheduling (FCS) framework for adaptive real-time systems. An advantage of the FCS framework is its use of feedback control theory (rather than ad hoc solutions) as a scientific underpinning. We apply a control theory based methodology to systematically design FCS algorithms to satisfy the transient and steady state performance specifications of real-time systems. In particular, we establish dynamic models of real-time systems and develop performance analyses of FCS algorithms, which are major challenges and key steps for the design of control theory based adaptive real-time systems. We also present a FCS architecture that allows plug-ins of different real-time scheduling policies and QoS optimization algorithms. Based on our framework, we identify different categories of real-time applications where different FCS algorithms should be applied. Performance …",Kluwer Academic Publishers,,2002
93,Adaptive control of plants with unknown hystereses,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YOZbkCEAAAAJ&citation_for_view=YOZbkCEAAAAJ:9yKSN-GCB0IC,"For a system with hysteresis, the authors present a parameterized hysteresis model and develop a hysteresis inverse. The authors then design adaptive controllers with an adaptive hysteresis inverse for plants with unknown hysteresis. A new adaptive controller structure is introduced which is capable of achieving a linear parameterization and a linear error model in the presence of a hysteresis nonlinearity. A robust adaptive law is used to update the controller parameters and hysteresis inverse parameters, which ensures the global boundedness of the closed-loop signals for a wide class of of hysteresis models. Simulations show that the use of the adaptive hysteresis inverse leads to major improvements of system performance.<>",IEEE,,2002
94,Robust backstepping sliding-mode control and observer-based fault estimation for a quadrotor UAV,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YOZbkCEAAAAJ&citation_for_view=YOZbkCEAAAAJ:BOlwja0KXvYC,"This study gives the mathematic model of a quadrotor unmanned aerial vehicle (UAV) and then proposes a robust nonlinear controller which combines the sliding-mode control technique and the backstepping control technique. To achieve Cartesian position trajectory tracking capability, the construction of the controller can be divided into two stages: a regular SMC controller for attitude subsystem (inner loop) is first developed to guarantee fast convergence rapidity of Euler angles and the backstepping technique is applied to the position loop until desired attitudes are obtained and then the ultimate control laws. The stability of the closed-loop system is guaranteed by stabilizing each of the subsystems step by step and the robustness of the controller against model uncertainty and external disturbances is investigated. In addition, an adaptive observer-based fault estimation scheme is also considered for taking off …",IEEE,,2016
95,A discrete-time least-squares adaptive state tracking control scheme with a mobile-robot system study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YOZbkCEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=YOZbkCEAAAAJ:a2necdfpwlEC,"This paper develops an adaptive state tracking control scheme for discrete-time systems, using least-squares algorithms, as the new solution to the long-standing discrete-time adaptive state tracking control problem. The system stability and state tracking properties are proved mathematically. The developed adaptive state tracking control scheme, combined with a newly proposed collision avoidance mechanism, is applied to a multi-robot system to achieve tracking objectives. Simulation results demonstrate its effectiveness in achieving state tracking and collision avoidance.",IEEE,,2025
96,Adaptive output tracking control with reference model system uncertainties,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YOZbkCEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=YOZbkCEAAAAJ:zzCxg_vo7cAC,"This paper develops new adaptive output tracking control schemes with the reference output signal generated from an unknown reference system whose output derivatives are also unknown. To deal with such reference system uncertainties, an expanded adaptive controller structure is developed to include a parametrized estimator of an equivalent reference input signal. Without using the knowledge of the reference system transfer function and equivalent input, both are the critical components of a traditional model reference adaptive control (MRAC) scheme, the new MRAC schemes, developed for various cases of plant and reference model uncertainties, ensure completely parametrized error equations and globally stable parameter adaptation, leading to the desired closed-loop system stability and asymptotic output tracking properties.",Pergamon,,2025
97,Koopman System Approximation-Based Optimal Control of Multiple Mobile Robots,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YOZbkCEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=YOZbkCEAAAAJ:NtGNdKbuCngC,"This article presents a study of the Koopman operator theory and its application to optimal control of a multiple-mobile-robot system. The operator, while operating on a set of observation functions of the state vector of a nonlinear system, produces a set of dynamic equations that, through a dynamic transformation, form a new dynamic system. The Koopman system technique is then applied to the development of a linear or bilinear model approximation of nonlinear utility functions for optimal control of a system of multiple (mobile) robots, by selecting the utility functions as the Koopman system state variables and expressing the set of Koopman variables as the state variables of a linear or bilinear system whose parameters are determined through optimization. An iterative algorithm is developed to estimate the parameters adaptively. Finally, the optimal control problems based on a linear or bilinear approximation …",IEEE,,2025
98,Adaptive output tracking control with reference model system uncertainties: extensions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YOZbkCEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=YOZbkCEAAAAJ:gmHTDCtJMcoC,"This paper develops some extensions to the work of [1] which studied the continuous-time adaptive output tracking control schemes with the reference output signal generated from an unknown reference model system. The presented extensions include adaptive control schemes with reference model system uncertainties for single-input single-output (SISO) discrete-time systems and multi-input multi-output (MIMO) discrete-time, continuous-time and feedback linearizable systems as well. To deal with such reference model system uncertainties, the adaptive controller structures are expanded to include a parametrized estimator of the equivalent reference input signal, to ensure a completely parametrized error system with a known regressor vector, suitable for stable adaptive controller parameter update law design.",,,2024
99,Discrete-time adaptive state tracking control schemes using gradient algorithms,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YOZbkCEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=YOZbkCEAAAAJ:Nufq_to8ts0C,"This paper revisits a classical adaptive control problem: adaptive state tracking control of a state-space plant model, and solves the open discrete-time state tracking model reference adaptive control problem. Adaptive state tracking control schemes for continuous-time systems have been reported in the literature, using a Lyapunov-algorithm based design and analysis procedure. Such a procedure has not been successfully applied to the discrete-time adaptive state tracking control problem which has remained open. In this paper, new adaptive state tracking control schemes are developed for discrete-time systems, using gradient algorithms for updating the controller parameters. Both direct and indirect adaptive designs are derived, which have the desired parameter adaptation properties and closed-loop system stability and state tracking properties. Such a new gradient-algorithm based framework is also …",Pergamon,,2024
100,Nanoshell-mediated near-infrared thermal therapy of tumors under magnetic resonance guidance,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XlhhQA0AAAAJ&citation_for_view=XlhhQA0AAAAJ:WF5omc3nYNoC,"Metal nanoshells are a class of nanoparticles with tunable optical resonances. In this article, an application of this technology to thermal ablative therapy for cancer is described. By tuning the nanoshells to strongly absorb light in the near infrared, where optical transmission through tissue is optimal, a distribution of nanoshells at depth in tissue can be used to deliver a therapeutic dose of heat by using moderately low exposures of extracorporeally applied near-infrared (NIR) light. Human breast carcinoma cells incubated with nanoshells in vitro were found to have undergone photothermally induced morbidity on exposure to NIR light (820 nm, 35 W/cm2), as determined by using a fluorescent viability stain. Cells without nanoshells displayed no loss in viability after the same periods and conditions of NIR illumination. Likewise, in vivo studies under magnetic resonance guidance revealed that exposure to low doses of …",National Academy of Sciences,,2003
101,Photo-thermal tumor ablation in mice using near infrared-absorbing nanoparticles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XlhhQA0AAAAJ&citation_for_view=XlhhQA0AAAAJ:_FxGoFyzp5QC,"The following study examines the feasibility of nanoshell-assisted photo-thermal therapy (NAPT). This technique takes advantage of the strong near infrared (NIR) absorption of nanoshells, a new class of gold nanoparticles with tunable optical absorptivities that can undergo passive extravasation from the abnormal tumor vasculature due to their nanoscale size. Tumors were grown in immune-competent mice by subcutaneous injection of murine colon carcinoma cells (CT26.WT). Polyethylene glycol (PEG) coated nanoshells (≈130 nm diameter) with peak optical absorption in the NIR were intravenously injected and allowed to circulate for 6 h. Tumors were then illuminated with a diode laser (808 nm, 4W/cm2, 3 min). All such treated tumors abated and treated mice appeared healthy and tumor free >90 days later. Control animals and additional sham-treatment animals (laser treatment without nanoshell injection …",Elsevier,,2004
102,Immunotargeted nanoshells for integrated cancer imaging and therapy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XlhhQA0AAAAJ&citation_for_view=XlhhQA0AAAAJ:ufrVoPGSRksC,"Nanoshells are a novel class of optically tunable nanoparticles that consist of a dielectric core surrounded by a thin gold shell. Based on the relative dimensions of the shell thickness and core radius, nanoshells may be designed to scatter and/or absorb light over a broad spectral range including the near-infrared (NIR), a wavelength region that provides maximal penetration of light through tissue. The ability to control both wavelength-dependent scattering and absorption of nanoshells offers the opportunity to design nanoshells which provide, in a single nanoparticle, both diagnostic and therapeutic capabilities. Here, we demonstrate a novel nanoshell-based all-optical platform technology for integrating cancer imaging and therapy applications. Immunotargeted nanoshells are engineered to both scatter light in the NIR enabling optical molecular cancer imaging and to absorb light, allowing selective destruction of …",American Chemical Society,,2005
103,Photopolymerizable hydrogels for tissue engineering applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XlhhQA0AAAAJ&citation_for_view=XlhhQA0AAAAJ:roLk4NBRz8UC,"Photopolymerized hydrogels are being investigated for a number of tissue engineering applications because of the ability to form these materials in situ in a minimally invasive manner such as by injection. In addition, hydrogels, three-dimensional networks of hydrophilic polymers that are able to swell large amounts of water, can be made to resemble the physical characteristics of soft tissues. Hydrogel materials also generally exhibit high permeability and good biocompatibility making, these materials attractive for use in cell encapsulation and tissue engineering applications. A number of hydrogel materials can be formed via photopolymerization processes mild enough to be carried out in the presence of living cells. This allows one to homogeneously seed cells throughout the scaffold material and to form hydrogels in situ. This review presents advantages of photopolymerization of hydrogels and describes the …",Elsevier,Biomaterials,2002
104,Near-infrared resonant nanoshells for combined optical imaging and photothermal cancer therapy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XlhhQA0AAAAJ&citation_for_view=XlhhQA0AAAAJ:hqOjcs7Dif8C,"Metal nanoshells are core/shell nanoparticles that can be designed to either strongly absorb or scatter within the near-infrared (NIR) wavelength region (∼650−950 nm). Nanoshells were designed that possess both absorption and scattering properties in the NIR to provide optical contrast for improved diagnostic imaging and, at higher light intensity, rapid heating for photothermal therapy. Using these in a mouse model, we have demonstrated dramatic contrast enhancement for optical coherence tomography (OCT) and effective photothermal ablation of tumors.",American Chemical Society,,2007
105,Enzyme-mediated free radical initiating systems for the production of hydrogels and controlled radical polymerization processes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XlhhQA0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XlhhQA0AAAAJ:Y9VhQm-5nPIC,"The present disclosure describes, in part, an enzyme-mediated radical initiating system and methods of using the system to produce polymers, including polymeric hydrogels, at ambient conditions.",,,2025
106,A Multi-Institutional Study of Magnetic Resonance/Ultrasound Fusion–Guided Nanoparticle-Directed Focal Therapy for Prostate Ablation: Erratum,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XlhhQA0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XlhhQA0AAAAJ:ifOnle78iJkC,"A Multi-Institutional Study of Magnetic Resonance/Ultrasound Fusion–Guided Nanoparticle-Directed Focal Therapy for Prostate A Page 1 Errata Erratum A Multi-Institutional Study of Magnetic Resonance/ Ultrasound FusioneGuided Nanoparticle-Directed Focal Therapy for Prostate Ablation: Erratum Steven E. Canfield, Arvin K. George, Joshua S. Jue, Sara C. Lewis, Matthew S. Davenport, Varaha S. Tammisetti, Mahir Maruf, Leonardo D. Borregalaes, Yara Kadria-Vili, Jon A. Schwartz, Jennifer West, Naomi J. Halas, and Ardeshir R. Rastinehad Volume 212, Issue 6, Page 862: On page 864 the keyword “nanoparticles” has been changed to “nanoshells.” The online and PDF versions of the article have been updated. REFERENCE Canfield SE, George AK, Jue JS, et al. A multi-institutional study of magnetic resonance/ultrasound fusioneguided nanoparticle-directed focal therapy for prostate ablation. J Urol. 2024;212(6):…",Wolters Kluwer,,2025
107,Detection of fluorescent protein mechanical switching in cellulo,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XlhhQA0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XlhhQA0AAAAJ:YPNY0knpFBYC,"The ability of cells to sense and respond to mechanical forces is critical in many physiological and pathological processes. However, determining the mechanisms by which forces affect protein function inside cells remains challenging. Motivated by in vitro demonstrations of fluorescent proteins (FPs) undergoing reversible mechanical switching of fluorescence, we investigated whether force-sensitive changes in FP function could be visualized in cells. Guided by a computational model of FP mechanical switching, we develop a formalism for its detection in Förster resonance energy transfer (FRET)-based biosensors and demonstrate its occurrence in cellulo within a synthetic actin crosslinker and the mechanical linker protein vinculin. We find that in cellulo mechanical switching is reversible and altered by manipulation of cell force generation, external stiffness, and force-sensitive bond dynamics of the biosensor …",Elsevier,,2024
108,Neurogenic Cell Behavior in 3D Culture Enhanced Within a Highly Compliant Synthetic Hydrogel Platform Formed via Competitive Crosslinking,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XlhhQA0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XlhhQA0AAAAJ:H7nrzBkawXsC,"Purpose Scaffold materials that better support neurogenesis are still needed to improve cell therapy outcomes for neural tissue damage. We have used a modularly tunable, highly compliant, degradable hydrogel to explore the impacts of hydrogel compliance stiffness on neural differentiation. Here we implemented competitive matrix crosslinking mechanics to finely tune synthetic hydrogel moduli within soft tissue stiffnesses, a range much softer than typically achievable in synthetic crosslinked hydrogels, providing a modularly controlled and ultrasoft 3D culture model which supports and enhances neurogenic cell behavior. Methods Soluble competitive allyl monomers were mixed with proteolytically-degradable poly(ethylene glycol) diacrylate derivatives and crosslinked to form a matrix, and resultant hydrogel stiffness and diffusive properties were evaluated. Neural PC12 cells or primary rat fetal neural stem cells …",Springer International Publishing,,2024
109,Scaling the propulsive performance of heaving flexible panels,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A8eaZMAAAAJ&citation_for_view=8A8eaZMAAAAJ:u-x6o8ySG0sC,"We present an experimental investigation of flexible panels actuated with heave oscillations at their leading edge. Results are presented from kinematic video analysis, particle image velocimetry, and direct force measurements. Both the trailing edge amplitude and the mode shapes of the panel are found to scale with dimensionless parameters originating from the Euler–Bernoulli beam equation. The time-averaged net thrust increases with heaving frequency, but experiences localized boosts near resonant frequencies where the trailing edge amplitude is maximized. These boosts correspond to local maxima in the propulsive efficiency. For a constant heave amplitude, the time-averaged net thrust coefficient is shown to be a function of Strouhal number over a wide range of conditions. It appears, therefore, that self-propelled swimming (zero net thrust) only occurs over a small range of Strouhal numbers. Under …",Cambridge University Press,,2014
110,Tunable stiffness enables fast and efficient swimming in fish-like robots,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A8eaZMAAAAJ&citation_for_view=8A8eaZMAAAAJ:GnPB-g6toBAC,"Fish maintain high swimming efficiencies over a wide range of speeds. A key to this achievement is their flexibility, yet even flexible robotic fish trail real fish in terms of performance. Here, we explore how fish leverage tunable flexibility by using their muscles to modulate the stiffness of their tails to achieve efficient swimming. We derived a model that explains how and why tuning stiffness affects performance. We show that to maximize efficiency, muscle tension should scale with swimming speed squared, offering a simple tuning strategy for fish-like robots. Tuning stiffness can double swimming efficiency at tuna-like frequencies and speeds (0 to 6 hertz; 0 to 2 body lengths per second). Energy savings increase with frequency, suggesting that high-frequency fish-like robots have the most to gain from tuning stiffness.",American Association for the Advancement of Science,,2021
111,Maximizing the efficiency of a flexible propulsor using experimental optimization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A8eaZMAAAAJ&citation_for_view=8A8eaZMAAAAJ:_FxGoFyzp5QC,"Experimental gradient-based optimization is used to maximize the propulsive efficiency of a heaving and pitching flexible panel. Optimum and near-optimum conditions are studied via direct force measurements and particle image velocimetry (PIV). The net thrust and power scale predictably with the frequency and amplitude of the leading edge, but the efficiency shows a complex multimodal response. Optimum pitch and heave motions are found to produce nearly twice the efficiencies of optimum heave-only motions. Efficiency is globally optimized when (i) the Strouhal number is within an optimal range that varies weakly with amplitude and boundary conditions; (ii) the panel is actuated at a resonant frequency of the fluid–panel system; (iii) heave amplitude is tuned such that trailing-edge amplitude is maximized while the flow along the body remains attached; and (iv) the maximum pitch angle and phase lag are …",Cambridge University Press,,2015
112,Unsteady propulsion near a solid boundary,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A8eaZMAAAAJ&citation_for_view=8A8eaZMAAAAJ:d1gkVwhDpl0C,"Experimental and computational results are presented on an aerofoil undergoing pitch oscillations in ground effect, that is, close to a solid boundary. The time-averaged thrust is found to increase monotonically as the mean position of the aerofoil approaches the boundary while the propulsive efficiency stays relatively constant, showing that ground effect can enhance thrust at little extra cost for a pitching aerofoil. Vortices shed into the wake form pairs rather than vortex streets, so that in the mean a momentum jet is formed that angles away from the boundary. The time-averaged lift production is found to have two distinct regimes. When the pitching aerofoil is between 0.4 and 1 chord lengths from the ground, the lift force pulls the aerofoil towards the ground. In contrast, for wall proximities between 0.25 and 0.4 chord lengths, the lift force pushes the aerofoil away from the ground. Between these two regimes there is a …",Cambridge University Press,,2014
113,Propulsive performance of unsteady tandem hydrofoils in a side-by-side configuration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A8eaZMAAAAJ&citation_for_view=8A8eaZMAAAAJ:WF5omc3nYNoC,"Experimental and analytical results are presented on two identical bio-inspired hydrofoils oscillating in a side-by-side configuration. The time-averaged thrust production and power input to the fluid are found to depend on both the oscillation phase differential and the transverse spacing between the foils. For in-phase oscillations, the foils exhibit an enhanced propulsive efficiency at the cost of a reduction in thrust. For out-of-phase oscillations, the foils exhibit enhanced thrust with no observable change in the propulsive efficiency. For oscillations at intermediate phase differentials, one of the foils experiences a thrust and efficiency enhancement while the other experiences a reduction in thrust and efficiency. Flow visualizations reveal how the wake interactions lead to the variations in propulsive performance. Vortices shed into the wake from the tandem foils form vortex pairs rather than vortex streets. For in-phase …",AIP Publishing,,2014
114,Wavenumber affects the lift of ray-inspired fins near a substrate,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A8eaZMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8A8eaZMAAAAJ:f2IySw72cVMC,"Rays and skates tend to have different fin kinematics depending on their proximity to a ground plane such as the sea-floor. Near the ground, rays tend to be more undulatory (high wavenumber), while far from the ground, rays tend to be more oscillatory (low wavenumber). It is unknown whether these differences are driven by hydrodynamics or other biological pressures. Here, we show that near the ground, the time-averaged lift on a ray-like fin is highly dependent on wavenumber. We support our claims using a ray-inspired robotic rig that can produce oscillatory and undulatory motions on the same fin. Potential flow simulations reveal that lift is always negative because quasi-steady forces overcome wake-induced forces. Three-dimensional flow measurements demonstrate that oscillatory wakes are more disrupted by the ground than undulatory wakes. All these effects lead to a suction force towards the ground that …",The Royal Society,,2025
115,Hydrodynamic interactions of low-aspect-ratio oscillating panels in a tip-to-tip formation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A8eaZMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8A8eaZMAAAAJ:EUQCXRtRnyEC,"The vertical, tip-to-tip arrangement of neighboring caudal fins, common in densely packed fish schools, has received much less attention than staggered or side-by-side pairings. We explore this configuration using a canonical system of two trapezoidal plates (aspect ratio AR = 1.2) that pitch about their leading edges while heaving harmonically at a Strouhal number St = 0.45 and a reduced frequency k = 2.09. Direct numerical simulations based on an immersed-boundary method are conducted over a Reynolds number range of 600 <= Re <= 1e4, and complementary water-channel experiments extend this range to 1e4 <= Re <= 3e4, thereby validating the computations at higher flow speeds. Results indicate that when the plates oscillate in phase at a nondimensional vertical spacing H/c <= 1.0, the cycle-averaged thrust coefficient of each plate rises by up to 14.5% relative to an isolated plate; the enhancement decreases monotonically as the spacing increases. Anti-phase motion instead lowers the time-average power coefficient by up to 6%, with only a modest thrust penalty, providing an alternative interaction regime. Flow visualization shows that in-phase kinematics accelerate the stream between the plates, intensifying the adjacent leading-edge vortices. Downstream, the initially separate vortex rings merge into a single, larger ring that is strongly compressed in the spanwise direction; this wake compression correlates with the measured thrust gain. The interaction mechanism and its quantitative benefits persist throughout the entire numerical and experimental Reynolds-number sweep, indicating weak Re-sensitivity within 600 <= Re <= 3e4 …",,,2025
116,"Spontaneous snapping-induced jet flows for fast, maneuverable surface and underwater soft flapping swimmer",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A8eaZMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8A8eaZMAAAAJ:pyW8ca7W8N0C,"Manta rays use wing-like pectoral fins for intriguing oscillatory swimming. It provides rich inspiration for designing potentially fast, efficient, and maneuverable soft swimming robots, which, however, have yet to be realized. It remains a grand challenge to combine fast speed, high efficiency, and high maneuverability in a single soft swimmer while using simple actuation and control. Here, we report leveraging spontaneous snapping stroke in the monostable flapping wing of a manta-like soft swimmer to address the challenge. The monostable wing is pneumatically actuated to instantaneously snap through to stroke down, and upon deflation, it will spontaneously stroke up by snapping back to its initial state, driven by elastic restoring force, without consuming additional energy. This largely simplifies designs, actuation, and control for achieving a record-high speed of 6.8 body length per second, high energy efficiency …",American Association for the Advancement of Science,,2024
117,Ground effects on oscillatory and undulatory batoid-inspired fins,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A8eaZMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8A8eaZMAAAAJ:D03iK_w7-QYC,"Experiments and simulations were employed to study the propulsion of batoid-inspired fins near the ground, focusing on the effect of wavenumber. Three wavenumbers were tested, ranging from oscillation (wavenumber< 1) to undulation (wavenumber> 1). Unlike 2D hydrofoils, which produce both suction and repulsive forces in the lateral direction, the 3D fins here produced only suction forces. These suction forces were most prominent at low wavenumbers, low ground distances, and high Strouhal numbers. Using inviscid simulations, we determined that the suction force resulted from the dominance of negative quasi-steady lift over positive wake-induced lift, with the added-mass lift staying equal to zero. Thrust generation and power consumption also increased with Strouhal number and decreased with wavenumber, but they were not as susceptible to ground effects as lift. Three-dimensional flow measurements …",,,2024
118,Breaking the Mold: A New Way to School,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8A8eaZMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8A8eaZMAAAAJ:a0OBvERweLwC,"A fish can improve its efficiency by swimming near other fish. Studying how neighbor-proximity affects performance leads to a better understanding of fish schools and robot swarms. Due to experimental limitations, vertical offsets between fish neighbors (ie offsets along the dorsoventral axis) have received less attention. If the vertically-separated foils are actuated in-phase, they can be placed on the same driveshaft, but out-of-phase actuations are more challenging to reproduce. We present here a new setup that uses horizontal airfoils to enable multi-hydrofoil, vertically separated, out-of-phase motions. We present preliminary force data, optimization tests, and particle image velocimetry (PIV) obtained with our new setup. We compare our results with vertically-separated, in-phase foils actuated with a single driveshaft (Re= 10k-30k).",,,2024
119,Plastic anisotropy and the role of non-basal slip in magnesium alloy AZ31B,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oyJwW5sAAAAJ&citation_for_view=oyJwW5sAAAAJ:u-x6o8ySG0sC,"Mechanistic explanations for the plastic behavior of a wrought magnesium alloy are developed using a combination of experimental and simulation techniques. Parameters affecting the practical sheet formability, such as strain hardening rate, strain rate sensitivity, the degree of anisotropy, and the stresses and strains at fracture, are examined systematically by conducting tensile tests of variously oriented samples at a range of temperatures (room temperature to 250 °C) and strain rates (10−5–0.1 s−1). Polycrystal plasticity simulations are used to model the observed anisotropy and texture evolution. Strong in-plane anisotropy observed at low temperatures is attributed to the initial texture and the greater than anticipated non-basal cross-slip of dislocations with 〈a〉 type Burgers vectors. The agreement between the measured and simulated anisotropy and texture is further validated by direct observations of the …",Pergamon,,2005
120,Application of texture simulation to understanding mechanical behavior of Mg and solid solution alloys containing Li or Y,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oyJwW5sAAAAJ&citation_for_view=oyJwW5sAAAAJ:u5HHmVD_uO8C,"The viscoplastic self-consistent model was used to interpret differences in the mechanical behavior of hexagonal close packed magnesium alloys. There are only subtle differences in the compression textures of magnesium and its solid solution alloys containing lithium or yttrium. However, the plane strain compression textures of the alloys showed an increasing tendency for the basal poles to rotate away from the “normal direction” towards the “rolling direction”. Texture simulations enabled these distinctions to be attributed to the increased activity of the non-basal 〈 c + a 〉 slip mode. The alloys had improved compressive ductilities compared to pure magnesium, and the increased c + a slip mode activity provides a satisfying explanation for this improvement, since it can accommodate c-axis compression within individual grains. Accounting for individual deformation mode hardening enabled the flow curves to be …",Pergamon,,2001
121,The texture and anisotropy of magnesium–zinc–rare earth alloy sheets,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oyJwW5sAAAAJ&citation_for_view=oyJwW5sAAAAJ:UeHWp8X0CEIC,"In this paper, the rolling textures of six magnesium alloys containing different levels of zinc and rare earth (RE, e.g. mischmetal or Y) additions are examined. The overall texture strength and the basal pole intensity aligned with the sheet normal direction is lower for RE-containing alloys than for conventional alloys. The distinct textures generated in this study allow the influence of texture on the mechanical response to be investigated. The anisotropy of the yield and flow strengths is reversed and the planar anisotropy is reduced (r∼1) in comparison to conventional alloys. Both aspects of the anisotropy are related to the fact that the dominant texture components in the Mg–Zn–RE alloys place more grains in favourable orientations for basal slip and tensile twinning, particularly during transverse direction tension. Mg sheets with lower r-values should have improved forming behaviour, at least under straining …",Pergamon,,2007
122,Hardening evolution of AZ31B Mg sheet,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oyJwW5sAAAAJ&citation_for_view=oyJwW5sAAAAJ:2osOgNQ5qMEC,"The monotonic and cyclic mechanical behavior of O-temper AZ31B Mg sheet was measured in large-strain tension/compression and simple shear. Metallography, acoustic emission (AE), and texture measurements revealed twinning during in-plane compression and untwinning upon subsequent tension, producing asymmetric yield and hardening evolution. A working model of deformation mechanisms consistent with the results and with the literature was constructed on the basis of predominantly basal slip for initial tension, twinning for initial compression, and untwinning for tension following compression. The activation stress for twinning is larger than that for untwinning, presumably because of the need for nucleation. Increased accumulated hardening increases the twin nucleation stress, but has little effect on the untwinning stress. Multiple-cycle deformation tends to saturate, with larger strain cycles saturating …",Pergamon,,2007
123,Enhanced ductility in strongly textured magnesium produced by equal channel angular processing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oyJwW5sAAAAJ&citation_for_view=oyJwW5sAAAAJ:d1gkVwhDpl0C,"Equal channel angular processing is shown to induce a strong deformation texture, which persists after recrystallization. The enhancement in the tensile ductility along the extrusion axis originally reported by Mukai et al. [Scripta Mater 45 (2001) 89] is discussed in terms of magnesium’s deformation mechanisms, plastic anisotropy, and the texture itself.",Pergamon,,2004
124,Evaluation of Combining Heat Induction and Laser Ablation for the Removal of Potentially Hazardous Bridge Coatings,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oyJwW5sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oyJwW5sAAAAJ:Ade32sEp0pkC,"This project aimed to evaluate whether combining induction coating removal (ICR) and laser ablation coating removal (LACR) could be combined to remove hazardous bridge coatings at practical rates. This study included evaluations of the coating removal rates, surface cleanliness, surface profile, steel substrate mechanical properties, recoating adhesion performance, field demonstrations, and environmental and industrial hygiene evaluations of ICR, LACR, and ICR first plus LACR afterward (ICR+LACR). Coating removal data showed that using ICR+LACR could result in a coating removal rate approximately 10 times faster than using LACR alone. ICR can quickly remove the bulk coating layers but leave the residual primer on the steel surface. LACR can then quickly remove the remaining primer layer to provide a clean surface ready to be recoated.",,,2025
125,Dislocation density measurements on Mg alloys reveal surprising temperature dependences,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oyJwW5sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oyJwW5sAAAAJ:1yWc8FF-_SYC,"There has been tremendous worldwide effort to determine the deformation mechanisms responsible for the behavior of Mg and other non-cubic metal alloys. Here, ex-situ X-ray line profile analysis (XLPA) and electron backscattered diffraction (EBSD) are employed to examine the densities of dislocations with , and <c+a> Burgers vectors within Mg alloy sheet materials tested in uniaxial tension at various temperatures. EBSD reveals geometrically necessary dislocation (GND) accumulation near grain boundaries during low-temperature plasticity, whereas GNDs are primarily associated with grain subdivision after high-temperature deformation. Similar to previous studies, the current XLPA results suggest that the relative density of dislocations drops with increasing temperature more rapidly than and <c+a>. This implies that non-basal slip is more prevalent at elevated temperatures. However, published in-situ XLPA …",Pergamon,,2025
126,Strain partitioning-induced anisotropy in thermomechanically processed magnesium alloys comprised of earth-abundant elements,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oyJwW5sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oyJwW5sAAAAJ:WC23djZS0W4C,"Dilute Mg alloys based upon earth-abundant elements, e.g., Al, Ca, and Zn have attractive combinations of strength, ductility, and workability. Even higher strength can be obtained in work-hardened material without the heat treatments required to induce Guinier-Preston zone strengthening of previously studied versions of these alloys. This stems from a slightly stronger crystallographic texture than is present after solutionizing, a high dislocation density, and to a lesser degree, a fine distribution of globular Zn-rich precipitates. The anisotropic plastic response of sheet material is described using an elasto-viscoplastic self-consistent (EVPSC) polycrystal model. Strain partitioning between grains during rolling-induced strain hardening is held responsible for the yield strength, ductility, and especially, strain hardening anisotropy. Texture-induced plastic anisotropy is well-known, but the effect of strong partitioning of …",Pergamon,,2025
127,Evolution of dislocations during the rapid solidification in additive manufacturing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oyJwW5sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oyJwW5sAAAAJ:owLR8QvbtFgC,"Materials processed by fusion-based additive manufacturing (AM) typically exhibit relatively high dislocation densities, along with cellular structures and elemental segregation. This representative structural feature significantly influences material performance; however, post-mortem microstructure characterizations of AM materials cannot capture the dynamic evolution of dislocations during the manufacturing process, thereby offering limited mechanism-based guidance for further advancing AM techniques and facilitating the qualification and certification of AM products. In this study, we conduct operando high-energy synchrotron X-ray diffraction experiments on wire-laser directed energy deposition of 316 L stainless steel. Through a unique configuration, our operando synchrotron experiments semi-quantitatively probe the dislocation density in solid phases and their dynamic changes during solidification and …",Nature Publishing Group UK,,2025
128,Guinier-Preston (GP) zone strengthening of dilute magnesium alloys comprised of earth-abundant elements,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oyJwW5sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oyJwW5sAAAAJ:1taIhTC69MYC,"Dilute Mg alloys based upon earth abundant Al, Zn, and Ca (along with minor additions of Mn and Zr) exhibit attractive combinations of strength, ductility, and workability via high-speed extrusion. These alloys derive their strength from high number densities of ordered, single atomic layer Guinier-Preston (GP) zones. The present study explores the potential of two quaternary Mg-Zn-Ca-Zr (ZXK210 and ZXK310) alloys produced as sheet materials. The anisotropic plastic responses of the two alloys are described using an elasto-viscoplastic self-consistent (EVPSC) polycrystal plasticity model. Similar to what was observed in AXM alloys with Mg-Ca-Al GP zones, prismatic slip is more potently strengthened than basal slip. The Mg-Zn-Ca GP zones are found to be intrinsically stronger and have a higher antiphase domain boundary energy than the Mg-Al-Ca GP zones. Finally, it is shown that the ZXK alloys are immune …",Pergamon,,2025
129,Multilayer polypyrrole nanosheets with self‐organized surface structures for flexible and efficient solar–thermal energy conversion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xmmtv8gAAAAJ&citation_for_view=xmmtv8gAAAAJ:HtS1dXgVpQUC,"Converting solar energy into concentrated heat is very appealing for various applications. Polypyrrole (PPy) is known to possess excellent photothermal property with low thermal conductivity, and thus is an ideal candidate for solar–thermal energy conversion. However, solar–thermal materials based on PPy or other conducting polymers still exhibit limited energy conversion efficiency due to the lack of effective light‐trapping schemes. Here, it is demonstrated that multilayer PPy nanosheets with spontaneously formed surface structures such as wrinkles and ridges via sequential polymerization on paper substrates can dramatically enhance broadband and wide‐angle light absorption across the full solar spectrum, leading to an impressive solar–thermal conversion efficiency of 95.33%. The intriguing solar–thermal properties and structural features of multilayer PPy nanosheets can be used for solar heating and …",,,2019
130,"A self‐healable, highly stretchable, and solution processable conductive polymer composite for ultrasensitive strain and pressure sensing",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xmmtv8gAAAAJ&citation_for_view=xmmtv8gAAAAJ:_FM0Bhl9EiAC,"Mimicking human skin's functions to develop electronic skins has inspired tremendous efforts in design and synthesis of novel soft materials with simplified fabrication methods. However, it still remains a great challenge to develop electronically conductive materials that are both stretchable and self‐healable. Here it is demonstrated that a ternary polymer composite comprised of polyaniline, polyacrylic acid, and phytic acid can exhibit high stretchability (≈500%) and excellent self‐healing properties. The polymer composite with optimized composition shows an electrical conductivity of 0.12 S cm−1. On rupture, both electrical and mechanical properties can be restored with ≈99% efficiency in a 24 h period, which is enabled by the dynamic hydrogen bonding and electrostatic interactions. It is further shown that this composite is both strain and pressure sensitive, and therefore can be used for fabricating strain and …",,,2018
131,"An epidermal stimulation and sensing platform for sensorimotor prosthetic control, management of lower back exertion, and electrical muscle activation",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xmmtv8gAAAAJ&citation_for_view=xmmtv8gAAAAJ:VaXvl8Fpj5cC,"Skin-mounted sensors of physiological signals are useful in areas ranging from clinical diagnostics to human–machine interfaces.[1–6] The recent development of concepts in “skinlike” semiconductor technologies, sometimes referred to as epidermal electronics, create important opportunities in long-term, noninvasive, conformal interfaces to the body.[7–13] These systems offer advantages in device mechanics and user mobility over traditional technologies for healthcare monitoring and disease diagnostics, with demonstrated capabilities in precision measurement of hydration,[14] strain,[15–17] pressure,[18, 19] temperature,[20] and other parameters of interest. Additional recent work shows that similar platforms designed for the fingertips can offer advanced capabilities in electrotactile stimulation.[21] This previous work focused, however, on materials and circuit design aspects without any demonstrated …",,,2015
132,Epidermal photonic devices for quantitative imaging of temperature and thermal transport characteristics of the skin,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xmmtv8gAAAAJ&citation_for_view=xmmtv8gAAAAJ:tYavs44e6CUC,"Characterization of temperature and thermal transport properties of the skin can yield important information of relevance to both clinical medicine and basic research in skin physiology. Here we introduce an ultrathin, compliant skin-like, or ‘epidermal’, photonic device that combines colorimetric temperature indicators with wireless stretchable electronics for thermal measurements when softly laminated on the skin surface. The sensors exploit thermochromic liquid crystals patterned into large-scale, pixelated arrays on thin elastomeric substrates; the electronics provide means for controlled, local heating by radio frequency signals. Algorithms for extracting patterns of colour recorded from these devices with a digital camera and computational tools for relating the results to underlying thermal processes near the skin surface lend quantitative value to the resulting data. Application examples include non-invasive spatial …",Nature Publishing Group UK,,2014
133,Micromechanical modelling of the effect of plastic deformation on the mechanical behaviour in pseudoelastic shape memory alloys,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xmmtv8gAAAAJ&citation_for_view=xmmtv8gAAAAJ:mvPsJ3kp5DgC,"Except for the recoverable strain induced by phase transformation, NiTi alloys are very ductile even in the martensite phase. The purpose of the present paper is to study the influence of permanent deformation, which results from plastic deformation of martensite, on the mechanical behaviour of pseudoelastic NiTi alloys. Based on phenomenological theory of martensitic transformation and crystal plasticity, a new three dimensional micromechanical model is proposed by coupling both the slip and twinning deformation mechanisms. The present model is implemented as User MATerial subroutine (UMAT) into ABAQUS/Standard to study the influences of plastic deformation on the stress and strain fields, and on the evolution of martensite transformation. Results show that with the increasing of plastic deformation the residual strain increases and the phase transformation stress–strain curves from the martensite to …",Pergamon,,2008
134,Processing soft thin films on liquid surface for seamless creation of on-liquid walkable devices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xmmtv8gAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xmmtv8gAAAAJ:PYBJJbyH-FwC,"Walking on liquid surface is a unique locomotion ability of insects, but engineering on-liquid walkable devices currently requires disjointed, multistage fabrication and delicate deployment. Here, we introduce HydroSpread—a direct processing technology that enables seamless fabrication and patterning of soft films on liquid surface. It leverages the controlled spreading of liquid ink on liquid surface and combines with precise laser engraving supported by rapid heat transfer at the solid-liquid interface. Geometric shapes, including basic forms of straight lines, sharp turns and circles, and complex patterns, were fabricated with exceptional fidelity to design specifications. We propose two heat-driven hydrodynamic locomotion mechanisms, fin-like bending and leg-like buckling. By harnessing these principles, we engineered two walkable devices—HydroFlexor and HydroBuckler—and demonstrated robust on-water …",American Association for the Advancement of Science,,2025
135,Vat Photopolymerization Printing of Modular Soft Stretchable Low-Cost Elastomers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xmmtv8gAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xmmtv8gAAAAJ:7H_MAutzIkAC,"Additive manufacturing of elastomers enables the fabrication of many technologically important structures and devices. However, it remains a challenge to develop soft and stretchable elastomers for vat photopolymerization (VP) printing, one of the most used additive manufacturing techniques for producing objects with relatively high resolution and smooth finishes. Here, we report a modular soft stretchable low-cost elastomer resin for VP printing. The resin consists of mainly commodity acrylates and can be photocured to form a dual-network containing covalent crosslinks and reversible double hydrogen bonds. Controlling the ratio of covalent and reversible crosslinks enables elastomers with an exceptional combination of softness and stretchability (Young’s modulus of 20–150 kPa and tensile breaking strain of 510–1350%) that cannot be achieved by existing VP resins. Using a customized VP printing platform …",American Chemical Society,,2025
136,Mechanical Flexibility Improves Thermal Conduction of Confined Liquid in Nanofluidics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xmmtv8gAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xmmtv8gAAAAJ:7wO8s98CvbsC,"Nanofluidics systems demonstrate the potential to address the thermal management challenge in nanoelectronics devices with extraordinary transport properties. However, the phonon features in different substrates have led to contradictory thermal transport properties of the confined liquid. Understanding the correlation between the thermal transport of nanoconfined liquid and substrate vibration is of critical importance. Herein, we demonstrate that the phonon resonance between the substrates and the confined water molecules can significantly enhance the thermal conductivity of the water. Detailed analyses reveal that the phonon resonance shortens the lifetime of hydrogen bonds, promotes the mobility of the water molecules, and enhances the thermal conductivity. Moreover, the effect of phonon resonance is more pronounced with a reduced channel size owing to stronger solid–liquid interactions. These …",American Chemical Society,,2025
137,Degradation of Hydrogen Bonds Enormously Enhances Convective Heat Transfer in Nanofluidics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xmmtv8gAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xmmtv8gAAAAJ:WHdLCjDvYFkC,"The ultrafast mass transport of liquid through nanochannels holds promising potential to tackle the challenge of thermal management in high-power-density electronic devices. However, convective heat transfer in underpinned nanofluidics-based environments remains elusive. Here, we report with atomistic simulations that the convective heat transfer in nanochannels can be enhanced by ∼50% due to the deterioration of hydrogen bonds subjected to internal stress. The degraded hydrogen bonds largely weaken the intrinsic constraints by local confinement, significantly promoting the mobility of the confined liquid molecules, which facilitates phonon transmission for rapid heat transfer. The internal stress is further elucidated and quantitatively correlated with the convective heat transfer through the development of a thermal-mechanics scaling law that incorporates the Nusselt number and the interaction energy …",American Chemical Society,,2025
138,Method and system for transfer printing of films,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xmmtv8gAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xmmtv8gAAAAJ:MhiOAD_qIWkC,"The capillary transfer technology presented here represents a powerful approach to transfer soft films from surface of liquid onto a solid substrate in a fast and defect-free manner. The fundamental theoretical model and transfer criteria validated with comprehensive experiments and finite element analyses, for the first time provides a quantitative guide and optimization for the choice of material systems, operating conditions and environments for scalable on-demand transfers with high yield. The intrinsically moderate capillary transfer force and externally selectable transfer direction offer robust capabilities for achieving deterministic assembly and surface properties of structures with complex layouts and patterns for potentially broad applications in the fabrication of flexible/stretchable electronics, surface wetting structures and optical devices. Integration of this technology with other advanced manufacturing …",,,2025
139,Self-exciting hurdle models for terrorist activity,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pbOK99MAAAAJ&citation_for_view=pbOK99MAAAAJ:d1gkVwhDpl0C,"A predictive model of terrorist activity is developed by examining the daily number of terrorist attacks in Indonesia from 1994 through 2007. The dynamic model employs a shot noise process to explain the self-exciting nature of the terrorist activities. This estimates the probability of future attacks as a function of the times since the past attacks. In addition, the excess of nonattack days coupled with the presence of multiple coordinated attacks on the same day compelled the use of hurdle models to jointly model the probability of an attack day and corresponding number of attacks. A power law distribution with a shot noise driven parameter best modeled the number of attacks on an attack day …",Institute of Mathematical Statistics,,2011
140,Is hydrothermal treatment coupled with carbon capture and storage an energy-producing negative emissions technology?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pbOK99MAAAAJ&citation_for_view=pbOK99MAAAAJ:_kc_bZDykSQC,"This paper evaluates the feasibility of hydrothermal treatment (HTT) with carbon capture and storage (CCS) as an energy producing negative emissions technology (NET) and compares such system with a conventional bioenergy with carbon capture and sequestration (BECCS) system. Machine learning models were developed to predict product yields and characteristics from HTT of various feedstocks. The model results were then integrated into a life cycle assessment (LCA) model to compute two metrics: energy return on investment (EROI) and net global warming potential (GWP). Results showed random forest models had better prediction accuracy than regression tree and multiple linear regression to model HTT of feedstocks (e.g., microalgae, crops/forest residues, energy crops, and biodegradable organic wastes) and predicted the mass yields of multiple products (biocrude, hydrochar, gas, and aqueous co …",Pergamon,,2020
141,Development of wastewater pooled surveillance of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) from congregate living settings,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pbOK99MAAAAJ&citation_for_view=pbOK99MAAAAJ:-f6ydRqryjwC,"Wastewater-based monitoring for severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) at the individual building level could be an efficient, passive means of early detection of new cases in congregate living settings, but this approach has not been validated. Preliminary samples were collected from a hospital and a local municipal wastewater treatment plant. Molecular diagnostic methods were compared side by side to assess feasibility, performance, and sensitivity. Refined sample collection and processing protocols were then used to monitor two occupied dormitory complexes (n = 105 and 66) over 8 weeks. Wastewater results were validated using known case counts from external clinical testing of building occupants. Results confirm that ultracentrifugation from a 24-h composite collection had a sensitivity of 96.2% and a specificity of 100%. However, the method could not distinguish new …",American Society for Microbiology,,2021
142,"Terrorism Risk, Resilience and Volatility: A Comparison of Terrorism Patterns in Three Southeast Asian Countries",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pbOK99MAAAAJ&citation_for_view=pbOK99MAAAAJ:W7OEmFMy1HYC,"Objective This article explores patterns of terrorist activity over the period from 2000 through 2010 across three target countries: Indonesia, the Philippines and Thailand. Methods We use self-exciting point process models to create interpretable and replicable metrics for three key terrorism concepts: risk, resilience and volatility, as defined in the context of terrorist activity. Results Analysis of the data shows significant and important differences in the risk, volatility and resilience metrics over time across the three countries. For the three countries analysed, we show that risk varied on a scale from 0.005 to 1.61 “expected terrorist attacks per day”, volatility ranged from 0.820 to 0.994 “additional attacks caused by each attack”, and resilience, as measured by the number of days until risk subsides to a pre-attack level, ranged from 19 to 39 days. We find that of the three countries, Indonesia had the lowest average risk and …",Springer Netherlands,,2012
143,Consistency and specificity in burglars who commit prolific residential burglary: Testing the core assumptions underpinning behavioural crime linkage,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pbOK99MAAAAJ&citation_for_view=pbOK99MAAAAJ:5nxA0vEk-isC,"Purpose Behavioural crime linkage is underpinned by two assumptions: (a) that offenders exhibit some degree of consistency in the way they commit offences (their modus operandi [MO]); and, (b) that offenders can be differentiated on the basis of their offence behaviour. The majority of existing studies sample at most three crimes from an offender's series of detected crimes and do not examine whether patterns differ across offenders. Here, we examine patterns observed across the entire detected series of each sampled offender, and assess how homogeneous patterns are across offenders. Methods Using a non‐parametric resampling approach, we analyse the entire crime series of 153 prolific burglars to determine if they exhibit consistency and specificity in the way they commit offences. Results Findings suggest that offenders exhibit consistency in the way they commit offences. With respect to specificity, our …",,,2014
144,Addressing uncertainty in machine learning-integrated life cycle assessment (ML+ LCA),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pbOK99MAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pbOK99MAAAAJ:zA6iFVUQeVQC,"There has been a recent surge in studies applying artificial intelligence, most notably machine learning (ML), to questions about environmental sustainability and climate change. Particularly, there has been growing interest in combining ML and life cycle assessment (LCA) as a means to expand the breadth and depth of LCA studies. However, much of the ML-integrated LCA (ML + LCA) work published to date has not considered the uncertainty of ML modeling. This study explores the application of ML techniques for use in LCA with careful focus on propagating and managing uncertainty. An existing open-access ML + LCA model of hydrothermal biomass treatment was selected as a case study. The benchmark model was rebuilt, and four different uncertainty treatments (cases) were evaluated: (I) no uncertainty analysis, (II) uncertainty analysis for ML only, (III) uncertainty analysis for LCA only (via Monte Carlo …",Academic Press,,2025
145,Machine Learning for Predicting Waitlist Mortality in Pediatric Heart Transplantation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pbOK99MAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pbOK99MAAAAJ:rO6llkc54NcC,"Background Waitlist mortality remains a critical issue for pediatric heart transplant (HTx) candidates, particularly for candidates with congenital heart disease. Listing center organ offer acceptance practices have been identified as a factor influencing waitlist outcomes. We utilized machine learning (ML) to identify factors associated with waitlist mortality, combining variables associated with institutional offer acceptance practices as well as candidate‐specific risk factors. Methods We analyzed the Organ Procurement and Transplantation Network database for pediatric HTx candidates listed between 2010 and 2020. Various statistical and ML models were employed to identify predictors of waitlist mortality or clinical deterioration leading to waitlist removal. The dataset was split into training (82%) and testing (18%), and the final model was selected based on predictive performance. SHAP values were used to assess …",,,2025
146,Contextual Embeddings in Sociological Research: Expanding the Analysis of Sentiment and Social Dynamics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pbOK99MAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pbOK99MAAAAJ:pqnbT2bcN3wC,"The authors introduce BERTNN (Bidirectional Encoder Representations from Transformers Neural Network), a novel methodology designed to expand affective lexicons, a critical component in sociological research. BERTNN estimates the affective meanings and their distribution for new concepts, bypassing the need for extensive surveys by leveraging their contextual usage in language. The cornerstone of BERTNN is the use of nuanced word embeddings from Bidirectional Encoder Representations from Transformers. BERTNN uniquely encodes words within the framework of synthesized social event sentences, preserving their meaning across actor-behavior-object positions. The model is fine-tuned on the basis of the implied sentiment changes, providing a more refined estimation of affective meanings. BERTNN outperforms previous approaches, setting a new standard in deriving multidimensional affective …",SAGE Publications,,2025
147,Endogenous and exogenous effects in self‐exciting process models of terrorist activity,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pbOK99MAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pbOK99MAAAAJ:M05iB0D1s5AC,"A model based on the cluster process representation of the self‐exciting process model is derived to allow for variation in the excitation effects for terrorist events in a self‐exciting or cluster process model. The model's derivation and implementation details are given and applied to data from the Global Terrorism Database (National Consortium for the Study of Terrorism and Responses to Terrorism (START), 2015) from 2000 to 2013. Results regarding the practical interpretation and implications for a theoretical model paralleling existing criminological theory are discussed.","John Wiley & Sons, Inc.",,2025
148,Time of week intensity estimation from partly interval censored data with applications to police patrol planning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pbOK99MAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pbOK99MAAAAJ:ldfaerwXgEUC,"Law enforcement agencies are tasked with crime prevention and crime reduction under limited resources. Having an accurate temporal estimate of the crime rate would be valuable to achieve such a goal. However, estimation is usually complicated by the interval censored nature of crime data. We cast the problem of intensity estimation as a Poisson regression using an EM algorithm to estimate the parameters. Two special penalties are added that provide smoothness over the time of day and day of week. This approach provides accurate intensity estimates and can also uncover day of week clusters that share the same intensity patterns. Both simulated and real crime data gathered from the city of Cincinnati and the city of Dallas are used to demonstrate the effectiveness of the proposed model.",Taylor & Francis,,2025
149,Environmental life cycle comparison of algae to other bioenergy feedstocks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qp3i-1oAAAAJ&citation_for_view=qp3i-1oAAAAJ:u5HHmVD_uO8C,"Algae are an attractive source of biomass energy since they do not compete with food crops and have higher energy yields per area than terrestrial crops. In spite of these advantages, algae cultivation has not yet been compared with conventional crops from a life cycle perspective. In this work, the impacts associated with algae production were determined using a stochastic life cycle model and compared with switchgrass, canola, and corn farming. The results indicate that these conventional crops have lower environmental impacts than algae in energy use, greenhouse gas emissions, and water regardless of cultivation location. Only in total land use and eutrophication potential do algae perform favorably. The large environmental footprint of algae cultivation is driven predominantly by upstream impacts, such as the demand for CO2 and fertilizer. To reduce these impacts, flue gas and, to a greater extent …",American Chemical Society,,2010
150,A review of engineering research in sustainable manufacturing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qp3i-1oAAAAJ&citation_for_view=qp3i-1oAAAAJ:W7OEmFMy1HYC,"Sustainable manufacturing requires simultaneous consideration of economic, environmental, and social implications associated with the production and delivery of goods. Fundamentally, sustainable manufacturing relies on descriptive metrics, advanced decision-making, and public policy for implementation, evaluation, and feedback. In this paper, recent research into concepts, methods, and tools for sustainable manufacturing is explored. At the manufacturing process level, engineering research has addressed issues related to planning, development, analysis, and improvement of processes. At a manufacturing systems level, engineering research has addressed challenges relating to facility operation, production planning and scheduling, and supply chain design. Though economically vital, manufacturing processes and systems have retained the negative image of being inefficient, polluting, and dangerous …",American Society of Mechanical Engineers,Journal of manufacturing science and engineering,2013
151,Pilot-scale data provide enhanced estimates of the life cycle energy and emissions profile of algae biofuels produced via hydrothermal liquefaction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qp3i-1oAAAAJ&citation_for_view=qp3i-1oAAAAJ:isC4tDSrTZIC,"Life cycle assessment (LCA) has been used widely to estimate the environmental implications of deploying algae-to-energy systems even though no full-scale facilities have yet to be built. Here, data from a pilot-scale facility using hydrothermal liquefaction (HTL) is used to estimate the life cycle profiles at full scale. Three scenarios (lab-, pilot-, and full-scale) were defined to understand how development in the industry could impact its life cycle burdens. HTL-derived algae fuels were found to have lower greenhouse gas (GHG) emissions than petroleum fuels. Algae-derived gasoline had significantly lower GHG emissions than corn ethanol. Most algae-based fuels have an energy return on investment between 1 and 3, which is lower than petroleum biofuels. Sensitivity analyses reveal several areas in which improvements by algae bioenergy companies (e.g., biocrude yields, nutrient recycle) and by supporting …",Elsevier,,2013
152,Environmental impacts of algae-derived biodiesel and bioelectricity for transportation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qp3i-1oAAAAJ&citation_for_view=qp3i-1oAAAAJ:u-x6o8ySG0sC,"Algae are a widely touted source of bioenergy with high yields, appreciable lipid contents, and an ability to be cultivated on marginal land without directly competing with food crops. Nevertheless, recent work has suggested that large-scale deployment of algae bioenergy systems could have unexpectedly high environmental burdens. In this study, a “well-to-wheel” life cycle assessment was undertaken to evaluate algae’s potential use as a transportation energy source for passenger vehicles. Four algae conversion pathways resulting in combinations of bioelectricity and biodiesel were assessed for several relevant nutrient procurement scenarios. Results suggest that algae-to-energy systems can be either net energy positive or negative depending on the specific combination of cultivation and conversion processes used. Conversion pathways involving direct combustion for bioelectricity production generally …",American Chemical Society,,2011
153,Food–energy–water implications of negative emissions technologies in a+ 1.5 C future,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qp3i-1oAAAAJ&citation_for_view=qp3i-1oAAAAJ:1yQoGdGgb4wC,"Scenarios for meeting ambitious climate targets rely on large-scale deployment of negative emissions technologies (NETs), including direct air capture (DAC). However, the tradeoffs between food, water and energy created by deploying different NETs are unclear. Here we show that DAC could provide up to 3 GtCO2 yr−1 of negative emissions by 2035—equivalent to 7% of 2019 global CO2 emissions—based on current-day assumptions regarding price and performance. DAC in particular could exacerbate demand for energy and water, yet it would avoid the most severe market-mediated effects of land-use competition from bioenergy with carbon capture and storage and afforestation. This could result in staple food crop prices rising by approximately fivefold relative to 2010 levels in many parts of the Global South, raising equity concerns about the deployment of NETs. These results highlight that delays in …",Nature Publishing Group UK,,2020
154,Identifying key uncertainties in energy transitions with a Puerto Rico case study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qp3i-1oAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qp3i-1oAAAAJ:Ehil0879vHcC,"Deterministic energy transition planning risks uninformed decisions. Yet, the challenge of high-dimensional uncertainty–encompassing various technological, economic, social, and climatic factors–often leads to a deterministic treatment or simplification of uncertainties in planning. Here, we propose a computationally efficient framework that leverages surrogate-based sensitivity analysis to identify the key uncertainty sources driving the cost of different energy transition scenarios. We applied the proposed approach to Puerto Rico as a hurricane-prone power system that lacks efficient management. We find that changes in the frequency of hurricanes and organizational inefficiency are the two primary sources of uncertainty determining the system’s total expected cost. When examining operational costs, different transition scenarios demonstrate unique key uncertainty sources. For example, the price of biofuel would …",Nature Publishing Group UK,,2025
155,Cementitious materials and methods of making and using thereof,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qp3i-1oAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qp3i-1oAAAAJ:yMeIxYmEMEAC,"BACKGROUND Concrete is the most consumed man-made material in the world. A typical concrete is made by mixing Portland cement, water and aggregates such as sand and crushed stone. Portland cement is a synthetic material made by burning a mixture of ground limestone and clay, or materials of similar composition in a rotary kiln at a sintering temperature of 1450 C. Portland cement manufacturing is not only an energy-intensive process, but one which releases considerable quantities of greenhouse gas (CO 2). The cement industry accounts for approximately 5% of global anthropogenic CO 2 emissions. More than 60% of this CO 2 comes from the chemical decomposition, or calcination of limestone.",,,2025
156,"Provincial-scale assessment of direct air capture to meet China's climate neutrality goal under limited bioenergy supply (vol 19, 114021, 2024)",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qp3i-1oAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qp3i-1oAAAAJ:QYdC8u9Cj1oC,,IOP Publishing Ltd,,2025
157,Corrigendum: provincial-scale assessment of direct air capture to meet China’s climate neutrality goal under limited bioenergy supply (2024 Environ. Res. Lett. 19 114021),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qp3i-1oAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qp3i-1oAAAAJ:IRz6iEL74y4C,"In Kim et al (2024) an error in the processing code for figure 2 caused CO2 sequestration rates in 2060 to be reported incorrectly on the map. A corrected version of figure 2 is provided here in figure 1. The sequestration rates now match those reported in supplementary figure 17, which reports CO2 emissions and removals for the provinces on gridded panels in alphabetical order as opposed arranging them quasi-spatially on a map. The correction here does not affect the major conclusions of the paper.",IOP Publishing,,2025
158,Automated brightfield morphometry of 3D organoid populations by OrganoSeg,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Be9T0PsAAAAJ&citation_for_view=Be9T0PsAAAAJ:qjMakFHDy7sC,"Spheroid and organoid cultures are powerful in vitro models for biology, but size and shape diversity within the culture is largely ignored. To streamline morphometric profiling, we developed OrganoSeg, an open-source software that integrates segmentation, filtering, and analysis for archived brightfield images of 3D culture. OrganoSeg is more accurate and flexible than existing platforms, and we illustrate its potential by stratifying 5167 breast-cancer spheroid and 5743 colon and colorectal-cancer organoid morphologies. Organoid transcripts grouped by morphometric signature heterogeneity were enriched for biological processes not prominent in the original RNA sequencing data. OrganoSeg enables complete, objective quantification of brightfield phenotypes, which may give insight into the molecular and multicellular mechanisms of organoid regulation.",Nature Publishing Group UK,,2018
159,Tumor-suppressor inactivation of GDF11 occurs by precursor sequestration in triple-negative breast cancer,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Be9T0PsAAAAJ&citation_for_view=Be9T0PsAAAAJ:2osOgNQ5qMEC,"Triple-negative breast cancer (TNBC) is an aggressive and heterogeneous carcinoma in which various tumor-suppressor genes are lost by mutation, deletion, or silencing. Here we report a tumor-suppressive mode of action for growth-differentiation factor 11 (GDF11) and an unusual mechanism of its inactivation in TNBC. GDF11 promotes an epithelial, anti-invasive phenotype in 3D triple-negative cultures and intraductal xenografts by sustaining expression of E-cadherin and inhibitor of differentiation 2 (ID2). Surprisingly, clinical TNBCs retain the GDF11 locus and expression of the protein itself. GDF11 bioactivity is instead lost because of deficiencies in its convertase, proprotein convertase subtilisin/kexin type 5 (PCSK5), causing inactive GDF11 precursor to accumulate intracellularly. PCSK5 reconstitution mobilizes the latent TNBC reservoir of GDF11 in vitro and suppresses triple-negative mammary cancer …",Elsevier,,2017
160,A time-and matrix-dependent TGFBR3–JUND–KRT5 regulatory circuit in single breast epithelial cells and basal-like premalignancies,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Be9T0PsAAAAJ&citation_for_view=Be9T0PsAAAAJ:9yKSN-GCB0IC,"Basal-like breast carcinoma is characterized by poor prognosis and high intratumour heterogeneity. In an immortalized basal-like breast epithelial cell line, we identified two anticorrelated gene-expression programs that arise among single extracellular matrix (ECM)-attached cells during organotypic three-dimensional culture. The first contains multiple TGF-β-related genes including TGFBR3, whereas the second contains JUND and the basal-like marker KRT5. TGFBR3 and JUND interconnect through four negative-feedback loops to form a circuit that exhibits spontaneous damped oscillations in three-dimensional culture. The TGFBR3–JUND circuit is conserved in some premalignant lesions that heterogeneously express KRT5. The circuit depends on ECM engagement, as detachment causes a rewiring that is triggered by RPS6 dephosphorylation and maintained by juxtacrine tenascin C, which is critical for …",Nature Publishing Group UK,,2014
161,Parameterizing cell-to-cell regulatory heterogeneities via stochastic transcriptional profiles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Be9T0PsAAAAJ&citation_for_view=Be9T0PsAAAAJ:d1gkVwhDpl0C,"Regulated changes in gene expression underlie many biological processes, but globally profiling cell-to-cell variations in transcriptional regulation is problematic when measuring single cells. Transcriptome-wide identification of regulatory heterogeneities can be robustly achieved by randomly collecting small numbers of cells followed by statistical analysis. However, this stochastic-profiling approach blurs out the expression states of the individual cells in each pooled sample. Here, we show that the underlying distribution of single-cell regulatory states can be deconvolved from stochastic-profiling data through maximum-likelihood inference. Guided by the mechanisms of transcriptional regulation, we formulated plausible mixture models for cell-to-cell regulatory heterogeneity and maximized the resulting likelihood functions to infer model parameters. Inferences were validated both computationally and …",National Academy of Sciences,,2014
162,Antisense oligonucleotide therapy in a humanized mouse model of MECP2 duplication syndrome,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Be9T0PsAAAAJ&citation_for_view=Be9T0PsAAAAJ:IjCSPb-OGe4C,"Many intellectual disability disorders are due to copy number variations, and, to date, there have been no treatment options tested for this class of diseases. MECP2 duplication syndrome (MDS) is one of the most common genomic rearrangements in males and results from duplications spanning the methyl-CpG binding protein 2 (MECP2) gene locus. We previously showed that antisense oligonucleotide (ASO) therapy can reduce MeCP2 protein amount in an MDS mouse model and reverse its disease features. This MDS mouse model, however, carried one transgenic human allele and one mouse allele, with the latter being protected from human-specific MECP2-ASO targeting. Because MeCP2 is a dosage-sensitive protein, the ASO must be titrated such that the amount of MeCP2 is not reduced too far, which would cause Rett syndrome. Therefore, we generated an “MECP2 humanized” MDS model that carries …",American Association for the Advancement of Science,,2021
163,Acute MeCP2 loss in adult mice reveals transcriptional and chromatin changes that precede neurological dysfunction and inform pathogenesis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Be9T0PsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Be9T0PsAAAAJ:UebtZRa9Y70C,"Mutations in the X-linked methyl-CpG-binding protein 2 (MECP2) gene cause Rett syndrome, a severe childhood neurological disorder. MeCP2 is a well-established transcriptional repressor, yet upon its loss, hundreds of genes are dysregulated in both directions. To understand what drives such dysregulation, we deleted Mecp2 in adult mice, circumventing developmental contributions and secondary pathogenesis. We performed time series transcriptional, chromatin, and phenotypic analyses of the hippocampus to determine the immediate consequences of MeCP2 loss and the cascade of pathogenesis. We find that loss of MeCP2 causes immediate and bidirectional progressive dysregulation of the transcriptome. To understand what drives gene downregulation, we profiled genome-wide histone modifications and found that a decrease in histone H3 acetylation (ac) at downregulated genes is among the earliest …",Elsevier,,2025
164,Structural variant allelic heterogeneity in MECP2 duplication syndrome provides insight into clinical severity and variability of disease expression,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Be9T0PsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Be9T0PsAAAAJ:0EnyYjriUFMC,"Background MECP2 Duplication Syndrome, also known as X-linked intellectual developmental disorder Lubs type (MRXSL; MIM: 300260), is a neurodevelopmental disorder caused by copy number gains spanning MECP2. Despite varying genomic rearrangement structures, including duplications and triplications, and a wide range of duplication sizes, no clear correlation exists between DNA rearrangement and clinical features. We had previously demonstrated that up to 38% of MRXSL families are characterized by complex genomic rearrangements (CGRs) of intermediate complexity (2 ≤ copy number variant breakpoints < 5), yet the impact of these genomic structures on regulation of gene expression and phenotypic manifestations have not been investigated. Methods To study the role of the genomic rearrangement structures on an individual’s clinical phenotypic variability, we employed a comprehensive …",BioMed Central,,2024
165,Modeling antisense oligonucleotide therapy in MECP2 duplication syndrome human iPSC-derived neurons reveals gene expression programs responsive to …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Be9T0PsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Be9T0PsAAAAJ:Se3iqnhoufwC,"Genomic copy-number variations (CNVs) that can cause neurodevelopmental disorders often encompass many genes, which complicates our understanding of how individual genes within a CNV contribute to pathology. MECP2 duplication syndrome (MDS or MRXSL in OMIM; OMIM#300260) is one such CNV disorder caused by duplications spanning methyl CpG-binding protein 2 (MECP2) and other genes on Xq28. Using an antisense oligonucleotide (ASO) to normalize MECP2 dosage is sufficient to rescue abnormal neurological phenotypes in mouse models overexpressing MECP2 alone, implicating the importance of increased MECP2 dosage within CNVs of Xq28. However, because MDS CNVs span MECP2 and additional genes, we generated human neurons from multiple MDS patient-derived induced pluripotent cells (iPSCs) to evaluate the benefit of using an ASO against MECP2 in a MDS human …",Oxford University Press,,2024
166,A novel pathogenic mutation of MeCP2 impairs chromatin association independent of protein levels,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Be9T0PsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Be9T0PsAAAAJ:roLk4NBRz8UC,"Loss-of-function mutations in MECP2 cause Rett syndrome (RTT), a severe neurological disorder that mainly affects girls. Mutations in MECP2 do occur in males occasionally and typically cause severe encephalopathy and premature lethality. Recently, we identified a missense mutation (c. 353G> A, p. Gly118Glu [G118E]), which has never been seen before in MECP2, in a young boy who suffered from progressive motor dysfunction and developmental delay. To determine whether this variant caused the clinical symptoms and study its functional consequences, we established two disease models, including human neurons from patient-derived iPSCs and a knock-in mouse line. G118E mutation partially reduces MeCP2 abundance and its DNA binding, and G118E mice manifest RTT-like symptoms seen in the patient, affirming the pathogenicity of this mutation. Using live-cell and single-molecule imaging, we found …",Cold Spring Harbor Lab,,2023
167,"MeCP2 regulates Gdf11, a dosage-sensitive gene critical for neurological function",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Be9T0PsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Be9T0PsAAAAJ:LkGwnXOMwfcC,"Loss-and gain-of-function of MeCP2 causes Rett syndrome (RTT) and MECP2 duplication syndrome (MDS), respectively. MeCP2 binds methyl-cytosines to finely tune gene expression in the brain, but identifying genes robustly regulated by MeCP2 has been difficult. By integrating multiple transcriptomics datasets, we revealed that MeCP2 finely regulates growth differentiation factor 11 (Gdf11). Gdf11 is down-regulated in RTT mouse models and, conversely, up-regulated in MDS mouse models. Strikingly, genetically normalizing Gdf11 dosage levels improved several behavioral deficits in a mouse model of MDS. Next, we discovered that losing one copy of Gdf11 alone was sufficient to cause multiple neurobehavioral deficits in mice, most notably hyperactivity and decreased learning and memory. This decrease in learning and memory was not due to changes in proliferation or numbers of progenitor cells in the hippocampus. Lastly, loss of one copy of Gdf11 decreased survival in mice, corroborating its putative role in aging. Our data demonstrate that Gdf11 dosage is important for brain function.",eLife Sciences Publications Limited,,2023
168,Developing active learning of Linear Algebra in Engineering by incorporating MATLAB and Autograder,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L-TiSRAAAAAJ&citation_for_view=L-TiSRAAAAAJ:d1gkVwhDpl0C,"The purpose of this paper is to redesign a traditional linear algebra course that focuses mainly on theoretical concepts without any numerical application, in order to enhance the learning experience for students. This was achieved by conducting a comprehensive study of the students' needs, contents covered, pedagogical approaches used at peer institutions, and existing literature published by experts in the field.",,,2023
169,Finding Gateaux-saddles by a local minimax method,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L-TiSRAAAAAJ&citation_for_view=L-TiSRAAAAAJ:9yKSN-GCB0IC,"Motivated by quasilinear elliptic PDEs in physical applications, Gateaux-saddles of a class of functionals J:H→{±∞}∪ℝ, which are only Gateaux-differentiable at regular points, are considered. Since mathematical results and numerical methods for saddles of 𝒞1 or locally Lipschitz continuous functionals in the literature are not applicable, the main objective of this article is to introduce a new mixed norm strong-weak topology approach such that a mathematical framework of a local minimax method is established to handle the singularity issue and to use the Gateaux-derivative of J for finding multiple Gateaux-saddles. Algorithm implementations on weak form and error control are presented. Numerical examples solving quasilinear elliptic problems from physical applications are successfully carried out to illustrate the method. Some interesting solution properties are to be numerically observed and open for analytical …",Taylor & Francis,,2017
170,Student Perceptions on the Effectiveness of Incorporating Numerical Computations into an Engineering Linear Algebra Course,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L-TiSRAAAAAJ&citation_for_view=L-TiSRAAAAAJ:zYLM7Y9cAGgC,"Experts and researchers have indicated that the integration of programming languages (eg, MATLAB, Python, Mathematica, etc.) into linear algebra classes would be advantageous. In response, we restructured APMA 3080-Linear Algebra by adding four numerical computational components, utilizing MATLAB as the principal tool in this course. This modification is elaborately depicted in a published ASEE paper. In this study, our interest lies in thoroughly analyzing students' perceptions of the efficacy of integrating numerical computational components through MATLAB to bolster their success, shifting the focus from solely expert perspectives. More specifically, the key research questions are:",,,2024
171,WIP: Integrating Student-developed Applications and In-class Learning Games to Optimize Learning Outcomes: A Case Study in An Introductory Statistical Learning and Programming …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L-TiSRAAAAAJ&citation_for_view=L-TiSRAAAAAJ:ufrVoPGSRksC,"Advancements in educational technology have significantly enhanced teaching methods in applied mathematics, yet engaging students remains a challenge due to its complexity. Traditional methods, such as lectures and problem sets, often fall short in addressing abstract concepts, computational difficulties, and the practical applications of theory in an interactive way. Student-developed applications, closely aligned with the specific challenges learners face, target common learning difficulties more effectively than those created by instructors or commercial developers. While research exists on technology use in education, the impact of student-generated applications has not been fully explored, particularly when integrated with in-class learning games. This study addresses the gap by investigating the efficacy of 18 student-developed Shiny R web-based applications within the introductory statistical learning and programming course,“From Data to Knowledge.”",,,2025
172,Student perception on Inquiry Based Learning Ordinary Differential Equation course,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L-TiSRAAAAAJ&citation_for_view=L-TiSRAAAAAJ:WF5omc3nYNoC,"At many higher education institutions, differential equations classes focus on solving equations through symbolic manipulation, with applications often presented as isolated topics scattered throughout the semester. Starting in 2021, to better integrate applications and promote critical thinking, differential equation professors at one institution shifted from a traditional lecture-based approach to an inquiry-oriented, worksheet-based format. In this new design, students learn through daily structured worksheets that typically begin with an application motivating the need to solve a new type of differential equation. These worksheets guide students to develop methods for solving these equations by building on prior knowledge.",,,2025
173,Integrating Precalculus into Calculus II and Its Outcomes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L-TiSRAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=L-TiSRAAAAAJ:Y0pCki6q_DkC,"Integrating Precalculus into Calculus II and Its Outcomes In many calculus courses, a lack of precalculus skills can be a major hindrance to student success. At our institution, lots of students often take Calculus II directly after graduating from high school, with varying levels of precalculus preparation. As a result, many students consistently make precalculus-related errors in their calculus courses, which leads to increased academic challenges and reduced confidence. However, practical constraints like extended graduation timelines and financial limitations have prevented a dedicated precalculus course. To foster a more inclusive and equitable learning environment, the purpose of this research is to offer precalculus practice opportunities that are accessible to all students, allowing them to improve their precalculus skills without becoming overwhelmed. This is accomplished by integrating precalculus instruction into the curriculum of Calculus II and evaluating its impact.",,,2024
174,Exploring Effective Pedagogical Approaches for Teaching Linear Algebra to Engineering Students: A Literature Review,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L-TiSRAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=L-TiSRAAAAAJ:Tyk-4Ss8FVUC,"A few years ago, when the authors embarked on the task of redesigning a linear algebra course for engineering students, there was a lack of available review papers providing a comprehensive foundation on the topic and an explanation of the current state of knowledge for engineering students. Undeterred, the authors undertook an extensive examination of existing literature related to linear algebra and carefully examined their applicability for engineering students, to successfully redevelop the course. Subsequently, the objective of this paper is to provide a list of pedagogical methods the authors has reviewed for teaching linear algebra courses that applicable to engineering students. The ultimate intention is to assist future scholars who may find themselves in a similar position as the author, enabling them to save a significant amount of time by benefiting from the insights presented in this paper.",,2024 ASEE Annual Conference & Exposition,2024
175,Dynamic multinuclear sites formed by mobilized copper ions in NOx selective catalytic reduction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2gZgq68AAAAJ&citation_for_view=2gZgq68AAAAJ:Zph67rFs4hoC,"Copper ions exchanged into zeolites are active for the selective catalytic reduction (SCR) of nitrogen oxides (NOx) with ammonia (NH3), but the low-temperature rate dependence on copper (Cu) volumetric density is inconsistent with reaction at single sites. We combine steady-state and transient kinetic measurements, x-ray absorption spectroscopy, and first-principles calculations to demonstrate that under reaction conditions, mobilized Cu ions can travel through zeolite windows and form transient ion pairs that participate in an oxygen (O2)–mediated CuI→CuII redox step integral to SCR. Electrostatic tethering to framework aluminum centers limits the volume that each ion can explore and thus its capacity to form an ion pair. The dynamic, reversible formation of multinuclear sites from mobilized single atoms represents a distinct phenomenon that falls outside the conventional boundaries of a heterogeneous or …",American Association for the Advancement of Science,,2017
176,Catalysis in a cage: condition-dependent speciation and dynamics of exchanged Cu cations in SSZ-13 zeolites,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2gZgq68AAAAJ&citation_for_view=2gZgq68AAAAJ:9yKSN-GCB0IC,"The relationships among the macroscopic compositional parameters of a Cu-exchanged SSZ-13 zeolite catalyst, the types and numbers of Cu active sites, and activity for the selective catalytic reduction (SCR) of NOx with NH3 are established through experimental interrogation and computational analysis of materials across the catalyst composition space. Density functional theory, stochastic models, and experimental characterizations demonstrate that within the synthesis protocols applied here and across Si:Al ratios, the volumetric density of six-membered-rings (6MR) containing two Al (2Al sites) is consistent with a random Al siting in the SSZ-13 lattice subject to Löwenstein’s rule. Further, exchanged CuII ions first populate these 2Al sites before populating remaining unpaired, or 1Al, sites as CuIIOH. These sites are distinguished and enumerated ex situ through vibrational and X-ray absorption spectroscopies …",American Chemical Society,,2016
177,Isolation of the copper redox steps in the standard selective catalytic reduction on Cu‐SSZ‐13,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2gZgq68AAAAJ&citation_for_view=2gZgq68AAAAJ:Se3iqnhoufwC,"Operando X‐ray absorption experiments and density functional theory (DFT) calculations are reported that elucidate the role of copper redox chemistry in the selective catalytic reduction (SCR) of NO over Cu‐exchanged SSZ‐13. Catalysts prepared to contain only isolated, exchanged CuII ions evidence both CuII and CuI ions under standard SCR conditions at 473 K. Reactant cutoff experiments show that NO and NH3 together are necessary for CuII reduction to CuI. DFT calculations show that NO‐assisted NH3 dissociation is both energetically favorable and accounts for the observed CuII reduction. The calculations predict in situ generation of Brønsted sites proximal to CuI upon reduction, which we quantify in separate titration experiments. Both NO and O2 are necessary for oxidation of CuI to CuII, which DFT suggests to occur by a NO2 intermediate. Reaction of Cu‐bound NO2 with proximal NH4+ completes …",WILEY‐VCH Verlag,,2014
178,Identification of the active Cu site in standard selective catalytic reduction with ammonia on Cu-SSZ-13,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2gZgq68AAAAJ&citation_for_view=2gZgq68AAAAJ:MXK_kJrjxJIC,"Copper-exchanged SSZ-13 catalysts were used for the standard selective catalytic reduction (SCR) reaction at 473 K with 320 ppm NO, 320 ppm NH3, 10% O2, 8% CO2, and 6% H2O. The copper to total aluminum atomic ratio (Cu:Altot) was varied from 0 to 0.35 (copper to framework Al ratio (Cu:Alf) = 0–0.41) over seven samples with silicon to total aluminum atomic ratio (Si:Altot) ranging between 4.3 and 4.5 (silicon to framework Al (Si:Alf) = 5.1–5.3). The standard SCR rate per gram was observed to increase linearly up to Cu:Altot = 0.2 (Cu:Alf = 0.23) with a maximum rate of 3.8 × 10−6 mol NO g cat−1 s−1, which ruled out heat and mass transfer effects by the Koros–Nowak test. The rate per gram was observed to track with a hydrated Cu(II) species in ultraviolet–visible–near infrared spectroscopy (UV–Vis–NIR) at ambient conditions. This species was shown by operando X-ray absorption spectroscopy (XAS) to …",Academic Press,,2014
179,NO oxidation: A probe reaction on Cu-SSZ-13,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2gZgq68AAAAJ&citation_for_view=2gZgq68AAAAJ:UebtZRa9Y70C,"The site requirements and mechanism of dry NO oxidation were examined on a series of Cu-SSZ-13 catalysts (silicon/aluminum atomic ratio = 4.5) with Cu:total-aluminum (Cu/Altot) atomic ratios ranging from 0.02 to 1.6. Catalysts with Cu/Altot atomic ratio < 0.2 exhibit immeasurable NO oxidation rates (per mole Cu), while NO oxidation rates increase monotonically with Cu/Altot atomic ratio from 0.2 up to 0.5. Hydrated Cu-SSZ-13 catalysts with Cu/Altot atomic ratio < 0.2 exhibit a near infrared feature at 12,500 cm–1 under ambient conditions that we assign to a d–d transition of an isolated, hydrated Cu2+ ion. X-ray absorption near edge structure (XANES) measurements on the same catalysts under ambient conditions quantitatively match a [Cu(H2O)6]2+ reference. The 12,500 cm–1 feature intensity is constant above Cu/Altot atomic ratio = 0.2, implying that the additional Cu ions adopt other configurations. Catalysts …",Academic Press,,2014
180,Singlet-Fission Dynamics Modified through Templated Organic Semiconductor Crystallization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2gZgq68AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2gZgq68AAAAJ:NhqRSupF_l8C,"Singlet fission (SF) is a process of multiexciton generation in molecular semiconductor materials that holds promise for improving light-to-charge conversion efficiencies in photovoltaic devices. Molecular packing structure is well-known to impact the electronic coupling that underlies triplet-pair generation, as well as pair separation and triplet transport that occur through singlet fission, ultimately affecting the potential to increase conversion efficiencies in light-harvesting devices. We previously demonstrated that templating the crystallization of 6,13-bis(triisopropylsilylethynyl)pentacene (TIPS-Pn) films on a series of lead-halide perovskites provides a means to control intermolecular packing and alter the kinetics of triplet-pair separation and recombination. Here we contrast triplet transport with the ultrafast interconversion of the singlet exciton to the correlated triplet pair and the dependence of these processes on template-modified crystal packing. We observe that rate constants for the conversion of singlet excitons to correlated triplet pairs likewise are sensitive to the template structure but with a trend that is anticorrelated with those for triplet-pair separation and triplet-triplet annihilation. This observation is consistent with the divergent requisite frontier orbital overlap symmetries of adjacent chromophores that underlie the electronic coupling associated with the generation of triplet pairs and the subsequent triplet transport. We examine how the template-dependent packing structures, as determined by molecular dynamics simulations of a film-template interface, alter figures of merit for electronic interactions (estimated by frontier-orbital overlaps) that …",,,2025
181,"Influence of Temperature, Water, and Dioxygen on the Interconversion of Monomeric and Dimeric Cu Configurations in Cu-SSZ-13",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2gZgq68AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2gZgq68AAAAJ:D03iK_w7-QYC,"Dynamic transformations of active sites in Cu-SSZ-13 in response to changing temperatures, water (H2O) pressures, and dioxygen (O2) pressures have been investigated using successive transient CO titration and NO + NH3 titration experiments. The proportion of the CO-titratable dimeric CuII sites increases with temperature and decreases upon hydrothermal aging (HTA). Integral CO2 formation and NO consumption data indicate that the CO-titratable active site configuration is a mono μ-oxo dicopper (Z2Cu2O) or bis μ-hydroxyl dicopper (Z2Cu2O2H2) species generated from condensation of proximal ZCuOH monomers. Spatially distant ZCuOH monomers require temperatures above 300 °C for intercage diffusion and subsequent dimerization. Autoreduction accounts for 20–25% of the CuI fraction during CO titration at high temperatures. Isolated Z2Cu sites do not participate in CO titration and are not …",American Chemical Society,,2025
182,Liquid-like Pore Environments Promote Dynamic Multi-Site Oxidation Catalysis over Metal-Zeolites,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2gZgq68AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2gZgq68AAAAJ:f2IySw72cVMC,,AIChE,,2025
183,Machine Learning Force Field Applied to Studying the Effects of Oxygen and Chlorine on Silver Catalysts Reconstruction in Ethylene Epoxidation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2gZgq68AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2gZgq68AAAAJ:b0M2c_1WBrUC,,AIChE,,2025
184,Effect of Ligand Environment for Wacker Oxidation in FAU Zeolites,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2gZgq68AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2gZgq68AAAAJ:EUQCXRtRnyEC,,AIChE,,2025
185,Climate adaptation as a control problem: Review and perspectives on dynamic water resources planning under uncertainty,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4W9ZUSQAAAAJ&citation_for_view=4W9ZUSQAAAAJ:W7OEmFMy1HYC,"Climate change introduces substantial uncertainty to water resources planning and raises the key question: when, or under what conditions, should adaptation occur? A number of recent studies aim to identify policies mapping future observations to actions—in other words, framing climate adaptation as an optimal control problem. This paper uses the control paradigm to review and classify recent dynamic planning studies according to their approaches to uncertainty characterization, policy structure, and solution methods. We propose a set of research gaps and opportunities in this area centered on the challenge of characterizing uncertainty, which prevents the unambiguous application of control methods to this problem. These include exogenous uncertainty in forcing, model structure, and parameters propagated through a chain of climate and hydrologic models; endogenous uncertainty in human‐environmental …",,,2020
186,Rival framings: A framework for discovering how problem formulation uncertainties shape risk management trade‐offs in water resources systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4W9ZUSQAAAAJ&citation_for_view=4W9ZUSQAAAAJ:9yKSN-GCB0IC,"Managing water resources systems requires coordinated operation of system infrastructure to mitigate the impacts of hydrologic extremes while balancing conflicting multisectoral demands. Traditionally, recommended management strategies are derived by optimizing system operations under a single problem framing that is assumed to accurately represent the system objectives, tacitly ignoring the myriad of effects that could arise from simplifications and mathematical assumptions made when formulating the problem. This study illustrates the benefits of a rival framings framework in which analysts instead interrogate multiple competing hypotheses of how complex water management problems should be formulated. Analyzing rival framings helps discover unintended consequences resulting from inherent biases of alternative problem formulations. We illustrate this on the monsoonal Red River basin in Vietnam by …",,,2017
187,"Exploring How Changing Monsoonal Dynamics and Human Pressures Challenge Multireservoir Management for Flood Protection, Hydropower Production, and Agricultural Water Supply",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4W9ZUSQAAAAJ&citation_for_view=4W9ZUSQAAAAJ:UeHWp8X0CEIC,"Multireservoir systems require robust and adaptive control policies capable of managing hydroclimatic variability and human demands across a range of time scales. This is especially true for river basins with high intraannual and interannual variability, such as monsoonal systems that need to buffer against seasonal droughts while also managing extreme floods. Moreover, the timing, intensity, duration, and frequency of these hydrologic extremes may evolve with deeply uncertain changes in socioeconomic and climatic pressures. This study contributes an innovative method for exploring how possible changes in the timing and magnitude of the monsoonal cycle impact the robustness of reservoir operating policies designed assuming stationary hydrologic and socioeconomic conditions. We illustrate this analysis on the Red River basin in Vietnam, where reservoirs and dams serve as important sources of …",,,2018
188,Direct policy search for robust multi-objective management of deeply uncertain socio-ecological tipping points,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4W9ZUSQAAAAJ&citation_for_view=4W9ZUSQAAAAJ:2osOgNQ5qMEC,"Managing socio-ecological systems is a challenge wrought by competing societal objectives, deep uncertainties, and potentially irreversible tipping points. A classic, didactic example is the shallow lake problem in which a hypothetical town situated on a lake must develop pollution control strategies to maximize its economic benefits while minimizing the probability of the lake crossing a critical phosphorus (P) threshold, above which it irreversibly transitions into a eutrophic state. Here, we explore the use of direct policy search (DPS) to design robust pollution control rules for the town that account for deeply uncertain system characteristics and conflicting objectives. The closed loop control formulation of DPS improves the quality and robustness of key management tradeoffs, while dramatically reducing the computational complexity of solving the multi-objective pollution control problem relative to open loop control …",Elsevier,,2017
189,"Balancing exploration, uncertainty and computational demands in many objective reservoir optimization",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4W9ZUSQAAAAJ&citation_for_view=4W9ZUSQAAAAJ:qjMakFHDy7sC,"Reservoir operations are central to our ability to manage river basin systems serving conflicting multi-sectoral demands under increasingly uncertain futures. These challenges motivate the need for new solution strategies capable of effectively and efficiently discovering the multi-sectoral tradeoffs that are inherent to alternative reservoir operation policies. Evolutionary many-objective direct policy search (EMODPS) is gaining importance in this context due to its capability of addressing multiple objectives and its flexibility in incorporating multiple sources of uncertainties. This simulation-optimization framework has high potential for addressing the complexities of water resources management, and it can benefit from current advances in parallel computing and meta-heuristics. This study contributes a diagnostic assessment of state-of-the-art parallel strategies for the auto-adaptive Borg Multi Objective Evolutionary …",Elsevier,,2017
190,Comparing Robust Optimization Approaches for Addressing Hydrologic Model Uncertainty in Infrastructure Planning: A Green Infrastructure Example,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4W9ZUSQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=4W9ZUSQAAAAJ:ZeXyd9-uunAC,"Water resources planning is dependent on hydrologic models to estimate flows and storage in candidate engineering designs. However, such models are calibrated with limited flow data relative to the many model parameters. This may result in different equifinal parameterizations that imply different optimal designs. To assess if and how this uncertainty should be considered, we compare three methods for multiobjective optimization of green infrastructure (GI): one that designs to the most likely parameterization and two robust alternatives that use several likely parameterizations with (1) likelihood-weighted objective functions, and (2) min-max objective functions. To evaluate these methods, we set synthetic true values for model parameters, use them to simulate observed streamflow, and then use Bayesian calibration to estimate parametric uncertainty. We compare results from optimization to the synthetic …",American Society of Civil Engineers,,2025
191,Quantifying and Designing Infrastructure for Nonstationary Flood Risks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4W9ZUSQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=4W9ZUSQAAAAJ:IWHjjKOFINEC,"In recent years, climate change has led to a rise in intense precipitation events, presenting the need for efficient and cost-effective flood management infrastructure. In Charlottesville, VA, one key area identified for improvement is Meadow Creek. This paper examines different infrastructure options for flood management in Meadow Creek under various climate change scenarios. This analysis is carried out by optimizing infrastructure designs with the Environmental Protection Agency’s Storm Water Management Model under uncertain future conditions captured by climate projections from the Coupled Model Intercomparison Project 6. The optimization seeks to minimize cost and runoff volume while maximizing cobenefits. Our findings provide a set of non-dominated green infrastructure solutions and provide a methodology for selecting a recommended compromise solution. This analysis contributes to our goal of …",IEEE,,2025
192,"Dam Reoperation to Mitigate Changing Climate Extremes in the Omo River Basin, Ethiopia",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4W9ZUSQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=4W9ZUSQAAAAJ:7PzlFSSx8tAC,"Climate change is projected to increase the intensity and frequency of extremes in river basins around the world. Water infrastructure such as reservoirs are often used to buffer against these extremes, enabling a more reliable water supply for human uses like irrigation. Yet this can have negative impacts on the system’s ecological flows. In designing water infrastructure for human adaptation to climate change, it is important to consider whether the infrastructure is mitigating or exacerbating climate change impacts on ecological systems. Prior work has found that dams mitigate long-duration extremes but exacerbate short-duration extremes. In this study, we investigate whether reservoir operations can be designed to also yield beneficial climate adaptation outcomes for short-duration high and low flow extremes while still improving average socioeconomic and ecological objectives compared to uncontrolled …",American Society of Civil Engineers,,2024
193,Exploring the benefits of integrated energy-water management in reducing economic and environmental tradeoffs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4W9ZUSQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=4W9ZUSQAAAAJ:QIV2ME_5wuYC,"Integrated water-energy management is crucial for balancing socioeconomic and environmental objectives in multi-reservoir systems. Multipurpose reservoirs support clean energy production, recreation, navigation, and flood protection but also disrupt natural water flows and fish migration. As hydropower's role evolves with grid decarbonization, managing these tradeoffs becomes increasingly complex. An integrated model combining economic and environmental factors is essential to inform how to adapt hydropower operations effectively to complement decarbonization of the electric grid. However, existing literature lacks such comprehensive models. This study introduces an integrated water-energy optimization model using the Columbia River Basin (CRB) and Mid-Columbia energy market as a case study. The model couples a simulation of operations of 47 CRB reservoirs with a unit commitment/economic …",IOP Publishing,,2024
194,Scenario storyline discovery for planning in multi‐actor human‐natural systems confronting change,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4W9ZUSQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=4W9ZUSQAAAAJ:L8Ckcad2t8MC,"Scenarios have emerged as valuable tools in managing complex human‐natural systems, but the traditional approach of limiting focus on a small number of predetermined scenarios can inadvertently miss consequential dynamics, extremes, and diverse stakeholder impacts. Exploratory modeling approaches have been developed to address these issues by exploring a wide range of possible futures and identifying those that yield consequential vulnerabilities. However, vulnerabilities are typically identified based on aggregate robustness measures that do not take full advantage of the richness of the underlying dynamics in the large ensembles of model simulations and can make it hard to identify key dynamics and/or storylines that can guide planning or further analyses. This study introduces the FRamework for Narrative Storylines and Impact Classification (FRNSIC; pronounced “forensic”): a scenario discovery …",,,2024
195,A versatile sharp interface immersed boundary method for incompressible flows with complex boundaries,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SrYdog8AAAAJ&citation_for_view=SrYdog8AAAAJ:YOwf2qJgpHMC,"A sharp interface immersed boundary method for simulating incompressible viscous flow past three-dimensional immersed bodies is described. The method employs a multi-dimensional ghost-cell methodology to satisfy the boundary conditions on the immersed boundary and the method is designed to handle highly complex three-dimensional, stationary, moving and/or deforming bodies. The complex immersed surfaces are represented by grids consisting of unstructured triangular elements; while the flow is computed on non-uniform Cartesian grids. The paper describes the salient features of the methodology with special emphasis on the immersed boundary treatment for stationary and moving boundaries. Simulations of a number of canonical two- and three-dimensional flows are used to verify the accuracy and fidelity of the solver over a range of Reynolds numbers. Flow past suddenly accelerated bodies are …",Academic Press,,2008
196,Wake topology and hydrodynamic performance of low-aspect-ratio flapping foils,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SrYdog8AAAAJ&citation_for_view=SrYdog8AAAAJ:_kc_bZDykSQC,Numerical simulations are used to investigate the effect of aspect ratio on the wake topology and hydrodynamic performance of thin ellipsoidal flapping foils. The study is motivated by the quest to understand the hydrodynamics of fish pectoral fins. The simulations employ an immersed boundary method that allows us to simulate flows with complex moving boundaries on fixed Cartesian grids. A detailed analysis of the vortex topology shows that the wake of low-aspect-ratio flapping foils is dominated by two sets of interconnected vortex loops that evolve into distinct vortex rings as they convect downstream. The flow downstream of these flapping foils is characterized by two oblique jets and the implications of this characteristic on the hydrodynamic performance are examined. Simulations are also used to examine the thrust and propulsive efficiency of these foils over a range of Strouhal and Reynolds numbers as well …,Cambridge University Press,,2006
197,A sharp interface immersed boundary method for compressible viscous flows,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SrYdog8AAAAJ&citation_for_view=SrYdog8AAAAJ:4TOpqqG69KYC,"An immersed boundary method for computing viscous, subsonic compressible flows with complex shaped stationary immersed boundaries is presented. The method employs a ghost-cell technique for imposing the boundary conditions on the immersed boundaries. The current approach leads to a sharp representation of the immersed boundaries, a property that is especially useful for flow simulations at high Reynolds numbers. Another unique feature of the method is that it can be applied on Cartesian as well as generalized body non-conformal curvilinear meshes. A mixed second-order central difference-QUICK scheme is used which allows a high degree of control over the numerical damping. A bilinear interpolation scheme used in conjunction with the ghost-cell approach results in second-order global as well as local spatial accuracy. The solver is parallelized for distributed memory platforms using domain …",Academic Press,,2007
198,Computational analysis of vortex dynamics and performance enhancement due to body–fin and fin–fin interactions in fish-like locomotion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SrYdog8AAAAJ&citation_for_view=SrYdog8AAAAJ:O0nohqN1r9EC,"Numerical simulations are used to investigate the hydrodynamic benefits of body–fin and fin–fin interactions in a fish model in carangiform swimming. The geometry and kinematics of the model are reconstructed in three-dimensions from high-speed videos of a live fish, Crevalle Jack (Caranx hippos), during steady swimming. The simulations employ an immersed-boundary-method-based incompressible Navier–Stokes flow solver that allows us to quantitatively characterize the propulsive performance of the fish median fins (the dorsal and the anal fins) and the caudal fin using three-dimensional full body simulations. This includes a detailed analysis of associated performance enhancement mechanisms and their connection to the vortex dynamics. Comparisons are made using three different models containing different combinations of the fish body and fins to provide insights into the force production. The results …",Cambridge University Press,,2017
199,Locomotion with flexible propulsors: I. Experimental analysis of pectoral fin swimming in sunfish,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SrYdog8AAAAJ&citation_for_view=SrYdog8AAAAJ:M3ejUd6NZC8C,"A full understanding of the mechanics of locomotion can be achieved by incorporating descriptions of (1) three-dimensional kinematics of propulsor movement,(2) material properties of the propulsor,(3) power input and control and (4) the fluid dynamics effects of propulsor motion into (5) a three-dimensional computational framework that models the complexity of propulsors that deform and change area. In addition, robotic models would allow for further experimental investigation of changes to propulsor design and for testing of hypothesized relationships between movement and force production. Such a comprehensive suite of data is not yet available for any flexible propulsor. In this paper, we summarize our research program with the goal of producing a comprehensive data set for each of the five components noted above through a study of pectoral fin locomotion in one species of fish: the bluegill sunfish Lepomis …",IOP Publishing,,2006
200,Computational analysis of fish-foil pairing and wake energy extraction in low-speed flow,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SrYdog8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=SrYdog8AAAAJ:vnF2_uLGgtgC,"The energetic consequences of swimming within a neighboring fish’s vortex street remain a central question in collective locomotion. Recent flume experiments in which a flapping hydrofoil generated a biomimetic wake demonstrated that a trout can station-keep behind the foil while displaying kinematics markedly different from those used in uniform flow. To examine the underlying hydrodynamics, we accurately replicate the fish-foil system by first reproducing the experimentally recorded motions using a joint-based kinematic reconstruction method, and then we simulate the fluid dynamics with three-dimensional computational fluid dynamics. A companion simulation without the foil is also conducted to isolate wake effects. Relative to uniform-flow swimming, the presence of the foil wake reduces the trout’s cycle-averaged hydrodynamic power expenditure by 11.4±0.0003%, a benefit that arises because vortex …",IOP Publishing,,2025
201,Fin-Fin Interactions and the Impact on Performance of an Underwater Tuna-Like Robot,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SrYdog8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=SrYdog8AAAAJ:3lUAU8Oskd0C,"The presence of median fins on fish bodies has been found to enhance swimming performance in carangiform locomotion through wake interactions with caudal fin vortices. Tunas are unique in possessing both dorsal and anal fins, as well as smaller finlet structures along their posterior body region. In the development of bio-inspired swimming robots, optimizing the location and size of these fins is crucial. This paper presents a parametric study that examines the effects of various median fin arrangements on the hydrodynamic performance of a model tuna robot. The body motion of the computational model is based on kinematic data from a tuna robot model. Dorsal and anal fin pairs were modeled, with variations in their height, aspect ratio, and positioning along the body. The body motion and flow speed are held constant for each case. The cases are run on an in-house flow solver that uses an immersed …",American Society of Mechanical Engineers,,2025
202,Data-Driven Optimization of Fish Schooling Formations for Enhanced Propulsive Efficiency,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SrYdog8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=SrYdog8AAAAJ:xyvS_IvSCKsC,"The non-convex nature of optimizing propulsive efficiency in fish schools arises from the non-linear relationship between performance and vortex interactions, and the possibility of interacting with vortices at multiple locations downstream. As a result, gradient-based methods that rely on linearized assumptions often fall short of achieving optimal performance. This paper describes an optimization model that employs a Kriging guided Genetic Algorithm as the iterative model and an in-house Computational Fluid Dynamics (CFD) code as the evaluation mechanism. The in-house flow solver solves the incompressible Navier-Stokes equations, on a non-body-conforming Cartesian grid, using a sharp-interface immersed boundary method (IBM) to accurately impose the boundary conditions. The Kriging guided Genetic Algorithm (GA) seeks to maximize the group efficiency of a 2-D fish school by changing the …",American Society of Mechanical Engineers,,2025
203,Hydrodynamic Interactions Between Schooling Fish in a Three-Dimensional Non-Planar Cluster,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SrYdog8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=SrYdog8AAAAJ:KI9T_ytC6pkC,"Schooling fish can fall into many different positions relative to their neighbors, resulting in different hydrodynamic interactions. Fish in large schools have been observed to share similar frontal planes relative to their neighbors, especially those at the front of the school, and differ from each other in their depths. In this work, we analyze two frontal triangular formations: side triangle (ST) and downward triangle (DT). In these formations the neighbors share the same frontal plane (same streamwise position) but vary in depth. In our prior study of the side-by-side interactions between neighbors, the undulating phase difference between the nearest laterally separated neighbors heavily impact the propulsive performance of the swimmers. Thus, in this study, we varied the phase difference between nearest lateral neighbors, between values of 0 and π, to analyze the in-phase and anti-phase modes of interaction. We …",American Society of Mechanical Engineers,,2025
204,Hydrodynamic Impacts of Body Shape on Propulsion Efficiency in Underwater Robot Design,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SrYdog8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=SrYdog8AAAAJ:TGkaJS32XoUC,"Many studies have been conducted to understand kinematic design parameters and their effects on propulsive performance in fish and their bio-inspired robotic counterparts. Little attention has been given, however, to the impacts of body morphology on the hydrodynamic performance in undulating swimmers. In this research, we parametrically study the effects of three-dimensional fish body shape on the hydrodynamic drag, thrust, and efficiency in a carangiform swimmer. This research develops a novel method for generating fish-like body shapes that maintain the basic characteristics of a carangiform fish body. A class shape transformation method is used to define an airfoil shape for the top and side profiles of the fish body, and an ellipse connects the two foil shapes to define a three-dimensional body. This method allows the measurement and change of basic airfoil shape characteristics (leading edge …",American Society of Mechanical Engineers,,2025
205,Capacitive biopotential measurement for electrophysiological signal acquisition: A review,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7oNkNtIAAAAJ&citation_for_view=7oNkNtIAAAAJ:mVmsd5A6BfQC,"A conventional clinical biopotential measurement system requires the use of wet electrodes that are in contact with skin using conductive gel. Those systems can acquire high-quality signals but may not be feasible for a long-term purpose due to the skin irritation and allergic contact dermatitis. The emerging of human-centered monitoring calls for alternative solutions. Recent technological advances enable capacitive measurement of electrophysiological measurement, which can acquire signals through cloth or even with an air gap; however, difficulties still exist. This paper systemically reviews the recent progress in capacitive measurement from electrode design, analog front end to high-level system architecture, aiming to provide comprehensive and practical instructions for entire system design. The current development serves as the solid fundamental, raising new solutions for future improvement. In addition, the …",IEEE,IEEE Sensors Journal,2016
206,An innovative nonintrusive driver assistance system for vital signal monitoring,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7oNkNtIAAAAJ&citation_for_view=7oNkNtIAAAAJ:Tyk-4Ss8FVUC,"This paper describes an in-vehicle nonintrusive biopotential measurement system for driver health monitoring and fatigue detection. Previous research has found that the physiological signals including eye features, electrocardiography (ECG), electroencephalography (EEG) and their secondary parameters such as heart rate and HR variability are good indicators of health state as well as driver fatigue. A conventional biopotential measurement system requires the electrodes to be in contact with human body. This not only interferes with the driver operation, but also is not feasible for long-term monitoring purpose. The driver assistance system in this paper can remotely detect the biopotential signals with no physical contact with human skin. With delicate sensor and electronic design, ECG, EEG, and eye blinking can be measured. Experiments were conducted on a high fidelity driving simulator to validate the system …",IEEE,,2014
207,A fiber Bragg grating sensor for radial artery pulse waveform measurement,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7oNkNtIAAAAJ&citation_for_view=7oNkNtIAAAAJ:blknAaTinKkC,"In this paper, we report the design and experimental validation of a novel optical sensor for radial artery pulse measurement based on fiber Bragg grating (FBG) and lever amplification mechanism. Pulse waveform analysis is a diagnostic tool for clinical examination and disease diagnosis. High fidelity radial artery pulse waveform has been investigated in clinical studies for estimating central aortic pressure, which is proved to be predictors of cardiovascular diseases. As a three-dimensional cylinder, the radial artery needs to be examined from different locations to achieve optimal pulse waveform for estimation and diagnosis. The proposed optical sensing system is featured as high sensitivity and immunity to electromagnetic interference for multilocation radial artery pulse waveform measurement. The FBG sensor can achieve the sensitivity of 8.236 nm/N, which is comparable to a commonly used electrical sensor …",IEEE,,2017
208,Critical insights for advanced bridge scour detection using the natural frequency,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7oNkNtIAAAAJ&citation_for_view=7oNkNtIAAAAJ:TQgYirikUcIC,"Scour around bridge foundations is regarded as one of the predominant causes of bridge failures. The concept of vibration-based real-time bridge scour detection has been explored in recent years by investigating the change in the natural frequency spectrum of a bridge or a bridge component with respect to the scour depth. Despite the progress, significant issues still remain unsolved in the application of this concept. This paper investigates three unsolved issues in the current framework of scour detection using the natural frequency spectrum: the physical meaning of the measured predominant natural frequency, the location of sensor installation, and the influence of the shape of scour holes, which are easily neglected but critical to the further implementations of the natural frequency spectrum-based bridge scour detection. Firstly, in-depth discussions of these three major issues were made separately by …",Academic Press,,2017
209,Non-contact sensing of physiological signals,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7oNkNtIAAAAJ&citation_for_view=7oNkNtIAAAAJ:W7OEmFMy1HYC,"BACKGROUND [0004] Tra? ic accidents are projected to be the third leading cause of death and disability in 2020. Driver fatigue is a leading cause of tra? ic accidents. For example, the Federal Motor Carrier Safety Administration (FMCSA) issued regu lations on the Hours of Service (HOS) in order to prevent accidents caused by driver fatigue. These rules regulate the minimum time drivers must spend on resting betWeen driving shifts. HoWever, since different drivers have different physi cal and mental conditions, safety risks still remain.[0005] Generally, driver fatigue impairs cognitive skills and reduces the vigilance and attention of drivers to continue driving safely. Assessment of driver fatigue can be divided into tWo categories, subjective methods and objective meth ods. The subjective assessment is based on the state of drivers described by themselves. For example, special-purpose ques tionnaires can be …",,,2012
210,Building Occupancy Detection Using Thermal Imaging based Edge Computing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7oNkNtIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7oNkNtIAAAAJ:5ugPr518TE4C,"As energy costs continue to rise, energy efficiency within buildings is becoming increasingly important to reduce energy costs for consumers and to improve the competitiveness of businesses. Occupancy detection has been proven to be an efficient way to improve building energy performance by smartly enabling the control of the heating, ventilating, air-conditioning (HVAC), and lighting systems. Several devices have been developed and practically employed in buildings to enable occupancy detection; however, there are still major challenges in low accuracy, required motion, and/or inability to detect focused areas. This paper presents an edge computing thermal imaging system that can precisely detect the presence and count the number of people in a focused area in real-time. A convolutional neural network (CNN) with fewer than ten hidden layers can extract the required features needed to detect persons …",Pergamon,,2025
211,Distributed Sensing Enabled Embodied Intelligence for Soft Finger Manipulation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7oNkNtIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7oNkNtIAAAAJ:wbdj-CoPYUoC,"Soft continuum robots are constructed from soft and compliant materials and can provide high flexibility and adaptability to various applications. They have theoretically infinite degrees of freedom (DOFs) and can generate highly nonlinear behaviors, which leads to challenges in accurately modeling and controlling their deformation, compliance, and behaviors. Inspired by animals, embodied intelligence utilizes physical bodies as an intelligent resource for information processing and task completion and offloads the computational cost of central control, which provides a unique approach to understanding and modeling soft robotics. In this study, we propose a theoretical framework to explain and guide distributed sensing enabled embodied intelligence for soft finger manipulation from a physics-based perspective. Specifically, we aim to provide a theoretical foundation to guide future sensor design and placement by addressing two key questions: (1) whether and why the state of a specific material point such as the tip trajectory of a soft finger can be predicted using distributed sensing, and, (2) how many sensors are sufficient for accurate prediction. These questions are critical for the design of soft and compliant robotic systems with embedded sensing for embodied intelligence. In addition to theoretical analysis, the study presents a feasible approach for real-time trajectory prediction through optimized sensor placement, with results validated through both simulation and experiment. The results showed that the tip trajectory of a soft finger can be predicted with a finite number of sensors with proper placement. While the proposed method is …",MDPI,,2025
212,Numerical Analysis of the Aerodynamic Interactions in Tandem Flying Snake Airfoils,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7oNkNtIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7oNkNtIAAAAJ:1qzjygNMrQYC,"During gliding, flying snakes flatten their ribs to create an airfoil-like cross-section and adopt S-shape postures, allowing upstream body segments to generate wake structures that affect the aerodynamic performance of downstream segments. This study investigates these interactions using numerical simulations of two-dimensional snake cross-sectional airfoils. By employing an immersed-boundary-method-based incompressible flow solver with tree topological local mesh refinement, various foil positions and movements were analyzed. The results show that aligning the downstream foil with the upstream foil reduces lift production by 86.5% and drag by 96.3%, leading to a 3.77-fold increase in the lift-to-drag ratio compared to a single airfoil. This improvement is attributed to the vortex–wedge interaction between the upstream vortex and the following foil’s leading edge (wedge), which enhances the gliding efficiency of the posterior body. Furthermore, integrating specific pitching motions with coordinated vortex shedding could further optimize its lift production. These findings provide valuable insights into the aerodynamics of tandem flying snake airfoils, offering guidance for configuring optimal body postures for improving gliding efficiency.",MDPI,,2025
213,NeuroFlex: Feasibility of EEG-Based Motor Imagery Control of a Soft Glove for Hand Rehabilitation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7oNkNtIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7oNkNtIAAAAJ:eflP2zaiRacC,"Motor impairments resulting from neurological disorders, such as strokes or spinal cord injuries, often impair hand and finger mobility, restricting a person’s ability to grasp and perform fine motor tasks. Brain plasticity refers to the inherent capability of the central nervous system to functionally and structurally reorganize itself in response to stimulation, which underpins rehabilitation from brain injuries or strokes. Linking voluntary cortical activity with corresponding motor execution has been identified as effective in promoting adaptive plasticity. This study introduces NeuroFlex, a motion-intent-controlled soft robotic glove for hand rehabilitation. NeuroFlex utilizes a transformer-based deep learning (DL) architecture to decode motion intent from motor imagery (MI) EEG data and translate it into control inputs for the assistive glove. The glove’s soft, lightweight, and flexible design enables users to perform rehabilitation exercises involving fist formation and grasping movements, aligning with natural hand functions for fine motor practices. The results show that the accuracy of decoding the intent of fingers making a fist from MI EEG can reach up to 85.3%, with an average AUC of 0.88. NeuroFlex demonstrates the feasibility of detecting and assisting the patient’s attempted movements using pure thinking through a non-intrusive brain–computer interface (BCI). This EEG-based soft glove aims to enhance the effectiveness and user experience of rehabilitation protocols, providing the possibility of extending therapeutic opportunities outside clinical settings.",MDPI,,2025
214,Physics-guided deep learning enabled surrogate modeling for pneumatic soft robots,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7oNkNtIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7oNkNtIAAAAJ:D_sINldO8mEC,"Soft robots, formulated by soft and compliant materials, have grown significantly in recent years toward safe and adaptable operations and interactions with dynamic environments. Modeling the complex, nonlinear behaviors and controlling the deformable structures of soft robots present challenges. This study aims to establish a physics-guided deep learning (PGDL) computational framework that integrates physical models into deep learning framework as surrogate models for soft robots. Once trained, these models can replace computationally expensive numerical simulations to shorten the computation time and enable real-time control. This PGDL framework is among the first to integrate first principle physics of soft robots into deep learning toward highly accurate yet computationally affordable models for soft robot modeling and control. The proposed framework has been implemented and validated using three different …",IEEE,,2024
215,Effect of peptide sequence on the LCST-like transition of elastin-like peptides and elastin-like peptide–collagen-like peptide conjugates: Simulations and experiments,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cyUv82QAAAAJ&citation_for_view=cyUv82QAAAAJ:u5HHmVD_uO8C,"Elastin-like polypeptides (ELPs) are thermoresponsive biopolymers that undergo an LCST-like phase transition in aqueous solutions. The temperature of this LCST-like transition, Tt , can be tuned by varying the number of repeat units in the ELP, sequence and composition of the repeat units, the solution conditions, and via conjugation to other biomacromolecules. In this study, we show how and why the choice of guest (X) residue in the VPGXG pentad repeat tunes the Tt of short ELPs, (VPGXG)4, in the free state and when conjugated to collagen-like peptides (CLPs). In experiments, the (VPGWG)4 chain (in short, WWWW) has a Tt < 278 K, while (VPGFG)4 or FFFF has a Tt > 353 K in both free ELP and ELP–CLP systems. The Tt for the FWWF ELP sequence decreases from being >353 K for free ELP to <278 K for the corresponding ELP–CLP system. The decrease in Tt upon conjugation to CLP has been shown to …",American Chemical Society,,2019
216,Molecular modeling and simulations of peptide–polymer conjugates,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cyUv82QAAAAJ&citation_for_view=cyUv82QAAAAJ:d1gkVwhDpl0C,"Peptide–polymer conjugates are a class of soft materials composed of covalently linked blocks of protein/polypeptides and synthetic/natural polymers. These materials are practically useful in biological applications, such as drug delivery, DNA/gene delivery, and antimicrobial coatings, as well as nonbiological applications, such as electronics, separations, optics, and sensing. Given their broad applicability, there is motivation to understand the molecular and macroscale structure, dynamics, and thermodynamic behavior exhibited by such materials. We focus on the past and ongoing molecular simulation studies aimed at obtaining such fundamental understanding and predicting molecular design rules for the target function. We describe briefly the experimental work in this field that validates or motivates these computational studies. We also describe the various models (e.g., atomistic, coarse-grained, or hybrid) and …",Annual Reviews,Annual Review of Chemical and Biomolecular Engineering,2020
217,Placement of tyrosine residues as a design element for tuning the phase transition of elastin-peptide-containing conjugates: experiments and simulations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cyUv82QAAAAJ&citation_for_view=cyUv82QAAAAJ:9yKSN-GCB0IC,"Elastin-like polypeptides (ELP) have been widely used in the biomaterials community due to their controllable, thermoresponsive properties and biocompatibility. Motivated by our previous work on the effect of tryptophan (W) substitutions on the LCST-like transitions of short ELPs, we studied a series of short ELPs containing tyrosine (Y) and/or phenylalanine (F) guest residues with only 5 or 6 pentapeptide repeat units. A combination of experiments and molecular dynamics (MD) simulations illustrated that the substitution of F with Y guest residues impacted the transition temperature (Tt) of short ELPs when conjugated to collagen-like-peptides (CLP), with a reduction in the transition temperature observed only after substitution of at least two residues. Placement of the Y residues near the N-terminal end of the ELP, away from the tethering point to the CLP, resulted in a lower Tt than that observed for peptides with the …",Royal Society of Chemistry,,2020
218,Combining simulations and experiments for the molecular engineering of multifunctional collagen mimetic peptide-based materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cyUv82QAAAAJ&citation_for_view=cyUv82QAAAAJ:2osOgNQ5qMEC,"Assembling peptides allow the creation of structurally complex materials, where amino acid selection influences resulting properties. We present a synergistic approach of experiments and simulations for examining the influence of natural and non-natural amino acid substitutions via incorporation of charged residues and a reactive handle on the thermal stability and assembly of multifunctional collagen mimetic peptides (CMPs). Experimentally, we observed inclusion of charged residues significantly decreased the melting temperature of CMP triple helices with further destabilization upon inclusion of the reactive handle. Atomistic simulations of a single CMP triple helix in explicit water showed increased residue-level and helical structural fluctuations caused by the inclusion of the reactive handle; however, these atomistic simulations cannot be used to predict changes in CMP melting transition. Coarse-grained (CG …",Royal Society of Chemistry,,2021
219,Smoother surfaces enhance diffusion of nanorods in entangled polymer melts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cyUv82QAAAAJ&citation_for_view=cyUv82QAAAAJ:dhFuZR0502QC,"Coarse-grained molecular dynamics simulations are used to study the diffusion of thin nanorods in entangled polymer melts for varying nanorod length and roughness. While prior studies observed a nanorod parallel diffusion constant scaling inversely with rod length D∥ ∼ l–1, here, we show that this scaling is not universal and depends sensitively on the nanorod surface roughness. We observe D∥ ∼ l–k, where k < 1 and decreases with decreasing surface roughness. The weaker scaling is driven by the non-Gaussian diffusion of nanorods due to the emergence of an intermittent hopping process that becomes more pronounced with decreasing roughness at the monomer scale. Analysis shows that the mean hop size grows for smoother rods but shows little to no variation with rod length. The mean hopping frequency shows no dependence on either rod length or roughness, suggesting it originates from the …",American Chemical Society,,2024
220,Probing Nanorod Assembly and Dynamics in Polymer Nanocomposites in Equilibrium and Shear,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cyUv82QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=cyUv82QAAAAJ:RHpTSmoSYBkC,"Coarse-grained molecular dynamics simulations are used to examine the structure and dynamics of nanorod assemblies in polymer melts under equilibrium and simple shear. We show that as the concentration of nanorods increases, there is a transition from an isotropic phase to a two-phase region in which the nanorods phase separate into a dilute phase and dense bundles of hexagonally packed nanorods. The onset of the two-phase region is below that predicted by Onsager theory, which we attribute to an effective increase in the diameter of nanorods due to a layer of polymer bound to the rod surfaces. Equilibrium simulations show that increasing polymer chain length N enhances nanorod bundling at fixed nanorod concentration. Simulations of systems undergoing simple shear show that flow enhances nanorod alignment and bundling relative to those of equilibrium systems with similar properties. Finally …",American Chemical Society,,2025
221,Disentangling the Effects of Polymer Matrix Chain Length and Processing Conditions on Nanorod Assembly in Polymer Nanocomposites,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cyUv82QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=cyUv82QAAAAJ:hFOr9nPyWt4C,,AIChE,,2024
222,Biomaterials: Graduate Student Award Session (Invited Talks),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cyUv82QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=cyUv82QAAAAJ:hC7cP41nSMkC,,AIChE,,2024
223,Impact of L-and D-Peptide Isomer Mixtures on Self-Assembly in Tissue Engineering: A Molecular Dynamics Study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cyUv82QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=cyUv82QAAAAJ:HDshCWvjkbEC,,AIChE,,2024
224,Asymmetric crowders and membrane morphology at the nexus of intracellular trafficking and oncology,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cyUv82QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=cyUv82QAAAAJ:ZeXyd9-uunAC,"A definitive understanding of the interplay between protein binding/migration and membrane curvature evolution is emerging but needs further study. The mechanisms defining such phenomena are critical to intracellular transport and trafficking of proteins. Among trafficking modalities, exosomes have drawn attention in cancer research as these nano-sized naturally occurring vehicles are implicated in intercellular communication in the tumor microenvironment, suppressing anti-tumor immunity and preparing the metastatic niche for progression. A significant question in the field is how the release and composition of tumor exosomes are regulated. In this perspective article, we explore how physical factors such as geometry and tissue mechanics regulate cell cortical tension to influence exosome production by co-opting the biophysics as well as the signaling dynamics of intracellular trafficking pathways and how …",Elsevier,Mechanobiology in Medicine,2024
225,"Chitosan-DNA nanoparticles as gene carriers: synthesis, characterization and transfection efficiency",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=evWMvjgAAAAJ&citation_for_view=evWMvjgAAAAJ:u5HHmVD_uO8C,"Chitosan-DNA nanoparticles were prepared using a complex coacervation process. The important parameters for the nanoparticle synthesis were investigated, including the concentrations of DNA, chitosan and sodium sulfate, temperature of the solutions, pH of the buffer, and molecular weights of chitosan and DNA. At an amino group to phosphate group ratio (N/P ratio) between 3 and 8 and a chitosan concentration of 100 μg/ml, the size of particles was optimized to ∼100–250 nm with a narrow distribution, with a composition of 35.6 and 64.4% by weight for DNA and chitosan, respectively. The surface charge of these particles was slightly positive with a zeta potential of +12 to +18 mV at pH lower than 6.0, and became nearly neutral at pH 7.2. The chitosan-DNA nanoparticles could partially protect the encapsulated plasmid DNA from nuclease degradation as shown by electrophoretic mobility analysis. The …",Elsevier,,2001
226,Polysaccharide colloidal particles as delivery systems for macromolecules,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=evWMvjgAAAAJ&citation_for_view=evWMvjgAAAAJ:u-x6o8ySG0sC,"Mucosal delivery of complex molecules such as peptides, proteins, oligonucleotides, and plasmids is one of the most intensively studied subjects. The use of colloidal carriers made of hydrophilic polysaccharides, i.e. chitosan, has arisen as a promising alternative for improving the transport of such macromolecules across biological surfaces. This article reviews the approaches which have aimed to associate macromolecules to chitosan in the form of colloidal structures and analyzes the evidence of their efficacy in improving the transport of the associated molecule through mucosae and epithelia. Chitosan has been shown to form colloidal particles and entrap macromolecules through a number of mechanisms, including ionic crosslinking, desolvation, or ionic complexation, though some of these systems have been realized only in conjunction with DNA molecules. An alternative involving the chemical modification …",Elsevier,Advanced drug delivery reviews,2001
227,Chitosan nanoparticles as delivery systems for doxorubicin,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=evWMvjgAAAAJ&citation_for_view=evWMvjgAAAAJ:d1gkVwhDpl0C,"The aim of this paper was to evaluate the potential of chitosan nanoparticles as carriers for the anthracycline drug, doxorubicin (DOX). The challenge was to entrap a cationic, hydrophilic molecule into nanoparticles formed by ionic gelation of the positively charged polysaccharide chitosan. To achieve this objective, we attempted to mask the positive charge of DOX by complexing it with the polyanion, dextran sulfate. This modification doubled DOX encapsulation efficiency relative to controls and enabled real loadings up to 4.0 wt.% DOX. Separately, we investigated the possibility of forming a complex between chitosan and DOX prior to the formation of the particles. Despite the low complexation efficiency, no dissociation of the complex was observed upon formation of the nanoparticles. Fluorimetric analysis of the drug released in vitro showed an initial release phase, the intensity of which was dependent on the …",Elsevier,,2001
228,A systems model of signaling identifies a molecular basis set for cytokine-induced apoptosis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=evWMvjgAAAAJ&citation_for_view=evWMvjgAAAAJ:zYLM7Y9cAGgC,"Signal transduction pathways control cellular responses to stimuli, but it is unclear how molecular information is processed as a network. We constructed a systems model of 7980 intracellular signaling events that directly links measurements to 1440 response outputs associated with apoptosis. The model accurately predicted multiple time-dependent apoptotic responses induced by a combination of the death-inducing cytokine tumor necrosis factor with the prosurvival factors epidermal growth factor and insulin. By capturing the role of unsuspected autocrine circuits activated by transforming growth factor–α and interleukin-1α, the model revealed new molecular mechanisms connecting signaling to apoptosis. The model derived two groupings of intracellular signals that constitute fundamental dimensions (molecular “basis axes”) within the apoptotic signaling network. Projection along these axes captures the entire …",AAAS,,2005
229,Low molecular weight chitosan nanoparticles as new carriers for nasal vaccine delivery in mice,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=evWMvjgAAAAJ&citation_for_view=evWMvjgAAAAJ:9yKSN-GCB0IC,"High molecular weight (Mw) chitosan (CS) solutions have already been proposed as vehicles for nasal immunization. The aim of the present work was to investigate the potential utility of low Mw CS in the form of nanoparticles as new long-term nasal vaccine delivery vehicles. For this purpose, CS of low Mws (23 and 38 kDa) was obtained previously by a depolymerization process of the commercially available CS (70 kDa). Tetanus toxoid (TT), used as a model antigen, was entrapped within CS nanoparticles by an ionic cross-linking technique. TT-loaded nanoparticles were first characterized for their size, electrical charge, loading efficiency and in vitro release of antigenically active toxoid. The nanoparticles were then administered intranasally to conscious mice in order to study their feasibility as vaccine carriers. CS nanoparticles were also labeled with FITC-BSA and their interaction with the rat nasal mucosa …",Elsevier,,2004
230,Systems Virology at Scale,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=evWMvjgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=evWMvjgAAAAJ:JQOojiI6XY0C,"Today’s subcellular and multicellular models of infection are poised to tackle bigger questions about virus-host interactions and the determinants of susceptibility. This opportunity comes from increased computing power, improved model architectures, and comprehensive datasets collected from virus-infected hosts. Here we summarize recent advances in viral modeling and data science that illustrate how systems models have successfully traversed increasing time–length scales, levels of detail, and ranges of biological context. The latest progress is encouraging, but recent findings just scratch the surface given how many different viruses exist or could someday emerge—the scale of the effort should align with the scale of the challenge. Abstraction of molecular and cellular networks by systems virology complements public-health models of viral transmission that are widely applied to human populations.",Elsevier,Current Opinion in Systems Biology,2025
231,"Fast, flexible, learning-free organoid quantification and tracking with OrganoSeg2",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=evWMvjgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=evWMvjgAAAAJ:UHK10RUVsp4C,"Organoids are routinely imaged by brightfield microscopy at low magnification, but these images are challenging to analyze quantitatively at scale. Given differences in organoid-culture format and image acquisition among research groups, there is a general need for versatile segmentation algorithms that refine for specific applications. Here, we introduce OrganoSeg2, an overhauled software that substantively advances the multi-window adaptive thresholding of its predecessor. OrganoSeg2 gives users access to additional segmentation parameters that were latent in OrganoSeg, and common operations are accelerated ∼10-fold. Using data from six organoid types, we find that the generalized segmentation accuracy of OrganoSeg2 surpasses multiple alternatives, including segmenters based on deep learning. OrganoSeg2 adds longitudinal single-organoid tracking and multicolor fluorescence quantification, which we use to examine growth trajectories and radiotherapy responses in luminal breast cancer organoids. OrganoSeg2 is shared freely as installation packages for current users and source code for future developers (https://github.com/JanesLab/OrganoSeg2). MOTIVATION Organoids are routinely documented with low-magnification brightfield and fluorescence images that are challenging to quantify accurately in large numbers. OrganoSeg2 is a streamlined, highly customizable segmenter that surpasses its prior version and AI-themed competitors in various organoid contexts. New longitudinal tracking and fluorescence capabilities of OrganoSeg2 are demonstrated with experiments investigating the cell-death responses of luminal …",Cold Spring Harbor Laboratory,,2025
232,Age-dependent topoisomerase I depletion alters recruitment of rDNA silencing complexes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=evWMvjgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=evWMvjgAAAAJ:dQ2og3OwTAUC,"Genomic instability and loss of proteostasis are two of the primary Hallmarks of Aging. Although these hallmarks are well-defined in the literature, the mechanisms that drive genomic instability and loss of proteostasis as cells age are still largely unknown. Using budding yeast replicative lifespan as a model for aging in actively dividing cells, we identified nuclear proteins that were depleted in the earliest stages of aging. We found that many age-depleted proteins were involved in ribosome biogenesis, specifically in ribosome processing, or in maintenance of chromatin stability. We focused on topoisomerase I (Top1) as a novel age-depleted nuclear protein and found that its depletion in the early stages of aging was not a result of transcriptional changes or changes in protein turnover. Despite the stark depletion of Top1 in early aging, rescue of this age-dependent depletion was actually harmful to replicative lifespan. We found that Top1, when overexpressed, disrupts the stoichiometry of the RENT complex by pulling Sir2 away from the ribosomal DNA (rDNA), a phenotype which is further enhanced when the overexpressed Top1 is catalytically dead. Loss of Sir2 from the rDNA via the overexpression of catalytically dead Top1 decreases RNA Pol II silencing of a reporter gene inside or adjacent to the rDNA, consistent with the lifespan defect. Finally, we found that the catalytic activity of Top1 plays an important role in the establishment of rDNA silencing, raising the possibility that rDNA secondary structure/DNA topology is important for RNA Pol I-dependent spreading of silent chromatin across the rDNA locus.",Cold Spring Harbor Laboratory,,2025
233,Cahn-Hilliard dynamical models for condensed biomolecular systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=evWMvjgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=evWMvjgAAAAJ:hkOj_22Ku90C,"Biomolecular condensates create dynamic subcellular compartments that alter systems-level properties of the networks surrounding them. One model combining soluble and condensed states is the Cahn-Hilliard equation, which specifies a diffuse interface between the two phases. Customized approaches required to solve this equation are largely inaccessible. Using two complementary numerical strategies, we built stable, self-consistent Cahn-Hilliard solvers in Python, MATLAB, and Julia. The algorithms simulated the complete time evolution of condensed droplets as they dissolved or persisted, relating critical droplet size to a coefficient for the diffuse interface in the Cahn-Hilliard equation. We applied this universal relationship to the chromosomal passenger complex, a multi-protein assembly that reportedly condenses on mitotic chromosomes. The fully constrained Cahn-Hilliard simulations yielded dewetting and coarsening behaviors that closely mirrored experiments in different cell types. The Cahn-Hilliard equation tests whether condensate dynamics behave as a phase-separated liquid, and its numerical solutions advance generalized modeling of biomolecular systems.",Cold Spring Harbor Laboratory,,2025
234,Ten simple rules for developing a training program,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=evWMvjgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=evWMvjgAAAAJ:PR6Y55bgFSsC,"In every facet of a workforce, there is a continual need to develop training programs to update skills and knowledge. Particularly in biomedical and health sciences research, with rapidly changing science comes the need for rapidly developed requisite training. Training programs may be proactive based on institutional aspirations or reactive to institutional needs and/or funder requirements. Target trainees may be pre-professional, early in their careers, or individuals long immersed in a discipline. From our experience leading different training programs, there are several governing principles for the development and implementation of successful training experiences. There are several related Ten Simple Rules articles, including on how to selftrain for a new field [1], run workshops [2], and provide bioinformatics training [3, 4]. This Ten Simple Rules article represents lessons we’ve learned through success and failure in the development of new training programs. We hope they can be a guide for those wishing to embark on the rewarding journey of training students and professionals to hone their skills and synthesize new information in rapidly evolving fields. Our focus for the rules and examples below is on longer-term (eg, 1-to 2-year) professional development and training programs for graduate degree students, postdoctoral fellows, and early career faculty. These rules draw on our experience developing a 1-year enrichment program in systems biology and biomolecular data science for PhD students and a 2-year program in clinical translational science for early career faculty. While grounded in these experiences, we emphasize that many of …",Public Library of Science,,2025
235,OWL: Cooperative Thread Array Aware Scheduling Techniques for Improving GPGPU Performance,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9RgqL8gAAAAJ&citation_for_view=9RgqL8gAAAAJ:qjMakFHDy7sC,"Emerging GPGPU architectures, along with programming models like CUDA and OpenCL, offer a cost-effective platform for many applications by providing high thread level parallelism at lower energy budgets. Unfortunately, for many general-purpose applications, available hardware resources of a GPGPU are not efficiently utilized, leading to lost opportunity in improving performance. A major cause of this is the inefficiency of current warp scheduling policies in tolerating long memory latencies. In this paper, we identify that the scheduling decisions made by such policies are agnostic to thread-block, or cooperative thread array (CTA), behavior, and as a result inefficient. We present a coordinated CTA-aware scheduling policy that utilizes four schemes to minimize the impact of long memory latencies. The first two schemes, CTA-aware two-level warp scheduling and locality aware warp scheduling, enhance per …",ACM,,2013
236,Cache Revive: Architecting Volatile STT-RAM Caches for Enhanced Performance in CMPs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9RgqL8gAAAAJ&citation_for_view=9RgqL8gAAAAJ:9yKSN-GCB0IC,"High density, low leakage and non-volatility are the attractive features of Spin-Transfer-Torque-RAM (STT-RAM), which has made it a strong competitor against SRAM as a universal memory replacement in multi-core systems. However, STT-RAM suffers from high write latency and energy which has impeded its widespread adoption. To this end, we look at trading-off STT-RAM's non-volatility property (data-retention-time) to overcome these problems. We formulate the relationship between retention-time and write-latency, and find optimal retention-time for architecting an efficient cache hierarchy using STT-RAM. Our results show that, compared to SRAM-based design, our proposal can improve performance and energy consumption by 18% and 60%, respectively.",ACM,,2012
237,Neither More Nor Less: Optimizing Thread-level Parallelism for GPGPUs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9RgqL8gAAAAJ&citation_for_view=9RgqL8gAAAAJ:2osOgNQ5qMEC,"General-purpose graphics processing units (GPG-PUs) are at their best in accelerating computation by exploiting abundant thread-level parallelism (TLP) offered by many classes of HPC applications. To facilitate such high TLP, emerging programming models like CUDA and OpenCL allow programmers to create work abstractions in terms of smaller work units, called cooperative thread arrays (CTAs). CTAs are groups of threads and can be executed in any order, thereby providing ample opportunities for TLP. The state-of-the-art GPGPU schedulers allocate maximum possible CTAs per-core (limited by available on-chip resources) to enhance performance by exploiting TLP. However, we demonstrate in this paper that executing the maximum possible number of CTAs on a core is not always the optimal choice from the performance perspective. High number of concurrently executing threads might cause more …",IEEE,,2013
238,Scheduling techniques for GPU architectures with processing-in-memory capabilities,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9RgqL8gAAAAJ&citation_for_view=9RgqL8gAAAAJ:eflP2zaiRacC,"Processing data in or near memory (PIM), as opposed to in conventional computational units in a processor, can greatly alleviate the performance and energy penalties of data transfers from/to main memory. Graphics Processing Unit (GPU) architectures and applications, where main memory bandwidth is a critical bottleneck, can benefit from the use of PIM. To this end, an application should be properly partitioned and scheduled to execute on either the main, powerful GPU cores that are far away from memory or the auxiliary, simple GPU cores that are close to memory (e.g., in the logic layer of 3D-stacked DRAM). This paper investigates two key code scheduling issues in such a GPU architecture that has PIM capabilities, to maximize performance and energy-efficiency: (1) how to automatically identify the code segments, or kernels, to be offloaded to the cores in memory, and (2) how to concurrently schedule …",,,2016
239,Orchestrated Scheduling and Prefetching for GPGPUs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9RgqL8gAAAAJ&citation_for_view=9RgqL8gAAAAJ:UeHWp8X0CEIC,"In this paper, we present techniques that coordinate the thread scheduling and prefetching decisions in a General Purpose Graphics Processing Unit (GPGPU) architecture to better tolerate long memory latencies. We demonstrate that existing warp scheduling policies in GPGPU architectures are unable to effectively incorporate data prefetching. The main reason is that they schedule consecutive warps, which are likely to access nearby cache blocks and thus prefetch accurately for one another, back-to-back in consecutive cycles. This either 1) causes prefetches to be generated by a warp too close to the time their corresponding addresses are actually demanded by another warp, or 2) requires sophisticated prefetcher designs to correctly predict the addresses required by a future ""far-ahead"" warp while executing the current warp. We propose a new prefetch-aware warp scheduling policy that overcomes these …",ACM,,2013
240,NetCrafter: Tailoring Network Traffic for Non-Uniform Bandwidth Multi-GPU Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9RgqL8gAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9RgqL8gAAAAJ:0N-VGjzr574C,"Multiple Graphics Processing Units (GPUs) are being integrated into systems to meet the computing demands of emerging workloads. To continuously support more GPUs in a system, it is important to connect them efficiently and effectively. To this end, emerging multi-GPU systems are adopting a hierarchical approach – a group of GPUs with high affinity are connected with higher-bandwidth networks, while multiple groups of GPUs are connected with lower-bandwidth networks to support the scaling of GPUs. Unfortunately, such a non-uniform bandwidth configuration leads to significant performance bottlenecks, especially across lower-bandwidth networks. We present NetCrafter, a combination of novel approaches to deal with the network traffic. NetCrafter is based on three observations: a) not all flits in the network fully utilize the network bandwidth, b) not all requested flits are even necessary – they are …",,,2025
241,TrioSim: A Lightweight Simulator for Large-Scale DNN Workloads on Multi-GPU Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9RgqL8gAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9RgqL8gAAAAJ:foquWX3nUaYC,"Deep Neural Networks (DNNs) have become increasingly capable of performing tasks ranging from image recognition to content generation. The training and inference of DNNs heavily rely on GPUs, as GPUs’ massively parallel architecture delivers extremely high computing capability. With the growing complexity of DNNs and the size of training datasets, training DNNs with a large number of GPUs is becoming a prevalent strategy. Researchers have been exploring how to design software and hardware systems for GPU farms to achieve the best utilization, efficiency, and DNN accuracy during training or inference. However, when designing and deploying such systems, designers usually rely on testing on physical hardware platforms equipped with many GPUs, incurring high costs that are almost prohibitive for system designers to test different configurations and designs, even for highly resourceful companies …",,,2025
242,Dissecting Performance Overheads of Confidential Computing on GPU-based Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9RgqL8gAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9RgqL8gAAAAJ:HbR8gkJAVGIC,"Confidential computing (CC) is a critical technology for protecting data in use. By leveraging encryption and virtual machine (VM) level isolation, CC allows existing code to run without modification while offering confidentiality and integrity guarantees. However, the performance impact of CC in GPU-based systems can be significant. In this work, we present a comprehensive performance evaluation of CC guided by a simple performance model. Specifically, we start by evaluating CUDA applications with a focus on data transfer, memory management, encryption, kernel launch, and kernel execution. We also present a detailed event-level analysis of these applications, revealing that the execution times of kernels that do not use unified virtual memory (UVM) are mostly unaffected, while associated kernel launch overhead and queuing time increase significantly. On the other hand, the execution time of kernels using …",,,2025
243,Pushing the Performance Envelope of DNN-based Recommendation Systems Inference on GPUs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9RgqL8gAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9RgqL8gAAAAJ:SpbeaW3--B0C,"Personalized recommendation is a ubiquitous appli-cation on the internet, with many industries and hyperscalers extensively leveraging Deep Learning Recommendation Models (DLRMs) for their personalization needs (like ad serving or movie suggestions). With growing model and dataset sizes pushing computation and memory requirements, GPUs are being increasingly preferred for executing DLRM inference. However, serving newer DLRMs, while meeting acceptable latencies, continues to remain challenging, making traditional deployments increasingly more GPU-hungry, resulting in higher inference serving costs. In this paper, we show that the embedding stage continues to be the primary bottleneck in the GPU inference pipeline, leading up to a 3.2 x embedding-only performance slowdown. To thoroughly grasp the problem, we conduct a detailed microarchitecture characterization and highlight the …",IEEE,,2024
244,Aspis: Lightweight Neural Network Protection Against Soft Errors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9RgqL8gAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9RgqL8gAAAAJ:i2xiXl-TujoC,"Convolutional neural networks (CNN) are incorporated into many image-based tasks across a variety of domains. Some of these are safety critical tasks such as object classification/detection and lane detection for self-driving cars. These applications have strict safety requirements and must guarantee the reliable operation of the neural networks in the presence of soft errors (i.e., transient faults) in DRAM. Standard safety mechanisms (e.g., triplication of data/computation) provide high resilience, but introduce intolerable overhead. We perform detailed characterization and propose an efficient methodology for pinpointing critical weights by using an efficient proxy, the Taylor criterion. Using this characterization, we design Aspis, an efficient software protection scheme that does selective weight hardening and offers a performance/reliability tradeoff. Aspis provides higher resilience comparing to state-of-the-art …",IEEE,,2024
245,Scenario-based resilience assessment framework for critical infrastructure systems: Case study for seismic resilience of seaports,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PO4tyicAAAAJ&citation_for_view=PO4tyicAAAAJ:IjCSPb-OGe4C,"A number of metrics in the past have been proposed and numerically implemented to assess the overall performance of large systems during natural disasters and their recovery in the aftermath of the events. Among such performance measures, resilience is a reliable metric. This paper proposes a probabilistic framework for scenario-based resilience assessment of infrastructure systems. The method accounts for uncertainties in the process including the correlation of the earthquake intensity measures, fragility assessment of structural components, estimation of repair requirements, the repair process, and finally the service demands. The proposed method is applied to a hypothetical seaport terminal and the system level performance of the seaport is assessed using various performance metrics. Results of this analysis have shown that medium to large seismic events may significantly disrupt the operation of …",Elsevier,,2014
246,Development of a risk framework for forecasting earthquake losses in port systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PO4tyicAAAAJ&citation_for_view=PO4tyicAAAAJ:Tyk-4Ss8FVUC,"Ports play a critical role in transportation infrastructure but are vulnerable to seismic hazards. Downtime and reduced throughput from seismic damage in ports results in significant business interruption losses for port stakeholders. Managing risks from systemwide disruptions resulting from earthquake damage has been studied as a central element of a project sponsored by the National Science Foundation Network for Earthquake Engineering Simulation (NEES) program. Presented are the concepts and methods developed for the seismic risk management of a portwide system of berths. The framework used to calculate port losses is discussed, particularly the use of spatially correlated ground motion intensity measures that estimate damage to pile-supported wharves and container cranes, the repair costs and downtimes subsequently determined via repair models for both types of structures, and the impact on …",SAGE Publications,,2016
247,Synthesis of trenchless technologies.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PO4tyicAAAAJ&citation_for_view=PO4tyicAAAAJ:eQOLeE2rZwMC,"The purpose of this study was to examine the current state of the practice of state highway agencies regarding methods and specifications for using trenchless technologies. From the perspective of the Virginia Department of Transportation (VDOT), the paramount concern associated with trenchless construction is the safety of the traveling public. Since such construction typically takes place without the re-routing of traffic, any sudden and substantial surface displacement of the overlying roadway has the potential for catastrophic consequences. Surface monitoring during and after construction is a critical activity to ensure successful installation. The study focused on the most commonly used trenchless methods for new construction, including the selection of the most appropriate trenchless technology for specific applications, the identification of minimum geotechnical investigation requirements, design considerations, construction monitoring, costs, and performance. The study did not address all potentially available methods of utility construction and rehabilitation. To achieve the study objective, two tasks were performed: (1) the literature on the current state of the practice with respect to the use of trenchless technology in other states was reviewed, and (2) identified specifications and design guidelines of various state transportation agencies were analyzed and examined for potential applicability to trenchless construction activities administered by VDOT. The study concluded that trenchless technologies have been widely adopted but design guidelines and construction specifications vary significantly. Accurate subsurface characterization is …",Virginia Center for Transportation Innovation and Research,,2015
248,Framework for earthquake risk assessment for container ports,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PO4tyicAAAAJ&citation_for_view=PO4tyicAAAAJ:u-x6o8ySG0sC,"As critical transportation infrastructure, ports are vulnerable to a variety of natural disasters. On the West Coast of the United States, earthquakes are a concern. Currently, risk management practices for seismic design in ports consider only the seismic performance of individual wharf and crane structures. The practices do not consider how damage to and downtime of these structures might disrupt the overall port system's ship-handling operations or what regional, national, and even international economic impacts could result from extended earthquake-induced disruption of a major container port. Managing risks from systemwide disruptions caused by earthquake damage is the focus of a Grand Challenge project sponsored by the National Science Foundation Network for Earthquake Engineering Simulation program. This paper provides an overview of the concepts and methods developed for the seismic risk …",SAGE Publications,,2010
249,A method of mapping sinkhole susceptibility using a geographic information system: a case study for interstates in the karst counties of Virginia,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PO4tyicAAAAJ&citation_for_view=PO4tyicAAAAJ:ufrVoPGSRksC,"Karst terrain is landscape underlain by limestone that has been chemically dissolved by acidic groundwater, producing subsurface voids that pose risks for sinkholes if the overlaying soils can no longer support their own weight and collapse. The western counties of Virginia are heavy in karst due to their natural, geographic boundary of the western Ridge Province and the eastern Blue Ridge Mountain Range. As a result, the Commonwealth of Virginia Hazard Mitigation Plan recommends that the Virginia Department of Transportation (VDOT) develop a method to determine the roadways and regions most susceptible to experiencing sinkholes, in an effort to reduce the number of reported sinkhole damage to property. While many noninvasive methods exist to detect subsurface voids, such as electric resistivity imaging, ground penetrating radar, and seismic surveys, these methods are time consuming and costly. This study proposes the use of a geographic information system (GIS) to create a susceptibility map, pinpointing regions in the karst counties of Virginia, in particular, along interstates, most at risk of future sinkhole development, determined by five factors that have previously been shown to play a role in the acceleration of sinkhole formation in Virginia: bedrock type, proximity to fault lines, drainage class, slope of incised river banks, and minimum soil depth to bedrock. The analysis compares a 1: 24,000 scale map of existing sinkholes developed by Virginia Department of Mines Minerals and Energy (DMME) geologist, David Hubbard, with a series of risk maps representing differing combinations of each of the five risk factors to determine …",,,2015
250,Design and Application of an Open-Science Electrical Resistivity Meter to Make Geotechnical Laboratory Education More Relevant and Engaging,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PO4tyicAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=PO4tyicAAAAJ:8k81kl-MbHgC,"Electrical Resistivity (ER) surveys have been used to investigate soils for over a century but a “black box” traditionally surrounds commercial ER equipment. This work proposes the design of an intuitive, low-cost ER meter for hands-on geotechnical education. The prototype leverages $40 worth of integrated-circuit modules and less than 80 lines of open-source commands to inject a current into the ground and measure the site’s potential response. The device was validated against test circuits with ohmic values ranging over 4 orders of magnitude and yielded marginal mean absolute percentage error less than 3%. The proposed ER meter was thereafter implemented in a tabletop laboratory setting to perform Constant Separation Traversing (CST) surveys using Wenner array along parallel profiles. The resulting CST matrix showed values of apparent resistivity consistently in agreement with the modeled earth stratum. Over the extent of a buried Styrofoam feature, the device generated measurements up to 70% higher and identified clear lateral disruptions in subsurface conditions. Overall, the proposed ER meter proved to be a tool well suited for tabletop experiments and capable of characterizing complex test beds. Its open-science design addresses the issues of the “black box” surrounding proprietary equipment and makes it accessible to the community at large for a fraction of the cost of commercial units. With practical applications for hands-on teaching and interactive learning, this work makes geotechnical laboratory education more engaging and relevant. As such, it has the potential to modernize STEM curricula and advance the …",,,2023
251,Conceptualizing social justice in civil engineering and professors’ perspective: A systematic literature review,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PO4tyicAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=PO4tyicAAAAJ:5nxA0vEk-isC,"Professors are responsible for teaching and shaping the next generation of civil engineers. As the conduits for transferring knowledge, the positionality of an engineering professor will inherently shape how engineering students perceive their expected role as civil engineers in society, embedding both identity and priorities. Nonetheless, professors are not provided with the tools needed to create a human-centered learning environment that promotes a more equitable lens through which students can view the ethical responsibilities of a civil engineer. The framing utilized in the curriculum to communicate ethical measures lacks the intricate and contextual complexities of real-world scenarios and historical views of all stakeholders (Bucciarelli, 2007). Professors’ perspectives must be taken into account when considering teaching and identifying any perceived barriers hindering this process. There is a hierarchy in engineering curricula where technical courses are prioritized, and non-technical courses are seen as an add-on. We must account for what is being left out of the problem-solving process and whose perspectives are not being considered (Leydens and Lucena, 2017). Civil engineering curriculum should include a focus on Diversity, Equity, Inclusion and Justice (DEIJ) to produce students with a stronger sense of social agency when they enter into their profession (Garibay, 2015) by providing them with (1) a better understanding of the implications of the historical and present contextualization of the work of civil engineers,(2) a recognition for the role/power they play in society, and (3) an understanding for the intersection of social justice …",,2023 ASEE Annual Conference & Exposition,2023
252,Multimodal Transportation Facility Resilience Index,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PO4tyicAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=PO4tyicAAAAJ:Se3iqnhoufwC,"A new paradigm for complex systems performance and maintenance decision making is developing in the form of resilience engineering. Depending on the subject area, different definitions of resilience exist. In this project, we adopt a definition appropriate for resilience in transportation systems: the ability of the system to recover and adapt to external shocks, which include natural, intentional and technogenic disasters and failure due to poor design. These disturbances can ultimately affect the smooth and efficient operation of systems and may demand a shift of process, strategies and/or coordination. This project builds off existing research and uses graph theory methods to develop a methodology to determine the resilience index of any transportation infrastructure system. This project also introduces weighting into the methodology based on traffic volume. Two weighting strategies are offered. It is shown that the inclusion of either weighting strategy increases the resilience of infrastructure systems and provides a more complete model. Finally, the methodology developed is applied to the network of major state and federal highways in Albemarle County, Virginia, to illustrate the process of determining a transportation infrastructure system’s resilience index.",Mid-Atlantic Transportation Sustainability University Transportation Center,,2017
253,Using readily available data and GIS to map sinkhole risk in the Karst Counties of Virginia,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PO4tyicAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=PO4tyicAAAAJ:UebtZRa9Y70C,"The following study proposes a methodology for taking readily available geographic information system (GIS) data and using that to create sinkhole susceptibility maps, pinpointing regions prone to future sinkhole development. Susceptibility can be determined by extracting data from GIS databases of factors previously shown to accelerate sinkhole formation. This inexpensive and noninvasive methodology allows input factors to be adjusted to accommodate mapping of various regions across the globe. The methodology was tested using the counties in and adjacent to the Valley and Ridge geologic region of Virginia, which are heavy in karst. The five risk factors previously shown to play a role in Virginian sinkhole formation examined in this study include: bedrock type, proximity to fault lines, drainage class, slope of incised river banks, and soil depth above bedrock. Two susceptibility maps were created. This first …",,Transportation Research Board 96th Annual MeetingTransportation Research Board,2017
254,Understanding Host Network Stack Overheads,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Meb0eTcAAAAJ&citation_for_view=Meb0eTcAAAAJ:2osOgNQ5qMEC,"Traditional end-host network stacks are struggling to keep up with rapidly increasing datacenter access link bandwidths due to their unsustainable CPU overheads. Motivated by this, our community is exploring a multitude of solutions for future network stacks: from Linux kernel optimizations to partial hardware offload to clean-slate userspace stacks to specialized host network hardware. The design space explored by these solutions would benefit from a detailed understanding of CPU inefficiencies in existing network stacks. This paper presents measurement and insights for Linux kernel network stack performance for 100Gbps access link bandwidths. Our study reveals that such high bandwidth links, coupled with relatively stagnant technology trends for other host resources (e.g., CPU speeds and capacity, cache sizes, NIC buffer sizes, etc.), mark a fundamental shift in host network stack bottlenecks. For instance …",,,2021
255,Network-Wide Heavy Hitter Detection with Commodity Switches,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Meb0eTcAAAAJ&citation_for_view=Meb0eTcAAAAJ:u5HHmVD_uO8C,"Many network monitoring tasks identify subsets of traffic that stand out, e.g., top-k flows for a particular statistic. A Protocol Independent Switch Architecture (PISA) switch can identify these ""heavy hitter"" flows directly in the data plane, by aggregating traffic statistics across packets and comparing against a threshold. However, network operators often want to identify interesting traffic on a network-wide basis. To bridge the gap between line-rate monitoring and network-wide visibility, we present a distributed heavy-hitter detection scheme for networks modeled as one-big switch. We use adaptive thresholds to perform efficient threshold monitoring directly in the data plane. We implement our system using the P4 language, and evaluate it using real-world packet traces. We demonstrate that our solution can accurately detect network-wide heavy hitters with up to 70% savings in communication overhead compared to an …",,,2018
256,{TCP}{≈}{RDMA}:{CPU-efficient} Remote Storage Access with i10,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Meb0eTcAAAAJ&citation_for_view=Meb0eTcAAAAJ:9yKSN-GCB0IC,"This paper presents design, implementation and evaluation of i10, a new remote storage stack implemented entirely in the kernel. i10 runs on commodity hardware, allows unmodified applications to operate directly on kernel's TCP/IP network stack, and yet, saturates a 100Gbps link for remote accesses using CPU utilization similar to state-of-the-art user-space and RDMA-based solutions.",,,2020
257,Towards s Tail Latency and Terabit Ethernet: Disaggregating the Host Network Stack,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Meb0eTcAAAAJ&citation_for_view=Meb0eTcAAAAJ:IjCSPb-OGe4C,"Dedicated, tightly integrated, and static packet processing pipelines in today's most widely deployed network stacks preclude them from fully exploiting capabilities of modern hardware. We present NetChannel, a disaggregated network stack architecture for μs-scale applications running atop Terabit Ethernet. NetChannel's disaggregated architecture enables independent scaling and scheduling of resources allocated to each layer in the packet processing pipeline. Using an end-to-end NetChannel realization within the Linux network stack, we demonstrate that NetChannel enables new operating points---(1) enabling a single application thread to saturate multi-hundred gigabit access link bandwidth; (2) enabling near-linear scalability for small message processing with number of cores, independent of number of application threads; and, (3) enabling isolation of latency-sensitive applications, allowing them to …",,,2022
258,dcPIM: Near-Optimal Proactive Datacenter Transport,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Meb0eTcAAAAJ&citation_for_view=Meb0eTcAAAAJ:UeHWp8X0CEIC,"Datacenter Parallel Iterative Matching (dcPIM) is a proactive data-center transport design that simultaneously achieves near-optimal tail latency for short flows and near-optimal network utilization, without requiring any specialized network hardware. dcPIM places its intellectual roots in the classical PIM protocol, variations of which are used in almost all switch fabrics. The key technical result in dcPIM is a new theoretical analysis of the PIM protocol for the datacenter context: we show that, unlike switch fabrics where PIM requires log(n) rounds of control plane messages (for an n-port switch fabric) to guarantee near-optimal network utilization, the datacenter context enables PIM to guarantee near-optimal utilization with constant number of rounds (independent of the number of hosts in the datacenter)! dcPIM design builds upon insights gained from this analysis, and extends the PIM design to overcome the unique …",,,2022
259,Fast & Safe IO Memory Protection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Meb0eTcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Meb0eTcAAAAJ:ufrVoPGSRksC,"IO Memory protection mechanisms prevent malicious and/or buggy IO devices from executing errant transfers into memory. Modern servers achieve this using an IOMMU---IO devices operate on virtual addresses, and IOMMU translates virtual addresses to physical addresses (potentially speeding up translations using a cache called IOTLB) before executing memory transfers. Despite their importance, design of memory protection mechanisms that can provide strong safety properties while achieving high performance has remained elusive. Indeed, recent studies from production datacenters demonstrate that inefficiencies within state-of-the-art memory protection mechanisms result in significant throughput degradation, orders-of-magnitude tail latency inflation, and violation of isolation guarantees. We present Fast & Safe (F&S), a simple modification to existing memory protection mechanisms that enables them to …",,,2024
260,Building Networked Systems for Terabit Ethernet,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Meb0eTcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Meb0eTcAAAAJ:WF5omc3nYNoC,"Over the last two decades, hardware in datacenters has shown diverging trends. On the one hand, access link bandwidth has increased rapidly, with datacenters now commonly supporting Terabit Ethernet (ie, Ethernet with speeds above 100Gbps). Modern network hardware is capable of supporting microsecond-scale latency and multi-hundred-gigabit bandwidth. However, on the other hand, the slowdown of Moore’s Law and the end of Dennard scaling have resulted in total compute capacity (the number of CPU cores multiplied by per-core performance) remaining largely stagnant. As a result, network performance bottlenecks have shifted to the host network stacks, which are responsible for processing network packets to and from applications.",,,2024
261,High-throughput and Flexible Host Networking via Control and Data Path Physical Separation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Meb0eTcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Meb0eTcAAAAJ:eQOLeE2rZwMC,,,,2024
262,Harmony: A Congestion-free Datacenter Architecture,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Meb0eTcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Meb0eTcAAAAJ:YsMSGLbcyi4C,"Datacenter networks today provide best-effort delivery—messages may observe unpredictable queueing, delays, and drops due to switch buffer overflows within the network. Such weak guarantees reduce the set of assumptions that system designers can rely upon from the network, thus introducing inefficiency and complexity in host hardware and software.",,,2024
263,OptORAMa: optimal oblivious RAM,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UF-wXn0AAAAJ&citation_for_view=UF-wXn0AAAAJ:3fE2CSJIrl8C,"Oblivious RAM (ORAM), first introduced in the ground-breaking work of Goldreich and Ostrovsky (STOC ’87 and J. ACM ’96) is a technique for provably obfuscating programs’ access patterns, such that the access patterns leak no information about the programs’ secret inputs. To compile a general program to an oblivious counterpart, it is well-known that amortized blowup is necessary, where N is the size of the logical memory. This was shown in Goldreich and Ostrovksy’s original ORAM work for statistical security and in a somewhat restricted model (the so called balls-and-bins model), and recently by Larsen and Nielsen (CRYPTO ’18) for computational security. A long standing open question is whether there exists an optimal ORAM construction that matches the aforementioned logarithmic lower bounds (without making large memory word assumptions, and assuming a constant number of CPU registers). In this paper …",Springer International Publishing,,2020
264,Doubly efficient private information retrieval and fully homomorphic RAM computation from ring LWE,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UF-wXn0AAAAJ&citation_for_view=UF-wXn0AAAAJ:0EnyYjriUFMC,"A (single server) private information retrieval (PIR) allows a client to read data from a public database held on a remote server, without revealing to the server which locations she is reading. In a doubly efficient PIR (DEPIR), the database is first preprocessed, but the server can subsequently answer any client’s query in time that is sub-linear in the database size. Prior work gave a plausible candidate for a public-key variant of DEPIR, where a trusted party is needed to securely preprocess the database and generate a corresponding public key for the clients; security relied on a new non-standard code-based assumption and a heuristic use of ideal obfuscation. In this work we construct the stronger unkeyed notion of DEPIR, where the preprocessing is a deterministic procedure that the server can execute on its own. Moreover, we prove security under just the standard ring learning-with-errors (RingLWE) assumption …",,,2023
265,"Oblivious hashing revisited, and applications to asymptotically efficient ORAM and OPRAM",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UF-wXn0AAAAJ&citation_for_view=UF-wXn0AAAAJ:u-x6o8ySG0sC,"Oblivious RAM (ORAM) is a powerful cryptographic building block that allows a program to provably hide its access patterns to sensitive data. Since the original proposal of ORAM by Goldreich and Ostrovsky, numerous improvements have been made. To date, the best asymptotic overhead achievable for general block sizes is , due to an elegant scheme by Kushilevitz et al., which in turn relies on the oblivious Cuckoo hashing scheme by Goodrich and Mitzenmacher. In this paper, we make the following contributions: we first revisit the prior -overhead ORAM result. We demonstrate the somewhat incompleteness of this prior result, due to the subtle incompleteness of a core building block, namely, Goodrich and Mitzenmacher’s oblivious Cuckoo hashing scheme. Even though we do show how to patch the prior result such that we can fully realize Goodrich and Mitzenmacher’s elegant blueprint for …",Springer International Publishing,,2017
266,Delegating RAM computations with adaptive soundness and privacy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UF-wXn0AAAAJ&citation_for_view=UF-wXn0AAAAJ:Tyk-4Ss8FVUC,"We consider the problem of delegating RAM computations over persistent databases. A user wishes to delegate a sequence of computations over a database to a server, where each computation may read and modify the database and the modifications persist between computations. Delegating RAM computations is important as it has the distinct feature that the run-time of computations maybe sub-linear in the size of the database. We present the first RAM delegation scheme that provide both soundness and privacy guarantees in the adaptive setting, where the sequence of delegated RAM programs are chosen adaptively, depending potentially on the encodings of the database and previously chosen programs. Prior works either achieved only adaptive soundness without privacy [Kalai and Paneth, ePrint’15], or only security in the selective setting where all RAM programs are chosen statically [Chen et al. ITCS’16 …",Springer Berlin Heidelberg,,2016
267,Cryptography for parallel RAM from indistinguishability obfuscation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UF-wXn0AAAAJ&citation_for_view=UF-wXn0AAAAJ:UeHWp8X0CEIC,"Since many cryptographic schemes are about performing computation on data, it is important to consider a computation model which captures the prominent features of modern system architecture. Parallel random access machine (PRAM) is such an abstraction which not only models multiprocessor platforms, but also new frameworks supporting massive parallel computation such as MapReduce. In this work, we explore the feasibility of designing cryptographic solutions for the PRAM model of computation to achieve security while leveraging the power of parallelism and random data access. We demonstrate asymptotically optimal solutions for a wide-range of cryptographic tasks based on indistinguishability obfuscation. In particular, we construct the first publicly verifiable delegation scheme with privacy in the persistent database setting, which allows a client to privately delegate both computation and data to a …",,,2016
268,A logarithmic lower bound for oblivious ram (for all parameters),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UF-wXn0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=UF-wXn0AAAAJ:YOwf2qJgpHMC,"An oblivious RAM (ORAM), introduced by Goldreich and Ostrovsky [J. ACM, 43 (1996), pp. 431–473] is a (probabilistic) RAM that hides its access pattern; i.e., for every input the observed locations accessed are similarly distributed. In recent years there has been great progress both in terms of upper bounds and in terms of lower bounds, essentially pinning down the smallest overhead possible in various settings of parameters. We observe that there is a very natural setting of parameters in which no nontrivial lower bound is known—not even those in restricted models of computation (like the so-called balls and bins model). Let and be the number of cells and bit-size of cells, respectively, in the RAM that we wish to simulate obliviously. Denote by the cell bit-size of the ORAM. All previous ORAM lower bounds have a multiplicative factor which makes them trivial in many settings of parameters of interest. In this work, we prove a new …",Society for Industrial and Applied Mathematics,,2025
269,Black box crypto is useless for doubly efficient PIR,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UF-wXn0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=UF-wXn0AAAAJ:Zph67rFs4hoC,"A (single server) private information retrieval (PIR) allows a client to read data from a public database held on a remote server, without revealing to the server which locations she is reading. In a doubly efficient PIR (DEPIR), the database is first preprocessed offline into a data structure, which then allows the server to answer any client query efficiently in sub-linear online time. Constructing DEPIR is a notoriously difficult problem, and this difficulty even extends to a weaker notion secret-key DEPIR (SK-DEPIR), where the database is preprocessed using secret randomness and the client is given a secret key for making queries. We currently only have constructions of SK-DEPIR from the Ring LWE assumption or from non-standard code-based assumptions. We show that the black-box use of essentially all generic cryptographic primitives (e.g., key agreement, oblivious transfer, indistinguishability obfuscation, etc …",Springer Nature Switzerland,,2025
270,MegaBlocks: Breaking the Logarithmic I/O-Overhead Barrier for Oblivious RAM,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UF-wXn0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=UF-wXn0AAAAJ:_kc_bZDykSQC,"Oblivious RAM (ORAM) is a central cryptographic primitive that enables secure memory access while hiding access patterns. Among existing ORAM paradigms, hierarchical ORAMs were long considered impractical despite their asymptotic optimality. However, recent advancements (FutORAMa, CCS'23) demonstrate that hierarchical ORAM-based schemes can be made efficient given sufficient client-side memory. In this work, we present a new hierarchical ORAM construction that achieves practical performance without requiring large local memory. From a theoretical standpoint, we identify that there is a gap in the literature concerning the asymmetric setting, where the logical word size is asymptotically smaller than the physical memory block size. In this scenario, the best-known construction (OptORAMa, J.\ACM'23,) turns every logical query into physical memory accesses (quantity known as``I/O overhead''), whereas the lower bound of Komargodski and Lin (CRYPTO'21) implies that accesses are needed. We close this gap by constructing an optimal ORAM for the asymmetric setting, achieving an I/O overhead of . Our construction features exceptionally small constants (between 1 and 4, depending on the block size) and operates without requiring large local memory. We implement our scheme and compare it to PathORAM (CCS'13) and FutORAMa, demonstrating significant improvement. For 1TB logical memory, our construction obtains - reduction in I/O overhead and bandwidth compared to PathORAM, and -- improvement over FutORAMa. This improvement applies when those …",,,2025
271,Efficient Garbled Pseudorandom Functions and Lookup Tables from Minimal Assumption,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UF-wXn0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=UF-wXn0AAAAJ:ULOm3_A8WrAC,"Yao's garbled circuits have received huge attention in both theory and practice. While garbled circuits can be constructed using minimal assumption (ie, the existence of pseudorandom functions or one-way functions), the state-of-the-art constructions (eg, Rosulek-Roy, Crypto 2021) are based on stronger assumptions. In particular, the``Free-XOR''technique (Kolesnikov-Schneider, ICALP 2008) is essential in these state-of-the-art constructions, and their security can only be proven in the random oracle model, or rely on the``circular-correlation robust hash''assumption. In this paper, we aim to develop new techniques to construct efficient garbling schemes using minimal assumptions. Instead of generically replacing the Free-XOR technique, we focus on garbling schemes for specific functionalities. We successfully eliminated the need for Free-XOR in several state-of-the-art schemes, including the one-hot garbling (Heath and Kolesnikov, CCS 2021) and the garbled pseudorandom functions, and the garbled lookup tables (Heath, Kolesnikov and Ng, Eurocrypt 2024). Our schemes are based on minimal assumptions, ie, standard pseudorandom functions (PRFs)---we resolved the need for circular security. The performance of our scheme is almost as efficient as the best results except for a small constant factor. Namely, for any lookup table , our scheme takes bits of communication, where is the security parameter of PRF.",,,2025
272,"Doubly efficient cryptography: commitments, arguments and RAM MPC",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UF-wXn0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=UF-wXn0AAAAJ:KlAtU1dfN6UC,"Can a sender commit to a long input without even reading all of it? Can a prover convince a verifier that an NP statement holds without even reading the entire witness? Can a set of parties run a multiparty computation (MPC) protocol in the RAM model, without necessarily even reading their entire inputs? We show how to construct such “doubly efficient” schemes in a setting where parties can preprocess their input offline, but subsequently they can engage in many different protocol executions over this input in sublinear online time. We do so in the plain model, without any common setup. Our constructions rely on doubly efficient private information retrieval (DEPIR) as a building block and can be instantiated based on Ring LWE. In more detail, we begin by constructing doubly efficient (interactive) commitments, where the sender preprocesses the input offline, and can later commit to this input to arbitrary receivers in …",Springer Nature Switzerland,,2024
273,Computational design of peptides that target transmembrane helices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=A37Uj4kAAAAJ&citation_for_view=A37Uj4kAAAAJ:u5HHmVD_uO8C,"A variety of methods exist for the design or selection of antibodies and other proteins that recognize the water-soluble regions of proteins; however, companion methods for targeting transmembrane (TM) regions are not available. Here, we describe a method for the computational design of peptides that target TM helices in a sequence-specific manner. To illustrate the method, peptides were designed that specifically recognize the TM helices of two closely related integrins (αIIbβ3 and αvβ3) in micelles, bacterial membranes, and mammalian cells. These data show that sequence-specific recognition of helices in TM proteins can be achieved through optimization of the geometric complementarity of the target-host complex.",American Association for the Advancement of Science,,2007
274,The structure and function of platelet integrins,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=A37Uj4kAAAAJ&citation_for_view=A37Uj4kAAAAJ:d1gkVwhDpl0C,"Integrins are a ubiquitous family of non‐covalently associated α/β transmembrane heterodimers linking extracellular ligands to intracellular signaling pathways [1] [Cell, 2002; 110: 673]. Platelets contain five integrins, three β1 integrins that mediate platelet adhesion to the matrix proteins collagen, fibronectin and laminin, and the β3 integrins αvβ3 and αIIbβ3 [2] [J Clin Invest, 2005; 115: 3363]. While there are only several hundred αvβ3 molecules per platelet, αvβ3 mediates platelet adhesion to osteopontin and vitronectin in vitro [3] [J Biol Chem, 1997; 272: 8137]; whether this occurs in vivo remains unknown. By contrast, the 80 000 αIIbβ3 molecules on agonist‐stimulated platelets bind fibrinogen, von Willebrand factor, and fibronectin, mediating platelet aggregation when the bound proteins crosslink adjacent platelets [2] [J Clin Invest, 2005; 115: 3363]. Although platelet integrins are poised to shift from resting to …",Blackwell Publishing Ltd,Journal of Thrombosis and Haemostasis,2009
275,"Protein-protein interactions in the membrane: sequence, structural, and biological motifs",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=A37Uj4kAAAAJ&citation_for_view=A37Uj4kAAAAJ:u-x6o8ySG0sC,"Single-span transmembrane (TM) helices have structural and functional roles well beyond serving as mere anchors to tether water-soluble domains in the vicinity of the membrane. They frequently direct the assembly of protein complexes and mediate signal transduction in ways analogous to small modular domains in water-soluble proteins. This review highlights different sequence and structural motifs that direct TM assembly and discusses their roles in diverse biological processes. We believe that TM interactions are potential therapeutic targets, as evidenced by natural proteins that modulate other TM interactions and recent developments in the design of TM-targeting peptides.",Elsevier,Structure,2008
276,Evolution of Invasion in a Diverse Set of Fusobacterium Species,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=A37Uj4kAAAAJ&citation_for_view=A37Uj4kAAAAJ:4DMP91E08xMC,"The diverse Fusobacterium genus contains species implicated in multiple clinical pathologies, including periodontal disease, preterm birth, and colorectal cancer. The lack of genetic tools for manipulating these organisms leaves us with little understanding of the genes responsible for adherence to and invasion of host cells. Actively invading Fusobacterium species can enter host cells independently, whereas passively invading species need additional factors, such as compromise of mucosal integrity or coinfection with other microbes. We applied whole-genome sequencing and comparative analysis to study the evolution of active and passive invasion strategies and to infer factors associated with active forms of host cell invasion. The evolution of active invasion appears to have followed an adaptive radiation in which two of the three fusobacterial lineages acquired new genes and underwent expansions of …",American Society for Microbiology,,2014
277,Single-enzyme biomineralization of cadmium sulfide nanocrystals with controlled optical properties,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=A37Uj4kAAAAJ&citation_for_view=A37Uj4kAAAAJ:RHpTSmoSYBkC,"Nature has evolved several unique biomineralization strategies to direct the synthesis and growth of inorganic materials. These natural systems are complex, involving the interaction of multiple biomolecules to catalyze biomineralization and template growth. Herein we describe the first report to our knowledge of a single enzyme capable of both catalyzing mineralization in otherwise unreactive solution and of templating nanocrystal growth. A recombinant putative cystathionine γ-lyase (smCSE) mineralizes CdS from an aqueous cadmium acetate solution via reactive H2S generation from l-cysteine and controls nanocrystal growth within the quantum confined size range. The role of enzymatic nanocrystal templating is demonstrated by substituting reactive Na2S as the sulfur source. Whereas bulk CdS is formed in the absence of the enzyme or other capping agents, nanocrystal formation is observed when smCSE is …",National Academy of Sciences,,2016
278,Optimizing Scaled up Production and Purification of Recombinant Hydrophobin HFBI in Pichia pastoris,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=A37Uj4kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=A37Uj4kAAAAJ:zGWyAL6qfKUC,"Hydrophobins are small, surface-active protein biosurfactants secreted by filamentous fungi with potential applications in industries such as pharmaceuticals, sanitation, and biomaterials. Additionally, hydrophobins are known to stabilize enzymatic processing of biomass for improved catalytic efficiency. In this study, Pichia pastoris was used to recombinantly express hydrophobin HFBI from Trichoderma reesei, a well-characterized fungal system used industrially for bioethanol production. Iterative optimization was performed on both the induction and purification of HFBI, ultimately producing yields of 86.6 mg/L HFBI and elution concentrations of 48 μM HFBI determined pure by SDS-PAGE, over a five-day methanol-fed batch shake flask induction regiment followed by a single unit operation multimodal cation exchange purification. This final purified material represents an improvement over prior approaches to enable a wider range of potential applications for biosurfactants.",MDPI,,2025
279,Effect of Mutations on Smlt1473 Binding to Various Substrates Using Molecular Dynamics Simulations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=A37Uj4kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=A37Uj4kAAAAJ:beqBT5984LEC,"Smlt1473 is a polysaccharide lyase from Stenotrophomonas maltophilia whose crystal structure was solved recently by using X-ray crystallography. There was an effort to study the effect of mutations on the activity of Smlt1473 binding to various substrates like hyaluronic acid (HA), mannuronic acid (ManA), and alginate. In this study, we use molecular docking and molecular dynamics simulations to investigate the effect of binding of various substrates (HA and ManA) to Smlt1473 and two of its mutants H221F and R312L. We further studied the stability in the binding of Smlt1473 to its various substrates as well as the role of fluctuations. Machine learning-based clustering algorithms were used to group the entire simulation trajectory into various stable states. The molecular interactions of Smlt1473 with the substrates were calculated, and the importance of specific residues was tested with observed activity assays due …",American Chemical Society,,2025
280,Applying a polysaccharide lyase from Stenotrophomonas maltophilia to disrupt alginate exopolysaccharide produced by Pseudomonas aeruginosa clinical isolates,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=A37Uj4kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=A37Uj4kAAAAJ:TY5xIG7f_2sC,"Pseudomonas aeruginosa is considered one of the most challenging, drug-resistant, opportunistic pathogens partly due to its ability to synthesize robust biofilms. Biofilm is a mixture of extracellular polymeric substances (EPS) that encapsulates microbial cells, leading to immune evasion, antibiotic resistance, and thus higher risk of infection. In the cystic fibrosis lung environment, P. aeruginosa undergoes a mucoid transition, defined by overproduction of the exopolysaccharide alginate. Alginate encapsulation results in bacterial resistance to antibiotics and the host immune system. Given its role in airway inflammation and chronic infection, alginate is an obvious target to improve treatment for P. aeruginosa infection. Previously, we demonstrated polysaccharide lyase Smlt1473 from Stenotrophomonas maltophilia strain k279a can catalyze the degradation of multiple polyuronides in vitro, including D-mannuronic acid …",American Society for Microbiology,,2025
281,Directed Evolution of Silicatein Reveals Biomineralization Synergism between Protein Sequences,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=A37Uj4kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=A37Uj4kAAAAJ:-w1eE4La9_EC,"Biomineralization is a green synthesis route for a variety of metal nanoparticles. Silicatein is a biomineralization protein originally found in marine sponge Tethya aurantia that converts inorganic precursors to metal oxide nanoparticles. In this work, we investigate the popular catalytic triad hypothesis and implement directed evolution with the aim to improve the solubility and kinetics of silicatein to enable increased nanoparticle synthesis. Site-directed mutagenesis with catalytic triad residues did not abolish biomineralization activity, aligning with the results seen in one previous study. Recombinant production of silicatein and mutants in Escherichia coli following library generation and a survival screen yielded several mutant proteins with augmented biomineralization activity. Sequence analysis of these mutant proteins reveals multiple sequences within a single cell that contribute to enhanced biomineralization …",American Chemical Society,,2025
282,Integrating Bacteriocins and Biofilm-Degrading Enzymes to Eliminate L. monocytogenes Persistence,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=A37Uj4kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=A37Uj4kAAAAJ:4Wrxgq2JVp0C,"Listeria monocytogenes is a Gram-positive bacterium causing listeriosis, a severe infection responsible for significant morbidity and mortality globally. Its persistence on food processing surfaces via biofilm formation presents a major challenge, as conventional sanitizers and antimicrobials exhibit limited efficacy against biofilm-embedded cells. This study investigates a novel approach combining an engineered polysaccharide-degrading enzyme (CAase) with a bacteriocin (thermophilin 110) produced by Streptococcus thermophilus. Laboratory assays evaluated the effectiveness of this combination in disrupting biofilms and inactivating L. monocytogenes on various surfaces. The results demonstrated that CAase effectively disrupts biofilm structures, while thermophilin 110 significantly reduces bacterial growth and viability. The preliminary trials indicate a dual-action approach offers a potential alternative to conventional treatments, enhancing food safety by effectively controlling Listeria biofilms in food processing environments.",MDPI,,2025
283,"Cyborg maintenance: Design, breakdown, and inclusion",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09bX2gIAAAAJ&citation_for_view=09bX2gIAAAAJ:IjCSPb-OGe4C,"The lived experiences of common cyborgs are ignored by those who most wish to be cyborg. I push back against the utopic, teleological imaginaries of the Transhumanist movement using a daily concern for actual cyborgs: maintenance. Scholarly work on maintenance is sparse, relatively recent, and generally focused on infrastructure and large technological systems. I merge the work done on these large technological systems with the biopolitical work by disability studies scholars and activists. I show that the common narratives of innovation that insist that technology becomes faster, more efficient, and more durable over time are false, and how upkeep rather than upgrading will be the norm for cyborg bodies. I call for a more deliberate design ethos for producing more accessible maintenance as well. The interfaces between technology and the body are sites of significant breakdown as each degrades the other …",Springer International Publishing,,2019
284,Engineering our selves: morphological freedom and the myth of multiplicity,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09bX2gIAAAAJ&citation_for_view=09bX2gIAAAAJ:u-x6o8ySG0sC,"What would you change about yourself if you could? If you could design and build a feature and add it to yourself, what would it be? Would you design something that makes you better at something you’re not very good at? Maybe you love music, but haven’t ever been very good at singing. If you could buy a piece of technology that would allow you to be able to sing well, would you? Or might you further improve on a skill you’re already good at? What if you could design a chip that would make you able to do extraordinarily difficult calculations and statistical modeling in your head? Would you? Or might you give yourself a skill or ability that is currently outside the range of human ability. What if you could buy a piece of tech that could give you the ability to fly, or access the internet with just a thought? Such approaches raise the potential for completely re-engineering the human body. Would you re-engineer yourself?.",Springer International Publishing,,2021
285,Morphological freedom and the construction of bodymind malleability from eugenics to transhumanism,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09bX2gIAAAAJ&citation_for_view=09bX2gIAAAAJ:Tyk-4Ss8FVUC,"This dissertation examines how the human bodymind has been seen as malleable by science, technology, and policy practitioners from the Eugenic era in the United States in the first half of the 20th century, to the future imaginaries of Transhumanists and technology innovators. I critique the main goal of these practitioners–to perfect the human bodymind and through that perfection, perfecting human society–as utopic, impossible, and amoral. I argue instead, that we are intra-dependent–dependent on and through each other and our ecological contexts. I ground this argument both in the lived experience of those whose bodymind arrangements go against our normative expectations–folks like disabled people, queer and transgender people, body modders, and more–and in the philosophical metaphysics of Karen Barad's Agential Realism. I argue that we can only produce a future where bodymind alteration is acceptable if we first value different bodymind arrangements. I argue both that we cannot consider ourselves individuals, separate from the world or each other, and that multiplicity of bodyminds is a generative, heterotopic (neither utopic nor dystopic), force toward which we ought strive through engaging intentionally with each other in care relations.",Virginia Tech,,2021
286,Imagining Otherwise: The Importance of Speculative Fiction to New Social Justice Imaginaries,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09bX2gIAAAAJ&citation_for_view=09bX2gIAAAAJ:u5HHmVD_uO8C,"Earle Catalyst: Feminism, Theory, Technoscience 5 (1) 2 speculative fiction continues to be predominantly white and male, Schalk shows us how diversification of the medium is, in fact, happening. She also helps us as readers understand, through speculative fiction, the various intersectional oppressions that (dis) abled women of color (and others) navigate In their non-speculative, everyday lived experience. Schalk begins by examining Octavia Butler's novel Kindred (1979). According to Schalk, Kindred illustrates that disability is not merely a metaphor for Blackness or slavery, but must also be taken as the literal, embodied reality of enslaved people. In the opening of Kindred, we learn that the protagonist has lost her arm in mysterious circumstances. The specter of eventual disability forces the reader to “anticipate and expect that disablement could occur at any moment in the text, an experience that psychologically gestures toward the vulnerability of slaves to disability at any moment as well”(p. 50). The ways in which disability affects slaves’ productivity in the slave economy becomes a literal and metaphorical mirror for how disability affects us all in our own society. Schalk returns to Butler's work in Chapter 3, examining the",,,2019
287,Cyborg-Technology Relations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09bX2gIAAAAJ&citation_for_view=09bX2gIAAAAJ:qjMakFHDy7sC,"We advocate for a philosophizing of cyborg-technology relations that takes account disabled technology users. First, we sketch out how tech-driven ableism (“technoableism”) is present in most discourse about technology, and then address how ableism has shaped accounts of disability in philosophy more broadly too. We examine this in historical and media context, then turn to what an unapologetic disability-forward approach to cyborg-technology relations looks like, and what it means to listen to the cyborgs we know and love. This work draws from the interdisciplinary field of disability studies and STS work on crip technoscience. We situate this work mostly within North American media and history of disability and Silicon Valley boosterism on tech, but accounts of technology and of disability are not unique to these locations.",TU Delft OPEN,,2024
288,The Problem of the Sexy Cyborg: The Ethics of Cyborg Imagery,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09bX2gIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=09bX2gIAAAAJ:2osOgNQ5qMEC,"In this article, I discuss two popular tropes about the cyborg in speculative fiction visual media: apotheosis — the pinnacle of human form and function; and grotesquerie — the violation of that perfection through fascinating horror. I look at these tropes in service of discussing the effects of such images and cultural understandings on actual cyborgs. The everyday or common cyborgs that are disabled people; the ones with prosthetics, who use wheelchairs, hearing aids, beta blockers, and Ritalin, who have artificial valves, knees, and pacemakers. I argue that the imagery of perfection and horror that surround cyborgs in media reinforce problematic tropes about disabled people, specifically the tropes of the super crip, pity, and bitter cripple narratives, and the ugly is evil trope where physical disfigurements and disabilities are often shorthand for moral failing. I connect these tropes to longstanding beliefs that were foundational to the eugenics movement of the 19th and 20th centuries, and that still cause resistance to robust social services for disabled people.",,,2024
289,Social Foundations of Education as a Model for Social Foundations of Engineering: Possibilities for Engaging the Philosophy of Engineering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09bX2gIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=09bX2gIAAAAJ:W7OEmFMy1HYC,"The field of social foundations of education emerged in the early 1930s with the aim of developing a comprehensive understanding of “the cultural phenomena—institutions, processes, practices, beliefs, values, and ways of knowing—that underlie any society’s educational ideas and practices”[1]. By extension, social foundations of engineering—a field that does not yet exist, but should—would seek to understand the institutions, processes, practices, beliefs, values, and ways of knowing that underlie engineering education and practice. The fundamentals of these foundations have emerged in critiques of engineering grounded in several different perspectives including science, technology, and society (STS), engineering ethics, and engineering and social justice. Thus far, however, these perspectives have not coalesced into a coherent intellectual framework. In this paper, we draw parallels between engineering and social foundations of education as the field has evolved over time and argue that social foundations of education provides a promising model for social foundations of engineering. We draw on the literature in philosophy of engineering, STS, and engineering and social justice to identify intellectual traditions and frameworks that can be used to flesh out the conception of social foundations of engineering.",,,2024
290,Embodiment Diffracted: Queering and Cripping Morphological Freedom,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09bX2gIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=09bX2gIAAAAJ:d1gkVwhDpl0C,"Transhumanists offer as a human right, the duty to allow all people to alter their bodyminds (or not) as they see fit (so long as it doesn’t hurt anyone else) without suffering any legal or socioeconomic repercussions. On the face of it, this seems like an incredibly positive and egalitarian human right that has the potential to stop discrimination against marginalized people. However, transhumanists also insist on treating everyone as an individual, and not as a member of any “arbitrary” demographic or group. By disregarding demography, and insisting on treating everyone as an individual, transhumanists fail to appreciate the power of shared embodiment, both politically, socially, and individually. Morphological Freedom thus becomes implicitly focused more on providing rich folks freedom from social mores and laws that may limit their access to technological advantages over non-enhanced people in the marketplace …",Springer International Publishing,,2022
291,Deadnames and Missing Chiralities: A Response to Steve Fuller’s “The Problem of Cishumanism”,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09bX2gIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=09bX2gIAAAAJ:UeHWp8X0CEIC,"“Cisgender,” is a term first attributed to German sexologist Volkmar Sigusch and his coining of the term “cis-sexual” in the mid 1990’s (Sigusch 1995). In a 2015 interview (German language, found here) Sigusch explains his reasoning for the coinage, citing the Latin pair of prefixes “cis”(meaning “this side of”), and “trans”(meaning “on the other side of”), arguing that “if there is such a thing as transgender, there must also be cisgender, people who perceive and live their gender as being on this side of their physical sex, basically the so-called normals. For trans people, my invention in the nineties must have been a linguistic liberation blow, because the term has become accepted worldwide”(translation provided by my colleague Romy Rasper and DeepL. com). Transgender activists quickly pounced on the term (see Martine Rothblatt’s first book The Apartheid of Sex (1995), and its updated version From Transgender to Transhuman (2011)), as Steve Fuller (2022) rightly points out, to mark those who were not trans, in effect de-naturalizing identity politics from the always-already what we “are”(see:“born this way”) to a place where identity is fluid and changeable. This use of “cis” and “trans” was not new in 1995. In fact, they have been commonly used in chemistry since the early 20th century to describe molecule chiralities. Chirality is a term coined by Lord Kelvin in 1894 to describe the relationship of certain geometrical figures. Kelvin wrote “I call any geometrical figure, or group of points,‘chiral’, and say that it has chirality if its image in a plane mirror, ideally realized, cannot be brought to coincide with itself.” In much the same way that we have left and …",,,2022
292,Microresonator soliton dual-comb spectroscopy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wgw6h_MAAAAJ&citation_for_view=wgw6h_MAAAAJ:5nxA0vEk-isC,"Measurement of optical and vibrational spectra with high resolution provides a way to identify chemical species in cluttered environments and is of general importance in many fields. Dual-comb spectroscopy has emerged as a powerful approach for acquiring nearly instantaneous Raman and optical spectra with unprecedented resolution. Spectra are generated directly in the electrical domain, without the need for bulky mechanical spectrometers. We demonstrate a miniature soliton-based dual-comb system that can potentially transfer the approach to a chip platform. These devices achieve high-coherence pulsed mode locking. They also feature broad, reproducible spectral envelopes, an essential feature for dual-comb spectroscopy. Our work shows the potential for integrated spectroscopy with high signal-to-noise ratios and fast acquisition rates.",American Association for the Advancement of Science,,2016
293,Soliton frequency comb at microwave rates in a high-Q silica microresonator,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wgw6h_MAAAAJ&citation_for_view=wgw6h_MAAAAJ:eQOLeE2rZwMC,"Frequency combs are having a broad impact on science and technology because they provide a way to coherently link radio/microwave-rate electrical signals with optical-rate signals derived from lasers and atomic transitions. Integrating these systems on a photonic chip would revolutionize instrumentation, time keeping, spectroscopy, navigation, and potentially create new mass-market applications. A key element of such a system-on-a-chip will be a mode-locked comb that can be self-referenced. The recent demonstration of soliton mode locking in crystalline and silicon nitride micro-resonators has provided a way to both mode lock and generate femtosecond time-scale pulses. Here, soliton mode locking is demonstrated in high-Q silica resonators. The resonators produce low-phase-noise soliton pulse trains at readily detectable pulse rates—two essential properties for the operation of frequency combs. A …",Optical Society of America,,2015
294,Searching for exoplanets using a microresonator astrocomb,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wgw6h_MAAAAJ&citation_for_view=wgw6h_MAAAAJ:QyXJ3EUuO1IC,"Orbiting planets induce a weak radial velocity (RV) shift in the host star that provides a powerful method of planet detection. Importantly, the RV technique provides information about the exoplanet mass, which is unavailable with the complementary technique of transit photometry. However, RV detection of an Earth-like planet in the ‘habitable zone’ requires extreme spectroscopic precision that is only possible using a laser frequency comb (LFC). Conventional LFCs require complex filtering steps to be compatible with astronomical spectrographs, but a new chip-based microresonator device, the Kerr soliton microcomb, , , , –, is an ideal match for astronomical spectrograph resolution and can eliminate these filtering steps. Here, we demonstrate an atomic/molecular line-referenced soliton microcomb for calibration of astronomical spectrographs. These devices can ultimately provide LFC systems that would occupy …",Nature Publishing Group,,2019
295,Chaos-assisted broadband momentum transformation in optical microresonators,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wgw6h_MAAAAJ&citation_for_view=wgw6h_MAAAAJ:Ade32sEp0pkC,"The law of momentum conservation rules out many desired processes in optical microresonators. We report broadband momentum transformations of light in asymmetric whispering gallery microresonators. Assisted by chaotic motions, broadband light can travel between optical modes with different angular momenta within a few picoseconds. Efficient coupling from visible to near-infrared bands is demonstrated between a nanowaveguide and whispering gallery modes with quality factors exceeding 10 million. The broadband momentum transformation enhances the device conversion efficiency of the third-harmonic generation by greater than three orders of magnitude over the conventional evanescent-wave coupling. The observed broadband and fast momentum transformation could promote applications such as multicolor lasers, broadband memories, and multiwavelength optical networks.",American Association for the Advancement of Science,,2017
296,Bridging ultrahigh-Q devices and photonic circuits,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wgw6h_MAAAAJ&citation_for_view=wgw6h_MAAAAJ:WC9gN4BGCRcC,"Optical microresonators are essential to a broad range of technologies and scientific disciplines. However, many of their applications rely on discrete devices to attain challenging combinations of ultra-low-loss performance (ultrahigh Q) and resonator design requirements. This prevents access to scalable fabrication methods for photonic integration and lithographic feature control. Indeed, finding a microfabrication bridge that connects ultrahigh-Q device functions with photonic circuits is a priority of the microcavity field. Here, an integrated resonator having a record Q factor over 200 million is presented. Its ultra-low-loss and flexible cavity design brings performance to integrated systems that has been the exclusive domain of discrete silica and crystalline microcavity devices. Two distinctly different devices are demonstrated: soliton sources with electronic repetition rates and high-coherence/low-threshold Brillouin …",Nature Publishing Group,,2018
297,Integrated Architecture for the Automated Generation and Coil Stabilization of a PZT-Enabled Microcomb,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wgw6h_MAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wgw6h_MAAAAJ:TlpoogIpr_IC,"Silicon nitride Dissipative Kerr Soliton (DKS) microcombs have emerged as a future solution to bring metrological optical frequency comb capabilities into a photonic integrated platform with mass-scale fabrication benefits. Precision applications demand low comb line phase noise as well as high repetition rate stability, but current approaches to achieve this involve complex architectures, multiple lasers, and high-power components, which are challenging to integrate to the chip scale. To achieve this goal, new architectures are needed to simplify the comb generation, actuation, and pump laser requirements, while enabling chip-integrated solutions. Here we demonstrate a greatly simplified stabilized DKS comb architecture with a single laser and a single point electronic control of both the microcomb generation and its stabilization to a coil-resonator reference. The silicon nitride microcomb is integrated with a low power, broadband PZT actuator that is driven by a simple electronic control sequence that generates a soliton and stabilizes it to the 16-meter silicon nitride coil resonator. PZT-enabled control brings flexibility and simplicity to the soliton generation and stabilization using a single CW pump laser, resulting in significantly reduced electronic and optical infrastructure. We demonstrate coil-resonator locking which suppresses the 1 kHz frequency noise by 40 dB over the 35 nm wide comb spectrum, with comb line linewidths as low as 66 Hz and 108 GHz soliton repetition rate phase noise equivalent to -118 dBc/Hz when divided down to 10 GHz. The low power PZT actuator consumes nW bias power and the coil resonator allows flexible dual …",,,2025
298,Photonic chip-based optical frequency division with PZT-integrated soliton microcombs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wgw6h_MAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wgw6h_MAAAAJ:SnGPuo6Feq8C,"Optical frequency division (OFD) produces low-noise microwave and millimeter-wave signals by transferring the exceptional stability of optical references to electronic frequency domains. Recent developments in integrated optical references and soliton microcombs have paved the way for miniaturizing OFD oscillators to chip scale. Critical to this realization is a rapid tunable frequency comb that is stabilized to the optical references, thereby coherently linking optical and electronic frequencies. In this work, we advance the on-chip OFD technology using an integrated high-speed PZT stress-optic actuator on the SiN soliton microcomb resonator. The integrated PZT actuator tunes the resonance frequency of the soliton-generating microresonator with a bandwidth exceeding 10s MHz and independently adjusts the soliton repetition rate without perturbing the frequency comb offset. Optical frequency division and low-noise mmWave generation are demonstrated by feedback control of the soliton repetition rate through the integrated PZT-actuator, and the soliton microcomb is stabilized to a pair of reference lasers that are locked to an integrated 4-meter SiN coil reference cavity. Our approach provides a fast, versatile and integrated control mechanism for OFD oscillators and their applications in advanced communications, sensing, and precise timing.",,,2025
299,Microcavity Kerr optical frequency division with integrated SiN photonics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wgw6h_MAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wgw6h_MAAAAJ:mWEH9CqjF64C,"Optical frequency division has revolutionized microwave and millimetre-wave generation and set spectral purity records owing to its unique capability to transfer high fractional stability from optical to electronic frequencies. Recently, rapid developments in integrated optical reference cavities and microresonator-based optical frequency combs (microcombs) have created a path to transform optical frequency division technology to the chip scale. Here we demonstrate an ultralow-phase-noise millimetre-wave oscillator by leveraging integrated photonic components and microcavity Kerr optical frequency division. The oscillator derives its stability from an integrated complementary-metal–oxide–semiconductor-compatible SiN coil cavity, and the optical frequency division is achieved spontaneously through Kerr interaction in the integrated SiN microresonator between the soliton microcombs and the injected reference …",Nature Publishing Group,,2025
300,"Low voltage, high speed PZT actuated Si3N4 microcombs for laser-tuning-free soliton generation and modulation",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wgw6h_MAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wgw6h_MAAAAJ:DrR-2ekChdkC,"We demonstrate an integrated PZT SiN Kerr-microcomb requiring< 10 Volts to initiate a 40-comb line 106.8 GHz soliton without laser frequency tuning. Actuation of 172 MHz/V and modulation bandwidth of 70 MHz, a 10x/4x improvement.",Optica Publishing Group,,2025
301,Heterogeneous integration of a high-speed photodiode with microcavity solitons for on-chip mmWave generation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wgw6h_MAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wgw6h_MAAAAJ:rTD5ala9j4wC,We present a photonically driven on-chip millimeter wave (mmWave) source<?TeX \LDQvoffset{2pc}\LDQhoffset{0pt}?> enabled by the heterogeneous<?TeX \LDQvoffset{3pc}\LDQhoffset{0pt}?> integration of a high-speed InGaAs/InP photodiode and silicon nitride () microcavity solitons. The chip delivers mmWaves with of electrical power at a frequency of 98 GHz with kHz-class linewidth and low phase noise and marks a significant advancement in on-chip photonic mmWave source performance. This breakthrough not only demonstrates capabilities of heterogeneous photonic integration but also<?TeX \LDQvoffset{5pc}\LDQhoffset{0pt}?> offers a compact and scalable solution for future low-noise mmWave applications in communications and sensing<?TeX \break?> technologies.,Optica Publishing Group,,2025
302,Using LEGO MINDSTORMS NXT and LEJOS in an advanced software engineering course,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ixa74FIAAAAJ&citation_for_view=Ixa74FIAAAAJ:u-x6o8ySG0sC,"This paper describes the benefits of using LeJOS and the Lego Mindstorms NXT set for teaching advanced software development. While Lego Mindstorms has been used in introduction to computer science courses, it is not reported to be widely used in a simulated production environment requiring such things as threading, network communications, and the implementation of command protocols. Additionally, because the Mindstorms NXT system supports Bluetooth communications with multiple devices, it is possible to use this system as the basis for a complex, communicating system requiring multiple software artifacts on different machines.",IEEE,,2010
303,From domain models to architecture frameworks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ixa74FIAAAAJ&citation_for_view=Ixa74FIAAAAJ:u5HHmVD_uO8C,Thispaper &resses how domain analysis served to help create reusable architectures and components in the development of a real-time embealied system. The subject domain is portable winders communication devices. The paper discwrses this experience in terms of discovering and developing reusable@ neworkr for this domain. Some interesting differences between this approach and what is usually suggested as a process for developing frameworks are described.,,,1997
304,Computing classification system 1998: current status and future maintenance report of the CCS Update Committee,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ixa74FIAAAAJ&citation_for_view=Ixa74FIAAAAJ:roLk4NBRz8UC,"The ACM Computing Classification System (CCS), which for 20 years has served as the primary and most generally used system for the classification and indexing of the published literature of computing, has been substantially revised to reflect the greatly changed nature of computing. In this article, the revision committee reports on its work, describes the changes in the CCS, proposes processes for making annual changes, and recommends a future total revision. Until 1995, the CCS was named the Computing Reviews Classification System, or CRCS. After a major overhaul of its basic structure in 1982 [1], the CCS was revised and updated in 1983 [2], in 1987 [3], and in 1991 [4]. The CCS is the basis for classifying all documents in the ACM Guide to Computing Literature (Guide), an annual bibliography that lists more than 20,000 new items, and has indexed more than 250,000 items since 1982. Various other organizations use it officially and unofficially to classify literature, reviewers, and so forth. A complete description of CCS’98 follows these discussions.",,,1998
305,The Effectiveness of the Stylometry of Function words in Discriminating between Shakespeare and Fletcher,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ixa74FIAAAAJ&citation_for_view=Ixa74FIAAAAJ:UeHWp8X0CEIC,"A number of recent successful authorship studies have relied on a statistical analysis of language features based on function words. However, stylometry has not been extensively applied to Elizabethan and Jacobean dramatic questions. To determine the effectiveness of such an approach in this field, language features are studied in twenty-four plays by Shakespeare and eight by Fletcher. The goal is to develop procedures that might be used to determine the authorship of individual scenes in The Two Noble Kinsmen and Henry VIII. Homonyms, spelling variants and contracted forms in old-spelling dramatic texts present problems for a computer analysis. A program that uses a system of pre-edit codes and replacement /expansion lists was developed to prepare versions of the texts in which all forms of common words can be recognized automatically. To evaluate some procedures for determining authorship developed by A. Q. Morton and his colleagues, occurrences of 30 common collocations and 5 proportional pairs are analyzed in the texts. Within-author variation for these features is greater than had been found in previous studies. Univariate chi-square tests are shown to be of limited usefulness because of the statistical distribution of these textual features and correlation between pairs of features. The best of the collocations do not discriminate as well as most of the individual words from which they are composed. Turning to the rate of occurrence of individual words and groups of words, distinctiveness ratios and t-tests are used to select variables that best discriminate between Shakespeare and Fletcher. Variation due to date of …",The University of Edinburgh,,1987
306,Architecting for domain variability,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ixa74FIAAAAJ&citation_for_view=Ixa74FIAAAAJ:d1gkVwhDpl0C,"This paper addresses how domain analysis served to help create reusable architectures and components in the development of a real-time embedded system. The resulting product is Motorola’s FLEX™ Kernel, a set of components to support development of portable wireless communication devices. The paper discusses this experience in terms of discovering and developing reusable frameworks for this domain. Our approach to incorporating tailorability into these components is described and compared with a recently published approach.",Springer Berlin Heidelberg,,1998
307,How student surveys drive change: using the data buddies department report from the computing research association,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ixa74FIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ixa74FIAAAAJ:Zph67rFs4hoC,"This panel provides examples of how faculty refine, expand, and evaluate initiatives to broaden participation in computing using the Data Buddies Survey (https://cra.org/cerp/data-buddies). The Computing Research Association administers the survey annually and prepares summary reports for over 140 member institutions. Participation is free, and the survey gathers information about students' educational experiences, confidence, attitudes, and career goals. Faculty and staff from prospective and participating institutions can benefit from the panelists' discussion of aligning department initiatives for broadening participation with data about students' experiences.",,,2021
308,Hazard Mitigation Planning for Utilities: Forming Partnerships for Leveraging Resources and Funding Opportunities,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ixa74FIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ixa74FIAAAAJ:KlAtU1dfN6UC,"Hazard mitigation is any sustained action taken to reduce loss of life and property by lessening the impacts of disasters. Recent disaster events have shown that is essential for both water utilities to employ hazard mitigation planning to protect functionality, so that they are better equipped to serve the needs of the service population, as well as minimize the cost of recovery. Applicants must have a FEMA approved hazard mitigation plan in order to be eligible to receive federal project grants. A plan for water and wastewater utilities may take the form of an individual mitigation plan, which may be annexed to the local or state plan, or the utility may participate in the development or update of a local mitigation plan within an applicable jurisdiction. The mitigation planning process for water utilities consists of analyzing a system's risk from natural hazards and its capability to handle them, identifying methods to address …",Water Environment Federation,,2012
309,Teaching second-level Java and software engineering with Android,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ixa74FIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ixa74FIAAAAJ:Tyk-4Ss8FVUC,"Over the past two years, second-year Java and software engineering courses have been taught at the University of Virginia and North Carolina State University utilizing the Android OS platform. Instructors taught a variety of traditional second-year topics, including abstraction, design, requirements, and testing, utilizing a variety of Android-based mobile devices. Anecdotal responses from student surveys and evaluations from five course sessions indicate that teaching lower-level courses with more advanced and current technology, even with a steeper learning curve, is beneficial. In this tutorial proposal, we outline our plan for presenting a session that would help educators incorporate the Android OS into their curriculum and how to use the system even if mobile devices are not available.",IEEE,,2011
310,Role of larger software artifacts in introductory computer science courses,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ixa74FIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ixa74FIAAAAJ:eQOLeE2rZwMC,"This paper compares the effectiveness of two approaches that can be used to teach concepts in introductory courses such as CS1 and CS2 - a conventional lecture-based approach and one using larger software programs (artifacts) with accompanying guided exercises. Our assessment includes measures of students' self-confidence as well as a measurement of their knowledge of the topics used in this study: inheritance and iterators. Finally, we consider some generalizations that can be made about these treatments and how well they perform.",IEEE,,2010
311,RAPTOR: Routing Attacks on Privacy in Tor,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ov72AA4AAAAJ&citation_for_view=ov72AA4AAAAJ:W7OEmFMy1HYC,"The Tor network is a widely used system for anonymous communication. However, Tor is known to be vulnerable to attackers who can observe traffic at both ends of the communication path. In this paper, we show that prior attacks are just the tip of the iceberg. We present a suite of new attacks, called Raptor, that can be launched by Autonomous Systems (ASes) to compromise user anonymity. First, AS-level adversaries can exploit the asymmetric nature of Internet routing to increase the chance of observing at least one direction of user traffic at both ends of the communication. Second, AS-level adversaries can exploit natural churn in Internet routing to lie on the BGP paths for more users over time. Third, strategic adversaries can manipulate Internet routing via BGP hijacks (to discover the users using specific Tor guard nodes) and interceptions (to perform traffic analysis). We demonstrate the feasibility of Raptor attacks by analyzing historical BGP data and Traceroute data as well as performing real-world attacks on the live Tor network, while ensuring that we do not harm real users. In addition, we outline the design of two monitoring frameworks to counter these attacks: BGP monitoring to detect control-plane attacks, and Traceroute monitoring to detect data-plane anomalies. Overall, our work motivates the design of anonymity systems that are aware of the dynamics of Internet routing.",USENIX Association,,2015
312,Bamboozling certificate authorities with {BGP},https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ov72AA4AAAAJ&citation_for_view=ov72AA4AAAAJ:KlAtU1dfN6UC,"The Public Key Infrastructure (PKI) protects users from malicious man-in-the-middle attacks by having trusted Certificate Authorities (CAs) vouch for the domain names of servers on the Internet through digitally signed certificates. Ironically, the mechanism CAs use to issue certificates is itself vulnerable to man-in-the-middle attacks by network-level adversaries. Autonomous Systems (ASes) can exploit vulnerabilities in the Border Gateway Protocol (BGP) to hijack traffic destined to a victim's domain. In this paper, we rigorously analyze attacks that an adversary can use to obtain a bogus certificate. We perform the first real-world demonstration of BGP attacks to obtain bogus certificates from top CAs in an ethical manner. To assess the vulnerability of the PKI, we collect a dataset of 1.8 million certificates and find that an adversary would be capable of gaining a bogus certificate for the vast majority of domains. Finally, we propose and evaluate two countermeasures to secure the PKI: 1) CAs verifying domains from multiple vantage points to make it harder to launch a successful attack, and 2) a BGP monitoring system for CAs to detect suspicious BGP routes and delay certificate issuance to give network operators time to react to BGP attacks.",,,2018
313,Counter-RAPTOR: Safeguarding Tor against active routing attacks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ov72AA4AAAAJ&citation_for_view=ov72AA4AAAAJ:kNdYIx-mwKoC,"Tor is vulnerable to network-level adversaries who can observe both ends of the communication to deanonymize users. Recent work has shown that Tor is susceptible to the previously unknown active BGP routing attacks, called RAPTOR attacks, which expose Tor users to more network-level adversaries. In this paper, we aim to mitigate and detect such active routing attacks against Tor. First, we present a new measurement study on the resilience of the Tor network to active BGP prefix attacks. We show that ASes with high Tor bandwidth can be less resilient to attacks than other ASes. Second, we present a new Tor guard relay selection algorithm that incorporates resilience of relays into consideration to proactively mitigate such attacks. We show that the algorithm successfully improves the security for Tor clients by up to 36% on average (up to 166% for certain clients). Finally, we build a live BGP monitoring system …",IEEE,,2017
314,Securing internet applications from routing attacks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ov72AA4AAAAJ&citation_for_view=ov72AA4AAAAJ:aqlVkmm33-oC,Application-layer and network-layer defenses are critical for fortifying routing attacks.,ACM,Communications of the ACM,2021
315,Tempest: Temporal dynamics in anonymity systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ov72AA4AAAAJ&citation_for_view=ov72AA4AAAAJ:3fE2CSJIrl8C,"Many recent proposals for anonymous communication omit from their security analyses a consideration of the effects of time on important system components. In practice, many components of anonymity systems, such as the client location and network structure, exhibit changes and patterns over time. In this paper, we focus on the effect of such temporal dynamics on the security of anonymity networks. We present Tempest, a suite of novel attacks based on (1) client mobility, (2) usage patterns, and (3) changes in the underlying network routing. Using experimental analysis on real-world datasets, we demonstrate that these temporal attacks degrade user privacy across a wide range of anonymity networks, including deployed systems such as Tor; path-selection protocols for Tor such as DeNASA, TAPS, and Counter-RAPTOR; and network-layer anonymity protocols for Internet routing such as Dovetail and HORNET. The degradation is in some cases surprisingly severe. For example, a single host failure or network route change could quickly and with high certainty identify the client's ISP to a malicious host or ISP. The adversary behind each attack is relatively weak - generally passive and in control of one network location or a small number of hosts. Our findings suggest that designers of anonymity systems should rigorously consider the impact of temporal dynamics when analyzing anonymity.",,,2018
316,Scaling SCIERA: A Journey Through the Deployment of a Next-generation Network,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ov72AA4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ov72AA4AAAAJ:hFOr9nPyWt4C,"The SCION Next-Generation Network (NGN) architecture has expanded steadily since 2017, with today 20+ ISPs offering SCION connectivity. In production, IP-to-SCION-to-IP translation by SCION-IP-Gateways (SIGs) is used, such that applications are unaware of the NGN communication. To accelerate innovation and deployments, our aim is to increase the number of native SCION use cases, where the application is fully SCION-aware and optimizes communication across all path choices offered by the network. We set out to achieve two core objectives: (1) facilitating simple native connectivity for applications, and (2) enhancing the scalability of SCION deployment at academic sites. With these goals in mind, we built the SCION Education, Research, and Academic (SCIERA) network infrastructure. This paper presents key lessons learned from the SCIERA deployment, which we anticipate will offer actionable …",,,2025
317,RPKI-Based Location-Unaware Tor Guard Relay Selection Algorithms,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ov72AA4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ov72AA4AAAAJ:-f6ydRqryjwC,"Tor is a well-known anonymous communication tool, used by people with various privacy and security needs. Prior works have exploited routing attacks to observe Tor traffic and deanonymize Tor users. Subsequently, location-aware relay selection algorithms have been proposed to defend against such attacks on Tor. However, location-aware relay selection algorithms are known to be vulnerable to information leakage on client locations and guard placement attacks. Can we design a new location-unaware approach to relay selection while achieving the similar goal of defending against routing attacks? Towards this end, we leverage the Resource Public Key Infrastructure (RPKI) in designing new guard relay selection algorithms. We develop a lightweight Discount Selection algorithm by only incorporating Route Origin Authorization (ROA) information, and a more secure Matching Selection algorithm by incorporating both ROA and Route Origin Validation (ROV) information. Our evaluation results show an increase in the number of ROA-ROV matched client-relay pairs using our Matching Selection algorithm, reaching 48.47% with minimal performance overhead through custom Shadow simulations and benchmarking.",,,2025
318,Exploring the Ecosystem of DNS HTTPS Resource Records: An End-to-End Perspective,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ov72AA4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ov72AA4AAAAJ:ZeXyd9-uunAC,"The DNS HTTPS resource record is a new DNS record type designed for the delivery of configuration information and parameters required to initiate connections to HTTPS network services. In addition, it is a key enabler for TLS Encrypted ClientHello (ECH) by providing the cryptographic keying material needed to encrypt the initial exchange. To understand the adoption of this new DNS HTTPS record, we perform a longitudinal study on the server-side deployment of DNS HTTPS for Tranco top million domains, as well as an analysis of the client-side support for DNS HTTPS through snapshots from major browsers. To the best of our knowledge, our work is the first longitudinal study on DNS HTTPS server deployment, and the first known study on client-side support for DNS HTTPS. Despite the rapidly growing trend of DNS HTTPS adoption, our study highlights challenges and concerns in the deployment by both …",,,2024
319,Mutual TLS in Practice: A Deep Dive into Certificate Configurations and Privacy Issues,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ov72AA4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ov72AA4AAAAJ:L8Ckcad2t8MC,"Transport Layer Security (TLS) is widely recognized as the essential protocol for securing Internet communications. While numerous studies have focused on investigating server certificates used in TLS connections, our study delves into the less explored territory of mutual TLS (mTLS) where both parties need to provide certificates to each other. By utilizing TLS connection logs collected from a large campus network over 23 months, we identify over 2.2 million unique server certificates and over 3.4 million unique client certificates used in over 1.2 billion mutual TLS connections. By jointly analyzing TLS connection data (e.g., port numbers) and certificate data (e.g., issuers for server/client certificates), we quantify the prevalent use of untrusted certificates and uncover potential security concerns resulting from misconfigured certificates, sharing of certificates between servers and clients, and long-expired certificates …",,,2024
320,Intercepting Bluetooth Traffic from Wearable Health Devices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ov72AA4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ov72AA4AAAAJ:IWHjjKOFINEC,"Smart wearable devices are increasingly used to track health conditions and monitor health-related activities, such as blood pressure monitors, oximeters, and smartwatches. Such smart wearable devices often rely on Bluetooth Low Energy (BLE) to send health measurement data to the smartphone, which may then use Wi-Fi to sync up data to the cloud. Several recent works have explored passive attacks on the BLE or Wi-Fi or WAN traffic to infer user activities through the packet metadata. In our work, we take a first step towards investigating the effectiveness of active attacks that intercept the Bluetooth connection between the device and phone, enabling the adversary to extract user health data from encrypted Bluetooth packets which cannot be observed by passive attackers. We find that several popular wearable health devices are vulnerable to the attacks. The reason is rooted in the lack of security mechanisms …",IEEE,,2024
321,A learning platform for SQL injection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1DsajQoAAAAJ&citation_for_view=1DsajQoAAAAJ:Tyk-4Ss8FVUC,"We present a web application system where users can learn about and practice SQL injection attacks. Our system is designed for students in a university level database or computer security class, and is aimed towards students familiar with SQL but with little experience in web security. Our platform currently contains 12 levels, each of which demonstrates a SQL vulnerability that the user must exploit. For each level, we explain the goal of the challenge, and also provide detailed solutions. Our system provides advantages over other methods of teaching SQL injection because it is hands-on, the challenges provide a greater scope of vulnerability coverage, and is easily extensible, allowing instructors to add their own SQL injection problems for their students.",,,2019
322,Hobbits: Hadoop and Hive based Internet traffic analysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1DsajQoAAAAJ&citation_for_view=1DsajQoAAAAJ:qjMakFHDy7sC,"Internet traffic measurement and analysis have long been used to characterize network usage and user behaviors, but face the problem of scalability under the explosive growth of Internet traffic and high-speed access. In this paper, we present Hobbits, a Hadoop and Hive based traffic analysis system that performs Internet Protocol (IP) and Transport Control Protocol (TCP) analysis of large-sized Internet traffic in a scalable manner. Our experimental evaluation on real datasets confirms that Hobbits outperforms previous solutions in terms of both job completion time and storage efficiency.",IEEE,,2016
323,MapReduce-based deep learning with handwritten digit recognition case study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1DsajQoAAAAJ&citation_for_view=1DsajQoAAAAJ:UeHWp8X0CEIC,"Faced with the continuously increasing scale of data and expectation on response time, complex deep learning technologies, though highly accurate, present two non-rival challenges: a large amount of training data makes a model impossible to be built in short time and intolerable time-cost prohibits acceptable real-time responses. In this research we focus on improving the accuracy and efficiency of the handwritten digit recognition problem. We chose this problem because it is regarded as the prototype of a lot of complex recognition and classification problems. The success of classification of the handwritten digit dataset can be extended further to other advanced areas. The Convolutional Neural Network (CNN) is implemented to do the recognition. We further improved the accuracy by adding elastic distortion to the input data, which helps the model better select the features. In addition we implement distributed …",IEEE,,2016
324,Who needs help? Automating student assessment within exploratory learning environments,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1DsajQoAAAAJ&citation_for_view=1DsajQoAAAAJ:2osOgNQ5qMEC,"This article describes efforts to offer automated assessment of students within an exploratory learning environment. We present a regression model that estimates student assessments in an ill-defined medical diagnosis tutor called Rashi. We were pleased to find that basic features of a student’s solution predicted expert assessment well, particularly when detecting low-achieving students. We also discuss how expert knowledge bases might be leveraged to improve this process. We suggest that developers of exploratory learning environments can leverage this technique with relatively few extensions to a mature system. Finally, we describe the potential to utilize this information to direct teachers’ attention towards students in need of help.",Springer International Publishing,,2015
325,Prediction of enzyme mutant activity using computational mutagenesis and incremental transduction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1DsajQoAAAAJ&citation_for_view=1DsajQoAAAAJ:u5HHmVD_uO8C,"Wet laboratory mutagenesis to determine enzyme activity changes is expensive and time consuming. This paper expands on standard one‐shot learning by proposing an incremental transductive method (T2bRF) for the prediction of enzyme mutant activity during mutagenesis using Delaunay tessellation and 4‐body statistical potentials for representation. Incremental learning is in tune with both eScience and actual experimentation, as it accounts for cumulative annotation effects of enzyme mutant activity over time. The experimental results reported, using cross‐validation, show that overall the incremental transductive method proposed, using random forest as base classifier, yields better results compared to one‐shot learning methods. T2bRF is shown to yield 90% on T4 and LAC (and 86% on HIV‐1). This is significantly better than state‐of‐the‐art competing methods, whose performance yield is at 80% or less …",Hindawi Publishing Corporation,,2011
326,How many words does it take to understand a low-resource language?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1DsajQoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1DsajQoAAAAJ:LkGwnXOMwfcC,"When developing language technology, researchers have routinely turned to transfer learning to resolve the data scarcity conundrum presented in low-resource languages. As far as we know, this study is the first to evaluate the amount of documentation needed for transfer learning, specifically the smallest vocabulary size needed to create a sentence embedding space. In adopting widely spoken languages as a proxy for low-resource languages, our experiments show that the relationship between a sentence embedding’s vocabulary size and performance is logarithmic with performance leveling at a vocabulary size of 25,000. It should be noted that this relationship cannot be replicated across all languages and this level of documentation does not exist for many low-resource languages. We do observe, however, that performance accelerates at a vocabulary size of≤ 1000, a quantity that is present in most low-resource language documentation. These results can aid researchers in understanding whether a low-resource language has enough documentation necessary to support the creation of a sentence embedding and language model.",,,2025
327,ASCI: AI-Smart Classroom Initiative,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1DsajQoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1DsajQoAAAAJ:_FxGoFyzp5QC,"The Artificial Intelligence Smart Classroom Initiative (ASCI) presents a re-imagined set of online course tools, designed primarily to support growing computer science classes. The system has four primary tools: an office hours queue, an automatic student grouping algorithm, a course-specific local large-language model (LLM), and administration tools for detecting students and TAs that need support. These tools interoperate to improve the quality of one another (e.g., LLM conversations support students directly in the office hours queue) and are enhanced by synchronizing data from multiple external sources such as Piazza, Gradescope, and Canvas. The system has been deployed in multiple courses over the past three semesters: initially as a FIFO queue, then supporting manual grouping and smart grouping of office hour attendees, and recently including LLM support. Preliminary results indicate that students …",,,2025
328,Towards more efficient office hours for large courses: Using cosine similarity to efficiently construct student help groups,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1DsajQoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1DsajQoAAAAJ:ufrVoPGSRksC,"As undergraduate enrollment in computer science rises, instructors continue to investigate methods to improve the student experience at scale. One aspect commonly used in courses at scale is queue-driven office hours, in which students join an online queue and meet with teaching assistants on a first-come, first-serve basis (FIFO). This poster introduces a novel office hours queue feature that automatically groups students in office hours using the cosine similarity metric across their reported issues provided upon joining the queue. Using real office hour attendance data from a 480-person undergraduate course as a basis for simulation, we find that moderate decreases in student wait time during the semester overall (11% on average) are possible, with more significant decreases possible on the busiest days (20% on average). This approach is suitable for real-world testing and these gains are possible without …",,,2024
329,Providing a Choice of Time Trackers on Online Assessments,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1DsajQoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1DsajQoAAAAJ:WF5omc3nYNoC,"Online assessments allow instructors to facilitate exams and quizzes in both virtual and large classes. Having a clear online timer during these assessments is vital to help students manage their time. However, these same timers can be a cause of anxiety, affecting student performance. Our goals were to determine (i) which types of visualizations are currently in use, (ii) which styles of online timer were preferred by students, and (iii) if providing students a choice of timer impacted their performance. We carried out a semester-long study employing multiple time-tracking displays across 29 online quizzes in three Computer Science courses with a total of 113 student participants. Timer visualizations included count down and elapsed time text as a text-only display or combined with a graphical representation, such as a color-changing progress bar, gray-scale progress bar, or changing phases of the moon …",,,2023
330,Empowering Diabetes Patients by Providing Machine Learning-Driven Predictions and Personalized Visualization Results,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1DsajQoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1DsajQoAAAAJ:YsMSGLbcyi4C,"Although millions of patients have diabetes, it is often challenging to interpret symptoms that historically lead to the condition. To solve this disparity, we created an end-to-end platform that uses a Random Forest model that predicts early-stage diabetes with 95.6% accuracy, then visualizes patient data for those with similar symptoms. After users enter their data for the five most strongly-correlated diabetes symptoms, the model predicts whether the user has diabetes. As a result, this project transforms how patients communicate about their own data, thereby serving as a mechanism to start important conversations with their doctors or others around the world.",IEEE,,2022
331,An introduction to sequential dynamical systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s7ntYOwAAAAJ&citation_for_view=s7ntYOwAAAAJ:qjMakFHDy7sC,"In this chapter we will give the formal definition of sequential dynamical systems (SDS). We will study SDS where the update order is a permutation of the vertex set of the underlying graph. In Chapter 7 we will extend our analysis to update orders that are words over the vertex set, that is, systems where vertices can be updated multiple times within a system update. Since most graphs in this chapter are combinatorial graphs (Section 3.1. 1), we will, by abuse of terminology, refer to combinatorial graphs simply as graphs unless ambiguity may arise.",Springer Science & Business Media,,2007
332,Elements of a theory of simulation II: sequential dynamical systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s7ntYOwAAAAJ&citation_for_view=s7ntYOwAAAAJ:u5HHmVD_uO8C,"We study a class of discrete dynamical systems that is motivated by the generic structure of simulations. The systems consist of the following data: (a) a finite graph Y with vertex set {1,…,n} where each vertex has a binary state, (b) functions F i: F 2n→ F 2n and (c) an update ordering π. The functions Fi update the binary state of vertex i as a function of the state of vertex i and its Y-neighbors and leave the states of all other vertices fixed. The update ordering is a permutation of the Y-vertices. By composing the functions Fi in the order given by π one obtains the sequential dynamical system (SDS): [Formula: see text] We derive a decomposition result, characterize invertible SDS and study fixed points. In particular we analyse how many different SDS that can be obtained by reordering a given multiset of update functions and give a criterion for when one can derive concentration results on this number. Finally, some …",Elsevier,,2000
333,"Discrete, sequential dynamical systems",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s7ntYOwAAAAJ&citation_for_view=s7ntYOwAAAAJ:u-x6o8ySG0sC,"We study a class of discrete dynamical systems that consists of the following data:(a) a finite loop-free graph Y with vertex set {1,…, n} where each vertex has a binary state,(b) a vertex labeled multi-set of functions (F i, Y: F 2 n→ F 2 n) i and (c) a permutation π∈ S n. The function F i, Y updates the state of vertex i as a function of the states of vertex i and its Y-neighbors and leaves the states of all other vertices fixed. The permutation π represents a Y-vertex ordering according to which the functions F i, Y are applied. By composing the functions F i, Y in the order given by π we obtain the dynamical system [F Y, π]=∏ i= 1 n F π (i), Y: F 2 n→ F 2 n, which we refer to as a sequential dynamical system (SDS). Among various basic results on SDS we will study their invertibility and analyze the set|{[F Y, π]| π∈ S n}| for fixed Y and (F i, Y) i. Finally, we give an estimate for the number of non-isomorphic digraphs Γ [F Y, π](having …",North-Holland,,2001
334,Elements of a theory of simulation III: Equivalence of SDS,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s7ntYOwAAAAJ&citation_for_view=s7ntYOwAAAAJ:d1gkVwhDpl0C,"In the development of mathematical foundations for a theory of simulation, a certain class of discrete sequential dynamical systems (SDS) is of particular importance. These systems which we refer to as SDS consist of: (a) a graph Y with vertex set {1,2,…,n}, where each vertex has associated a binary state, (b) a vertex labeled set of functions F i,Y: F 2n→ F 2n, and (c) a permutation π∈Sn. The function Fi,Y update the state of vertex i as a function of the states of vertex i and its Y-neighbors and leaves all other states invariant. By composing these functions in the order given by π, we obtain the SDS [Formula: see text] In this paper, we give a combinatorial upper bound for the number of non-equivalent SDS for a given graph, and we compute this bound explicitly for certain classes of graphs. We give a full characterization of invertible SDS, and analyze the set of fixed points of sequential and parallel cellular automata …",Elsevier,,2001
335,Epidemiological and Economic Impact of COVID-19 in the US,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s7ntYOwAAAAJ&citation_for_view=s7ntYOwAAAAJ:fQNAKQ3IYiAC,"This research measures the epidemiological and economic impact of COVID-19 spread in the US under different mitigation scenarios, comprising of non-pharmaceutical interventions. A detailed disease model of COVID-19 is combined with a model of the US economy to estimate the direct impact of labor supply shock to each sector arising from morbidity, mortality, and lockdown, as well as the indirect impact caused by the interdependencies between sectors. During a lockdown, estimates of jobs that are workable from home in each sector are used to modify the shock to labor supply. Results show trade-offs between economic losses, and lives saved and infections averted are non-linear in compliance to social distancing and the duration of the lockdown. Sectors that are worst hit are not the labor-intensive sectors such as the Agriculture sector and the Construction sector, but the ones with high valued jobs such …",Nature Publishing Group,,2021
336,Pandemics in Silico: Scaling Agent-Based Simulations on Realistic Social Contact Networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s7ntYOwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=s7ntYOwAAAAJ:nrtMV_XWKgEC,"Preventing the spread of infectious diseases requires implementing interventions at various levels of government and evaluating the potential impact and efficacy of those preemptive measures. Agent-based modeling can be used for detailed studies of the spread of such diseases in the presence of possible interventions. The computational cost of modeling epidemic diffusion through large social contact networks necessitates the use of parallel algorithms and resources in order to achieve quick turnaround times. In this work, we present Loimos, a scalable parallel framework for simulating epidemic diffusion. Loimos uses a hybrid of time-stepping and discrete event simulation to model disease spread, and is implemented on top of Charm++, an asynchronous, many-task runtime that enables over-decomposition and adaptive overlap of computation and communication. We demonstrate that Loimos is able to …",IEEE,,2025
337,DIMPLES: Distributed Influence Maximization for Pandemic pLanning on Exascale Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s7ntYOwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=s7ntYOwAAAAJ:t7zJ5fGR-2UC,"We study exascale parallel algorithms for the selection of intervention or monitoring strategies in massive realistic socio-technical networks through scalable Influence Maximization (InfMax) algorithms. We employ novel techniques to enable efficient scaling on up to 8k nodes of OLCF Frontier, with 65k AMD GPUs and 458k AMD CPU cores. Current state-of-the-art InfMax tools are limited to networks with only a few million actors (vertices) and a few hundred million interactions (edges). By overcoming these limitations, we show that our approach is capable of processing a realistic social contact network of the United States with 285 million nodes and about 8 billion edges. This two orders-of-magnitude improvement over the previous state-of-the-art is obtained by leveraging algorithmic advancements for the InfMax problem and designing several problem-specific approaches to overlap communication with …",,,2025
338,Epihiper—A high performance computational modeling framework to support epidemic science,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s7ntYOwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=s7ntYOwAAAAJ:_Re3VWB3Y0AC,"This paper describes Epihiper, a state-of-the-art, high performance computational modeling framework for epidemic science. The Epihiper modeling framework supports custom disease models, and can simulate epidemics over dynamic, large-scale networks while supporting modulation of the epidemic evolution through a set of user-programmable interventions. The nodes and edges of the social-contact network have customizable sets of static and dynamic attributes which allow the user to specify intervention target sets at a very fine-grained level; these also permit the network to be updated in response to nonpharmaceutical interventions, such as school closures. The execution of interventions is governed by trigger conditions, which are Boolean expressions formed using any of Epihiper’s primitives (e.g. the current time, transmissibility) and user-defined sets (e.g. people with work activities). Rich …",Oxford University Press,,2025
339,A Scalable Game-theoretic Approach to Urban Evacuation Routing and Scheduling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s7ntYOwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=s7ntYOwAAAAJ:uJ-U7cs_P_0C,"Evacuation planning is an essential part of disaster management where the goal is to relocate people under imminent danger to safety. However, finding jointly optimal evacuation routes and a schedule that minimizes the average evacuation time or evacuation completion time, is a computationally hard problem. As a result, large-scale evacuation routing and scheduling continues to be a challenge. In this paper, we present a game-theoretic approach to tackle this problem. We start by formulating a strategic routing and scheduling game, named the Evacuation Game: Routing and Scheduling (EGRES), where players choose their route and time of departure. We show that: (i) every instance of EGRES has at least one pure strategy Nash equilibrium, and (ii) an optimal outcome in an instance will always be an equilibrium in that instance. We then provide bounds on how bad an equilibrium can be compared to an …",IEEE,,2024
340,Role of heterogeneity: National scale data-driven agent-based modeling for the US COVID-19 Scenario Modeling Hub,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s7ntYOwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=s7ntYOwAAAAJ:-_dYPAW6P2MC,"UVA-EpiHiper is a national scale agent-based model to support the US COVID-19 Scenario Modeling Hub (SMH). UVA-EpiHiper uses a detailed representation of the underlying social contact network along with data measured during the course of the pandemic to initialize and calibrate the model. In this paper, we study the role of heterogeneity on model complexity and resulting epidemic dynamics using UVA-EpiHiper. We discuss various sources of heterogeneity that we encounter in the use of UVA-EpiHiper to support modeling and analysis of epidemic dynamics under various scenarios. We also discuss how this affects model complexity and computational complexity of the corresponding simulations. Using round 13 of the SMH as an example, we discuss how UVA-EpiHiper was initialized and calibrated. We then discuss how the detailed output produced by UVA-EpiHiper can be analyzed to obtain interesting …",Elsevier,,2024
341,Autonomous vehicles on the edge: A survey on autonomous vehicle racing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bj_imaYAAAAJ&citation_for_view=bj_imaYAAAAJ:2P1L_qKh6hAC,"The rising popularity of self-driving cars has led to the emergence of a new research field in recent years: Autonomous racing. Researchers are developing software and hardware for high-performance race vehicles which aim to operate autonomously on the edge of the vehicle’s limits: High speeds, high accelerations, low reaction times, highly uncertain, dynamic, and adversarial environments. This paper represents the first holistic survey that covers the research in the field of autonomous racing. We focus on the field of autonomous racecars only and display the algorithms, methods, and approaches used in the areas of perception, planning, control, and end-to-end learning. Further, with an increasing number of autonomous racing competitions, researchers now have access to high-performance platforms to test and evaluate their autonomy algorithms. This survey presents a comprehensive overview of the …",IEEE,,2022
342,MLE+ a tool for integrated design and deployment of energy efficient building controls,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bj_imaYAAAAJ&citation_for_view=bj_imaYAAAAJ:W7OEmFMy1HYC,"We present MLE+, a tool for energy-efficient building automation design, co-simulation and analysis. The tool leverages the high-fidelity building simulation capabilities of EnergyPlus and the scientific computation and design capabilities of Matlab for controller design. MLE+ facilitates integrated building simulation and controller formulation with integrated support for system identification, control design, optimization, simulation analysis and communication between software applications and building equipment. It provides streamlined workflows, a graphical front-end, and debugging support to help control engineers eliminate design and programming errors and take informed decisions early in the design stage, leading to fewer iterations in the building automation development cycle. We show through an example and two case studies how MLE+ can be used for designing energy-efficient control algorithms for both …",,,2012
343,Forecasting groundwater table in a flood prone coastal city with long short-term memory and recurrent neural networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bj_imaYAAAAJ&citation_for_view=bj_imaYAAAAJ:j3f4tGmQtD8C,"Many coastal cities are facing frequent flooding from storm events that are made worse by sea level rise and climate change. The groundwater table level in these low relief coastal cities is an important, but often overlooked, factor in the recurrent flooding these locations face. Infiltration of stormwater and water intrusion due to tidal forcing can cause already shallow groundwater tables to quickly rise toward the land surface. This decreases available storage which increases runoff, stormwater system loads, and flooding. Groundwater table forecasts, which could help inform the modeling and management of coastal flooding, are generally unavailable. This study explores two machine learning models, Long Short-term Memory (LSTM) networks and Recurrent Neural Networks (RNN), to model and forecast groundwater table response to storm events in the flood prone coastal city of Norfolk, Virginia. To determine the effect of training data type on model accuracy, two types of datasets (i) the continuous time series and (ii) a dataset of only storm events, created from observed groundwater table, rainfall, and sea level data from 2010–2018 are used to train and test the models. Additionally, a real-time groundwater table forecasting scenario was carried out to compare the models’ abilities to predict groundwater table levels given forecast rainfall and sea level as input data. When modeling the groundwater table with observed data, LSTM networks were found to have more predictive skill than RNNs (root mean squared error (RMSE) of 0.09 m versus 0.14 m, respectively). The real-time forecast scenario showed that models trained only on storm event …",MDPI,,2019
344,Training machine learning surrogate models from a high‐fidelity physics‐based model: Application for real‐time street‐scale flood prediction in an urban coastal community,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bj_imaYAAAAJ&citation_for_view=bj_imaYAAAAJ:BqipwSGYUEgC,"Mitigating the adverse impacts caused by increasing flood risks in urban coastal communities requires effective flood prediction for prompt action. Typically, physics‐based 1‐D pipe/2‐D overland flow models are used to simulate urban pluvial flooding. Because these models require significant computational resources and have long run times, they are often unsuitable for real‐time flood prediction at a street scale. This study explores the potential of a machine learning method, Random Forest (RF), to serve as a surrogate model for urban flood predictions. The surrogate model was trained to relate topographic and environmental features to hourly water depths simulated by a high‐resolution 1‐D/2‐D physics‐based model at 16,914 road segments in the coastal city of Norfolk, Virginia, USA. Two training scenarios for the RF model were explored: (i) training on only the most flood‐prone street segments in the study …",,,2020
345,F1/10: An open-source autonomous cyber-physical platform,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bj_imaYAAAAJ&citation_for_view=bj_imaYAAAAJ:R3hNpaxXUhUC,"In 2005 DARPA labeled the realization of viable autonomous vehicles (AVs) a grand challenge; a short time later the idea became a moonshot that could change the automotive industry. Today, the question of safety stands between reality and solved. Given the right platform the CPS community is poised to offer unique insights. However, testing the limits of safety and performance on real vehicles is costly and hazardous. The use of such vehicles is also outside the reach of most researchers and students. In this paper, we present F1/10: an open-source, affordable, and high-performance 1/10 scale autonomous vehicle testbed. The F1/10 testbed carries a full suite of sensors, perception, planning, control, and networking software stacks that are similar to full scale solutions. We demonstrate key examples of the research enabled by the F1/10 testbed, and how the platform can be used to augment research and education in autonomous systems, making autonomy more accessible.",,,2019
346,DBF-MA: A Differential Bayesian Filtering Planner for Multi-Agent Autonomous Racing Overtakes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bj_imaYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bj_imaYAAAAJ:OU6Ihb5iCvQC,"A significant challenge in autonomous racing is to generate overtaking maneuvers. Racing agents must execute these maneuvers on complex racetracks with little room for error. Optimization techniques and graph-based methods have been proposed, but these methods often rely on oversimplified assumptions for collision-avoidance and dynamic constraints. In this work, we present an approach to trajectory synthesis based on an extension of the Differential Bayesian Filtering framework. Our approach for collision-free trajectory synthesis frames the problem as one of Bayesian Inference over the space of Composite Bezier Curves. Our method is derivative-free, does not require a spherical approximation of the vehicle footprint, linearization of constraints, or simplifying upper bounds on collision avoidance. We conduct a closed-loop analysis of DBF-MA and find it successfully overtakes an opponent in 87% of tested scenarios, outperforming existing methods in autonomous overtaking.",,,2025
347,Probabilistic Collision Risk Estimation through Gauss-Legendre Cubature and Non-Homogeneous Poisson Processes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bj_imaYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bj_imaYAAAAJ:uWQEDVKXjbEC,"Overtaking in high-speed autonomous racing demands precise, real-time estimation of collision risk; particularly in wheel-to-wheel scenarios where safety margins are minimal. Existing methods for collision risk estimation either rely on simplified geometric approximations, like bounding circles, or perform Monte Carlo sampling which leads to overly conservative motion planning behavior at racing speeds. We introduce the Gauss-Legendre Rectangle (GLR) algorithm, a principled two-stage integration method that estimates collision risk by combining Gauss-Legendre with a non-homogeneous Poisson process over time. GLR produces accurate risk estimates that account for vehicle geometry and trajectory uncertainty. In experiments across 446 overtaking scenarios in a high-fidelity Formula One racing simulation, GLR outperforms five state-of-the-art baselines achieving an average error reduction of 77% and surpassing the next-best method by 52%, all while running at 1000 Hz. The framework is general and applicable to broader motion planning contexts beyond autonomous racing.",,,2025
348,HALO: Fault-Tolerant Safety Architecture For High-Speed Autonomous Racing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bj_imaYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bj_imaYAAAAJ:UxriW0iASnsC,"The field of high-speed autonomous racing has seen significant advances in recent years, with the rise of competitions such as RoboRace and the Indy Autonomous Challenge providing a platform for researchers to develop software stacks for autonomous race vehicles capable of reaching speeds in excess of 170 mph. Ensuring the safety of these vehicles requires the software to continuously monitor for different faults and erroneous operating conditions during high-speed operation, with the goal of mitigating any unreasonable risks posed by malfunctions in sub-systems and components. This paper presents a comprehensive overview of the HALO safety architecture, which has been implemented on a full-scale autonomous racing vehicle as part of the Indy Autonomous Challenge. The paper begins with a failure mode and criticality analysis of the perception, planning, control, and communication modules of the software stack. Specifically, we examine three different types of faults - node health, data health, and behavioral-safety faults. To mitigate these faults, the paper then outlines HALO safety archetypes and runtime monitoring methods. Finally, the paper demonstrates the effectiveness of the HALO safety architecture for each of the faults, through real-world data gathered from autonomous racing vehicle trials during multi-agent scenarios.",,,2025
349,Trajectory-to-Action Pipeline (TAP): Automated Scenario Description Extraction for Autonomous Vehicle Behavior Comparison,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bj_imaYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bj_imaYAAAAJ:KxtntwgDAa4C,"Scenario Description Languages (SDLs) provide structured, interpretable embeddings that represent traffic scenarios encountered by autonomous vehicles (AVs), supporting key tasks such as scenario similarity searches and edge case detection for safety analysis. This paper introduces the Trajectory-to-Action Pipeline (TAP), a scalable and automated method for extracting SDL labels from large trajectory datasets. TAP applies a rules-based cross-entropy optimization approach to learn parameters directly from data, enhancing generalization across diverse driving contexts. Using the Waymo Open Motion Dataset (WOMD), TAP achieves 30% greater precision than Average Displacement Error (ADE) and 24% over Dynamic Time Warping (DTW) in identifying behaviorally similar trajectories. Additionally, TAP enables automated detection of unique driving behaviors, streamlining safety evaluation processes for AV testing. This work provides a foundation for scalable scenario-based AV behavior analysis, with potential extensions for integrating multi-agent contexts.",,,2025
350,Foreword for ICCPS’24 Special Issue,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bj_imaYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bj_imaYAAAAJ:p2g8aNsByqUC,"Cyber-physical systems (CPS) research continues to advance the integration of computation, communication, and control into safety-critical and large-scale infrastructures. The ACM/IEEE International Conference on Cyber-Physical Systems (ICCPS), held as part of CPS-IoT Week, has long been a premier venue for disseminating these advances and fostering interdisciplinary dialogue. This special issue contains a selection of original papers, which extend earlier results presented at the 15th ACM/IEEE International Conference on Cyber-Physical Systems (ICCPS) that took place in Hong Kong from May 13–16, 2024, as part of CPS-IoT Week 2024. They cover different aspects of CPS research, reflecting both methodological rigor and practical impact.",ACM,ACM Transactions on Cyber-Physical Systems,2025
351,50-kHz-rate 2D imaging of temperature and H2O concentration at the exhaust plane of a J85 engine using hyperspectral tomography,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JQSJikAAAAAJ&citation_for_view=JQSJikAAAAAJ:nb7KW1ujOQ8C,"This paper describes a novel laser diagnostic and its demonstration in a practical aero-propulsion engine (General Electric J85). The diagnostic technique, named hyperspectral tomography (HT), enables simultaneous 2-dimensional (2D) imaging of temperature and water-vapor concentration at 225 spatial grid points with a temporal response up to 50 kHz. To our knowledge, this is the first time that such sensing capabilities have been reported. This paper introduces the principles of the HT techniques, reports its operation and application in a J85 engine, and discusses its perspective for the study of high-speed reactive flows.",Optical Society of America,,2013
352,Thermal management of cylindrical batteries investigated using wind tunnel testing and computational fluid dynamics simulation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JQSJikAAAAAJ&citation_for_view=JQSJikAAAAAJ:UebtZRa9Y70C,"This work studied the thermal management of lithium ion batteries both numerically and experimentally. Numerically, a two dimensional CFD (computational fluid dynamics) model has been developed to perform detailed simulations of the thermal management issues within a battery pack cooled by air. Experimentally, systematic tests were performed to provide datasets to validate the CFD model. The main components in the experimental facility included a multi-cell battery pack and a wind tunnel. The wind tunnel facility generated well-controlled cooling air flow with velocity up to 30 m s−1 (∼67 miles per hour). So that the study can be performed under flow conditions directly relevant to practice. The major contributions from this combined numerical-experimental study are threefold. First, the CFD model has been shown to capture the dynamics of the cooling of battery modules consisting of multiple battery cells …",Elsevier,,2013
353,Tomographic imaging of temperature and chemical species based on hyperspectral absorption spectroscopy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JQSJikAAAAAJ&citation_for_view=JQSJikAAAAAJ:M3ejUd6NZC8C,"A novel technique has been developed to obtain simultaneous tomographic images of temperature and species concentration based on hyperspectral absorption spectroscopy. The hyperspectral information enables several key advantages when compared to traditional tomography techniques based on limited spectral information. These advantages include a significant reduction in the number of required projection measurements, and an enhanced insensitivity to measurements/inversion uncertainties. These advantages greatly facilitate the practical implementation and application of the tomography technique. This paper reports the development of the technique, and the experimental demonstration of a prototype sensor in a near-adiabatic, atmospheric-pressure laboratory Hencken burner. The spatial and temporal resolution enabled by this new sensing technique is expected to resolve several key issues in …",Optical Society of America,,2009
354,Combined experimental and numerical study of thermal management of battery module consisting of multiple Li-ion cells,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JQSJikAAAAAJ&citation_for_view=JQSJikAAAAAJ:4OULZ7Gr8RgC,"Lithium ion (Li-ion) batteries are promising power sources for hybrid powertrain systems, and the thermal management of batteries has been identified as a critical issue both for safety and efficiency concerns. This work studied thermal management of a Li-ion battery module both experimentally and computationally. A battery module consisting of multiple cells was fabricated and experimentally tested in a wind tunnel facility. Systematic tests were performed under various flow velocities, charging and discharging current, and module configuration. Computationally, a high-fidelity two dimensional computational fluid dynamics (CFD) model was developed to capture the detailed dynamics of thermal management of the cells. Temperature rise of cells and pressure measurements were recorded in the experiments, and compared with CFD model simulations. Reasonable agreement was obtained, confirming the validity …",Pergamon,,2014
355,Numerical and experimental validation of a three-dimensional combustion diagnostic based on tomographic chemiluminescence,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JQSJikAAAAAJ&citation_for_view=JQSJikAAAAAJ:3s1wT3WcHBgC,"Three-dimensional (3D) measurements are highly desirable both for fundamental combustion research and practical monitoring and control of combustion systems. This work discusses a 3D diagnostic based on tomographic chemiluminescence (TC) to address this measurement need. The major contributions of this work are threefold. First, a hybrid algorithm is developed to solve the 3D TC problem. The algorithm was demonstrated in extensive tests, both numerical and experimental, to yield 3D reconstruction with high fidelity. Second, an experimental approach was designed to enable quantifiable metrics for examining key aspects of the 3D TC technique, including its spatial resolution and reconstruction accuracy. Third, based on the reconstruction algorithm and experimental results, we investigated the effects of the view orientations. The results suggested that for an unknown flame, it is better to use projections …",Optical Society of America,,2013
356,Correction of Beam Steering for Optical Measurements in Turbulent Reactive Flows,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JQSJikAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=JQSJikAAAAAJ:mvPsJ3kp5DgC,"The application of optical diagnostics in turbulent reactive flows often suffers from the beam steering (BS) effects, resulting in degraded image quality and/or measurement accuracy. This work investigated a method to correct the BS effects to improve the accuracy of optical diagnostics, with particle imagine velocimetry (PIV) measurements on turbulent reactive flames as an example. The proposed method used a guiding laser to correct BS. Demonstration in laboratory turbulent flames showed promising results where the accuracy of PIV measurement was significantly enhanced. Applicability to more complicated and practical situations are discussed.",SAE Technical Paper,,2021
357,In situ imaging of 4D fire events in a ground vehicle testbed using customized fiber-based endoscopes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JQSJikAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=JQSJikAAAAAJ:eflP2zaiRacC,"Understanding the dynamics of fire events in ground vehicles is critical to improving crew survivability. To advance our understanding, four dimensional (4D) measurements are sorely needed to resolve both the temporal and spatial dynamics of fire events. However, there are several key challenges toward such measurements, including equipment requirements and optical access. 4D measurements, especially with sufficient temporal resolution, can be equipment intensive. Such equipment requirements are further compounded by the relatively hostile environments encountered in vehicular testbeds. Moreover, there is often very limited optical access available for obtaining such measurements within vehicular environments. This work describes the design and implementation of a customized fiber-based endoscope (FBE) setup to overcome these challenges in order to enable 4D flame measurements in a ground …",Elsevier,,2020
358,3D tomography integrating view registration and its application in highly turbulent flames,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JQSJikAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=JQSJikAAAAAJ:BrmTIyaxlBUC,"Recently, reconstruction integrating view registration (RIVR) has been demonstrated as an improved method to significantly enhance the accuracy of three-dimensional (3D) measurements in nonreactive flows. This work extended the RIVR method to 3D measurements of highly turbulent reactive flows with two specific goals. The first goal was to examine if the RIVR method can be effectively applied to highly turbulent flame structures, which display distinctively different spatial features from nonreactive flows. This examination of RIVR was performed specifically using two performance metrics, accuracy and spatial resolution. The second goal was to quantify the end benefits the RIVR can bring about on key flame properties involved in turbulence-chemistry interaction, such as flame surface density. The results demonstrated that the RIVR method can effectively enhance reconstruction accuracy of the thin flame front …",Elsevier,,2020
359,Development of a Two-Dimensional Thermal Model for Li-Ion Battery Pack With Experimental Validation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JQSJikAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=JQSJikAAAAAJ:geHnlv5EZngC,"This paper reports the development of a two-dimensional two states (2D2S) model for the analysis of thermal behaviors of Li-ion battery packs and its experimental validation. This development was motivated by the need to fill a niche in our current modeling capabilities: the need to analyze 2D temperature (T) distributions in large-scale battery packs in real time. Past models were predominately developed to either provide detailed T information with high computational cost or provide real-time analysis but only 1D lumped T information. However, the capability to model 2D T field in real time is desirable in many applications ranging from the optimal design of cooling strategies to onboard monitoring and control. Therefore, this work developed a new approach to provide this desired capability. The key innovations in our new approach involved modeling the whole battery pack as a complete thermal-fluid …",American Society of Mechanical Engineers Digital Collection,,2020
360,Regularized tomographic PIV for incompressible flows based on conservation of mass,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JQSJikAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=JQSJikAAAAAJ:kRWSkSYxWN8C,"Three-dimensional and three-component (3D3C) velocity measurements have long been desired to resolve the 3D spatial structures of turbulent flows. Recent advancements have demonstrated tomographic particle image velocimetry (tomo-PIV) as a powerful technique to enable such measurements. The existing tomo-PIV technique obtains 3D3C velocity field by cross-correlating two frames of 3D tomographic reconstructions of the seeding particles. A most important issue in 3D3C velocity measurement involves uncertainty, as the derivatives of the measurements are usually of ultimate interest and uncertainties are amplified when calculating derivatives. To reduce the uncertainties of 3D3C velocity measurements, this work developed a regularized tomo-PIV method. The new method was demonstrated to enhance accuracy significantly by incorporating the conservation of mass into the tomo-PIV process. The …",Optical Society of America,,2020
361,Deepcache: Principled cache for mobile deep vision,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=f6FFhS8AAAAJ&citation_for_view=f6FFhS8AAAAJ:hMod-77fHWUC,"We present DeepCache, a principled cache design for deep learning inference in continuous mobile vision. DeepCache benefits model execution efficiency by exploiting temporal locality in input video streams. It addresses a key challenge raised by mobile vision: the cache must operate under video scene variation, while trading off among cacheability, overhead, and loss in model accuracy. At the input of a model, DeepCache discovers video temporal locality by exploiting the video's internal structure, for which it borrows proven heuristics from video compression; into the model, DeepCache propagates regions of reusable results by exploiting the model's internal structure. Notably, DeepCache eschews applying video heuristics to model internals which are not pixels but high-dimensional, difficult-to-interpret data. Our implementation of DeepCache works with unmodified deep learning models, requires zero …",,,2018
362,A first look at deep learning apps on smartphones,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=f6FFhS8AAAAJ&citation_for_view=f6FFhS8AAAAJ:GnPB-g6toBAC,"To bridge the knowledge gap between research and practice, we present the first empirical study on 16,500 the most popular Android apps, demystifying how smartphone apps exploit deep learning in the wild. To this end, we build a new static tool that dissects apps and analyzes their deep learning functions. Our study answers threefold questions: what are the early adopter apps of deep learning, what do they use deep learning for, and how do their deep learning models look like. Our study has strong implications for app developers, smartphone vendors, and deep learning R&D. On one hand, our findings paint a promising picture of deep learning for smartphones, showing the prosperity of mobile deep learning frameworks as well as the prosperity of apps building their cores atop deep learning. On the other hand, our findings urge optimizations on deep learning models deployed on smartphones, protection of …",,,2019
363,How far can client-only solutions go for mobile browser speed?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=f6FFhS8AAAAJ&citation_for_view=f6FFhS8AAAAJ:d1gkVwhDpl0C,"Mobile browser is known to be slow because of the bottleneck in resource loading. Client-only solutions to improve resource loading are attractive because they are immediately deployable, scalable, and secure. We present the first publicly known treatment of client-only solutions to understand how much they can improve mobile browser speed without infrastructure support. Leveraging an unprecedented set of web usage data collected from 24 iPhone users continuously over one year, we examine the three fundamental, orthogonal approaches a client-only solution can take: caching, prefetching, and speculative loading. Speculative loading, as is firstly proposed and studied in this work, predicts and speculatively loads the subresources needed to open a webpage once its URL is given. We show that while caching and prefetching are highly limited for mobile browsing, speculative loading can be significantly …",,,2012
364,Characterizing smartphone usage patterns from millions of android users,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=f6FFhS8AAAAJ&citation_for_view=f6FFhS8AAAAJ:mB3voiENLucC,"he prevalence of smart devices has promoted the popular- ity of mobile applications (a.k.a. apps) in recent years. A number of interesting and important questions remain unan- swered, such as why a user likes/dislikes an app, how an app becomes popular or eventually perishes, how a user selects apps to install and interacts with them, how frequently an app is used and how much traffic it generates, etc. This paper presents an empirical analysis of app usage behaviors collected from millions of users of Wandoujia, a leading An- droid app marketplace in China. The dataset covers two types of user behaviors of using over 0.2 million Android apps, including (1) app management activities (i.e., installa- tion, updating, and uninstallation) of over 0.8 million unique users and (2) app network traffic from over 2 million unique users. We explore multiple aspects of such behavior data and present interesting patterns of app …",,,2015
365,Why are web browsers slow on smartphones?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=f6FFhS8AAAAJ&citation_for_view=f6FFhS8AAAAJ:u5HHmVD_uO8C,"We report the first work that examines the internals of web browsers on smartphones, using the WebKit codebase, two generations of Android smartphones, and webpages visited by 25 smart-phone users over three months. We make many surprising findings. First, over half of the webpages visited by smartphone users are not optimized for mobile devices. This highlights the importance of client-based optimization and the limitation of prior work that only studies mobile webpages. Second, while prior work suggests that several compute-intensive operations should be the focus of optimization, our measurement and analysis show that their improvement will only lead to marginal performance gain with existing webpages. Furthermore, we find that resource loading, ignored by all except one prior work, contributes most to the browser delay. While our results agree with a recent network study showing that network …",,,2011
366,Proto: A Guided Journey through Modern OS Construction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=f6FFhS8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=f6FFhS8AAAAJ:fQNAKQ3IYiAC,"Proto is a new instructional OS that runs on commodity, portable hardware. It showcases modern features, including per-app address spaces, threading, commodity filesystems, USB, DMA, multicore support, self-hosted debugging, and a window manager. It supports rich applications such as 2D/3D games, music and video players, and a blockchain miner. Unlike traditional instructional systems, Proto emphasizes engaging, media-rich apps that go beyond basic terminal programs. Our method breaks down a full-featured OS into a set of incremental, self-contained prototypes. Each prototype introduces a minimal set of OS mechanisms, driven by the needs of specific apps. The construction process then progressively enables these apps by bringing up one mechanism at a time. Proto enables a wider audience to experience building a self-contained software system used in daily life.",,,2025
367,Profiling Large Language Model Inference on Apple Silicon: A Quantization Perspective,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=f6FFhS8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=f6FFhS8AAAAJ:LPZeul_q3PIC,"A systematic understanding of Apple Silicon is lacking in the current landscape of hardware efficiency; research focus is largely centered on accelerating GPUs for large-scale training or inference on CUDA devices. This paper investigates Apple Silicon's unique memory architecture that offers a unified memory integrating CPU and GPU memory and its implications for on-device LLM inference. We decipher myths about whether Apple Silicon is efficient for on-device inference compared to competitors such as NVIDIA GPUs by directly conducting latency and throughput comparison benchmarks. We explain the performance gap between them through profiling low level hardware metrics - ALU utilization, memory bandwidth, buffer usage, cache residency etc. at runtime. We draw several insights regarding performance bottlenecks such as dequantization overhead, compute throughput and memory bandwidth. We debunk existing false claims regarding large language model inference such as compressing models to lower bit precision is a defacto promise for faster inference across all hardware platforms. We find that the large unified memory enables Apple Silicon to be both cost effective and efficient against NVIDIA GPUs for ultra large language models. Our large scale evaluation on 5 hardware testbeds incorporating three Apple M-series devices: M2 Ultra, M2 Max and M4 Pro and two NVIDIA GPUs: NVIDIA RTX A6000, a multi GPU setup with 2xNVIDIA RTX A6000, 5 model scales ranging from 8B to 405B parameters and 14 quantization schemes gives an understanding of how Apple Silicon fits within the paradigm of on-device LLM inference …",,,2025
368,WhisperFlow: speech foundation models in real time,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=f6FFhS8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=f6FFhS8AAAAJ:8AbLer7MMksC,"Speech foundation models, such as OpenAI's Whisper, become the state of the art in speech understanding due to their strong accuracy and generalizability. Yet, their applications are mostly limited to processing pre-recorded speech, whereas processing of streaming speech, in particular doing it efficiently, remains rudimentary. Behind this inefficiency are multiple fundamental reasons: (1) speech foundation models are trained to process long, fixed-length voice inputs (often 30 seconds); (2) encoding each voice input requires encoding as many as 1,500 tokens with tens of transformer layers; (3) decoding each output entails an irregular, complex beam search. As such, streaming speech processing on resource-constrained client devices is more expensive than other AI tasks, e.g., text generation. To this end, we present a novel framework, WhisperFlow, which embodies both model and system optimizations. (1 …",,,2025
369,A Journey of Modern OS Construction From boot to DOOM,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=f6FFhS8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=f6FFhS8AAAAJ:08ZZubdj9fEC,"VOS is a first-of-its-kind instructional OS that: (1) Runs on commodity, portable hardware. (2) Showcases modern features, including per-app address spaces, threading, commodity filesystems, USB, DMA, multicore, self-hosted debugging, and a window manager. (3) Supports rich applications such as 2D/3D games, music and video players, and a blockchain miner. Unlike traditional instructional systems, VOS emphasizes strong motivation for building systems-supporting engaging, media-rich apps that go beyond basic terminal programs. To achieve this, we design VOS to strike a careful balance between essential OS complexity and overall simplicity. Our method, which we call inverse engineering, breaks down a full-featured OS into a set of incremental, self-contained prototypes. Each prototype introduces a minimal set of OS mechanisms, driven by the needs of specific apps. The construction process (i.e., forward engineering) then progressively enables these apps by bringing up one mechanism at a time. VOS makes it accessible for a wider audience to experience building a software system that is self-contained and usable in everyday scenarios.",,,2025
370,AnA: An Attentive Autonomous Driving System,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=f6FFhS8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=f6FFhS8AAAAJ:l7t_Zn2s7bgC,"In an autonomous driving system (ADS), the perception module is crucial to driving safety and efficiency. Unfortunately, the perception in today's ADS remains oblivious to driving decisions, contrasting to how humans drive. Our idea is to refactor ADS so that (1) the ADS guides its perception with the driving knowledge in situ; (2) the perception differentiates between awareness and attention. We propose a system called AnA with three novel mechanisms: (1) a query interface for the planning to express its interest in perception; (2) a query executor that maps queries to an optimal set of perception tasks; (3) a monitor for handling abnormal task executions with driving knowledge. On challenging driving benchmarks, AnA outperforms competitive baselines: it responds to adversarial events timely, reducing collisions by 2x; it reduces compute usage by 44% without compromising driving safety. We attribute AnA's efficacy …",,,2025
371,Full Paper: Exploratory Look at First-Year Engineering Students Sense of Belonging and Belonging Uncertainty,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fr64vWAAAAAJ&citation_for_view=fr64vWAAAAAJ:IjCSPb-OGe4C,"We present an initial, exploratory study of belonging and belonging uncertainty as related to topics of engineering identity, engineering culture, confidence in major selection, and use of university support resources among first-year engineering students. The first-year engineering program at our university is committed to supporting students’ sense of belonging and mitigating belonging uncertainty, but it is still unclear how the two constructs corelate to other outcomes of interest. We collected quantitative, Likert-scale survey data on first-year engineering students’ perceptions of belonging, engineering identity, engineering culture, engagement with university resources, and confidence in major selection at the start and the end of the 2023-24 academic year. We present descriptive statistics and an exploratory investigation into correlations between sense of belonging, belonging uncertainty, and various outcomes. Our exploratory findings revealed that sense of belonging did increase over the first year, and that sense of belonging correlated with belonging uncertainty. Additional findings include that sense of belonging increased with increasing engineering identity, faculty support, peer support, and, minimally, with confidence in future major coursework. There was no correlation with campus support resources. Findings highlight that sense of belonging is complex and no one factor can explain or predict belonging. These initial findings will inform future studies and provide valuable preliminary insights for first-year engineering programs interested in enhancing the experiences and academic outcomes of their students from a belonging perspective.",,,2025
372,Comparing Project-Based Learning (PBL) Approaches in BIM Education: Student-Identified vs. Industry-Provided Projects,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fr64vWAAAAAJ&citation_for_view=fr64vWAAAAAJ:zYLM7Y9cAGgC,"Project-based learning (PBL) is a widely adopted pedagogical approach in construction management and architecture education, offering students hands-on opportunities to bridge theory and practice. This study explores the effectiveness of two distinct PBL approaches—Student-Identified and Industry-Provided—within an introductory Building Information Modeling (BIM) course. The Student-Identified approach allows students to select projects within instructor-defined boundaries, fostering autonomy and ownership. In contrast, the Industry-Provided approach involves working on real-world projects provided by industry partners, emphasizing practical challenges and real-world relevance. The study compares these approaches across two course sections at Florida Gulf Coast University, analyzing their impact on student engagement, satisfaction, and learning outcomes. Data was collected through pre-course and post-course surveys, measuring students’ familiarity with and proficiency in BIM concepts, their engagement and enjoyment, and their perceptions of the learning methods. Final exam and overall course grades were also analyzed to assess performance differences between the two sections. Results indicate that both approaches effectively improved students’ familiarity with BIM concepts and software. The Student-Identified approach fostered greater engagement and ownership, while the Industry-Provided approach enhanced students’ understanding of real-world applications. However, no significant differences were observed in overall academic performance between the sections. The findings suggest that a hybrid model …",,,2025
373,Assessing the Effectiveness of Educational Interventions on Digital Skills for Middle Schoolers in Underserved Communities. The TechSpark Immokalee Case Study on Digital …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fr64vWAAAAAJ&citation_for_view=fr64vWAAAAAJ:qjMakFHDy7sC,"The proposed article delves into the impact of educational interventions on middle school students within an underrepresented community, with the goal of enhancing their awareness and interest in developing digital skills for future careers driven by technology. Supported by the Microsoft TechSpark program, these interventions provide students with hands-on experiences involving key technologies. The primary focus is on nurturing the digital skills necessary for utilizing and managing these technologies in future professional roles. In this initial phase of the project, the educational experiences are contextualized around future careers in the construction industry. This approach is driven by the industry's need to attract talent and modernize in order to contribute to societal economic development. The study is designed to conduct a pre-and post-intervention evaluation to measure the effectiveness of these interventions in achieving three key objectives:(1) Increasing awareness of digital skills among middle school students,(2) Enhancing understanding of anticipated job transformations in the future, and (3) Stimulating interest in potential careers within the construction industry. The research methodology involves collecting student surveys, and subsequent statistical analysis will compare the students' pre-and post-intervention responses. The study's significance lies in its potential to identify the effectiveness of these interventions, which can inform future support or enhancements.",,,2024
374,Personal Values to Foster the Inclusion of Minority-Owned Subcontractor Firms in the Procurement of Construction Services: A Preliminary Study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fr64vWAAAAAJ&citation_for_view=fr64vWAAAAAJ:9yKSN-GCB0IC,"This study explores whether priming universalism values in construction project owners for whom these values are central can increase the perceived importance of the inclusion of underrepresented firms when selecting a general contractor. This hypothesis was preliminarily tested in a sample of civil engineering and architecture students (n = 42), which was divided into two groups. Those in the experimental condition received the universalism prime whereas those in the control condition did not. Then, both groups completed a general contractor selection task, basing their choices on typical decision factors, including the utilization of small and women- and minority-owned (SWaM) firms in the project proposals. While results did not provide support for the initial hypothesis, subsequent analyses showed that the prime significantly affected how conformity, tradition, and self-direction values related to the importance …",,,2024
375,Synergizing Case-Based Learning and Industry Involvement in a CEM Course–A Case Study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fr64vWAAAAAJ&citation_for_view=fr64vWAAAAAJ:UeHWp8X0CEIC,"This paper synthesizes the lessons learned from the experience of developing and teaching a Case-Based Learning (CBL) course in Construction Engineering and Management (CEM) with a diverse group of industry partners. The authors analyzed and compared the participants' reflections on their experiences throughout the course to identify: 1) the factors that may foster and hinder students' learning and 2) potential opportunities and challenges of interacting with industry practitioners when using CBL as the core teaching strategy in a CEM course. While structuring the course, instructors should invest time in increasing the navigability of practitioners' supplemental material and guiding students through it. Case order matters–complexity and uncertainty should increase as students gain confidence with CBL—and including deliberate team preparation time was highly welcomed by students. Practitioners' presence in the classroom increased case credibility, which resulted in more self-reported student engagement. Welcoming more actors allows students to analyze the cases from diverse points of view. Instructors should act as discussion facilitators. Looking forward, practitioners should start documenting the alternatives considered beyond the definitive solution of a case to enrich the case's contents. These outcomes provide instructors interested in implementing CBL in their engineering courses with insights grounded in experience that will ease the process from ideation to delivery.",,,2023
376,Boundary layer turbulence and flow structure over a fringing coral reef,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wRoS80UAAAAJ&citation_for_view=wRoS80UAAAAJ:u-x6o8ySG0sC,"Measurements of velocity and rates of turbulence were made across a fringing coral reef in the Gulf of Aqaba, Red Sea, to determine the effect that the rough topography has on boundary layer mixing and flow dynamics. Observations were made at two fore‐reef sites and a nearby sandy slope. The friction velocity, u*, and drag coefficient, CD, were determined directly from turbulent Reynolds stresses measured using acoustic Doppler velocimeters. Values of CD for the coral substrates ranged from 0.009 to 0.015, three to five times greater than over the sandy bottom site. The turbulence dissipation rate, ε, was determined by fitting spectra of vertical velocity to the theoretical “5/3” law expected for the inertial subrange of turbulence. There was a local balance between production and dissipation of turbulent kinetic energy, signifying that we could estimate u* from either the mean velocity profile, turbulence, or …",The American Society of Limnology and Oceanography,,2006
377,Wave and tidally driven flows in eelgrass beds and their effect on sediment suspension,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wRoS80UAAAAJ&citation_for_view=wRoS80UAAAAJ:kNdYIx-mwKoC,"Seagrass beds alter their hydrodynamic environment by inducing drag on the flow, thereby attenuating wave energy and near-bottom currents. This alters the turbulent structure and shear stresses within and around the seagrass bed that are responsible for the suspension and deposition of sediment. To quantify these interactions, velocity, pressure, and sediment measurements were obtained across a density gradient of an eelgrass Zostera marina bed within a shallow coastal bay (1 to 2 m depth). Eelgrass beds were found to reduce near-bottom mean velocities by 70 to 90%, while wave heights were reduced 45 to 70% compared to an adjacent unvegetated region. Wave orbital velocities within the eelgrass bed were reduced by 20% compared to flow above the bed, primarily acting as a low-pass filter by removing high-frequency wave motion. However, relatively little reduction in wave energy occurred at lower …","Inter-Research, Nordbuente 23 Oldendorf/Luhe 21385",,2012
378,The Sponge Pump: The Role of Current Induced Flow in the Design of the Sponge Body Plan,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wRoS80UAAAAJ&citation_for_view=wRoS80UAAAAJ:Se3iqnhoufwC,"Sponges are suspension feeders that use flagellated collar-cells (choanocytes) to actively filter a volume of water equivalent to many times their body volume each hour. Flow through sponges is thought to be enhanced by ambient current, which induces a pressure gradient across the sponge wall, but the underlying mechanism is still unknown. Studies of sponge filtration have estimated the energetic cost of pumping to be <1% of its total metabolism implying there is little adaptive value to reducing the cost of pumping by using “passive” flow induced by the ambient current. We quantified the pumping activity and respiration of the glass sponge Aphrocallistes vastus at a 150 m deep reef in situ and in a flow flume; we also modeled the glass sponge filtration system from measurements of the aquiferous system. Excurrent flow from the sponge osculum measured in situ and in the flume were positively correlated (r>0.75) with the ambient current velocity. During short bursts of high ambient current the sponges filtered two-thirds of the total volume of water they processed daily. Our model indicates that the head loss across the sponge collar filter is 10 times higher than previously estimated. The difference is due to the resistance created by a fine protein mesh that lines the collar, which demosponges also have, but was so far overlooked. Applying our model to the in situ measurements indicates that even modest pumping rates require an energetic expenditure of at least 28% of the total in situ respiration. We suggest that due to the high cost of pumping, current-induced flow is highly beneficial but may occur only in thin walled sponges living in high flow …",Public Library of Science,,2011
379,Benthic flow environments affect recruitment of Crassostrea virginica larvae to an intertidal oyster reef,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wRoS80UAAAAJ&citation_for_view=wRoS80UAAAAJ:Zph67rFs4hoC,"Restoration efforts to enhance Crassostrea virginica oyster populations along the Virginia, USA, coastline focus on creating benthic habitat suitable for larval recruitment, survival, and growth. To determine how benthic flow processes affect larval recruitment, velocity and turbulence we collected data over multiple intertidal benthic surfaces including a mud bed, a C. virginica oyster reef, and 2 restoration sites comprised of deposited C. virginica oyster shell or the relatively larger Busycotypus canaliculatus whelk shell. Mean estimates of the drag coefficient, C D, used as a measure of hydrodynamic roughness over the C. virginica reef were found to be 2 times greater than over the restoration sites and 5 times greater than over the mud bed. Enhanced fluid shear increased both peak Reynolds stresses and vertical momentum transport above the reef, but within the interstitial areas between individual oysters, velocities …",,,2012
380,Wave attenuation by oyster reefs in shallow coastal bays,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wRoS80UAAAAJ&citation_for_view=wRoS80UAAAAJ:RYcK_YlVTxYC,"Oyster reef restoration in shallow estuarine environments has been thought to have the potential to provide shoreline protection as well as oyster habitat. This study was designed to address the question of how effective oyster reefs are at attenuating wave energy in shallow coastal bays. Measurements were made of waves on both sides of four restored intertidal oyster reefs and at a control site with no reef; mean water depths ranged from 0.9 to 1.3 m. The reefs differed in composition and position relative to the shoreline, but all had reef crest elevations between 0.3 and 0.5 m below mean sea level. Differences in wave heights between the exposed/sheltered sides and upwind/downwind sides of the reefs were used to quantify the effects of the reefs on waves under varying tidal and wind conditions. All four reefs were able to reduce wave heights by an average of 30–50% for water depths of 0.5–1.0 m (bracketing …",Springer US,,2019
381,Performance Evaluation of Natural and Nature-Based Features for Coastal Protection and Co-Benefits,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wRoS80UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wRoS80UAAAAJ:35r97b3x0nAC,"Built infrastructure, such as seawalls and levees, has long been used to reduce shoreline erosion and protect coastal properties from flood impacts. In contrast, natural and nature-based features (NNBF), including marshes, mangroves, oyster reefs, coral reefs, and seagrasses, offer not only coastal protection but also a range of valuable ecosystem services. There is no clear understanding of the capacity of either natural habitats or NNBF integrated with traditional engineered infrastructure to withstand extreme events, nor are there well-defined breakpoints at which these habitats fail to provide coastal protection. Evaluating existing NNBF strategies using a standardized set of metrics can help to assess their effectiveness to better inform design criteria. This review identifies a selection of NNBF projects with long-term monitoring programs and synthesizes the monitoring data to provide a literature-based performance …",Annual Reviews,Annual Review of Marine Science,2025
382,The turbulent soundscape of intertidal oyster reefs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wRoS80UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wRoS80UAAAAJ:7T2F9Uy0os0C,"Turbulence and sound are important cues for oyster reef larval recruitment. Numerous studies have found a relationship between turbulence intensity and swimming behaviors of marine larvae, while others have documented the importance of sounds in enhancing larval recruitment to oyster reefs. However, the relationship between turbulence and the reef soundscape is not well understood. In this study we made side-by-side acoustic Doppler velocimeter turbulence measurements and hydrophone soundscape recordings over 2 intertidal oyster reefs (1 natural and 1 restored) and 1 adjacent bare mudflat as a reference. Sound pressure levels (SPL) were similar across all three sites, although SPL >  2000 Hz was highest at the restored reef, likely due to its larger area that contained a greater number of sound-producing organisms. Flow noise (FN), defined as the mean of pressure fluctuations recorded by the hydrophone at f <  100 Hz, was significantly related to mean flow speed, turbulent kinetic energy, and turbulence dissipation rate (ε), agreeing with theoretical calculations for turbulence. Our results also show a similar relationship between ε and FN to what has been previously reported for ε vs. downward larval swimming velocity (wb), with both FN and wb demonstrating rapid growth at ε >  0.1 cm2 s−3. These results suggest that reef turbulence and sounds may attract oyster larvae in complementary and synergistic ways.",Public Library of Science,,2025
383,Spectral Wave Energy Dissipation by a Seagrass Meadow,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wRoS80UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wRoS80UAAAAJ:tKAzc9rXhukC,"Existing formulations for predicting wave dissipation by submerged canopies generally fall into three categories where (a) an empirical coefficient (energy dissipation factor) is attributed to the canopy ignoring its physical properties;(b) estimates of canopy drag forces based on a bulk drag coefficient and undisturbed velocities above the canopy are used to estimate dissipation; and (c) canopy flow theory is used to account for how modifications to in-canopy flows influence canopy forces and associated dissipation. We measured rates of spectral wave dissipation across a dense seagrass meadow comprised of Posidonia australis in southwestern Australia, which also included high-resolution flow measurements within and above the seagrass canopy. These observations were used to quantify the effectiveness of the three different approaches to predict observed rates of spectral wave dissipation. The results showed that conventional approaches that do not account for canopy flow modifications and/or seagrass flexibility tend to overestimate both bulk and frequency-dependent wave dissipation. Conversely, approaches that consider frequency-dependent flow attenuation in canopies were found to improve predictions of wave dissipation, particularly when also accounting for how the deflection of flexible seagrass blades induced by flow modifies the effective canopy height. The results show that the canopy flow velocities induced by short period wind waves were less attenuated than longer period swell, explaining the frequency dependency of rates of wave dissipation, with shorter period wave heights being more efficiently attenuated by the meadow.",American Geophysical Union,,2025
384,"Utilizing GIS-based multi-criteria decision analysis to map flooding and assess vulnerability of the mobility impaired in the coastal-urban community of Norfolk, Virginia",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wRoS80UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wRoS80UAAAAJ:JQOojiI6XY0C,"Increased frequency and severity of urban stormwater flooding has occurred in part due to a changing climate and enhanced storm intensities. This issue is amplified in coastal cities where stormwater drainage networks are overwhelmed not only by heavy precipitation, but also increased tidal elevations and storm surge from sea-level rise. Norfolk, Virginia, is one of the country's most vulnerable cities to projected increases in coastal flooding, and as such is actively engaged in efforts to improve the city's resilience. People with disabilities often require additional specialized resources in storm events, and thus it is crucial to understand the impacts of urban stormwater flooding on disabled populations to target resources for hazard mitigation and emergency response. This research applies a geographical information system (GIS)-based multicriteria decision analysis (MCDA) to Norfolk, VA, that allows for large-scale …",,,2024
385,Monolithic germanium/silicon avalanche photodiodes with 340 GHz gain–bandwidth product,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ma630HIAAAAJ&citation_for_view=ma630HIAAAAJ:UeHWp8X0CEIC,"Significant progress has been made recently in demonstrating that silicon photonics is a promising technology for low-cost optical detectors, modulators and light sources,,,,,,,,,,,. It has often been assumed, however, that their performance is inferior to InP-based devices. Although this is true in most cases, one of the exceptions is the area of avalanche photodetectors, where silicon's material properties allow for high gain with less excess noise than InP-based avalanche photodetectors and a theoretical sensitivity improvement of 3 dB or more. Here, we report a monolithically grown germanium/silicon avalanche photodetector with a gain–bandwidth product of 340 GHz, a keff of 0.09 and a sensitivity of −28 dB m at 10 Gb s−1. This is the highest reported gain–bandwidth product for any avalanche photodetector operating at 1,300 nm and a sensitivity that is equivalent to mature, commercially available III–V compound …",Nature Publishing Group UK,,2009
386,Microstructured silicon photodetector,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ma630HIAAAAJ&citation_for_view=ma630HIAAAAJ:_kc_bZDykSQC,"Photodetectors fabricated on microstructured silicon are reported. The photodetectors exhibited high photoresponse; at 3 V bias, the responsivities were 92 A∕ W at 850 nm and 119 A∕ W at 960 nm⁠. At wavelengths longer than 1.1 μ m⁠, the photodetectors still showed strong photoresponse. A generation-recombination gain mechanism has been proposed to explain the photoresponse of these photodiodes. From measurements of the noise current density, the calculated gain was approximately 1200 at 3 V bias.",AIP Publishing,,2006
387,Thermal treatment studies of the photoluminescence intensity of porous silicon,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ma630HIAAAAJ&citation_for_view=ma630HIAAAAJ:u5HHmVD_uO8C,Thermal annealing studies of the photoluminescence (PL) intensity and Fourier‐transform infrared spectroscopy have been performed concurrently on porous Si. A sharp reduction in the PL intensity is observed for annealing temperatures ≳300 °C and this coincides with desorption of hydrogen from the SiH2 surface species. A brief etch in HF can restore the luminescence of the samples annealed below 400 °C. We conclude that SiH2 is essential to the visible luminescence in porous Si.,American Institute of Physics,,1991
388,Correlation between silicon hydride species and the photoluminescence intensity of porous silicon,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ma630HIAAAAJ&citation_for_view=ma630HIAAAAJ:u-x6o8ySG0sC,"The role of silicon hydride species in the photoluminescence intensity behavior of porous Si has been studied. The surfaces of luminescent porous Si samples were converted to a predominate SiH termination using a remote H plasma. The as‐passivated samples were then immersed in various concentrations of hydrofluouric solutions to regulate the recovery of SiH2 termination on the surface. Photoluminescence measurements and transmission Fourier‐transform infrared spectroscopy have shown that predominant silicon monohydride (SiH) termination results in weak photoluminescence. In contrast, it has been observed that the appearance of silicon dihydride (SiH2) coincides with an increase in the photoluminescence intensity.",American Institute of Physics,,1992
389,Recent advances in telecommunications avalanche photodiodes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ma630HIAAAAJ&citation_for_view=ma630HIAAAAJ:4JMBOYKVnBMC,"For high-bit-rate long-haul fiber optic communications, the avalanche photodiode (APD) is frequently the photodetector of choice owing to its internal gain, which provides a sensitivity margin relative to PIN photodiodes. APDs can achieve 5–10-dB better sensitivity than PINs, provided that the multiplication noise is low and the gain-bandwidth product is sufficiently high. In the past decade, the performance of APDs for optical fiber communication systems has improved as a result of improvements in materials and the development of advanced device structures. This paper presents a brief review of APD fundamentals and describes some of the significant advances.",OSA,Journal of Lightwave Technology,2007
390,Matrix quantum kinetic treatment of impact ionization in avalanche photodiodes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ma630HIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ma630HIAAAAJ:UdECroDkmsIC,"Matrix-based quantum kinetic simulations have been widely used for the predictive modeling of electronic devices. Inelastic scattering from phonons and electrons are typically treated as higher-order processes in these treatments, captured using mean-field approximations. Carrier multiplication in avalanche photo-diodes (APDs), however, relies entirely on strongly inelastic impact ionization, making electron-electron scattering the dominant term requiring a rigorous, microscopic treatment. We go well beyond the conventional Born approximation for scattering to develop a matrix-based quantum kinetic theory for impact ionization, involving products of multiple Green's functions. Using a model semiconductor in a reverse-biased p-i-n configuration, we show how its calculated nonequilibrium charge distributions show multiplication at dead-space values consistent with energy-momentum conservation. Our matrix …",American Physical Society,,2025
391,Extended wavelength photodiodes in the B-III–V material system,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ma630HIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ma630HIAAAAJ:Qvnikpzo9sYC,"Highly mismatched B-III–V alloys present a promising avenue for near-infrared (NIR), direct bandgap optoelectronics that can be integrated on GaAs or Si, owing to their ability to vary bandgap and lattice constant independently. Here, we report the epitaxial growth, fabrication, and characterization of nearly strain-free, all-BGaInAs, pin photodiodes on GaAs substrates grown by molecular beam epitaxy. Incorporating boron effectively reduced the strain in InGaAs, yielding nearly lattice-matched BGaInAs layers with high surface quality, as confirmed by high-resolution x-ray diffraction and atomic force microscopy measurements. Strong photoluminescence (PL) intensity was observed for BGaInAs with up to 3.2% B (7% In). The operating wavelength consistently extended with increasing boron and indium incorporation as evidenced by PL and external quantum efficiency measurements, which agree with density …",AIP Publishing,,2025
392,Edge-coupled digital alloy AlInAsSb SPAD with high avalanche breakdown probability,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ma630HIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ma630HIAAAAJ:eRk_639DUGcC,"Waveguide-coupled single-photon avalanche detectors (SPADs) with near-unity detection efficiencies at 1550 nm operating at moderate temperatures are a crucial component for numerous quantum optics applications. The III–V compound quaternary Al x In 1− x As y Sb 1− y, has material characteristics that make it attractive for low-noise linear-mode APDs and high-detection-efficiency SPADs. It can be grown on mature substrates with a high degree of flexibility with respect to absorption cutoff and can also achieve high avalanche breakdown probabilities due to its strongly asymmetric ionization coefficients. In this work, we simulate and experimentally characterize the avalanche breakdown probability of an edge-coupled, 1550 nm-illuminated AlInAsSb-based SPAD. We report avalanche breakdown probabilities greater than 85% at an over-bias of less than 2.5%.",AIP Publishing,,2025
393,Ternary-containing Al0.7InAsSb digital alloys on InP and InP-on-Si,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ma630HIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ma630HIAAAAJ:8dO9Xi6wxqgC,"Al_xIn_1−xAs_ySb_1−y is a promising multiplier for avalanche photodiodes (APD) on InP for near-infrared applications. In this work, we investigated the potential of two different ternary-containing layer stacks for the growth of AlInAsSb digital alloys on InP and InP-on-Si templates with applications in future photodetectors. STEM measurements confirmed high-quality material and interfaces on both substrates with no evidence of phase separation. Low dark currents and high gains were measured from PIN diodes grown on both substrates, with slightly higher dark currents observed in the Si-based device due to defects resulting from lattice mismatch in the template.",Optica Publishing Group,,2025
394,A passivation study for AlInAsSb avalanche photodiodes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ma630HIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ma630HIAAAAJ:5c6--qz33SwC,"Avalanche photodiodes (APDs) are vital for a wide range of commercial, military, and research applications. Recently, the Al x In 1–x As y Sb 1–y digital alloy system has emerged as a promising material for next-generation APDs, offering a broadly tunable bandgap, high avalanche gain, and low excess noise. However, surface oxidation and defect formation on the etched Al 0.7 InAsSb sidewalls of mesa-structure devices can significantly increase device dark currents, degrade the signal-to-noise ratio, and limit device reliability. Effective surface passivation is thus essential for suppressing dark current and enhancing device performance. In this study, we systematically compare the impact of different passivation techniques, including SU-8 polymer, atomic layer deposition (ALD)-HfO 2, and ALD-Al 2 O 3, deposited at various temperatures, on the performance of Al 0.7 InAsSb p–i–n APDs grown on InP substrates …",AIP Publishing,,2025
395,Elucidating the contribution of mobile hydrogen-deformation interactions to hydrogen-induced intergranular cracking in polycrystalline nickel,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RXt_HaAAAAAJ&citation_for_view=RXt_HaAAAAAJ:zdX0sdgBH_kC,"Uniaxial mechanical testing conducted at room temperature (RT) and 77 K on hydrogen (H)-exposed nickel was coupled with targeted microscopy to evaluate the influence of deformation temperature, and therefore mobile H-deformation interactions, on intergranular cracking in nickel. Results from interrupted tensile tests conducted at cryogenic temperatures (77 K), where mobile H-deformation interactions are effectively precluded, and RT, where mobile H-deformation interactions are active, indicate that mobile H-deformation interactions are not an intrinsic requirement for H-induced intergranular fracture. Moreover, an evaluation of the true strain for intergranular microcrack initiation for testing conducted at RT and 77 K suggests that H which is segregated to grain boundaries prior to the onset of straining dominates the H-induced fracture process for the prescribed H concentration of 4000 appm. Finally …",Pergamon,,2018
396,Effect of corrosion severity on fatigue evolution in Al–Zn–Mg–Cu,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RXt_HaAAAAAJ&citation_for_view=RXt_HaAAAAAJ:u5HHmVD_uO8C,"The effect of existing-localized corrosion on fatigue cracking of 7075-T6511 was established using crack surface marker-band analysis and a fracture mechanics model. The substantial reduction of fatigue life due to EXCO solution L–S surface pre-corrosion is nearly independent of exposure time after initial-sharp degradation, scaling with the evolution of pit-cluster size and initial stress intensity range with exposure time. Independent of exposure time, formation of a resolvable fatigue crack (∼10μm) accounts for a similar-low (∼5%) fraction of total fatigue life at low stress range (σmax=150MPa, R=0.1). Crack formation occurs at microscopic protrusions into the corroded volume. A corrosion-modified-equivalent initial flaw size (CM-EIFS); predicted with the AFGROW tool using measured initial aspect ratio, initiation cycles, and total fatigue life inputs; accurately represents the corrosion damage effect on fatigue for a …",Pergamon,,2010
397,Driving forces for localized corrosion‐to‐fatigue crack transition in Al–Zn–Mg–Cu,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RXt_HaAAAAAJ&citation_for_view=RXt_HaAAAAAJ:2osOgNQ5qMEC,"Research on fatigue crack formation from a corroded 7075‐T651 surface provides insight into the governing mechanical driving forces at microstructure‐scale lengths that are intermediate between safe life and damage tolerant feature sizes. Crack surface marker‐bands accurately quantify cycles (Ni) to form a 10–20 μm fatigue crack emanating from both an isolated pit perimeter and EXCO corroded surface. The Ni decreases with increasing‐applied stress. Fatigue crack formation involves a complex interaction of elastic stress concentration due to three‐dimensional pit macro‐topography coupled with local micro‐topographic plastic strain concentration, further enhanced by microstructure (particularly sub‐surface constituents). These driving force interactions lead to high variability in cycles to form a fatigue crack, but from an engineering perspective, a broadly corroded surface should contain an extreme group …",Blackwell Publishing Ltd,,2011
398,On the suitability of slow strain rate tensile testing for assessing hydrogen embrittlement susceptibility,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RXt_HaAAAAAJ&citation_for_view=RXt_HaAAAAAJ:2Q0AJrNhS-QC,The onset of sub-critical crack growth during slow strain rate tensile testing (SSRT) is assessed through a combined experimental and modeling approach. A systematic comparison of the extent of intergranular fracture and expected hydrogen ingress suggests that hydrogen diffusion alone is insufficient to explain the intergranular fracture depths observed after SSRT experiments in a Ni–Cu superalloy. Simulations of these experiments using a new phase field formulation indicate that crack initiation occurs as low as 40% of the time to failure. The implications of such sub-critical crack growth on the validity and interpretation of SSRT metrics are then explored.,Pergamon,,2020
399,Measurement and modeling of hydrogen environment-assisted cracking in Monel K-500,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RXt_HaAAAAAJ&citation_for_view=RXt_HaAAAAAJ:WF5omc3nYNoC,"Hydrogen environment-assisted cracking (HEAC) of Monel K-500 is quantified using slow-rising stress intensity loading with electrical potential monitoring of small crack propagation and elastoplastic J-integral analysis. For this loading, with concurrent crack tip plastic strain and H accumulation, aged Monel K-500 is susceptible to intergranular HEAC in NaCl solution when cathodically polarized at −800 mVSCE (EA, vs saturated calomel) and lower. Intergranular cracking is eliminated by reduced cathodic polarization more positive than −750 mVSCE. Crack tip diffusible H concentration rises, from near 0 wppm at EA of −765 mVSCE, with increasing cathodic polarization. This behavior is quantified by thermal desorption spectroscopy and barnacle cell measurements of hydrogen solubility vs overpotential for planar electrodes, plus measured-local crevice potential, and pH scaled to the crack tip. Using crack tip H …",Springer US,,2014
400,Effect of Laser Surface Treatment on the Distribution of Beta Phase and Intermetallic Particles and the Surface Integrity of AA5456 Alloy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RXt_HaAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RXt_HaAAAAAJ:eJD0kABLposC,"AA5456-H116 alloy is widely used in marine environments owing to the combination of mechanical properties and general corrosion resistance. However, precipitation of β phase (Al3Mg2) on grain boundaries can occur at modestly elevated temperatures (> 50 °C), resulting in susceptibility to intergranular corrosion (IGC), intergranular stress corrosion cracking (IGSCC), and corrosion fatigue. This work uses electron backscatter diffraction (EBSD) and scanning electron microscopy (SEM) to examine the effect of continuous wave (CW) and defocused continuous wave (DCW) fiber laser surface treatment (LST) on the β phase and constituent intermetallic particles distribution in AA5456. The surface topography and subsurface defect distribution in the LST regions are also investigated; the presence of cracks and porosity was observed. Different CW/DCW processing parameters result in different aspect ratios …",Springer US,,2025
401,Methods for Regulating Depth of Corrosion Fissures in Simulated Fastener Holes of 7050-T7451 Aluminum Alloy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RXt_HaAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RXt_HaAAAAAJ:jtOrAYjvdewC,"This study presents a new test method for inducing controlled corrosion damage within simulated fastener holes of aluminum alloys, aimed at pretreating fatigue test specimens. The method involves insulating the outer surfaces while exposing the fastener hole surface to electrolytes containing 0.66 M NaCl+ 0.1 M AlCl3 with varying concentrations of K2S2O8. The evolution of corrosion damage within the fastener hole was examined as a function of exposure duration, electrolyte composition, and volume, as well as the effect of galvanic coupling with an SS316 cathode. Results indicate that fissure depth increases with an increase in K2S2O8 concentration, but does not progress further after 24 h to 48 h of exposure in the chemical, or freely-corroding, exposure test. In contrast, galvanic coupling with an SS316 plate significantly accelerates corrosion, leading to much deeper fissures in a shorter time. The importance …",NACE International,,2025
402,"Guest Editorial for the special issue on"" Understanding hydrogen-materials interactions""",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RXt_HaAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RXt_HaAAAAAJ:71d7Y1FijdoC,"Guest Editorial for the special issue on ""Understanding hydrogen-materials interactions"" - ADS Now on home page ads icon ads Enable full ADS view ADS Guest Editorial for the special issue on ""Understanding hydrogen-materials interactions"" Burns, James T. Abstract Publication: International Journal of Hydrogen Energy Pub Date: June 2025 DOI: 10.1016/j.ijhydene.2024.10.423 Bibcode: 2025IJHE..136..629B full text sources Elsevier | © The SAO Astrophysics Data System adshelp[at]cfa.harvard.edu The ADS is operated by the Smithsonian Astrophysical Observatory under NASA Cooperative Agreement 80NSSC21M0056 Smithsonian logo Harvard Center for Astrophysics logo NASA logo *The material contained in this document is based upon work supported by a National Aeronautics and Space Administration (NASA) grant or cooperative agreement. Any opinions, findings, conclusions or recommendations …",,,2025
403,The role of hydrogen-metal interactions in hydrogen environmentally assisted cracking susceptibility in additively manufactured 17-4 PH stainless steel,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RXt_HaAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RXt_HaAAAAAJ:iWL_APfBKHwC,"The role of hydrogen (H)-metal interactions in enhanced H environment-assisted cracking (HEAC) susceptibility of additively manufactured (AM) 17-4 PH stainless steel created using laser powder bed fusion (LPBF) is examined via comparison of the effective hydrogen diffusivity (D eff) and diffusible H content (C H, diff) between wrought 17-4 PH and AM 17-4 PH in the peak-aged and over-aged tempers. The increase in C H, diff as a function of hydrogen overpotential is assessed via the barnacle cell electrode technique, and D eff is determined using electrochemical permeation. Results demonstrate that the AM alloys consistently exhibit a lower C H, diff but increased D eff relative to analogous wrought materials. Potential contributions of microstructural features to the observed differences in H-metal interactions are examined, and the role of these features in altering HEAC resistance is phenomenologically …",Elsevier,,2025
404,Corie L. Cobb Named a 2024 Fellow of the National Academy of Inventors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RXt_HaAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RXt_HaAAAAAJ:yNlG6JgpFqoC,"Established by President Clinton in 1996, PECASE recognizes scientists and engineers who show exceptional potential for leadership early in their research careers. The award recognizes innovative and far-reaching developments in science and technology, expands awareness of careers in science and engineering, recognizes the scientific missions of participating agencies, enhances connections between research and impacts on society, and highlights the importance of science and technology for our nation’s future.",,,2025
405,Principal geodesic analysis for the study of nonlinear statistics of shape,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7pRRhkkAAAAJ&citation_for_view=7pRRhkkAAAAJ:UeHWp8X0CEIC,"A primary goal of statistical shape analysis is to describe the variability of a population of geometric objects. A standard technique for computing such descriptions is principal component analysis. However, principal component analysis is limited in that it only works for data lying in a Euclidean vector space. While this is certainly sufficient for geometric models that are parameterized by a set of landmarks or a dense collection of boundary points, it does not handle more complex representations of shape. We have been developing representations of geometry based on the medial axis description or m-rep. While the medial representation provides a rich language for variability in terms of bending, twisting, and widening, the medial parameters are not elements of a Euclidean vector space. They are in fact elements of a nonlinear Riemannian symmetric space. In this paper, we develop the method of principal geodesic …",IEEE,,2004
406,Functional connectivity magnetic resonance imaging classification of autism,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7pRRhkkAAAAJ&citation_for_view=7pRRhkkAAAAJ:r0BpntZqJG4C,"Group differences in resting state functional magnetic resonance imaging connectivity between individuals with autism and typically developing controls have been widely replicated for a small number of discrete brain regions, yet the whole-brain distribution of connectivity abnormalities in autism is not well characterized. It is also unclear whether functional connectivity is sufficiently robust to be used as a diagnostic or prognostic metric in individual patients with autism. We obtained pairwise functional connectivity measurements from a lattice of 7266 regions of interest covering the entire grey matter (26.4 million connections) in a well-characterized set of 40 male adolescents and young adults with autism and 40 age-, sex- and IQ-matched typically developing subjects. A single resting state blood oxygen level-dependent scan of 8 min was used for the classification in each subject. A leave-one-out classifier …",Oxford University Press,,2011
407,Riemannian geometry for the statistical analysis of diffusion tensor data,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7pRRhkkAAAAJ&citation_for_view=7pRRhkkAAAAJ:W7OEmFMy1HYC,"The tensors produced by diffusion tensor magnetic resonance imaging (DT-MRI) represent the covariance in a Brownian motion model of water diffusion. Under this physical interpretation, diffusion tensors are required to be symmetric, positive-definite. However, current approaches to statistical analysis of diffusion tensor data, which treat the tensors as linear entities, do not take this positive-definite constraint into account. This difficulty is due to the fact that the space of diffusion tensors does not form a vector space. In this paper we show that the space of diffusion tensors is a type of curved manifold known as a Riemannian symmetric space. We then develop methods for producing statistics, namely averages and modes of variation, in this space. We show that these statistics preserve natural geometric properties of the tensors, including the constraint that their eigenvalues be positive. The symmetric space …",Elsevier,,2007
408,Deformable M-Reps for 3D Medical Image Segmentation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7pRRhkkAAAAJ&citation_for_view=7pRRhkkAAAAJ:IjCSPb-OGe4C,"M-reps (formerly called DSLs) are a multiscale medial means for modeling and rendering 3D solid geometry. They are particularly well suited to model anatomic objects and in particular to capture prior geometric information effectively in deformable models segmentation approaches. The representation is based on figural models, which define objects at coarse scale by a hierarchy of figures—each figure generally a slab representing a solid region and its boundary simultaneously. This paper focuses on the use of single figure models to segment objects of relatively simple structure. A single figure is a sheet of medial atoms, which is interpolated from the model formed by a net, i.e., a mesh or chain, of medial atoms (hence the name m-reps), each atom modeling a solid region via not only a position and a width but also a local figural frame giving figural directions and an object angle between opposing …",Kluwer Academic Publishers,,2003
409,Longitudinal changes in cortical thickness in autism and typical development,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7pRRhkkAAAAJ&citation_for_view=7pRRhkkAAAAJ:5Ul4iDaHHb8C,"The natural history of brain growth in autism spectrum disorders remains unclear. Cross-sectional studies have identified regional abnormalities in brain volume and cortical thickness in autism, although substantial discrepancies have been reported. Preliminary longitudinal studies using two time points and small samples have identified specific regional differences in cortical thickness in the disorder. To clarify age-related trajectories of cortical development, we examined longitudinal changes in cortical thickness within a large mixed cross-sectional and longitudinal sample of autistic subjects and age- and gender-matched typically developing controls. Three hundred and forty-five magnetic resonance imaging scans were examined from 97 males with autism (mean age = 16.8 years; range 3–36 years) and 60 males with typical development (mean age = 18 years; range 4–39 years), with an average interscan …",Oxford University Press,,2014
410,RealDeal: Enhancing Realism and Details,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7pRRhkkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7pRRhkkAAAAJ:1lhNe0rCu4AC,"Generative models have been widely adopted in the biomedical domain, especially in image generation applications. Latent diffusion models achieve state-of-the-art results in generating brain MRIs. How-ever, due to latent compression, generated images from these models are overly smooth, lacking fine anatomical structures and scan acquisition noise that are typically seen in real images. We propose image-to-image diffusion models that are designed to enhance the realism and details of generated brain images by introducing sharp edges, fine textures, subtle anatomical features, and imaging noise. This work formulates the real-ism enhancing and detail adding process as an image-to-image diffusion model, which refines the quality of LDM-generated images. We employ commonly used metrics like FID and LPIPS for image realism assess-ment. Furthermore, we introduce new metrics to quantify the improved realism of images generated by RealDeal in terms of image noise distri-bution, sharpness, and texture.",Springer Nature,,2025
411,MedIL: Generating Arbitrary-Resolution Medical Images with Implicit Latent Spaces,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7pRRhkkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7pRRhkkAAAAJ:ALROH1vI_8AC,"We introduce MedIL, a first-of-its-kind autoencoder built for medical images with heterogeneous sizes and resolutions for image generation. Medical images are often large and heterogeneous, where fine details are of vital clinical importance. Image properties change drastically between different acquisition equipment, scan parameters, and pathologies, making realistic medical image generation challenging. Recent work in latent diffusion models (LDMs) has shown success in generating images resampled to a fixed size. However, this is a narrow subset of the native image resolutions, and resampling discards fine anatomical details. MedIL utilizes implicit neural representations to treat images as continuous signals, where encoding and decoding can be performed at arbitrary resolutions without prior resampling. We show how MedIL compresses and preserves fine details over large and multi-resolution datasets …",Springer Nature Switzerland,,2025
412,RealDeal: Enhancing Realism and Details in Brain Image Generation via Image-to-Image Diffusion Models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7pRRhkkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7pRRhkkAAAAJ:lgwcVrK6X84C,"Generative models have been widely adopted in the biomedical domain, especially in image generation applications. Latent diffusion models achieve state-of-the-art results in generating brain MRIs. However, due to latent compression, generated images from these models are overly smooth, lacking fine anatomical structures and scan acquisition noise that are typically seen in real images. We propose image-to-image diffusion models that are designed to enhance the realism and details of generated brain images by introducing sharp edges, fine textures, subtle anatomical features, and imaging noise. This work formulates the realism enhancing and detail adding process as an image-to-image diffusion model, which refines the quality of LDM-generated images. We employ commonly used metrics like FID and LPIPS for image realism assessment. Furthermore, we introduce new metrics to quantify the improved …",Springer Nature Switzerland,,2025
413,LDDMEm: Large Deformation Diffeomorphic Metric Embedding: Decoupling Shape Analysis from Image Registration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7pRRhkkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7pRRhkkAAAAJ:ubry08Y2EpUC,"We present a method, open-source software, and experiments which embed arbitrary deformation vector fields produced by any method (e.g., ANTs or VoxelMorph) in the Large Deformation Diffeomorphic Metric Mapping (LDDMM) framework. This decouples formal diffeomorphic shape analysis from image registration, which has many practical benefits. Shape analysis can be added to study designs without modification to already chosen image registration methods and existing databases of deformation fields can be reanalyzed within the LDDMM framework without repeating image registrations. Pairwise time series studies can be extended to full time series regression with minimal added computing. The diffeomorphic rigor of image registration methods can be compared by embedding deformation fields and comparing projection distances. Finally, the added value of formal diffeomorphic shape analysis can be …",Springer Nature Switzerland,,2025
414,Point-based shape representation generation with a correspondence-preserving diffusion model,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7pRRhkkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7pRRhkkAAAAJ:NyGDZy8z5eUC,"We propose a diffusion model designed to generate point-based shape representations with correspondences. Traditional statistical shape models have considered point correspondences extensively, but current deep learning methods do not take them into account, focusing on unordered point clouds instead. Current deep generative models for point clouds do not address generating shapes with point correspondences between generated shapes. This work aims to formulate a diffusion model that is capable of generating realistic point-based shape representations, which preserve point correspondences that are present in the training data. Using shape representation data with correspondences derived from Open Access Series of Imaging Studies 3 (OASIS-3), we demonstrate that our correspondence-preserving model effectively generates point-based hippocampal shape representations that are highly realistic compared to existing methods. We further demonstrate the applications of our generative model by downstream tasks, such as conditional generation of healthy and AD subjects and predicting morphological changes of disease progression by counterfactual generation.",,,2025
415,Locally differentially private protocols for frequency estimation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TkgyXGwAAAAJ&citation_for_view=TkgyXGwAAAAJ:MXK_kJrjxJIC,"Protocols satisfying Local Differential Privacy (LDP) enable parties to collect aggregate information about a population while protecting each user’s privacy, without relying on a trusted third party. LDP protocols (such as Google’s RAPPOR) have been deployed in real-world scenarios. In these protocols, a user encodes his private information and perturbs the encoded value locally before sending it to an aggregator, who combines values that users contribute to infer statistics about the population. In this paper, we introduce a framework that generalizes several LDP protocols proposed in the literature. Our framework yields a simple and fast aggregation algorithm, whose accuracy can be precisely analyzed. Our in-depth analysis enables us to choose optimal parameters, resulting in two new protocols (ie, Optimized Unary Encoding and Optimized Local Hashing) that provide better utility than protocols previously proposed. We present precise conditions for when each proposed protocol should be used, and perform experiments that demonstrate the advantage of our proposed protocols.",,,2017
416,Privacy at scale: Local differential privacy in practice,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TkgyXGwAAAAJ&citation_for_view=TkgyXGwAAAAJ:_kc_bZDykSQC,"Local differential privacy (LDP), where users randomly perturb their inputs to provide plausible deniability of their data without the need for a trusted party, has been adopted recently by several major technology organizations, including Google, Apple and Microsoft. This tutorial aims to introduce the key technical underpinnings of these deployed systems, to survey current research that addresses related problems within the LDP model, and to identify relevant open problems and research directions for the community.",,,2018
417,When machine unlearning jeopardizes privacy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TkgyXGwAAAAJ&citation_for_view=TkgyXGwAAAAJ:ZeXyd9-uunAC,"The right to be forgotten states that a data owner has the right to erase their data from an entity storing it. In the context of machine learning (ML), the right to be forgotten requires an ML model owner to remove the data owner's data from the training set used to build the ML model, a process known asmachine unlearning. While originally designed to protect the privacy of the data owner, we argue that machine unlearning may leave some imprint of the data in the ML model and thus create unintended privacy risks. In this paper, we perform the first study on investigating the unintended information leakage caused by machine unlearning. We propose a novel membership inference attack that leverages the different outputs of an ML model's two versions to infer whether a target sample is part of the training set of the original model but out of the training set of the corresponding unlearned model. Our experiments …",,,2021
418,Locally differentially private frequent itemset mining,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TkgyXGwAAAAJ&citation_for_view=TkgyXGwAAAAJ:ULOm3_A8WrAC,"The notion of Local Differential Privacy (LDP) enables users to respond to sensitive questions while preserving their privacy. The basic LDP frequent oracle (FO) protocol enables an aggregator to estimate the frequency of any value. But when each user has a set of values, one needs an additional padding and sampling step to find the frequent values and estimate their frequencies. In this paper, we formally define such padding and sample based frequency oracles (PSFO). We further identify the privacy amplification property in PSFO. As a result, we propose SVIM, a protocol for finding frequent items in the set-valued LDP setting. Experiments show that under the same privacy guarantee and computational cost, SVIM significantly improves over existing methods. With SVIM to find frequent items, we propose SVSM to effectively find frequent itemsets, which to our knowledge has not been done before in the LDP setting.",IEEE,,2018
419,Graph unlearning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TkgyXGwAAAAJ&citation_for_view=TkgyXGwAAAAJ:j3f4tGmQtD8C,"Machine unlearning is a process of removing the impact of some training data from the machine learning (ML) models upon receiving removal requests. While straightforward and legitimate, retraining the ML model from scratch incurs a high computational overhead. To address this issue, a number of approximate algorithms have been proposed in the domain of image and text data, among which SISA is the state-of-the-art solution. It randomly partitions the training set into multiple shards and trains a constituent model for each shard. However, directly applying SISA to the graph data can severely damage the graph structural information, and thereby the resulting ML model utility. In this paper, we propose GraphEraser, a novel machine unlearning framework tailored to graph data. Its contributions include two novel graph partition algorithms and a learning-based aggregation method. We conduct extensive …",,,2022
420,Network-Aware Differential Privacy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TkgyXGwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TkgyXGwAAAAJ:LPZeul_q3PIC,"Differential privacy (DP) is a privacy-enhancement technology (PET) that receives prominent attention from the academia, industry, and government. One main development over the past decade has been the decentralization of DP, including local DP and shuffle DP. Despite that decentralized DP heavily relies on network communications for data collection,we found that: 1) no systematic study has surveyed the research opportunities at the intersection of networking and DP; 2) nor have there been significant efforts to develop DP mechanisms that are explicitly tailored for network environments. In this paper, we seek to address this gap by initiating a new direction of network-aware DP. We identified two focus areas where the network research can offer substantive contributions to the design and deployment of DP, related to network security and topology. Through this work, we hope to encourage more research that adapt/optimize DP's deployment in various network environments.",,,2025
421,White-box Membership Inference Attacks against Diffusion Models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TkgyXGwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TkgyXGwAAAAJ:u_35RYKgDlwC,"Diffusion models have begun to overshadow GANs and other generative models in industrial applications due to their superior image generation performance. The complex architecture of these models furnishes an extensive array of attack features. In light of this, we aim to design membership inference attacks (MIAs) catered to diffusion models. We first conduct an exhaustive analysis of existing MIAs on diffusion models, taking into account factors such as black-box/white-box models and the selection of attack features. We found that white-box attacks are highly applicable in real-world scenarios, and the most effective attacks presently are white-box. Departing from earlier research, which employs model loss as the attack feature for white-box MIAs, we employ model gradients in our attack, leveraging the fact that these gradients provide a more profound understanding of model responses to various samples. We subject these models to rigorous testing across a range of parameters, including training steps, sampling frequency, diffusion steps, and data variance. Across all experimental settings, our method consistently demonstrated near-flawless attack performance, with attack success rate approaching and attack AUCROC near . We also evaluate our attack against common defense mechanisms, and observe our attacks continue to exhibit commendable performance.",,,2025
422,From easy to hard: Building a shortcut for differentially private image synthesis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TkgyXGwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TkgyXGwAAAAJ:8AbLer7MMksC,"Differentially private (DP) image synthesis aims to generate synthetic images from a sensitive dataset, alleviating the privacy leakage concerns of organizations sharing and utilizing synthetic images. Although previous methods have significantly progressed, especially in training diffusion models on sensitive images with DP Stochastic Gradient Descent (DP-SGD), they still suffer from unsatisfactory performance. In this work, inspired by curriculum learning, we propose a two-stage DP image synthesis framework, where diffusion models learn to generate DP synthetic images from easy to hard. Unlike existing methods that directly use DP-SGD to train diffusion models, we propose an easy stage in the beginning, where diffusion models learn simple features of the sensitive images. To facilitate this easy stage, we propose to use ‘central images’, simply aggregations of random samples of the sensitive dataset …",IEEE,,2025
423,Benchmarking differentially private tabular data synthesis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TkgyXGwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TkgyXGwAAAAJ:4fKUyHm3Qg0C,"Differentially private (DP) tabular data synthesis generates artificial data that preserves the statistical properties of private data while safeguarding individual privacy. The emergence of diverse algorithms in recent years has introduced challenges in practical applications, such as inconsistent data processing methods, lack of in-depth algorithm analysis, and incomplete comparisons due to overlapping development timelines. These factors create significant obstacles to selecting appropriate algorithms. In this paper, we address these challenges by proposing a benchmark for evaluating tabular data synthesis methods. We present a unified evaluation framework that integrates data preprocessing, feature selection, and synthesis modules, facilitating fair and comprehensive comparisons. Our evaluation reveals that a significant utility-efficiency trade-off exists among current state-of-the-art methods. Some statistical methods are superior in synthesis utility, but their efficiency is not as good as most machine learning-based methods. Furthermore, we conduct an in-depth analysis of each module with experimental validation, offering theoretical insights into the strengths and limitations of different strategies.",,,2025
424,DPImageBench: A Unified Benchmark for Differentially Private Image Synthesis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TkgyXGwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TkgyXGwAAAAJ:08ZZubdj9fEC,"Differentially private (DP) image synthesis aims to generate artificial images that retain the properties of sensitive images while protecting the privacy of individual images within the dataset. Despite recent advancements, we find that inconsistent--and sometimes flawed--evaluation protocols have been applied across studies. This not only impedes the understanding of current methods but also hinders future advancements. To address the issue, this paper introduces DPImageBench for DP image synthesis, with thoughtful design across several dimensions: (1) Methods. We study eleven prominent methods and systematically characterize each based on model architecture, pretraining strategy, and privacy mechanism. (2) Evaluation. We include nine datasets and seven fidelity and utility metrics to thoroughly assess them. Notably, we find that a common practice of selecting downstream classifiers based on the highest accuracy on the sensitive test set not only violates DP but also overestimates the utility scores. DPImageBench corrects for these mistakes. (3) Platform. Despite the methods and evaluation protocols, DPImageBench provides a standardized interface that accommodates current and future implementations within a unified framework. With DPImageBench, we have several noteworthy findings. For example, contrary to the common wisdom that pretraining on public image datasets is usually beneficial, we find that the distributional similarity between pretraining and sensitive images significantly impacts the performance of the synthetic images and does not always yield improvements. In addition, adding noise to low-dimensional …",,,2025
425,Operationalising competencies in higher education for sustainable development,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BYQG8dEAAAAJ&citation_for_view=BYQG8dEAAAAJ:a9-T7VOCCH8C,"Case study research offers a range of accounts for in-depth research in fields of higher education, in the sense of identifying relevant issues for promoting sustainable development and creating knowledge within and between different groups (Wals et al. 2013), in and outside higher education institutions. This chapter about case study research is aimed at contributing to increase the reliability and credibility of case study research and to establish it as a methodology with high potential for analysing social situations. In a first step we have to be distinctive about the terms ‘case’, ‘case study’ and ‘case study research’. In literature on environmental education and education for sustainable development the terms ‘case’ and ‘case study’ are quite commonly used (e.g. Karim et al. 2013; Togo and Lotz-Sisitka 2013; Evans et al. 2012; Svanström et al. 2012; James and Card 2012; Chapman 2011; Sanusi and Khelghat-Doost …",,,2016
426,Anticipatory life-cycle assessment for responsible research and innovation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BYQG8dEAAAAJ&citation_for_view=BYQG8dEAAAAJ:YohjEiUPhakC,"The goal of guiding innovation toward beneficial social and environmental outcomes – referred to in the growing literature as responsible research and innovation (RRI) – is intuitively worthwhile but lacks practicable tools for implementation. One potentially useful tool is life-cycle assessment (LCA), which is a comprehensive framework used to evaluate the environmental impacts of products, processes, and technologies. However, LCA ineffectively promotes RRI for at least two reasons: (1) Codified approaches to LCA are largely retrospective, relying heavily on data collected from mature industries with existing supply chains and (2) LCA underemphasizes the importance of stakeholder engagement to inform critical modeling decisions which diminishes the social credibility and relevance of results. LCA researchers have made piecemeal advances that address these shortcomings, yet there is no consensus …",Routledge,,2014
427,Illustrating anticipatory life cycle assessment for emerging photovoltaic technologies,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BYQG8dEAAAAJ&citation_for_view=BYQG8dEAAAAJ:kh2fBNsKQNwC,"Current research policy and strategy documents recommend applying life cycle assessment (LCA) early in research and development (R&D) to guide emerging technologies toward decreased environmental burden. However, existing LCA practices are ill-suited to support these recommendations. Barriers related to data availability, rapid technology change, and isolation of environmental from technical research inhibit application of LCA to developing technologies. Overcoming these challenges requires methodological advances that help identify environmental opportunities prior to large R&D investments. Such an anticipatory approach to LCA requires synthesis of social, environmental, and technical knowledge beyond the capabilities of current practices. This paper introduces a novel framework for anticipatory LCA that incorporates technology forecasting, risk research, social engagement, and comparative …",American Chemical Society,Environmental science & technology,2014
428,"Sustainability Education Framework for Teachers: Developing sustainability literacy through futures, values, systems, and strategic thinking",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BYQG8dEAAAAJ&citation_for_view=BYQG8dEAAAAJ:GtLg2Ama23sC,"The Sustainability Education Framework for Teachers (SEFT) intends to build a capacity for educators to be able to understand:(i) the broad, complex nature of sustainability,(ii) the problem-oriented, solution driven nature of sustainability, and (iii) how sustainability connects to them as both citizens and classroom teachers. SEFT embraces four ways of thinking––futures, values, systems, and strategic which are conceptualized as being bi-directional and interconnected. The framework aids in linking sustainability topics that are seemingly disparate to the novice teacher population by building upon knowledge, skills, and attitudes necessary for problem solving with respect to complex sustainability challenges. Imagined as a conceptual framework, it offers organizing principles for examining and considering sustainability problem/solution constellations in a coherent fashion. The framework provides the opportunity for self-reflection and independent enquiry by considering and learning through real world foci. Likewise, SEFT offers a logical framework for working in interpersonal, intragroup, and intergroup situations. The four lenses require considering critical inquiries related to societal values, equity, and visions of the future; unpacking the status quo; and exploring and articulating pathways towards a sustainable tomorrow.",,,2015
429,Acquisition of T-shaped expertise: an exploratory study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BYQG8dEAAAAJ&citation_for_view=BYQG8dEAAAAJ:sNmaIFBj_lkC,"Disciplinary boundaries become increasingly unclear when grappling with “wicked problems,” which present a complex set of policy, cultural, technological, and scientific dimensions. “T-shaped” professionals, i.e. individuals with a depth and breadth of expertise, are being called upon to play a critical role in complex problem-solving. This paper unpacks the notion of the “T-shaped expert” and seeks to situate it within the broader academic literature on expertise, integration, and developmental learning. A component of this project includes an exploratory study, which is aimed at evaluating the emergent attributes of T-shaped expertise in two different educational programs completed between January and May in 2015. The two programs build disciplinary knowledge in science, technology engineering, and mathematics fields at the core (vertical dimension), while expanding the students’ awareness and …",Routledge,,2017
430,The Myths of Regional Innovation: Sustainability Challenges and Responsible Innovation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BYQG8dEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BYQG8dEAAAAJ:Ak0FvsSvgGUC,"Billions of dollars, Euros, yen, and yuan in public funds are spent annually to promote innovation in metropolitan regions, attempting to transform the economy by attracting technology-based companies and supporting small startups to secure high-paying jobs. The impacts of those investments are typically assessed in terms of economic growth, venture capital, and jobs. Regional innovation is assessed with financial measures that do not account for the distribution of wealth, nor do they evaluate if innovation addresses broader sustainability concerns. This book draws on evidence from 144 interviews with civic leaders in three urban regions—Atlanta, Phoenix, and the Twin Cities—to illuminate three commonly accepted but flawed myths about innovation that misdirect policymakers and civic leaders and perpetuate the idea that innovation is solely about economic growth. This book offers evidence of the social networks, labor divisions, and conditions enabling innovation to dispel those three myths and propose more nuanced and realistic ways of thinking about regional innovation. This book is not an argument against innovation. Rather, it critically reflects upon investments in innovation and showcases laudable efforts to create a livable and sustainable city. The book offers a novel method to assess the processes and outcomes of innovation in a manner that can complement economic approaches. The author lays bare the human values that motivate city staff, corporate officers, and academic partners and highlights the efforts of organizations that often remain underappreciated. The evidence presented in this book puts forward a means to …",Routledge,,2025
431,How did STEM students respond to a cross-campus discussion forum about macroethics? An exploratory content analysis of students’ written reflections,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BYQG8dEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BYQG8dEAAAAJ:vDZJ-YLwNdEC,"Ethics education is increasingly recognized as an essential element of undergraduate programs focused on science, technology, engineering, and mathematics (STEM). One method is training future STEM professionals in responsible conduct of research at the individual level (microethics), but it is also important to focus on ethical issues at the societal and global levels (macroethics). Real-world challenges involve various disciplines, the integration of technical and ethical aspects of practice, and awareness of current societal dynamics. Macroethics in practice can lead a reflective STEM practitioner to acknowledge stakeholders and critically consider implications of their research. This research project engaged STEM students enrolled in physics, engineering, and chemistry courses at different universities with a common ethics education experience, the Collaborative Online Discussions about Ethics (CODE) forum …",Springer International Publishing,,2023
432,"Divergence and Convergence in Engineering Leadership, Entrepreneurship, Management, and Policy",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BYQG8dEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BYQG8dEAAAAJ:artPoR2Yc-kC,"A little over half (28 of 54) of the divisions of ASEE focus on the intersections between STEM disciplines and different contexts of engineering education and practice. These 28 divisions emphasize three broad areas:(1) humanistic content and goals;(2) particular groups of students, faculty, practitioners, or other stakeholders; and (3) specific arenas of activity and organizational contexts. Four of these “Engineering and...” divisions include engineering leadership, entrepreneurship, management, and policy. The divisions share goals such as connecting the technical and non-technical dimensions of engineering and transforming engineering education so that it more effectively prepares graduates for workplace success. Previous research suggested that interest in “Engineering and…” permeates ASEE and is concentrated in but not limited to the division most closely associated with the topic. This paper describes a transferable method that combines quantitative and qualitative methods to identify areas of convergence using papers published in the Leadership Development (LEAD) and the Engineering Entrepreneurship and Innovation (ENT) as evidence. These areas of convergence are:(1) program design and effectiveness,(2) individual capabilities (including traits and thinking tools),(3) teams and groups, and (4) identity and culture. Program design and effectiveness dominate the discourse of both divisions, suggesting that the two groups face similar challenges. Areas of apparent divergence include more concern with mindsets and innovativeness in ENT and more emphasis on team skills and mentorship in LEAD. These findings present …",,,2023
433,Practical Information,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BYQG8dEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BYQG8dEAAAAJ:gKiMpY-AVTkC,"General travel information fPET2023 will take place in building X (Mekelweg 8, 2628 CD Delft), on the TU Delft campus. The venue is easily reachable by bus from the train station Delft. You can take bus 40 (in the direction of Rotterdam Centraal), 69 (in the direction of TU Campus) or 174 (in the direction of Rotterdam Noord) to bus stop ‘Berlageweg’. In the morning of Wednesday 19th, you can for example take:",,,2023
434,Investigating innovation ecosystems for wearable medical devices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BYQG8dEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BYQG8dEAAAAJ:nVrZBo8bIpAC,"Wearable medical technologies (wearables) are a type of digital health technology that have the potential to transform the delivery of healthcare by offering a personalized, predictive, and preventative form of patient care. Unfortunately, the adoption of these technologies remains low, indicating an issue with the innovation ecosystem. Existing literature on innovation ecosystems fails to address wearables and the trade-offs between profitability and health outcomes, hindering discussion on how to promote the widespread adoption of wearables. This paper reviews and synthesizes literature from the business community and healthcare technology community on innovation ecosystems to contribute towards developing a more robust model of the innovation ecosystem for developing wearables. Future work aims to enrich this conceptualization with interviews of key actors in the innovation ecosystem. Clinical …",IEEE,2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC),2022
435,Compositional effects of additively manufactured refractory high-entropy alloys under high-energy helium irradiation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yo8PWTcAAAAJ&citation_for_view=yo8PWTcAAAAJ:qjMakFHDy7sC,"High-Entropy Alloys (HEAs) are proposed as materials for a variety of extreme environments, including both fission and fusion radiation applications. To withstand these harsh environments, materials processing must be tailored to their given application, now achieved through additive manufacturing processes. However, radiation application opportunities remain limited due to an incomplete understanding of the effects of irradiation on HEA performance. In this letter, we investigate the response of additively manufactured refractory high-entropy alloys (RHEAs) to helium (He) ion bombardment. Through analytical microscopy studies, we show the interplay between the alloy composition and the He bubble size and density to demonstrate how increasing the compositional complexity can limit the He bubble effects, but care must be taken in selecting the appropriate constituent elements.",Mdpi,,2022
436,Strain modulation using defects in two-dimensional,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yo8PWTcAAAAJ&citation_for_view=yo8PWTcAAAAJ:u-x6o8ySG0sC,"We investigate the nature of strain in and correlate it to defect types and densities, while systematically assessing the tolerance of this low dimensional material to He and Au ion irradiations. Through a series of theoretical predictions and experimental observations, we establish the onset of the crystalline-to-amorphous transition in and identify sulfur vacancies as the most favorable defects introduced during irradiation. We note the presence of both tensile and compressive strains, which depend on the types of defects introduced into the lattice and vary with increasing fluence. The results show that defects can be used to tune strain in two-dimensional materials and provide an exciting pathway for using external stimuli to control properties of low dimensional materials.",American Physical Society,,2020
437,Controlling neutral and charged excitons in MoS2 with defects,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yo8PWTcAAAAJ&citation_for_view=yo8PWTcAAAAJ:2osOgNQ5qMEC,"In this contribution, we use heavy ion irradiation and photoluminescence (PL) spectroscopy to demonstrate that defects can be used to tailor the optical properties of two-dimensional molybdenum disulfide (MoS2). Sonicated MoS2 flakes were deposited onto Si/SiO2 substrate and subjected to 3 MeV Au2+ ion irradiation at room temperature to fluences ranging from 1 × 1012 to 1 × 1016 cm−2. We demonstrate that irradiation-induced defects can control optical excitations in the inner core shell of MoS2 by binding A1s- and B1s-excitons, and correlate the exciton peaks to the specific defects introduced with irradiation. The systematic increase of ion fluence produced different defect densities in MoS2, which were estimated using B/A exciton ratios and progressively increased with ion fluence. We show that up to the fluences of 1 × 1014 cm−2, the MoS2 lattice remains crystalline and defect densities can be controlled …",Cambridge University Press,,2020
438,Non‐Linear Optics at Twist Interfaces in h‐BN/SiC Heterostructures,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yo8PWTcAAAAJ&citation_for_view=yo8PWTcAAAAJ:YsMSGLbcyi4C,"Understanding the emergent electronic structure in twisted atomically thin layers has led to the exciting field of twistronics. However, practical applications of such systems are challenging since the specific angular correlations between the layers must be precisely controlled and the layers have to be single crystalline with uniform atomic ordering. Here, an alternative, simple, and scalable approach is suggested, where nanocrystallinetwo‐dimensional (2D) film on 3D substrates yields twisted‐interface‐dependent properties. Ultrawide‐bandgap hexagonal boron nitride (h‐BN) thin films are directly grown on high in‐plane lattice mismatched wide‐bandgap silicon carbide (4H‐SiC) substrates to explore the twist‐dependent structure‐property correlations. Concurrently, nanocrystalline h‐BN thin film shows strong non‐linear second‐harmonic generation and ultra‐low cross‐plane thermal conductivity at room …",,,2023
439,Effect of the catalyst metal content and the carbon support on proton-exchange membrane fuel cells performance and durability,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yo8PWTcAAAAJ&citation_for_view=yo8PWTcAAAAJ:kNdYIx-mwKoC,"Catalysts based on Pt nanoparticles supported on carbon (Pt/C) are widely used in proton-exchange membrane fuel cell (PEMFC) cathodes. The Pt weight percent (wt%) and the type of carbon used influence the PEMFC performance and durability, but the mechanism of this influence remains poorly understood. Herein, we systematically investigated the effect of catalyst metal content and the type of carbon support on PEMFC performance and durability by employing two types of commercially available Pt/C catalysts. We evaluated the effect of differences in both local and average Pt wt% on both high surface area carbon (HSC) and Vulcan XC72, including durability testing with 30,000 accelerated stress test cycles. The results show that Pt wt% is the main factor controlling durability of Pt/HSC, with local Pt content being more important than average Pt content. Selection of Pt wt% on the HSC support involves a …",Pergamon,,2025
440,Tip-Induced Etching and Vacancy Island Evolution on 2H-TaS2 Revealed by STM,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yo8PWTcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=yo8PWTcAAAAJ:qxL8FJ1GzNcC,"Recent research on 2D materials using scanning probe microscopy reveals that the surface of transition metal dichalcogenides can be etched during the measurement via either a tunneling-field-driven or a scanning probe-driven process. The tip-induced manipulation of the surface structure and defects is a first step toward nanolithography using scanning probes. Real-space scanning tunneling microscopy experiments provide a surface defect inventory, which includes linear and point defects for 2H-TaS2 grown by chemical vapor transport. Extended periods of imaging trigger the formation of vacancy islands that grow and coalesce over time, leading to the sequential removal of entire layers. The growth kinetics of vacancies were observed over extended periods and quantified using AI and conventional image analysis tools. The vacancy islands have a linear growth rate of their perimeter and corresponding …",American Chemical Society,,2025
441,Atomic-resolution spectroscopic analysis of magnons in 2D materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yo8PWTcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=yo8PWTcAAAAJ:4TOpqqG69KYC,"Antiferromagnetic materials have a naturally occurring magnetic structure, but the direction of their ordered microscopic moments alternate between individual atomic sites in a crystal. This makes the characterization of magnetic materials difficult as their moments are invisible to common magnetic probes, and the lack of fine spatial resolution inhibits atomby- atom analysis of magnetic domains. Accordingly, it becomes imperative to have knowledge of the atomic arrangement of the respective film, and still retain the energy resolution to decouple magnon modes in the infrared regime. Hereby, the disordered phase of antiferromagnetic Fe2O3 (Hematene) is used; with the structure having an internal magnetic moment that can be picked up with spectroscopic means. Monochromated electron energy loss spectroscopy (EELS) inside an aberration-corrected scanning transmission electron microscope (STEM) is used to …",SPIE,,2025
442,Atomic-Scale Exciton Binding Energy Determination of Defected Transition Metal Dichalcogenides,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yo8PWTcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=yo8PWTcAAAAJ:YOwf2qJgpHMC,"The ability to confine excitons at localized heterogeneities in two-dimensional (2D) semiconductors is amongst the most desired breakthroughs warranted in the community, as it enables precise control over light absorption and emission at sub-nm limits. While this has been attempted for decades in bulk semiconductors using material modulation (manipulation of the structure of the solid), studying confinement in non-equilibrium driven low-dimensional films has traditionally been a “shot in the dark.” Meaning, our limitations in understanding how to confine electrons is due to poor control over the energy and trapping potential, as well as our customary use of diffraction-limited probes [1], forcing us to infer what the atomic scale looks like after acquiring a spectrum. Accordingly, a detailed study utilizing advancements in more than one characterization tool is warranted in order to obtain both localized optical and …",Oxford University Press,,2025
443,Phonon Damping in Amorphous Nitrides and Oxides Observed with Vibrational EELS,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yo8PWTcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=yo8PWTcAAAAJ:ULOm3_A8WrAC,"Characterizing the propagation of phonons in crystalline solids is a rather routine technique that is well-suited for optical probes. Phonons in amorphous solids are more difficult to capture since we do not have information of the precise arrangement of atoms, although the atoms are still localized and interact with each other at T> 0K. In amorphous materials the propagation of phonons reduces rapidly from damping, that is the dissipation of energy from internal or external influences, yet it is still hard to interpret how this seemingly randomized disorder has such a large effect on macroscale properties. Perhaps, if a probe can be localized within an amorphous film and at the interface between an amorphous film and a crystalline substrate to decouple the origin of phonon damping, we can differentiate between boundary scattering and anharmonic interactions contributing to damping. Often viewed as a negative …",Oxford University Press,,2025
444,Immobilization of Escherichia coli RNA Polymerase and Location of Binding Sites by Use of Chromatin Immunoprecipitation and Microarrays,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sl0D6rcAAAAJ&citation_for_view=sl0D6rcAAAAJ:u-x6o8ySG0sC,"The genome-wide location of RNA polymerase binding sites was determined in Escherichia coli using chromatin immunoprecipitation and microarrays (chIP-chip). Cross-linked chromatin was isolated in triplicate from rifampin-treated cells, and DNA bound to RNA polymerase was precipitated with an antibody specific for the β′ subunit. The DNA was amplified and hybridized to “tiled” oligonucleotide microarrays representing the whole genome at 25-bp resolution. A total of 1,139 binding sites were detected and evaluated by comparison to gene expression data from identical conditions and to 961 promoters previously identified by established methods. Of the detected binding sites, 418 were located within 1,000 bp of a known promoter, leaving 721 previously unknown RNA polymerase binding sites. Within 200 bp, we were able to detect 51% (189/368) of the known σ70-specific promoters occurring upstream of …",American Society for Microbiology,,2005
445,Genome-Scale Analysis of the Uses of the Escherichia coli Genome: Model-Driven Analysis of Heterogeneous Data Sets,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sl0D6rcAAAAJ&citation_for_view=sl0D6rcAAAAJ:u5HHmVD_uO8C,"The recent availability of heterogeneous high-throughput data types has increased the need for scalable in silico methods with which to integrate data related to the processes of regulation, protein synthesis, and metabolism. A sequence-based framework for modeling transcription and translation in prokaryotes has been established and has been extended to study the expression state of the entire Escherichia coli genome. The resulting in silico analysis of the expression state highlighted three facets of gene expression in E. coli: (i) the metabolic resources required for genome expression and protein synthesis were found to be relatively invariant under the conditions tested; (ii) effective promoter strengths were estimated at the genome scale by using global mRNA abundance and half-life data, revealing genes subject to regulation under the experimental conditions tested; and (iii) large-scale genome location …",American Society for Microbiology,,2003
446,Sequence-based analysis of metabolic demands for protein synthesis in prokaryotes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sl0D6rcAAAAJ&citation_for_view=sl0D6rcAAAAJ:d1gkVwhDpl0C,"Constraints-based models for microbial metabolism can currently be constructed on a genome-scale. These models do not account for RNA and protein synthesis. A scalable formalism to describe translation and transcription that can be integrated with the existing metabolic models is thus needed. Here, we developed such a formalism. The fundamental protein synthesis network described by this formalism was analysed via extreme pathway and flux balance analyses. The protein synthesis network exhibited one extreme pathway per messenger RNA synthesized and one extreme pathway per protein synthesized. The key parameters in this network included promoter strengths, messenger RNA half-lives, and the availability of nucleotide triphosphates, amino acids, RNA polymerase, and active ribosomes. Given these parameters, we were able to calculate a cell's material and energy expenditures for protein …",Academic Press,,2003
447,Long-range periodic patterns in microbial genomes indicate significant multi-scale chromosomal organization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sl0D6rcAAAAJ&citation_for_view=sl0D6rcAAAAJ:9yKSN-GCB0IC,"Genome organization can be studied through analysis of chromosome position-dependent patterns in sequence-derived parameters. A comprehensive analysis of such patterns in prokaryotic sequences and genome-scale functional data has yet to be performed. We detected spatial patterns in sequence-derived parameters for 163 chromosomes occurring in 135 bacterial and 16 archaeal organisms using wavelet analysis. Pattern strength was found to correlate with organism-specific features such as genome size, overall GC content, and the occurrence of known motility and chromosomal binding proteins. Given additional functional data for Escherichia coli, we found significant correlations among chromosome position dependent patterns in numerous properties, some of which are consistent with previously experimentally identified chromosome macrodomains. These results demonstrate that the large-scale organization of most sequenced genomes is significantly nonrandom, and, moreover, that this organization is likely linked to genome size, nucleotide composition, and information transfer processes. Constraints on genome evolution and design are thus not solely dependent upon information content, but also upon an intricate multi-parameter, multi-length-scale organization of the chromosome.",Public Library of Science,,2006
448,BME Labs in the Era of COVID-19: Transitioning a Hands-on Integrative Lab Experience to Remote Instruction Using Gamified Lab Simulations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sl0D6rcAAAAJ&citation_for_view=sl0D6rcAAAAJ:YOwf2qJgpHMC,"The COVID-19 induced abrupt transition to online learning that occurred in the Spring of 2020 presented particular challenges to the adaptation of hands-on laboratory courses in biomedical engineering. This paper describes the transition of such a course in one undergraduate program, assessment of this transition, and how this assessment has led to the design of the Fall 2020 online delivery format. In the spring, instruction was delivered online via asynchronous lectures and recorded video demonstrations, while raw data was provided to students to simulate specific laboratory techniques. Additionally, synchronous and asynchronous forms of student support were offered, including office hours and discussions. Student feedback was assessed via an end-of-semester survey designed specifically to analyze the students’ perceptions of the Spring 2020 transition to remote learning, as well as a comparison of …",,,2020
449,BOARD# 293: Reflection on Outcomes Data from Eight Years of a Summer REU Site in Systems Bioengineering and Biomedical Data Sciences,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sl0D6rcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=sl0D6rcAAAAJ:hC7cP41nSMkC,"The biotechnology and pharmaceutical industries are increasingly reliant on a workforce pipeline of graduates possessing the skills needed to quantitatively describe complex systems to predict functional outcomes relevant to healthy physiological function and to disease states. These skills will be essential for not only identifying novel drug targets and ascertaining the etiology of complex diseases such as cancer and heart disease, but also for achieving truly personalized medical diagnostics, therapies, and surgical approaches toward treating these diseases. Moreover, inherent biological complexity and high-throughput measurement approaches lead to massive “big data” sets, often with thousands of heterogeneous values. This complexity requires data science tools such as data-driven modeling and machine learning to appropriately integrate heterogeneous data. Thus, it is imperative to train a diverse new generation of scientists in the concepts and practice of multi-scale systems bioengineering and biomedical data sciences (BDS) research.",,,2025
450,REU Site: Multi-Scale Systems Bioengineering and Biomedical Data Sciences,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sl0D6rcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=sl0D6rcAAAAJ:7PzlFSSx8tAC,"This three-year REU Site: Multi-Scale Systems Bioengineering and Biomedical Data Sciences focuses on combining experimentation with computational analyses to discover the mechanisms of disease and identify new treatments and cures. The number of Americans with cardiovascular disease, obesity, diabetes, and cancer is increasing because these diseases are complex and affect each person differently based on their genetics, lifestyle, environment, and access to healthcare. Identifying effective therapies requires a workforce of biomedical researchers able to deploy state-of-the-art experimental protocols in wet-lab environments and analyze the resulting data sets using sophisticated algorithms and computational models. Ten undergraduates each summer will be recruited to participate in state-of-the-art systems bioengineering and data science research. REU students will engage in research projects …",,,2025
451,"Board 7: Work in Progress: A Collaborative, Principle-focused Curriculum Design Process for a BME Undergraduate Program",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sl0D6rcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=sl0D6rcAAAAJ:mVmsd5A6BfQC,"Biomedical engineers (BME) apply engineering principles to solve problems in biology and medicine and have contributed to revolutionary and life-saving concepts, such as artificial organs, advanced prosthetics, and new pharmaceuticals. As their impact on healthcare and society is significant, how BMEs learn to approach a problem is critical. What role should a BME play in deciding how gene editing is used in humans? How can a BME ensure that a medical decision-making algorithm serves all demographics equally? Given that today’s societal challenges are growing more complex, a new kind of engineer is required. Future engineers must consider the ethical and societal implications of their work, develop and implement systems of greater and greater complexity, and be prepared to live and work as global citizens, working in diverse groups and diverse contexts. ABET’s new Engineering Learning Outcomes and new addition of ethics, inclusivity, and empathy creates a need to address these new areas in a BME curriculum, and each department must determine how this is done in their specific program and educational environment. To ensure that undergraduate students graduate with the knowledge, tools, and experiences needed to meet these desired outcomes, and to ensure the curriculum meets the changing requirements and suggestions of accreditation bodies and professional societies, an effective continuous improvement process must be in place. A key process component often overlooked is the curriculum design process itself. An undergraduate BME program at a top R1 university, in close partnership with its teaching center …",,,2024
452,Physicochemical principles driving small molecule binding to RNA,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sl0D6rcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=sl0D6rcAAAAJ:QIV2ME_5wuYC,"The possibility of using RNA-targeting small molecules to treat diseases is gaining traction as the next frontier of drug discovery and development. The chemical characteristics of small molecules that bind to RNA are still relatively poorly understood, particularly in comparison to protein-targeting small molecules. To fill this gap, we have generated an unprecedented amount of RNA-small molecule binding data, and used it to derive physicochemical rules of thumb that could be used to define areas of chemical space enriched for RNA binders - the Small molecules Targeting RNA (STaR) rules of thumb. These rules have been applied to publicly available RNA-small molecule datasets and found to be largely generalizable. Furthermore, a number of patented RNA-targeting compounds and FDA-approved compounds also pass these rules, as well as key RNA binding approved drug case studies including Risdiplam. We anticipate this work will significantly accelerate the exploration of the RNA-targeted chemical space, towards unlocking RNA’s potential as a small molecule drug target. Graphical Abstract",Cold Spring Harbor Laboratory,,2024
453,The Effect of In-Person versus Pre-recorded Final Presentations on Student Learning Outcomes and Engagement,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sl0D6rcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=sl0D6rcAAAAJ:qxL8FJ1GzNcC,"Pre-recorded presentations are becoming more prevalent in professional settings, such as conferences and in the classroom, and require a different but related skill-set than the standard in-person presentation. To evaluate student performance and understanding of pre-recorded versus in-person presentations we conducted a preliminary research study in a Systems Bioengineering course with a mixture of undergraduate and graduate enrollment. For each of the four course modules, students were randomly assigned groups with at least two graduate students per group and developed a small computational model based on the module’s topic. Students presented their work in a pre-recorded presentation in the first and third modules and in an in-person presentation in the second and fourth modules. At the end of the course, students were asked to complete an anonymous Qualtrics survey, developed based on previous surveys that evaluated in-person versus virtual presentation formats [1, 2], to identify the positives and negatives associated with pre-recorded presentation on both the presenter and the audience member. Nine students, eight graduate students, and one undergraduate student completed the survey. All students had prior experience with in-person presentations, but only two students had previous experience with pre-recorded presentations. Students rated how delivering presentations in each presentation style impacted a variety of learning outcomes, such as ability to be innovative and take risks, improving teamwork skills, and improving communication skills, on a scale of 1 to 10—with 1 being no impact and 10 being great …",,,2023
454,Opportunities and obstacles for deep learning in biology and medicine,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eXKdSu0AAAAJ&citation_for_view=eXKdSu0AAAAJ:v6PuF9mNY3oC,"Deep learning describes a class of machine learning algorithms that are capable of combining raw inputs into layers of intermediate features. These algorithms have recently shown impressive results across a variety of domains. Biology and medicine are data-rich disciplines, but the data are complex and often ill-understood. Hence, deep learning techniques may be particularly well suited to solve problems of these fields. We examine applications of deep learning to a variety of biomedical problems—patient classification, fundamental biological processes and treatment of patients—and discuss whether deep learning will be able to transform these tasks or if the biomedical sphere poses unique challenges. Following from an extensive literature review, we find that deep learning has yet to revolutionize biomedicine or definitively resolve any of the most pressing challenges in the field, but promising advances have …",The Royal Society,Journal of the royal society interface,2018
455,Feature squeezing: Detecting adversarial examples in deep neural networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eXKdSu0AAAAJ&citation_for_view=eXKdSu0AAAAJ:sfsSB7lKuh0C,"Although deep neural networks (DNNs) have achieved great success in many tasks, they can often be fooled by \emph{adversarial examples} that are generated by adding small but purposeful distortions to natural examples. Previous studies to defend against adversarial examples mostly focused on refining the DNN models, but have either shown limited success or required expensive computation. We propose a new strategy, \emph{feature squeezing}, that can be used to harden DNN models by detecting adversarial examples. Feature squeezing reduces the search space available to an adversary by coalescing samples that correspond to many different feature vectors in the original space into a single sample. By comparing a DNN model's prediction on the original input with that on squeezed inputs, feature squeezing detects adversarial examples with high accuracy and few false positives. This paper explores two feature squeezing methods: reducing the color bit depth of each pixel and spatial smoothing. These simple strategies are inexpensive and complementary to other defenses, and can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks.",arXiv preprint arXiv:1704.01155,,2018
456,Random forest for bioinformatics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eXKdSu0AAAAJ&citation_for_view=eXKdSu0AAAAJ:mVmsd5A6BfQC,"Modern biology has experienced an increased use of machine learning techniques for large scale and complex biological data analysis. In the area of Bioinformatics, the Random Forest (RF)[6] technique, which includes an ensemble of decision trees and incorporates feature selection and interactions naturally in the learning process, is a popular choice. It is nonparametric, interpretable, efficient, and has high prediction accuracy for many types of data. Recent work in computational biology has seen an increased use of RF, owing to its unique advantages in dealing with small sample size, high-dimensional feature space, and complex data structures.","Springer, New York, NY",,2012
457,"Textattack: A framework for adversarial attacks, data augmentation, and adversarial training in nlp",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eXKdSu0AAAAJ&citation_for_view=eXKdSu0AAAAJ:eLRq4zTgah0C,"While there has been substantial research using adversarial attacks to analyze NLP models, each attack is implemented in its own code repository. It remains challenging to develop NLP attacks and utilize them to improve model performance. This paper introduces TextAttack, a Python framework for adversarial attacks, data augmentation, and adversarial training in NLP. TextAttack builds attacks from four components: a goal function, a set of constraints, a transformation, and a search method. TextAttack's modular design enables researchers to easily construct attacks from combinations of novel and existing components. TextAttack provides implementations of 16 adversarial attacks from the literature and supports a variety of models and datasets, including BERT and other transformers, and all GLUE tasks. TextAttack also includes data augmentation and adversarial training modules for using components of adversarial attacks to improve model accuracy and robustness. TextAttack is democratizing NLP: anyone can try data augmentation and adversarial training on any model or dataset, with just a few lines of code. Code and tutorials are available at https://github.com/QData/TextAttack.",,,2020
458,Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eXKdSu0AAAAJ&citation_for_view=eXKdSu0AAAAJ:qYOp8iumCsAC,"Although various techniques have been proposed to generate adversarial samples for white-box attacks on text, little attention has been paid to a black-box attack, which is a more realistic scenario. In this paper, we present a novel algorithm, DeepWordBug, to effectively generate small text perturbations in a black-box setting that forces a deep-learning classifier to misclassify a text input. We develop novel scoring strategies to find the most important words to modify such that the deep classifier makes a wrong prediction. Simple character-level transformations are applied to the highest-ranked words in order to minimize the edit distance of the perturbation. We evaluated DeepWordBug on two real-world text datasets: Enron spam emails and IMDB movie reviews. Our experimental results indicate that DeepWordBug can reduce the classification accuracy from 99% to 40% on Enron and from 87% to 26% on IMDB …",,"1st DEEP LEARNING AND SECURITY WORKSHOP (DLS18), arXiv preprint arXiv:1801.04354",2018
459,Zero-knowledge LLM hallucination detection and mitigation through fine-grained cross-model consistency,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eXKdSu0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=eXKdSu0AAAAJ:3jqAvCjcdfEC,"Large language models (LLMs) have demonstrated impressive capabilities across diverse tasks, but they remain susceptible to hallucinations--generating content that appears plausible but contains factual inaccuracies. We present Finch-Zk, a black-box framework that leverages FINe-grained Cross-model consistency to detect and mitigate Hallucinations in LLM outputs without requiring external knowledge sources. Finch-Zk introduces two key innovations: 1) a cross-model consistency checking strategy that reveals fine-grained inaccuracies by comparing responses generated by diverse models from semantically-equivalent prompts, and 2) a targeted mitigation technique that applies precise corrections to problematic segments while preserving accurate content. Experiments on the FELM dataset show Finch-Zk improves hallucination detection F1 scores by 6-39\% compared to existing approaches. For mitigation, Finch-Zk achieves 7-8 absolute percentage points improvement in answer accuracy on the GPQA-diamond dataset when applied to state-of-the-art models like Llama 4 Maverick and Claude 4 Sonnet. Extensive evaluation across multiple models demonstrates that Finch-Zk provides a practical, deployment-ready safeguard for enhancing factual reliability in production LLM systems.",,,2025
460,AIDE: Attribute-Guided MultI-Hop Data Expansion for Data Scarcity in Task-Specific Fine-tuning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eXKdSu0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=eXKdSu0AAAAJ:q7LczdTNAjsC,"Fine-tuning large language models (LLMs) for specific tasks requires diverse, high-quality training data. However, obtaining sufficient relevant data remains a significant challenge. Existing data synthesis methods either depend on extensive seed datasets or struggle to balance task relevance and data diversity. To address these challenges, we propose Attribute-guided multI-hop Data Expansion (AIDE), a novel data synthesis framework that uses a multi-hop process to expand very few seed data points while ensuring data diversity and task relevance. AIDE extracts the main topic and key knowledge attributes from the seeds to guide the synthesis steps. The process repeats for K hops, using the generated data as seeds. To prevent irrelevant data generation as the hop depth increases, AIDE incorporates a residual connection mechanism. Our empirical results show that AIDE enables fine-tuning of Mistral-7B, Llama-3.1-8B and Llama-3.2-3B from 10 seeds, surpassing the models fine-tuned on human curated data. Furthermore, AIDE outperforms state-of-the-art data synthesis methods, such as Evol-Instruct, by over 30% in task-specific fine-tuning. Code is available at https://github. com/Code4Graph/AIDE.",,,2025
461,Reward Is Enough: LLMs Are In-Context Reinforcement Learners,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eXKdSu0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=eXKdSu0AAAAJ:OqYjx1B7R3oC,"Reinforcement learning (RL) is a human-designed framework for solving sequential decision making problems. In this work, we demonstrate that, surprisingly, RL emerges in LLM's (Large Language Model) inference time -- a phenomenon known as in-context RL (ICRL). Specifically, we propose a novel multi-round prompting framework called ICRL prompting. The goal is to prompt the LLM to complete a task. After the LLM generates a response at the current round, we give numerical scalar feedbacks for the response, called the rewards. At the next round, we prompt the LLM again with the same task and a context consisting of all previous responses and rewards. We observe that the quality of the LLM's response increases as the context grows. In other words, the LLM is able to maximize the scalar reward signal in the inference time, just like an RL algorithm. We evaluate ICRL prompting in three benchmarks (Game of 24, creative writing, and ScienceWorld) and demonstrate significant performance improvements over baseline methods such as Self-Refine and Reflexion. Surprisingly, in some experiments the reward signals are generated by the LLM itself, yet performance improvements are still observed from ICRL prompting, offering a promising paradigm for scaling test-time compute.",,,2025
462,Hierarchical Prompt Decision Transformer: Improving Few-Shot Policy Generalization with Global and Adaptive Guidance,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eXKdSu0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=eXKdSu0AAAAJ:wH03y5nBhxsC,"Decision transformers recast reinforcement learning as a conditional sequence generation problem, offering a simple but effective alternative to traditional value or policy-based methods. A recent key development in this area is the integration of prompting in decision transformers to facilitate few-shot policy generalization. However, current methods mainly use static prompt segments to guide rollouts, limiting their ability to provide context-specific guidance. Addressing this, we introduce a hierarchical prompting approach enabled by retrieval augmentation. Our method learns two layers of soft tokens as guiding prompts: (1) global tokens encapsulating task-level information about trajectories, and (2) adaptive tokens that deliver focused, timestep-specific instructions. The adaptive tokens are dynamically retrieved from a curated set of demonstration segments, ensuring context-aware guidance. Experiments across …",,,2025
463,Augmented Adversarial Trigger Learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eXKdSu0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=eXKdSu0AAAAJ:ZZwcLRaXOV4C,"Gradient optimization-based adversarial attack methods automate the learning of adversarial triggers to generate jailbreak prompts or leak system prompts. In this work, we take a closer look at the optimization objective of adversarial trigger learning and propose ATLA: Adversarial Trigger Learning with Augmented objectives. ATLA improves the negative log-likelihood loss used by previous studies into a weighted loss formulation that encourages the learned adversarial triggers to optimize more towards response format tokens. This enables ATLA to learn an adversarial trigger from just one query-response pair and the learned trigger generalizes well to other similar queries. We further design a variation to augment trigger optimization with an auxiliary loss that suppresses evasive responses. We showcase how to use ATLA to learn adversarial suffixes jailbreaking LLMs and to extract hidden system prompts. Empirically we demonstrate that ATLA consistently outperforms current state-of-the-art techniques, achieving nearly 100% success in attacking while requiring 80% fewer queries. ATLA learned jailbreak suffixes demonstrate high generalization to unseen queries and transfer well to new LLMs.",,,2025
464,Seismic response control using shape memory alloys: a review,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VdoAeqAAAAAJ&citation_for_view=VdoAeqAAAAAJ:WF5omc3nYNoC,"Shape memory alloys (SMAs) are a class of alloys that possess numerous unique characteristics. They offer complete shape recovery after experiencing large strains, energy dissipation through hysteresis of response, excellent resistance to corrosion, high fatigue resistance, and high strength. These features of SMAs, which can be exploited for the use in control of civil structures subjected to seismic events, have attracted the interest of many researchers in structural engineering over the past decades. This article presents an extensive review of seismic applications of SMAs. First, a basic description of two unique effects of SMAs, namely shape memory and superelastic effect, is provided. Then, the mechanical characteristics of the most commonly used SMAs are discussed. Next, the material models proposed to capture the response of SMAs in seismic applications are briefly introduced. Finally, applications of …",Sage Publications,Journal of intelligent material systems and structures,2011
465,Application of semi-active control strategies for seismic protection of buildings with MR dampers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VdoAeqAAAAAJ&citation_for_view=VdoAeqAAAAAJ:d1gkVwhDpl0C,"Magnetorheological (MR) dampers are semi-active devices that can be used to control the response of civil structures during seismic loads. They are capable of offering the adaptability of active devices and stability and reliability of passive devices. One of the challenges in the application of the MR dampers is to develop an effective control strategy that can fully exploit the capabilities of the MR dampers. This study proposes two semi-active control methods for seismic protection of structures using MR dampers. The first method is the Simple Adaptive Control method which is classified as a direct adaptive control method. By using this method, the controlled system is forced to track the response of the system with desired behavior. The controller developed using this method can deal with the changes that occur in the characteristics of the structure because it can modify its parameters during the control procedure …",Elsevier,,2010
466,Optimal design of superelastic‐friction base isolators for seismic protection of highway bridges against near‐field earthquakes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VdoAeqAAAAAJ&citation_for_view=VdoAeqAAAAAJ:IjCSPb-OGe4C,"The seismic response of a multi‐span continuous bridge isolated with novel superelastic‐friction base isolator (S‐FBI) is investigated under near‐field earthquakes. The isolation system consists of a flat steel‐Teflon sliding bearing and a superelastic NiTi shape memory alloy (SMA) device. The key design parameters of an S‐FBI system are the natural period of the isolated bridge, the yielding displacement of the SMA device, and the friction coefficient of the sliding bearings. The goal of this study is to obtain optimal values for each design parameter by performing sensitivity analysis of a bridge isolated by an S‐FBI system. First, a three‐span continuous bridge is modeled as two‐degrees‐of‐freedom with the S‐FBI system. A neuro‐fuzzy model is used to capture rate‐ and temperature‐dependent nonlinear behavior of the SMA device. Then, a set of nonlinear time history analyses of the isolated bridge is performed …","John Wiley & Sons, Ltd.",,2011
467,Seismic assessment of bridge structures isolated by a shape memory alloy/rubber-basedisolation system,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VdoAeqAAAAAJ&citation_for_view=VdoAeqAAAAAJ:UeHWp8X0CEIC,"This paper explores the effectiveness of shape memory alloy (SMA)/rubber-based isolation systems for seismic protection of bridges against near-field earthquakes by performing a sensitivity analysis. The isolation system considered in this study consists of a laminated rubber bearing, which provides lateral flexibility while supplying high vertical load-carrying capacity, and an auxiliary device made of multiple loops of SMA wires. The SMA device offers additional energy dissipating and re-centering capability. A three-span continuous bridge is modeled with the SMA/rubber-based (SRB) isolation system. Numerical simulations of the bridge are conducted for various near-field ground motions that are spectrally matched to a target design spectrum. The normalized forward transformation strength, forward transformation displacement and pre-strain level of the SMA device, ambient temperature and the lateral stiffness …",IOP Publishing,,2010
468,Evaluation of the performance of a sliding-type base isolation system with a NiTi shape memory alloy device considering temperature effects,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VdoAeqAAAAAJ&citation_for_view=VdoAeqAAAAAJ:u-x6o8ySG0sC,"This paper investigates the seismic performance of a sliding-type base isolation system considering environmental temperature changes. The isolation system consists of a steel–Teflon sliding bearing that carries the vertical loads and dissipates energy as a result of its frictional behavior and a shape memory alloy (SMA) device that provides re-centering force and additional damping. A five-span continuous bridge is modeled with sliding bearings and an SMA device as a two-degree-of-freedom system. A neuro-fuzzy model that is capable of capturing the material response at different temperatures and loading frequencies is used to predict the force at superelastic NiTi shape memory alloy wires. The design parameters of the SMA device, i.e., the length and cross-sectional area of NiTi wires, are obtained through a multi-objective genetic algorithm optimization process. A time-domain method that uses wavelet …",Elsevier,,2010
469,Development of a latticed long-stroke SMA bar restrainer for seismic protection of bridges,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VdoAeqAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=VdoAeqAAAAAJ:_Re3VWB3Y0AC,"A latticed long-stroke restrainer with buckling restrained shape memory alloy bars (LLSR) is proposed as an attempt for limiting the excessive relative displacement between piers and girders of bridges. The design principle aims to enhance the stiffness of anti-buckling systems through the use of a lattice arrangement. Initially, the configuration, working mechanism, and theoretical analysis of LLSR were presented, followed by experimental tests of a single branch of LLSR. Numerical analyses are performed to investigate the effect of the diameter of SMA bars, the distance between the axis of branches, and the length of restrainers on the stability of LLSR. These analyses are based on a three-dimensional (3D) high-fidelity finite element model that has been verified by experimental results. Finally, a design procedure for LLSR is proposed. The results indicate that the use of a latticed design significantly enhances the …",Elsevier,,2025
470,Evaluating Contributions of Emerging Technologies to Civil Infrastructure System Resilience. I: A Decision-Making Workflow,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VdoAeqAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=VdoAeqAAAAAJ:kzcrU_BdoSEC,"Adopting emerging technologies (ETs) and enhancing civil infrastructure (CI) system resilience is a coupled process spanning technological, organizational, social, and economic dimensions, which concern both CI stakeholders and ET providers. To this end, no unified tool provides a decision-making aid on if and how a promising ET contributes to the resilience of an infrastructure system. This paper presents a decision-making workflow to evaluate an ET’s contribution to CI system resilience, which takes the form of a logic graph with breakdown scenarios. Using this workflow, an evaluator can identify the contribution of an ET and attribute it to one or more of five resilience properties, including resourcefulness, robustness, redundancy, rapidity, and an extended property- responsiveness. One case study of applying this workflow to a community’s water distribution system proves its effectiveness. The analytical …",American Society of Civil Engineers,,2025
471,Evaluating Contributions of Emerging Technologies to Civil Infrastructure System Resilience. II: Case Studies,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VdoAeqAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=VdoAeqAAAAAJ:Fu2w8maKXqMC,"Many emerging technologies are gaining attention in the civil engineering industry that claim to be able to aid in how civil infrastructure is constructed, monitored, or operated. At the same time, building and managing civil infrastructure with resilience has become popular with researchers and practitioners in the face of disrupting events. This paper follows Part I of this two-part set of papers. Part I proposes a qualitative workflow for evaluating emerging technologies and recognizing their specific contributions to civil infrastructure system resilience. In this work, we start with a graph-theoretic analysis to analyze the capacity of the proposed workflow as a logic graph. A collection of case studies is then presented across varying technological types to test this workflow and raise the visibility of several leading emerging technologies in the civil engineering industry. Each case study presents (1) an emerging technology, (2 …",American Society of Civil Engineers,,2025
472,"Experimental characterization of superelastic friction dampers with a focus on cyclic response, failure behavior and reparability",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VdoAeqAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=VdoAeqAAAAAJ:ZfRJV9d4-WMC,"This study investigates the experimental response of a hybrid shape memory alloy (SMA) cable-friction damping device with a specific focus on the failure behavior and reparability of the damper when tested at extreme deformations. The superelastic friction damper (SFD) is a hybrid seismic protection device that combines the high tensile strength and re-centering capability of superelastic SMA cables with stable, repeatable energy dissipation of a friction-based damping system. In this paper, the fabrication of a prototype damper and its experimental testing are discussed. The response of the SFD’s friction and self-centering mechanisms were separately evaluated considering design level deformations, cyclic loading, and large deformations up to failure. The performance of the device after the repair of failed components was also investigated. Findings from the study show that the SFD reached failure at a …",IOP Publishing,,2025
473,Shake Table Testing on a Four-Story Steel Frame Building with Shape Memory Alloy Cable Braces,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VdoAeqAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=VdoAeqAAAAAJ:tKAzc9rXhukC,"Superelastic shape memory alloys (SMAs) can recover large deformations upon unloading without the need of any external stimuli. Due to their excellent passive re-centering and good energy absorbing capabilities, superelastic SMAs have been considered for various earthquake engineering applications. However, most of the research to date has been on small-scale seismic devices and has remained in proof-of-concept stage. The cable form of SMAs exploits the excellent mechanical properties of thin wires to resist large axial loads. By leveraging the highly optimized manufacturing processes currently available for wires, SMA cables provide a large-capacity structural element with more favorable mechanical properties compared to SMA bars. This study explores the performance of SMA cable bracing systems through shake table tests. SMA cable brace is a promising self-centering system in that it introduces …",Springer Nature Switzerland,,2025
474,"Teaching through a global pandemic: educational landscapes before, during and after COVID-19",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bLuw1yoAAAAJ&citation_for_view=bLuw1yoAAAAJ:qxL8FJ1GzNcC,"The coronavirus (COVID-19) pandemic has forced an unprecedented global shift within higher education in how instructors communicate with and educate students. This necessary paradigm shift has compelled educators to take a critical look at their teaching styles and use of technology. Computing education traditionally focuses on experiential, in-person activities. The pandemic has mandated that educators reconsider their use of student time and has catalysed overnight innovations in the educational setting. Even in the unlikely event that we return entirely to pre-pandemic norms, many new practices have emerged that offer valuable lessons to be carried forward into our post-COVID-19 teaching. This working group will explore what the post-COVID-19 academic landscape might look like, and how we can use lessons learned during this educational shift to improve our subsequent practice. Following a …",,,2021
475,Gender and engagement in CS courses on piazza,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bLuw1yoAAAAJ&citation_for_view=bLuw1yoAAAAJ:YOwf2qJgpHMC,"Online discussion forums are being increasingly used in classrooms as a way to encourage collaborative learning and community. Piazza is one such forum that was built specifically for academic institutions, and has been widely adopted. Students have the opportunity to ask questions and seek answers from peers and instructors alike online, allowing them to find the information they need even if they do not know fellow students in the class or if they cannot make an instructor's office hours. However, recent analysis of the popular online discussion site Stack Overflow, suggests that women are more likely than men to withdraw from such a community if they do not identify other members of the same gender. Women are often a minority in computer science courses and may express difficulty interacting with or seeking help from their peers who are predominantly men. Considering the importance of providing equal …",,,2021
476,Stop reinventing the wheel! promoting community software in computing education,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bLuw1yoAAAAJ&citation_for_view=bLuw1yoAAAAJ:mVmsd5A6BfQC,"Historically, computing instructors and researchers have developed a wide variety of tools to support teaching and educational research, including exam and code testing suites and data collection solutions. However, these tools often find limited adoption beyond their creators. As a result, it is common for many of the same functionalities to be re-implemented by different instructional groups within the Computing Education community. We hypothesise that this is due in part to discoverability, availability, and adaptability challenges. Further, instructors often face institutional barriers to deployment, which can include hesitance of institutions to rely on community developed solutions that often lack a centralised authority and may be community or individually maintained. To this end, our working group explored what solutions are currently available, what instructors needed, and the reasons behind the above …",,,2022
477,Educational Landscapes during and after COVID-19,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bLuw1yoAAAAJ&citation_for_view=bLuw1yoAAAAJ:_kc_bZDykSQC,"The coronavirus (COVID-19) pandemic has forced an unprecedented global shift within higher education in the ways that we communicate with and educate students. This necessary paradigm shift has compelled educators to take a critical look at their teaching styles and use of technology. Computing education traditionally focuses on experiential, in-person activities. The pandemic has mandated that educators reconsider their use of student time and has catalysed overnight innovations in the educational setting. Even in the unlikely event that we return entirely to pre-COVID-19 norms, many new practices have emerged that offer valuable lessons to be carried forward into our post-COVID-19 teaching. This working group will explore what the post-COVID-19 academic landscape might look like, and how we can use lessons learned during this educational shift to improve our subsequent practice. The exploration …",,,2021
478,How do students collaborate? Analyzing group choice in a collaborative learning environment,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bLuw1yoAAAAJ&citation_for_view=bLuw1yoAAAAJ:ULOm3_A8WrAC,"Collaborative learning has been effective and widely adopted in Computer Science education. Existing studies have controlled for group sizes by assigning members to determine the optimal collaboration environment, with some focusing on a peer-programming environment and others observing a wider range of sizes and tasks. We analyzed collaboration trends through an observational study of 189 students in a large upper-level Computer Science algorithms course, which uses a less-constrained collaborative setting. In the course, the collaboration policy encourages students to choose their own groups for each assignment, up to four other students, offering insight into how groups evolve in size and membership when students are given the freedom to self-select. Since each student is required to submit their own individual work, we collected information about the grade and self-reported collaborators of each …",,,2021
479,Student Outcomes When Provided Programming Language Choice in an Algorithms Course,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bLuw1yoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bLuw1yoAAAAJ:HDshCWvjkbEC,"Students typically experience multiple programming languages early in their Computer Science studies. Some programs have trended towards starting with languages like Python [, , , ] to facilitate learning while enabling instructors to include real-world and engaging examples in the CS1 classroom, such as asking students to write classifiers for cancer data or create games . However, students may then be required to quickly transition to C++ , Java , or other languages as early as their second CS course. While several studies [, ] have shown that students make this transition fairly well, little evidence exists on student preferences and course outcomes in later courses when given a choice of language rather than the curriculum or instructor’s prescribed language. To address this gap, we examined programming language preference and performance of 268 students across two semesters in a third-in-a-sequence …",,,2025
480,Escaping the CS Dungeon: Modern College Curricula within and Beyond Computing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bLuw1yoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bLuw1yoAAAAJ:TQgYirikUcIC,"The prevalence of technology across disciplines has created a need for non-computing majors to learn programming and computing practices. Despite this, there is a lack of research documenting current programming course offerings for non-computing majors. Therefore, it is unclear how common these courses are, what fields these courses support, what programming languages are used in the courses, and what departments and institutions offer these courses. To answer these questions, we explored how and where computing is integrated into STEM and non-STEM undergraduate programs within different disciplines based on 81 survey responses of instructors teaching introductory programming courses at the 50 largest public universities in the United States. Our results indicate that computing courses are commonly offered to students of STEM and non-STEM disciplines in a variety of different programming languages.",,,2025
481,Auto-grading in Computing Education: Perceptions and Use,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bLuw1yoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bLuw1yoAAAAJ:hFOr9nPyWt4C,"Auto-grading technologies have become increasingly prevalent in computing education, driven by the need to handle growing class sizes and provide timely and effective feedback. We conducted a survey of 44 computer science instructors at various institutions in order to gather instructor experience and use of auto-graders, the features instructors value most, and the challenges and limitations faced when using these tools. We specifically asked about factors such as grading strategies and policies, opinions on existing tools, and other automated grading methods they employ. Our results indicated that instructors prefer tools that offer significant customizability and integration capabilities, with functionality and program output-based grading as the most commonly used approaches. They emphasized the need for integrated auto-grading solutions that include robust core features and prioritize extensibility to better …",,,2025
482,Kinematic and injury response of reclined PMHS in frontal impacts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1mneL4UAAAAJ&citation_for_view=1mneL4UAAAAJ:YOwf2qJgpHMC,"Frontal impacts with reclined occupants are rare but severe, and they are anticipated to become more common with the introduction of vehicles with automated driving capabilities. Computational and physical human surrogates are needed to design and evaluate injury countermeasures for reclined occupants, but the validity of such surrogates in a reclined posture is unknown. Experiments with post-mortem human subjects (PMHS) in a recline posture are needed both to define biofidelity targets for other surrogates and to describe the biomechanical response of reclined occupants in restrained frontal impacts. The goal of this study was to evaluate the kinematic and injury response of reclined PMHS in 30 g, 50 km/h frontal sled tests. Five midsize adult male PMHS were tested. A simplified semi-rigid seat with an anti-submarining pan and a non-production threepoint seatbelt (pre-tensioned, force-limited, seat …",SAE Technical Paper,,2021
483,Submarining sensitivity across varied anthropometry in an autonomous driving system environment,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1mneL4UAAAAJ&citation_for_view=1mneL4UAAAAJ:8k81kl-MbHgC,"Objective: Self-driving technology will bring novelty in occupant seating choices and vehicle interior design. Thus, vehicle safety systems may be challenged to protect occupants over a wider range of potential postures and seating choices. This study aims to investigate the effects of occupant size, seat recline, and knee bolster position on submarining risk and injury prediction metrics for reclined occupants in frontal crashes. Methods: Frontal crash finite element (FE) simulations were performed with the 3 simplified Global Human Body Model Consortium (GHBMC) occupant models: small female, midsize male, and large male. Additionally, a detailed GHBMC midsize male model was used to compare with selected simplified cases. For each simulation, parameters including seatback recline angle (0.9°, 10.9°, 20.9°, 30.9°) and knee bolster position relative to the occupant (baseline, close, far, and no knee bolster …",Taylor & Francis,,2019
484,Submarining sensitivity across varied seat configurations in autonomous driving system environment,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1mneL4UAAAAJ&citation_for_view=1mneL4UAAAAJ:Tyk-4Ss8FVUC,"Objective Self-driving technology will bring novelty in vehicle interior design and allow for a wide variety of occupant seating choices. Thus, vehicle safety systems may be challenged to protect occupants over a wider range of potential postures. This study aims to investigate the effects of the seat cushion angle on submarining risk, lumbar spine loads and pelvis excursion for reclined occupants in frontal crashes. Methods Frontal crash finite element simulations were performed with two of the simplified Global Human Body Model Consortium (GHBMC) occupant models: the small female and the midsize male. Occupant restraints consisted of a frontal airbag, a seatback-integrated 3-point belt with a lap belt anchor pre-tensioner, and a retractor pre-tensioner with a force limiter. For each simulation, parameters including seat cushion angle (3°, 8°, 13°), seatback recline angle (0°, 10°, 20°, 30°), and knee bolster (KB …",Taylor & Francis,,2020
485,Occupant safety in automated vehicles-effect of seatback recline on occupant restraint,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1mneL4UAAAAJ&citation_for_view=1mneL4UAAAAJ:4DMP91E08xMC,"The introduction of highly automated vehicles will influence occupant seating behavior and seat design, including broader adoption of reclined seating postures. The goal of this study was to perform a preliminary assessment of the usability of two occupant FE models (NHTSA THOR FE, and GHBMC Simplified Occupant) to examine restraint interactions, occupant kinematics, and occupant protection challenges for reclined occupants in frontal collisions. During frontal crash simulations, the GHBMC simplified model tended to exhibit a greater propensity for submarining and greater forward flexion of the lumbar spine compared to the THOR model. These findings will help define needs for occupant protection research for reclined occupants in automated vehicles.","Society of Automotive Engineers of Japan, INC",,2019
486,Thoracolumbar spine kinematics and injuries in frontal impacts with reclined occupants,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1mneL4UAAAAJ&citation_for_view=1mneL4UAAAAJ:_kc_bZDykSQC,"Objective Highly automated vehicles may permit alternative seating postures, which could alter occupant kinematics and challenge current restraint designs. One predicted posture is a reclined seated position. While the spine of upright occupants is subjected to flexion during frontal crashes, the orientation of reclined occupants tends to subject the spine to high compressive loads followed by high flexion loads. This study aims to investigate kinematics and mechanisms of loading in the thoracolumbar spine for a reclined seated posture through the use of postmortem human subjects (PMHS). Methods Frontal impact sled tests (50 kph delta-v) were conducted on five adult midsize male PMHS seated with the torso reclined to 50 degrees with respect to the vertical. The PMHS were seated on a semi-rigid seat and restrained by a seat-integrated three-point belt with dual lap-belt pretensioners and a shoulder-belt …",Taylor & Francis,,2020
487,Microstructure of the anterior iliac Spine: Identification of trends and relation to fracture tolerance,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1mneL4UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1mneL4UAAAAJ:35N4QoGY0k4C,"Seatbelt-induced pelvic iliac wing injuries have been observed since the 1970s, but only recently has there been quantification of fracture tolerance and injury risk of the iliac wing. Previous studies have shown a wide variation in iliac wing fracture tolerance with no significant relationships to pelvis size, sex, or other factors. A weighted average bone density (BD) calculation of the entire iliac wing produced the best predictive performance of fracture tolerance in parametric (Weibull) survival models. As a result, we endeavored to evaluate local bone microstructural properties at the site of loading and evaluate their relationship to fracture tolerance. Anterior iliac spine samples (ASIS, AIIS) were extracted from 42 iliac wings, originating from 11 male and 10 female post-mortem human surrogates (PMHS). Samples were scanned using micro-computed tomography, then 20 different cortical and trabecular bone …",Elsevier,,2025
488,Female and Combined Male–Female Injury Risk Functions for the Anterior Pelvis Under Frontal Lap Belt Loading Conditions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1mneL4UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1mneL4UAAAAJ:vV6vV6tmYwMC,"Purpose Iliac wing fractures due to lap belt loading have been observed in laboratory settings for 50 years and recent data suggest they are also occurring in the field. Automated driving systems (ADS) and other occupant compartment advancements are expected to offer enhanced flexibility in seating orientation, which could place a greater reliance on the seatbelt to restrain occupants. Such changes may increase seatbelt loads and create new challenges in successfully restraining occupants and mitigating injury to areas, such as the pelvis. Injury criteria exist for component-level male iliac wing fractures resulting from frontal lap belt loading, but not for females. Methods This study explored female iliac wing fracture tolerance in the same loading environment as a previous study that explored the fracture tolerance of isolated male iliac wings. Male and female fracture data were combined to evaluate the effect of sex …",Springer International Publishing,,2025
489,Evaluation of lap belt-pelvis load transfer in frontal impact simulations using finite element occupant models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1mneL4UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1mneL4UAAAAJ:RGFaLdJalmkC,"Objective The goal of this study was to examine the relationship between lap belt tension and force measured at the iliac wing and the effects of model type and torso posture on this relationship. From this analysis, preliminary transfer functions were developed to predict loads applied to the iliac wing as a function of lap belt tension at magnitudes typically measured in sled and vehicle crash tests. Methods A DOE study was conducted to provide a robust assessment of the lap belt-pelvis load relationship under various conditions. The GHBMC, THUMS, and THOR FE models were positioned in upright and reclined postures with several other intrinsic and extrinsic parameters varied for a total of 360 simulations. For the HBMs, instrumentation was developed to measure ASIS load at each iliac wing. Simulations that resulted in submarining were identified and removed from the subsequent development of lap belt-ASIS …",Taylor & Francis,,2024
490,"Assessing the Ability of Pressure Sensors Inserted into Intervertebral Discs to Detect Compression, Flexion, and Combined Flexion+ Compression Loading",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1mneL4UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1mneL4UAAAAJ:lSLTfruPkqcC,"Ongoing research in simulated vehicle crash environments utilizes postmortem human subjects (PMHS) as the closest approximation to live human response. Lumbar spine injuries are common in vehicle crashes, necessitating accurate assessment methods of lumbar loads. This study evaluates the effectiveness of lumbar intervertebral disc (IVD) pressure sensors in detecting various loading conditions on component PMHS lumbar spines, aiming to develop a reliable insertion method and assess sensor performance under different loading scenarios. The pressure sensor insertion method development involved selecting a suitable sensor, using a customized needle-insertion technique, and precisely placing sensors into the center of lumbar IVDs. Computed tomography (CT) scans were utilized to determine insertion depth and location, ensuring minimal tissue disruption during sensor insertion. Tests were …",,,2024
491,Restraint of Design for Obese Occupants: Rear-Seat Simulations [Second of Four Parts],https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1mneL4UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1mneL4UAAAAJ:ns9cj8rnVeAC,"This study evaluates the biofidelity of Global Human Body Modeling Consortium models representing obese people by comparing their kinematics with obese postmortem human surrogates in frontal sled tests. It was necessary to develop a finite element model to define accurate boundary conditions. Experimental tests with a robotic arm as well as an Instron machine were performed on the seat cushion and seat back foam to characterize the mechanical properties of the buck components. Then, the seat, seat back, frame, and seat reinforcement structure were 3D-scanned, cleaned, and meshed. Finally, the mechanical properties of the buck components were tuned based on the experimental tests. To investigate whether the model is capable of submarining, additional simulations (each with a modification to the model) were performed. The results showed that adding mass to the abdomen or removing the abdominal organs did not change the model’s behavior significantly.",United States. Department of Transportation. National Highway Traffic Safety Administration,,2024
492,HAMLET: A Hierarchical Multimodal Attention-based Human Activity Recognition Algorithm,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=t_ndTI4AAAAJ&citation_for_view=t_ndTI4AAAAJ:ML0RJ9NH7IQC,"To fluently collaborate with people, robots need the ability to recognize human activities accurately. Although modern robots are equipped with various sensors, robust human activity recognition (HAR) still remains a challenging task for robots due to difficulties related to multimodal data fusion. To address these challenges, in this work, we introduce a deep neural network-based multimodal HAR algorithm, HAMLET. HAMLET incorporates a hierarchical architecture, where the lower layer encodes spatio-temporal features from unimodal data by adopting a multi-head self-attention mechanism. We develop a novel multimodal attention mechanism for disentangling and fusing the salient unimodal features to compute the multimodal features in the upper layer. Finally, multimodal features are used in a fully connect neural-network to recognize human activities. We evaluated our algorithm by comparing its performance …",,,2020
493,Movement coordination in human–robot teams: a dynamical systems approach,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=t_ndTI4AAAAJ&citation_for_view=t_ndTI4AAAAJ:d1gkVwhDpl0C,"In order to be effective teammates, robots need to be able to understand high-level human behavior to recognize, anticipate, and adapt to human motion. We have designed a new approach to enable robots to perceive human group motion in real time to anticipate future actions and synthesize their own motion accordingly. We explore this within the context of joint action, in which humans and robots move together synchronously. In this paper we present an anticipation method, which takes high-level group behavior into account. We validate the method within a human-robot interaction scenario, in which an autonomous mobile robot observes a team of human dancers and then successfully and contingently coordinates its movements to “join the dance.” We compared the results of our anticipation method to move the robot with another method that did not rely on high-level group behavior and found that our …",IEEE,,2016
494,Multi-GAT: A Graphical Attention-based Hierarchical Multimodal Representation Learning Approach for Human Activity Recognition,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=t_ndTI4AAAAJ&citation_for_view=t_ndTI4AAAAJ:BwyfMAYsbu0C,"Recognizing human activities is one of the crucial capabilities that a robot needs to have to be useful around people. Although modern robots are equipped with various types of sensors, human activity recognition (HAR) still remains a challenging problem, particularly in the presence of noisy sensor data. In this work, we introduce a multimodal graphical attention-based HAR approach, called Multi-GAT, which hierarchically learns complementary multimodal features. We develop a multimodal mixture-of-experts model to disentangle and extract salient modality-specific features that enable feature interactions. Additionally, we introduce a novel message-passing based graphical attention approach to capture cross-modal relation for extracting complementary multimodal features. The experimental results on two multimodal human activity datasets suggest that Multi-GAT outperformed state-of-the-art HAR algorithms …",10.1109/LRA.2021.3059624,,2021
495,Human Robot Teaming: Approaches from Joint Action and Dynamical Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=t_ndTI4AAAAJ&citation_for_view=t_ndTI4AAAAJ:LkGwnXOMwfcC,"As robots start to work alongside people, they are expected to coordinate fluently with humans in teams. Many researchers have explored the problems involved in building more interactive and cooperative robots. In this chapter, we discuss recent work and the main application areas in human-robot teaming. We also shed light on some practical challenges to achieving fluent human-robot coordination and conclude the chapter with future directions for approaching these problems.",,,2017
496,Activity recognition in manufacturing: The roles of motion capture and sEMG+inertial wearables in detecting fine vs. gross motion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=t_ndTI4AAAAJ&citation_for_view=t_ndTI4AAAAJ:3fE2CSJIrl8C,"In safety-critical environments, robots need to reliably recognize human activity to be effective and trust-worthy partners. Since most human activity recognition (HAR) approaches rely on unimodal sensor data (e.g. motion capture or wearable sensors), it is unclear how the relationship between the sensor modality and motion granularity (e.g. gross or fine) of the activities impacts classification accuracy. To our knowledge, we are the first to investigate the efficacy of using motion capture as compared to wearable sensor data for recognizing human motion in manufacturing settings. We introduce the UCSD-MIT Human Motion dataset, composed of two assembly tasks that entail either gross or fine-grained motion. For both tasks, we compared the accuracy of a Vicon motion capture system to a Myo armband using three widely used HAR algorithms. We found that motion capture yielded higher accuracy than the …",,,2019
497,FuseCodec: Semantic-Contextual Fusion and Supervision for Neural Codecs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=t_ndTI4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=t_ndTI4AAAAJ:bz8QjSJIRt4C,"Speech tokenization enables discrete representation and facilitates speech language modeling. However, existing neural codecs capture low-level acoustic features, overlooking the semantic and contextual cues inherent to human speech. While recent efforts introduced semantic representations from self-supervised speech models or incorporated contextual representations from pre-trained language models, challenges remain in aligning and unifying the semantic and contextual representations. We introduce FuseCodec, which unifies acoustic, semantic, and contextual representations through strong cross-modal alignment and globally informed supervision. We propose three complementary techniques: (i) Latent Representation Fusion, integrating semantic and contextual features directly into the encoder latent space for robust and unified representation learning; (ii) Global Semantic-Contextual Supervision, supervising discrete tokens with globally pooled and broadcasted representations to enhance temporal consistency and cross-modal alignment; and (iii) Temporally Aligned Contextual Supervision, strengthening alignment by dynamically matching contextual and speech tokens within a local window for fine-grained token-level supervision. We further introduce FuseCodec-TTS, demonstrating our methodology's applicability to zero-shot speech synthesis. Empirically, FuseCodec achieves state-of-the-art performance in LibriSpeech, surpassing EnCodec, SpeechTokenizer, and DAC in transcription accuracy, perceptual quality, intelligibility, and speaker similarity. Results highlight the effectiveness of contextually and semantically guided …",,,2025
498,Energy-Based Transformers are Scalable Learners and Thinkers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=t_ndTI4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=t_ndTI4AAAAJ:kh2fBNsKQNwC,"Inference-time computation techniques, analogous to human System 2 Thinking, have recently become popular for improving model performances. However, most existing approaches suffer from several limitations: they are modality-specific (e.g., working only in text), problem-specific (e.g., verifiable domains like math and coding), or require additional supervision/training on top of unsupervised pretraining (e.g., verifiers or verifiable rewards). In this paper, we ask the question ""Is it possible to generalize these System 2 Thinking approaches, and develop models that learn to think solely from unsupervised learning?"" Interestingly, we find the answer is yes, by learning to explicitly verify the compatibility between inputs and candidate-predictions, and then re-framing prediction problems as optimization with respect to this verifier. Specifically, we train Energy-Based Transformers (EBTs) -- a new class of Energy-Based Models (EBMs) -- to assign an energy value to every input and candidate-prediction pair, enabling predictions through gradient descent-based energy minimization until convergence. Across both discrete (text) and continuous (visual) modalities, we find EBTs scale faster than the dominant Transformer++ approach during training, achieving an up to 35% higher scaling rate with respect to data, batch size, parameters, FLOPs, and depth. During inference, EBTs improve performance with System 2 Thinking by 29% more than the Transformer++ on language tasks, and EBTs outperform Diffusion Transformers on image denoising while using fewer forward passes. Further, we find that EBTs achieve better results than existing models on …",,,2025
499,A Data Capture and Gesture Recognition System to Enable Human-Robot Collaboration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=t_ndTI4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=t_ndTI4AAAAJ:Ri6SYOTghG4C,"Effective human-robot collaboration (HRC) relies on intuitive and reliable communication modalities, particularly in dynamic environments where traditional verbal or wearable sensor-based systems may be unreliable. While gesture-based communication offers a natural and non-intrusive alternative, it remains challenging due to limitations in current recognition systems, such as their dependence on large labeled datasets and lack of adaptability in various environmental conditions. Recent advances in vision-language models (VLMs) have shown promise in video understanding and general reasoning. However, they often lack the domain-specific context required for accurate classification in specialized applications. To address these challenges, we introduce a novel gesture recognition system that leverages a vision-language model (VLM) guided by retrieval-augmented generation (RAG) and chain-of-thought (CoT …",IEEE,,2025
500,"Using Physiological Measures, Gaze, and Facial Expressions to Model Human Trust in a Robot Partner",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=t_ndTI4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=t_ndTI4AAAAJ:YohjEiUPhakC,"With robots becoming increasingly prevalent in various domains, it has become crucial to equip them with tools to achieve greater fluency in interactions with humans. One of the promising areas for further exploration lies in human trust. A real-time, objective model of human trust could be used to maximize productivity, preserve safety, and mitigate failure. In this work, we attempt to use physiological measures, gaze, and facial expressions to model human trust in a robot partner. We are the first to design an in-person, human-robot supervisory interaction study to create a dedicated trust dataset. Using this dataset, we train machine learning algorithms to identify the objective measures that are most indicative of trust in a robot partner, advancing trust prediction in human-robot interactions. Our findings indicate that a combination of sensor modalities (blood volume pulse, electrodermal activity, skin temperature, and gaze) can enhance the accuracy of detecting human trust in a robot partner. Furthermore, the Extra Trees, Random Forest, and Decision Trees classifiers exhibit consistently better performance in measuring the person's trust in the robot partner. These results lay the groundwork for constructing a real-time trust model for human-robot interaction, which could foster more efficient interactions between humans and robots.",,,2025
501,A fault injection technique for VHDL behavioral-level models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hHrFiRAAAAAJ&citation_for_view=hHrFiRAAAAAJ:Tyk-4Ss8FVUC,"Designers are realizing the advantages of performing fault injection early, using simulation to inject faults into a model of the design rather than the actual system. The authors describe their technique for injecting faults into a system's VHDL behavioral level model. To demonstrate the technique, they evaluate an embedded control system providing fail safe operation in the railway industry.",IEEE,,2002
502,Dependability metrics to assess safety-critical systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hHrFiRAAAAAJ&citation_for_view=hHrFiRAAAAAJ:5nxA0vEk-isC,"Metrics are commonly used in engineering as measures of the performance of a system for a given attribute. For instance, in the assessment of fault tolerant systems, metrics such as the reliability, R(t) and the Mean Time To Failure (MTTF) are well-accepted as a means to quantify the fault tolerant attributes of a system with an associated failure rate, /spl lambda/. Unfortunately, there does not seem to be a consensus on comparable metrics to use in the assessment of safety-critical systems. The objective of this paper is to develop two metrics that can be used in the assessment of safety-critical systems, the steady-state safety, S/sub ss/, and the Mean Time To Unsafe Failure (MTTUF). S/sub ss/ represents the evaluation of the safety as a function of time, in the limiting case as time approaches infinity. The MTTUF represents the average or mean time that a system will operate safely before a failure that produces an …",IEEE,,2005
503,Safety-critical systems built with COTS,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hHrFiRAAAAAJ&citation_for_view=hHrFiRAAAAAJ:2osOgNQ5qMEC,"In the rail transportation industry competitive pressure has led to the increased use of COTS (commercial off-the-shelf equipment in safety critical systems), making it imperative that we extend proven safety techniques to COTS based systems as well. To this end, we have developed the Vital Framework (V-Frame), which is used to develop a safety critical platform from COTS hardware and software. The key technologies in this framework are formal methods, information redundancy, a proprietary data format, and a concurrent checking scheme. Combining these technologies results in a real time, checkable correctness criterion that is a signature of the application's algorithm structure and is independent of both the hardware and the operating system. V-Frame's most significant attribute is that the fail safe properties of applications do not require the firmware to be correct: the application will operate in a fail safe (or …",IEEE,,1996
504,Inventory management system for determining suggested part stocking levels for a vehicle dealer,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hHrFiRAAAAAJ&citation_for_view=hHrFiRAAAAAJ:u5HHmVD_uO8C,OBJECTIVE FOR NEXT RUN REst's OF EAST RUN OJECTIVE MWEST ExPECTED INVENTORY: TARGET WALUE 8S EXEECEO E-RE: LAST UPDATE DATE. Mar 10 2000,,,2002
505,A Safety Assessment Methodology for Complex Safety-Critical Hardware/Software Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hHrFiRAAAAAJ&citation_for_view=hHrFiRAAAAAJ:MXK_kJrjxJIC,,,,2000
506,An Analysis of the ATCS Generator Polynomial,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hHrFiRAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hHrFiRAAAAAJ:Zph67rFs4hoC,"SUMMARY & CONCL USIONSThe Advanced Train Control Systems (ATCS) specification provides a generator polynomial for calculating a vital Cyclic Redundancy Checksum (CRC) for computer-based communication and control. Unfortunately, very little if any published information exists concerning its design and performance. This paper presents an analysis of a code that uses the generator polynomial, providing what the authors believe is the first evidence of the minimum Hamming distance, thus supporting the use of the generator polynomial to provide vital serial communication in safety-critical railway systems.",IEEE,,2021
507,An Integrative Approach to Embedded Systems Courseware Submission Type: Work in Progress,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hHrFiRAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hHrFiRAAAAAJ:d1gkVwhDpl0C,"In 2012 a course, Introduction to Embedded Computing, in Electrical and Computer Engineering was introduced at the University of Virginia. This course was taught in a studio style environment and distinguished itself by reinforcing concepts from across multiple areas of electrical and computer engineering, ie, filtering simple controls, and motors, as key elements of our embedded computing laboratory sequence; a very simple CPU was employed. In 2017 an upper-level elective course in Advanced Embedded Computing was introduced. In this class, students work with a more capable ARM platform and implement a basic RTOS kernel with thread management, synchronization, and real-time scheduling features. In this work-in-progress paper, we discuss current course offerings and a new bridge course under development that explores introductory RTOS concepts and links embedded computing to advanced ECE courses at the second-and third-year levels.",,,2018
508,Assessment of Comprehension Retention in a Modern Electrical and Computer Engineering Curriculum,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hHrFiRAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hHrFiRAAAAAJ:kNdYIx-mwKoC,"The breadth of topics emerging under the umbrella of Electrical and Computer Engineering appears to be growing at an exponential rate. For example, we now consider advanced materials fabrication techniques and applications, heterogeneous systems, neurological processing, and artificial intelligence all to be related to the field. Complicating this state of affairs further is the requirement for our undergraduates to still attain a level of proficiency in core electrical engineering concepts such as circuit analysis, signal processing, E&M fields, and embedded computing. Furthermore, it is important that the students understand the relationships between these topics and to view them as an entire spectrum, and not as individual courses to be dispensed with at the end of a semester. To address these concerns we have undergone a major curriculum update in Electrical and Computer Engineering at UXX. We have moved …",,,2017
509,Development of Concept-Linking Inventories for a Breadth-First Approach in Electrical Engineering Fundamentals Pedagogy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hHrFiRAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hHrFiRAAAAAJ:zYLM7Y9cAGgC,"Our Electrical and Computer Engineering (ECE) Department started an effort three years ago to revise core courses in electrical circuits, electronics, and signals & systems. The revision effort sought to combine the three subjects into a tightly integrated three-course sequence. An objective was to include aspects of all three subjects in all three courses so that students would develop an understanding of relationships across the subjects. This revised approach introduced challenges to the assessment of learning outcomes. Traditional concept inventories are well established for individual topics such as electronics and signals and systems, but these single-subject inventories are not intended to assess relationships spanning multiple subjects. We endeavor in this paper to present our view of the interrelation among these core subjects and the resulting additions to concept inventories needed to assess understanding developed to bridge the topics.",,,2017
510,Method of analyzing the safety of a device employing on target hardware description language based fault injection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hHrFiRAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hHrFiRAAAAAJ:Y0pCki6q_DkC,METHOD OF ANALYZING THE SAFETY OF A DEVICE EMPLOYING ON TARGET HARDWARE DESCRIPTION LANGUAGE BASED FAULT INUECTION,,,2013
511,A steep-slope transistor based on abrupt electronic phase transition,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KQT0jk4AAAAJ&citation_for_view=KQT0jk4AAAAJ:JQOojiI6XY0C,"Collective interactions in functional materials can enable novel macroscopic properties like insulator-to-metal transitions. While implementing such materials into field-effect-transistor technology can potentially augment current state-of-the-art devices by providing unique routes to overcome their conventional limits, attempts to harness the insulator-to-metal transition for high-performance transistors have experienced little success. Here, we demonstrate a pathway for harnessing the abrupt resistivity transformation across the insulator-to-metal transition in vanadium dioxide (VO2), to design a hybrid-phase-transition field-effect transistor that exhibits gate controlled steep (‘sub-kT/q’) and reversible switching at room temperature. The transistor design, wherein VO2 is implemented in series with the field-effect transistor’s source rather than into the channel, exploits negative differential resistance induced across the VO2 …",Nature Publishing Group UK,,2015
512,Synchronized charge oscillations in correlated electron systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KQT0jk4AAAAJ&citation_for_view=KQT0jk4AAAAJ:W7OEmFMy1HYC,"Strongly correlated phases exhibit collective carrier dynamics that if properly harnessed can enable novel functionalities and applications. In this article, we investigate the phenomenon of electrical oscillations in a prototypical MIT system, vanadium dioxide (VO2). We show that the key to such oscillatory behaviour is the ability to induce and stabilize a non-hysteretic and spontaneously reversible phase transition using a negative feedback mechanism. Further, we investigate the synchronization and coupling dynamics of such VO2 based relaxation oscillators and show, via experiment and simulation, that this coupled oscillator system exhibits rich non-linear dynamics including charge oscillations that are synchronized in both frequency and phase. Our approach of harnessing a non-hysteretic reversible phase transition region is applicable to other correlated systems exhibiting metal-insulator transitions and can be …",Nature Publishing Group UK,,2014
513,Vertex coloring of graphs via phase dynamics of coupled oscillatory networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KQT0jk4AAAAJ&citation_for_view=KQT0jk4AAAAJ:9Nmd_mFXekcC,"While Boolean logic has been the backbone of digital information processing, there exist classes of computationally hard problems wherein this paradigm is fundamentally inefficient. Vertex coloring of graphs, belonging to the class of combinatorial optimization, represents one such problem. It is well studied for its applications in data sciences, life sciences, social sciences and technology, and hence, motivates alternate, more efficient non-Boolean pathways towards its solution. Here we demonstrate a coupled relaxation oscillator based dynamical system that exploits insulator-metal transition in Vanadium Dioxide (VO2) to efficiently solve vertex coloring of graphs. Pairwise coupled VO2 oscillator circuits have been analyzed before for basic computing operations, but using complex networks of VO2 oscillators, or any other oscillators, for more complex tasks have been challenging in theory as well as in experiments …",Nature Publishing Group UK,,2017
514,Joule Heating-Induced Metal–Insulator Transition in Epitaxial VO2/TiO2 Devices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KQT0jk4AAAAJ&citation_for_view=KQT0jk4AAAAJ:5qfkUJPXOUwC,"DC and pulse voltage-induced metal–insulator transition (MIT) in epitaxial VO2 two terminal devices were measured at various stage temperatures. The power needed to switch the device to the ON-state decrease linearly with increasing stage temperature, which can be explained by the Joule heating effect. During transient voltage induced MIT measurement, the incubation time varied across 6 orders of magnitude. Both DC I–V characteristic and incubation times calculated from the electrothermal simulations show good agreement with measured values, indicating Joule heating effect is the cause of MIT with no evidence of electronic effects. The width of the metallic filament in the ON-state of the device was extracted and simulated within the thermal model.",American Chemical Society,,2016
515,Transport properties of ultra-thin VO2 films on (001) TiO2 grown by reactive molecular-beam epitaxy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KQT0jk4AAAAJ&citation_for_view=KQT0jk4AAAAJ:7T2F9Uy0os0C,"We report the growth of (001)-oriented VO 2 films as thin as 1.5 nm with abrupt and reproducible metal-insulator transitions (MIT) without a capping layer. Limitations to the growth of thinner films with sharp MITs are discussed, including the Volmer-Weber type growth mode due to the high energy of the (001) VO 2 surface. Another key limitation is interdiffusion with the (001) TiO 2 substrate, which we quantify using low angle annular dark field scanning transmission electron microscopy in conjunction with electron energy loss spectroscopy. We find that controlling island coalescence on the (001) surface and minimization of cation interdiffusion by using a low growth temperature followed by a brief anneal at higher temperature are crucial for realizing ultrathin VO 2 films with abrupt MIT behavior.",AIP Publishing,,2015
516,FIMA: A Scalable Ferroelectric Compute-in-Memory Annealer for Accelerating Boolean Satisfiability,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KQT0jk4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=KQT0jk4AAAAJ:HeT0ZceujKMC,"In-memory compute kernels present a promising approach for addressing data-centric workloads. However, their scalability—particularly for computationally intensive tasks solving combinatorial optimization problems such as Boolean Satisfiability (SAT), which are inherently difficult to decompose—remains a significant challenge. In this work, we propose a ferroelectric non-volatile memory (NVM)-based compute-in-memory annealer for solving the Boolean MaxSAT problem. We experimentally demonstrate the computational functionality of the NVM array using a compact 20×10 HZO/IWO-based FeFET array. More importantly, through experimentally calibrated simulations, we demonstrate that our solution is compatible with a modular memory architecture, allowing the problem sizes to exceed the capacity of a single memory array. Our approach not only addresses the size limitations imposed by the read margin of …",IEEE,,2025
517,Spin Freezing in Oscillator Ising Machines: When Second Harmonic Injection Impedes Computation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KQT0jk4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=KQT0jk4AAAAJ:F9fV5C73w3QC,"Second harmonic injection (SHI) has emerged as a critical mechanism in enabling networks of coupled oscillators to function as Oscillator Ising Machines (OIMs), capable of minimizing the Ising Hamiltonian. While SHI facilitates phase binarization essential for mapping oscillator phases to spin states, we demonstrate that it can also induce a previously unreported phenomenon -- spin freezing -- where oscillator spins are unable to transition between spin states, even when such a transition can reduce the Ising energy. This freezing effect can impair the analog dynamics of the OIM, preventing it from reaching lower-energy spin configurations. Through theoretical analysis and numerical simulations, we show that the onset of spin freezing is highly sensitive to the initial phase configuration of the oscillators. Contrary to conventional practice, which favors random initialization, we find that initializing all oscillators at specific phase values ( or ) delays the onset of spin freezing and consistently yields higher-quality solutions. These findings point to the need to carefully engineer the SHI for optimal performance.",,,2025
518,Bridging the Analog and the Probabilistic Computing Divide: Configuring Oscillator Ising Machines as P-bit Engines,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KQT0jk4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=KQT0jk4AAAAJ:a3BOlSfXSfwC,"Oscillator Ising Machines (OIMs) and probabilistic bit (p-bit)-based computing platforms have emerged as promising paradigms for tackling complex combinatorial optimization problems. Although traditionally viewed as distinct approaches, this work presents a theoretically grounded framework for configuring OIMs as p-bit engines. We demonstrate that this functionality can be enabled through a novel interplay between first- and second harmonic injection to the oscillators. Our work identifies new synergies between the two methods and broadens the scope of applications for OIMs. We further show that the proposed approach can be applied to other analog dynamical systems, such as the Dynamical Ising Machine.",,,2025
519,Ferroelectric Memory Technology for Big Data Applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KQT0jk4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=KQT0jk4AAAAJ:OP4eGU-M3BUC,"Big Data has an insatiable appetite for larger and better-performing memory. While current memory technologies continue to advance, the performance gaps in current memory and storage technology have motivated the exploration of emerging memory technologies capable of providing new functionalities. Ferroelectric memory is one such promising candidate which has recently experienced a revival after the discovery of ferroelectricity in hafnium dioxide (HfO2) – the dielectric of choice in advanced CMOS manufacturing. While the commercial viability of ferroelectric memory technology has made significant progress over the past decade, several challenges related to variation and reliability still stand as a barrier to large-scale commercial implementation. Here, we review some of the outstanding challenges of ferroelectric memory technology along with the recent materials and device innovations that are being …",ACM,,2025
520,"Different paths, same destination: Designing physics-inspired dynamical systems with engineered stability to minimize the Ising Hamiltonian",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KQT0jk4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=KQT0jk4AAAAJ:LhH-TYMQEocC,"Oscillator Ising machines (OIMs) represent an exemplar case of using physics-inspired nonlinear dynamical systems to solve computationally challenging combinatorial optimization problems (COPs). The computational performance of such systems is highly sensitive to the underlying dynamical properties, the topology of the input graph, and their relative compatibility. In this work, we explore the concept of designing different dynamical systems that minimize the same objective function but exhibit drastically different dynamical properties. Our goal is to leverage this diversification in dynamics to reduce the sensitivity of the computational performance to the underlying graph and, subsequently, to enhance the overall effectiveness of such physics-based computational methods. To this end, we introduce the dynamical Ising machine (DIM), which, like the OIM, minimizes the Ising Hamiltonian but offers significantly …",American Physical Society,,2025
521,Qualitative coding: An approach to assess inter-rater reliability,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qtpjjnIAAAAJ&citation_for_view=qtpjjnIAAAAJ:d1gkVwhDpl0C,"When using qualitative coding techniques, establishing inter-rater reliability (IRR) is a recognized method of ensuring the trustworthiness of the study when multiple researchers are involved with coding. However, the process of manually determining IRR is not always fully explained within manuscripts or books. This is especially true if specialized qualitative coding software is being used since these software packages are often able to automatically calculate IRR providing little explanation on the methods used. Methods of coding without commercial software vary greatly including using non-specialized word processing or spreadsheet software and marking transcripts by hand using colored highlighters, pens, and even sticky notes. This array of coding approaches has led to a variety of techniques for calculating IRR. It is important that these techniques be shared, since IRR calculation is only automatic when using specialized coding software. This study summarizes a possible approach to establishing IRR for studies when researchers use word or spreadsheet processing software (eg, Microsoft Word® and Excel®). Additionally, the authors provide their recommendations or “tricks of the trade” for future teams interested in calculating IRR between members of a coding team without specialized software.",,,2017
522,Undergraduate engineering students' perceptions of research and researchers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qtpjjnIAAAAJ&citation_for_view=qtpjjnIAAAAJ:Tyk-4Ss8FVUC,"Background Participating in undergraduate research experiences (UREs) supports the development of engineering students' technical and professional skills. However, little is known about the perceptions of research or researchers that students develop through these experiences. Understanding these perceptions will provide insight into how students come to understand knowledge evaluation and creation, while allowing research advisors to better support student development. Purpose In this paper, we explore how undergraduate engineering students perceive what it means to do research and be a researcher, using identity and epistemic cognition as sensitizing concepts. Our goal is to explore students' views of UREs to make the benefits of these experiences more accessible. Design/Method We created and adapted open‐ended survey items from previously published studies. We collected responses …","John Wiley & Sons, Inc.",,2020
523,Enhancing research quality through analytical memo writing in a mixed methods grounded theory study implemented by a multi-institution research team,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qtpjjnIAAAAJ&citation_for_view=qtpjjnIAAAAJ:qjMakFHDy7sC,"In this Full Research Category paper, we will provide a detailed description of how we are using analytical memo-writing within a mixed methods grounded theory study. The goal of our work is to identify key elements from undergraduate research experiences (UREs) that can be translated into the classroom by exploring the connections between engineering students' researcher identities, perceptions of research, and epistemic thinking within the context of UREs. The qualitative phase of our study which is the focus on this paper takes a grounded theory approach as we explore our research questions using in-depth interviews. Interviews were conducted by researcher pairs, transcribed, and cleaned. Preliminary analysis, which included initial coding, was conducted by researcher pairs to increase the validity of the analysis and facilitate analytical discussions between researchers. After initial coding, the …",IEEE,,2019
524,"Elementary teachers' verbal supports of science and engineering practices in an NGSS‐aligned science, engineering, and computational thinking unit",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qtpjjnIAAAAJ&citation_for_view=qtpjjnIAAAAJ:Se3iqnhoufwC,"Contemporary science education frameworks identify computational thinking as an essential science and engineering practice that supports scientific sense‐making and engineering design. Despite national emphasis on teaching science, engineering, and computational thinking (NGSS Lead States, 2013), little research has investigated the ways that elementary teachers support students to engage in science and engineering practices (SEPs) within integrated science, engineering, and computational thinking curricula. This study explores how teachers provide verbal support of SEPs to upper elementary students during a 4‐week NGSS‐aligned curricular unit that challenged students to redesign their school to reduce water runoff. Students conducted hands‐on investigations of water runoff and created computational models to test their designs. Teacher audio data during the classroom implementation was …","John Wiley & Sons, Inc.",,2022
525,Stigma of mental health conditions within engineering culture and its relation to help-seeking attitudes: Insights from the first year of a longitudinal study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qtpjjnIAAAAJ&citation_for_view=qtpjjnIAAAAJ:4TOpqqG69KYC,"Colleges and universities are trying to keep pace with the increasing mental health needs of students. However, it has been documented that students’ attitudes towards seeking help are still a barrier to the use of available resources, and such attitudes vary across student subpopulations, with engineering students being less likely to seek help for mental health conditions (MHCs) than students in other fields when they need it [1]. Given the high-stress culture that has been promoted in the engineering field, it is important to explore the barriers that exist to our students’ help-seeking attitudes and the behaviors that would support their mental health and, consequently, their academic success. In addition, it is unknown how these barriers prevail as engineering students graduate and transition to their first professional engineering experiences. The central hypothesis of our larger project is that general and engineering-specific elements of stigma towards MHCs are negatively correlated with help-seeking attitudes of students and that such correlations vary by elements of their personal background. With our study we aim (1) to quantitatively measure the",,,2023
526,Full Paper: What are we Teaching First Year Students? A Qualitative Analysis of Introductory Engineering Course Syllabi,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qtpjjnIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qtpjjnIAAAAJ:IWHjjKOFINEC,"An introductory engineering course can have positive and lasting impacts on students’ attitudes and skills. However, introductory engineering courses vary widely. Reid et al.(2018) developed a taxonomy for mapping the terrain of introductory engineering courses which specifies the many topics that could be included in such a course. Our exploratory study extends this work with the goal of moving from what could be included towards what is included. Specifically, we address the research question: What do introductory engineering course syllabi communicate about what is valued in engineering? Our primary data source is syllabi of introductory engineering courses from 13 institutions across the US. Findings highlight the habits, mindsets, and technical skills being valued in introductory engineering courses. Technical skills were listed in greater detail, while personal and professional skills were often broadly addressed and listed in ways that did not clarify if they would be practiced independently or collaboratively.",,,2025
527,Elements of engineering culture affecting undergraduate students' mental health and their help‐seeking attitudes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qtpjjnIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qtpjjnIAAAAJ:L8Ckcad2t8MC,"Background Evidence exists that some aspects of engineering as a disciplinary culture are problematic for students' mental health and help‐seeking attitude (HSAs). In order to promote positive cultural change, it is critical to further characterize those problematic aspects of engineering culture. Purpose The purpose of this study is to expand on the specific mechanisms through which shared beliefs and values within engineering culture harm students' mental well‐being and how they transform decision making that limits help‐seeking. Design/Method Operationalizing engineering as a disciplinary culture and framed under social identity theory, we conducted a thematic analysis of 60 semi‐structured interviews among engineering undergraduates at two institutions in the continental United States. Results Problem solving and efficiency were a public representation of engineering that participants linked with a …","John Wiley & Sons, Inc.",,2025
528,BYOE: Teaching and Assessing Troubleshooting Strategies in Circuits Courses,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qtpjjnIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qtpjjnIAAAAJ:hC7cP41nSMkC,"BYOE: This paper details two breadboard-based laboratory experiments designed to teach and assess students’ use of troubleshooting strategies. Troubleshooting strategies allow engineers to methodically identify and repair faults in systems. Example strategies include: split-half or isolation, which involves testing intermediate system points to identify which sub-system is causing a fault; tracing or topographic search, which involves following the flow of the system typically from the starting or end point until you identify the fault location; and using domain knowledge to model or assess the system. Expert troubleshooters generally use both domain expertise and knowledge of troubleshooting strategies. While troubleshooting strategies are broadly relevant across engineering disciplines, they are rarely explicitly taught. Introducing these strategies explicitly into a curriculum can ensure more equal instruction than relying on “inevitable” errors as teaching tools during lab. Explicit lessons on troubleshooting can also help develop metacognitive strategies for students to help transfer knowledge between disciplines.",,,2025
529,"A Case Study of Elementary Teachers' Enactment of an NGSS-Aligned Computer Science Lesson: Verbal Support of Science, Engineering, Mathematics, and Computer Science Integration",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qtpjjnIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qtpjjnIAAAAJ:QIV2ME_5wuYC,"National frameworks for science, technology, engineering, math- ematics, and computer science (STEM+CS) education aim to inte- grate CS within K-12 science classrooms. However, the ways that elementary teachers verbally support CS integration during classroom enactment of STEM+CS projects has rarely been considered in research. This paper uses a descriptive, single case study methodology in the bounded context of a public elementary school to explore how two fifth-grade science teachers implicitly and explicitly support the integration of STEM+CS disciplines within a CS-focused lesson through verbal supports that were either planned in the STEM+CS project curricular materials or added by the teachers. Data sources included transcripts of all whole-class discussions that occurred while the two fifth-grade science teachers co-taught a CS lesson that spanned three fifty-minute class periods to two …",,,2025
530,Towards an EEG-based brain-computer interface for online robot control,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4AylPvYAAAAJ&citation_for_view=4AylPvYAAAAJ:W7OEmFMy1HYC,"According to New York Times, 5.6 million people in the United States are paralyzed to some degree. Motivated by requirements of these paralyzed patients in controlling assisted-devices that support their mobility, we present a novel EEG-based BCI system, which is composed of an Emotive EPOC neuroheadset, a laptop and a Lego Mindstorms NXT robot in this paper. We provide online learning algorithms that consist of k-means clustering and principal component analysis to classify the signals from the headset into corresponding action commands. Moreover, we also discuss how to integrate the Emotiv EPOC headset into the system, and how to integrate the LEGO robot. Finally, we evaluate the proposed online learning algorithms of our BCI system in terms of precision, recall, and the F-measure, and our results show that the algorithms can accurately classify the subjects’ thoughts into corresponding action …",Springer US,,2016
531,A software-based sonar ranging sensor for smart phones,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4AylPvYAAAAJ&citation_for_view=4AylPvYAAAAJ:9yKSN-GCB0IC,"We live in a 3-D world. However, the smart phones that we use every day are incapable of sensing depth, without the use of custom hardware. By creating new depth sensors, we can provide developers with the tools that they need to create immersive mobile applications that take advantage of the 3-D nature of our world. In this paper, we propose a new sonar sensor for smart phones. This sonar sensor does not require any additional hardware, and utilizes the phone’s microphone and rear speaker. The sonar sensor calculates distances by measuring the elapsed time between the initial pulse and its reflection. We evaluate the accuracy of the sonar sensor by using it to measure the distance from the phone to an object. We found that we were able to measure the distances of objects accurately with an error bound of 12 cm.",IEEE,,2015
532,Prototyping wearables: A code-first approach to the design of embedded systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4AylPvYAAAAJ&citation_for_view=4AylPvYAAAAJ:zYLM7Y9cAGgC,"As wearable devices become ubiquitous, there will be an increased demand for platforms that allow engineers and researchers to quickly prototype and evaluate new wearable devices. However, many of these platforms require that the hardware be configured before the code is written, thereby limiting the programmer to the limitations of the hardware. In this paper, we present a platform that allows researchers and engineers to quickly prototype new wearable devices using a code-first approach. This approach allows software developers to create new prototypes by first writing the code that the prototype is required to run. Once the code has been written, the hardware that is required to run the application can be generated by analyzing the code that the software developer has specified. This code-first approach is possible because of the system's architecture which is comprised of both a hardware and software …",IEEE,,2016
533,Ethical hacking: A hands-on introduction to breaking in,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4AylPvYAAAAJ&citation_for_view=4AylPvYAAAAJ:u5HHmVD_uO8C,"A hands-on guide to hacking computer systems from the ground up, from capturing traffic to crafting sneaky, successful trojans. A crash course in modern hacking techniques, Ethical Hacking is already being used to prepare the next generation of offensive security experts. In its many hands-on labs, you’ll explore crucial skills for any aspiring penetration tester, security researcher, or malware analyst. You’ll begin with the basics: capturing a victim’s network traffic with an ARP spoofing attack and then viewing it in Wireshark. From there, you’ll deploy reverse shells that let you remotely run commands on a victim’s computer, encrypt files by writing your own ransomware in Python, and fake emails like the ones used in phishing attacks. In advanced chapters, you’ll learn how to fuzz for new vulnerabilities, craft trojans and rootkits, exploit websites with SQL injection, and escalate your privileges to extract credentials, which you’ll use to traverse a private network. You’ll work with a wide range of professional penetration testing tools—and learn to write your own tools in Python—as you practice tasks like: Deploying the Metasploit framework’s reverse shells and embedding them in innocent-seeming files Capturing passwords in a corporate Windows network using Mimikatz Scanning (almost) every device on the internet to find potential victims Installing Linux rootkits that modify a victim’s operating system Performing advanced Cross-Site Scripting (XSS) attacks that execute sophisticated JavaScript payloads Along the way, you’ll gain a foundation in the relevant computing technologies. Discover how advanced fuzzers work behind the scenes, learn how …",No Starch Press,,2021
534,Smartphone application launch with smarter scheduling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4AylPvYAAAAJ&citation_for_view=4AylPvYAAAAJ:YsMSGLbcyi4C,"The time it takes to launch a smartphone application is unpredictable. In this paper, we explore how these unpredictable launch times are affected by constraints associated with reading (writing) from (to) flash storage. We conduct the first large-scale measurement study on the Android I/O delay using the data collected from our Android application running on 1480 devices within 188 days. Among others, we observe that reads experience up to 626% slowdown when blocked by concurrent writes. We use this obtained knowledge to design a pilot solution, wherein by prioritizing reads over writes we are able to reduce the launch delay by up to 37.8%.",,,2014
535,Meme Magic: Project in Sprints,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4AylPvYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=4AylPvYAAAAJ:2osOgNQ5qMEC,"Meme Magic is a series of six assignments intended to provide progressive exposure to programming in Java using a popular and recent concept: Memes. Memes utilize an image conveying a concept or feeling with a caption provided by the Meme author. The series of assignments, designed as sprints in the context of a larger project, begin with the design and scaffolding of Java classes needed to write a program to produce text-based Memes and end with a fully-functional graphical user interface. For a detailed list of learning goals, please see the Learning Goals section. In the first sprint, students depict the overall project structure of a text-based meme application using Unified Markup Language (UML) and write method stubs in Java. In each of the next two sprints, students implement half of the specified functionality and integrate those components to a fully working application. Students are asked to add …",,,2022
536,Redesigning the online video lecture player to promote active learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4AylPvYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=4AylPvYAAAAJ:UeHWp8X0CEIC,"This Research to Practice Work-In-Progress paper examines video lecture interactions and engagement boosting techniques. Posting video lectures online allows lecturers to extend their impact beyond the classroom. However, conventional video players may not be the best way to distribute lecture video content. When we looked at audience retention data for videos, we found that the watch patterns for lecture videos differed drastically from the watch patterns observed for non-lecture videos. In particular, we found that students were more likely to replay or skip sections of lecture videos than they were with non-lecture videos. Given these differences in viewing patterns, we created a new custom video player that is better suited for lectures to enhance student learning and to give instructors valuable feedback. Our custom video player has three main features: it logs student interactions to help instructors identify …",IEEE,,2020
537,Real-Time Encoding/Decoding for Pairwise Communication Over an Unreliable Sensor Network.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=4AylPvYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=4AylPvYAAAAJ:IjCSPb-OGe4C,"The length of time that a wireless sensor can be deployed is limited by its internal power supply. To increase the deployment lifetime of these sensors we must find ways to conserve power. In this paper, we propose an algorithm that reduces the amount of energy the transceiver consumes by compressing the bytes that are sent and received over the network. The algorithm compresses a data stream by exploiting its temporal locality and is designed to function efficiently on an unreliable network in real-time. A stream is compressed by using fewer bits to represent elements that frequently recur. We evaluate the proposed compression algorithm using a collection of independently collected traces from the crawdad database. We calculated the compression ratio for each trace and found that we were able to reduce the number of bytes transmitted by an average of 60%, resulting in a 30% increase in energy savings.",,,2019
538,Bond performance between ultrahigh-performance concrete and normal-strength concrete,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y0e7hZsAAAAJ&citation_for_view=Y0e7hZsAAAAJ:_FxGoFyzp5QC,"Ultrahigh-performance concrete (UHPC) exhibits several properties that make it appropriate for the rehabilitation of concrete structures. In this investigation, the application is focused on bridge deck overlays, but the study is equally applicable to other rehabilitation applications. Its negligible permeability makes this material suitable as a protective barrier that prevents any water or chemical penetration into the substrate. In addition, its ultra-high compressive strength and post-cracking tensile capacity could provide an improvement to the bearing capacity. However, for extensive acceptance, it has to be demonstrated that the bond between UHPC and normal strength concrete (NSC) offers a good long-term performance under a variety of operating conditions. The UHPC-NSC interface can experience high tensile, shear, and compressive stresses at both early and later life stages and the environmental conditions …",American Society of Civil Engineers,,2014
539,Robust pixel-level crack detection using deep fully convolutional neural networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y0e7hZsAAAAJ&citation_for_view=Y0e7hZsAAAAJ:ehoypfNsBj8C,"This paper introduces the idea of using deep fully convolutional neural networks for pixel-level defect detection in concrete infrastructure systems. Although coarse patch-level deep learning crack detection models abound in the literature and have shown promise, the coarse level of detail provided, together with the requirement for fixed-size input images, significantly detract from their applicability and usefulness for refined damage analysis. The deep fully convolutional model for crack detection introduced in this paper (CrackPix) leverages well-known image classification architectures for dense predictions by transforming their fully connected layers into convolutional filters. A transposed convolution layer is then used to upsample and resize the resulting prediction heatmap to the size of the input images, thus providing pixel-level predictions. To develop and train these models, a concrete crack image data set was …",American Society of Civil Engineers,,2019
540,Evaluation of commercially available remote sensors for highway bridge condition assessment,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y0e7hZsAAAAJ&citation_for_view=Y0e7hZsAAAAJ:zYLM7Y9cAGgC,"Improving transportation infrastructure inspection methods and the ability to assess conditions of bridges has become a priority in recent years as the transportation infrastructure continues to age. Current bridge inspection techniques consist largely of labor-intensive subjective measures for quantifying deterioration of various bridge elements. Some advanced nondestructive testing techniques, such as ground- penetrating radar, are being implemented; however, little attention has been given to remote sensing technologies. Remote sensing technologies can be used to assess and monitor the condition of bridge infrastructure and improve the efficiency of inspection, repair, and rehabilitation efforts. Most important, monitoring the condition of a bridge using remote sensors can eliminate the need for traffic disruption or total lane closure because remote sensors do not come in direct contact with the structure. The …",American Society of Civil Engineers,,2012
541,Increasing the robustness of material-specific deep learning models for crack detection across different materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y0e7hZsAAAAJ&citation_for_view=Y0e7hZsAAAAJ:Ul_CLA4dPeMC,"Infrastructure defect detection solutions based on computer vision have recently emerged as powerful tools with applications in both traditional inspection practices, as well as robotic inspections. These applications involve the collection of images from a wide range of infrastructure systems with heterogeneous characteristics such as conditions, materials, surface appearances and textures. Consequently, defect detection models need to be sufficiently robust to accommodate this type of heterogeneity. Existing image-based crack detection literature almost entirely focuses on models tailored to crack detection in either concrete or asphalt surfaces with prior knowledge of the material involved and studies on crack detection in more than one material are needed for truly automated inspection systems. This paper focuses on the adaptability of deep learning-based crack detection models across common construction …",Elsevier,,2020
542,Structural system identification based on variational mode decomposition,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y0e7hZsAAAAJ&citation_for_view=Y0e7hZsAAAAJ:urP0JZOBBUsC,"In this paper, a new structural identification method is proposed to identify the modal properties of engineering structures based on dynamic response decomposition using the variational mode decomposition (VMD). The VMD approach is a decomposition algorithm that has been developed as a means to overcome some of the drawbacks and limitations of the empirical mode decomposition method. The VMD-based modal identification algorithm decomposes the acceleration signal into a series of distinct modal responses and their respective center frequencies, such that when combined their cumulative modal responses reproduce the original acceleration response. The decaying amplitude of the extracted modal responses is then used to identify the modal damping ratios using a linear fitting function on modal response data. Finally, after extracting modal responses from available sensors, the mode shape vector …",Academic Press,,2018
543,What lies within: Utilizing graph neural networks for subsurface detection in finite element simulations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y0e7hZsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Y0e7hZsAAAAJ:KIRwYnRZzWQC,"Constrained maintenance budgets and rapidly aging infrastructure have driven stakeholders to seek innovative and cost-effective methods to improve the characterization of asset condition and operational performance. Over the years, these methods have included strategies such as structural health monitoring (SHM) to detect structural damage through changes in structural behavior and non-destructive evaluation (NDE) to characterize current condition state. However, current methods of assessment have proven complex in either implementation or inefficient with respect to their implementation strategy when coupled with the long service lives of these assets. In this work, a strategy for identifying unseen damage in structural components is introduced through a fusion of traditional finite element simulation and the use of graph neural networks (GNNs) for establishing damage identification. GNNs have …",Elsevier,,2025
544,Iterative Updating of Digital Twins Using Convolutional Neural Networks: A Framework for Robust Structural Behavior Prediction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y0e7hZsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Y0e7hZsAAAAJ:ynsZFq2pu0MC,"This study introduces a novel iterative updating strategy powered by convolutional neural networks (CNNs) within a digital twin framework for informing structural behavior of infrastructure assets. A two-dimensional (2D) cantilever plate is employed as a benchmark case study for the updating strategy within a digital twin framework. Two distinct surrogate models are the main components of the digital twin framework, which form the basis of this work. The first model is formulated as finite element analysis surrogate, and the training dataset is prepared based on traditional finite element analysis. The second model predicts 2D deformation based on real-world surface images, serving as the ground truth, which is trained on pairs of deformed and reference images of surfaces with speckle patterns. This ground truth deformation data bridges the gap between experimental observations (physical twin) and virtual modeling …",IEEE,,2025
545,Deep learning-based Visual Measurement Extraction within an Adaptive Digital Twin Framework from Limited Data Using Transfer Learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y0e7hZsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Y0e7hZsAAAAJ:cOfwuRB03ygC,"Digital Twins technology is revolutionizing decision-making in scientific research by integrating models and simulations with real-time data. Unlike traditional Structural Health Monitoring methods, which rely on computationally intensive Digital Image Correlation and have limitations in real-time data integration, this research proposes a novel approach using Artificial Intelligence. Specifically, Convolutional Neural Networks are employed to analyze structural behaviors in real-time by correlating Digital Image Correlation speckle pattern images with deformation fields. Initially focusing on two-dimensional speckle patterns, the research extends to three-dimensional applications using stereo-paired images for comprehensive deformation analysis. This method overcomes computational challenges by utilizing a mix of synthetically generated and authentic speckle pattern images for training the Convolutional Neural Networks. The models are designed to be robust and versatile, offering a promising alternative to traditional measurement techniques and paving the way for advanced applications in three-dimensional modeling. This advancement signifies a shift towards more efficient and dynamic structural health monitoring by leveraging the power of Artificial Intelligence for real-time simulation and analysis.",,,2024
546,Developing Augmented Reality Applications to Help Engineering Students Learn Spatial Structural Engineering Concepts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y0e7hZsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Y0e7hZsAAAAJ:-vzq6BoH5oUC,"In traditional mechanics-oriented classes, experience and the literature have shown that students are often challenged with conceptualizing complex three-dimensional behavior. Within the context of structural engineering and mechanics, the challenges manifest in scenarios related to linking this three-dimensional behavior with member response such as elastic buckling of columns and critical locations for shear and moment. While solutions such as props and videos have been used as examples in the past with some success, these tools do not spatially represent complex structural behaviors and are also limited to one-way interaction where the learner receives the information but cannot interact with the tools. This project leverages mobile augmented reality (AR) designed to help students visualize complex behaviors (deformation, strain, and stress) structural components with various loading and boundary conditions. The tool, STRUCT-AR utilizes finite element models pre-loaded into a mobile AR application that allows users to interact and engage with the models on their mobile device or tablet. Our vision of this technology is to provide a complementary teaching tool for enhancing personalized learning wherein students can leverage the technology as a learning companion both within the classroom and outside to better understand structural behaviors and mechanisms that are challenging to convey in a traditional 2D learning environment. This study uses a pilot study to evaluate how undergraduate and graduate students who have previously taken an introductory course on structural system design perceived the app. The purpose of this …",ASEE Conferences,,2024
547,Urban flood extent segmentation and evaluation from real-world surveillance camera images using deep convolutional neural network,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y0e7hZsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Y0e7hZsAAAAJ:s2G-WRnXBicC,"This study explores the use of Deep Convolutional Neural Network (DCNN) for semantic segmentation of flood images. Imagery datasets of urban flooding were used to train two DCNN-based models, and camera images were used to test the application of the models with real-world data. Validation results show that both models extracted flood extent with a mean F1-score over 0.9. The factors that affected the performance included still water surface with specular reflection, wet road surface, and low illumination. In testing, reduced visibility during a storm and raindrops on surveillance cameras were major problems that affected the segmentation of flood extent. High-definition web cameras can be an alternative tool with the models trained on the data it collected. In conclusion, DCNN-based models can extract flood extent from camera images of urban flooding. The challenges with using these models on real-world …",Elsevier,,2024
548,Opening the terahertz window with integrated diode circuits,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kyhUOY4AAAAJ&citation_for_view=kyhUOY4AAAAJ:d1gkVwhDpl0C,"The terahertz region of the electromagnetic spectrum, spanning from 100 GHz through 10 THz, is of increasing importance for a wide range of scientific, military and commercial applications. This interest is spurred by the unique properties of this spectral band and the very recent development of convenient terahertz sources and detectors. However, the terahertz band is also extremely challenging, in large part because it spans the transition from traditional electronics to photonics. This paper reviews the importance of this frequency band and summarizes the efforts of scientists and engineers to span the ""terahertz technology gap."" The emphasis is on solid-state circuits that use nonlinear diodes to translate the functionality of microwave technology to much higher frequencies.",IEEE,IEEE journal of solid-state circuits,2005
549,Thin film lithium niobate electro-optic modulator with terahertz operating bandwidth,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kyhUOY4AAAAJ&citation_for_view=kyhUOY4AAAAJ:zGdJYJv2LkUC,"We present a thin film crystal ion sliced (CIS) LiNbO_3 phase modulator that demonstrates an unprecedented measured electro-optic (EO) response up to 500 GHz. Shallow rib waveguides are utilized for guiding a single transverse electric (TE) optical mode, and Au coplanar waveguides (CPWs) support the modulating radio frequency (RF) mode. Precise index matching between the co-propagating RF and optical modes is responsible for the device’s broadband response, which is estimated to extend even beyond 500 GHz. Matching the velocities of these co-propagating RF and optical modes is realized by cladding the modulator’s interaction region in a thin UV15 polymer layer, which increases the RF modal index. The fabricated modulator possesses a tightly confined optical mode, which lends itself to a strong interaction between the modulating RF field and the guided optical carrier; resulting in a measured …",Optical Society of America,,2018
550,A 100-MESFET planar grid oscillator,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kyhUOY4AAAAJ&citation_for_view=kyhUOY4AAAAJ:u5HHmVD_uO8C,"A 100-MESFET oscillator which gives 21 W of CW effective radiated power (ERP) with a 16-dB directivity and a 20% DC-to-RF conversion efficiency at 5 GHz is presented. The oscillator is a planar grid structure periodically loaded with transistors. The grid radiates and the devices combine quasi-optically and lock to each other. The oscillator can also be quasi-optically injection-locked to an external signal. The planar grid structure is very simple. All of the devices share the same bias, and they can be power and frequency tuned with a mirror behind the grid or dielectric slabs in front of it. An equivalent circuit for an infinite grid predicts the mirror frequency tuning. The planar property of the oscillator offers the possibility of a wafer-scale monolithically integrated source. Thousands of active solid-state devices can potentially be integrated in a high-power source for microwave or millimeter-wave applications.<>",IEEE,,1991
551,Resonant metal-mesh bandpass filters for the far infrared,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kyhUOY4AAAAJ&citation_for_view=kyhUOY4AAAAJ:8AbLer7MMksC,"The spectral performance of freestanding resonant metal-mesh bandpass filters operating with center frequencies ranging from 585 GHz to 2.1 THz is presented. These filters are made up of a 12-μm-thick copper film with an array of cross-shaped apertures that fill a circular area with a 50-mm diameter. The filters exhibit power transmission in the range 97–100% at their respective center frequencies and stop-band rejection in excess of 18 dB. The theoretically predicted nondiffracting properties of the meshes are experimentally verified through high-resolution beam mapping. Scalability of the filter spectra with mesh dimensions is demonstrated over a wide spectral range. Several modeling methods are considered, and results from the models are shown.",Optical Society of America,,1994
552,A broadband quasi-optical terahertz detector utilizing a zero bias Schottky diode,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kyhUOY4AAAAJ&citation_for_view=kyhUOY4AAAAJ:hqOjcs7Dif8C,A quasi-optical broadband terahertz detector using a zero bias Schottky diode mounted on a self-complimentary sinuous antenna has been developed. Design and characterization of this detector are described. Measurements show that a responsivity of 300-1000 V/W covering the frequency range of 150-440 GHz has been achieved. The detector performance has been compared to waveguide detectors covering four frequency bands up to 600 GHz. A recent measurement at 600-900 GHz yielded the same output voltage as a waveguide detector. The noise equivalent power level of this detector is estimated to be 5-20 pW/√(Hz) based on the measurements of similar detectors.,IEEE,,2010
553,Photonically driven pseudo-continuous and broadband THz phase shifting using spatially resolved photoconductivity modulation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kyhUOY4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=kyhUOY4AAAAJ:qE4H1tSSYIIC,"We report what we believe to be a novel and unique approach for achieving high-performance and broadband THz phase shifting based on spatially-resolved photoconductivity modulation (SRPM). By changing the illumination area on a hybrid Au-Ge mesa-array (AGMA) structure in front of an indium tin oxide (ITO) layer for local photoconductivity modulation, the phase difference between the incident- and reflected-waves can be tuned nearly continuously with extremely low reflection loss. For a prototype demonstration, a photonically-driven THz phase shifting device based on the WR-5.1 (140-220 GHz) waveguide configuration was designed, modeled and simulated. To achieve phase tuning in the range of 0° to -180° at 180 GHz (band center frequency), a mesa-array consisting of 12 × 6 unit cells (each 105 μm × 105 μm) was designed, and a distance d of 250 μm between the AGMA and ITO was used …",Optica Publishing Group,,2025
554,Fabrication and Characterization of Submillimeter-Wave GaAs Quasi-Vertical Schottky Diodes Diffusion Bonded to Silicon,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kyhUOY4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=kyhUOY4AAAAJ:AYInfyleIOsC,"This work presents, to our knowledge, the first metal-to-metal diffusion-bonded Gallium Arsenide quasi-vertical Schottky diode heterogeneously integrated onto high resistivity silicon. Coplanar waveguide (CPW) fed quasi-vertical Schottky diodes were fabricated alongside a 25μm pitch on-wafer calibration kit and characterized with wafer probes and a vector network analyzer from 325-500 GHz. Diode parameters were extracted, and capacitance-voltage, and current-voltage were measured for a variety of diodes. Results indicate these diodes are suitable for high-frequency applications and have a high current density capacity, thus allowing their RF characterization under forward-bias conditions.",IEEE,,2024
555,The IMS2024 Technical Program: A Celebration in Our Nation’s Capital of the Broad Spectrum and Diversity of Our Profession,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kyhUOY4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=kyhUOY4AAAAJ:isU91gLudPYC,"Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.",IEEE,,2024
556,Improved Process Flow of Heterogeneously Integrated Gallium Arsenide Schottky Diodes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kyhUOY4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=kyhUOY4AAAAJ:C33y2ycGS3YC,"An improved process flow for fabricating heterogeneously integrated gallium arsenide Schottky diodes on membranes of 15 μm thick high-resistivity silicon microstrip substrate is reported. This effort has three focuses: 1) optimizing the fabrication of devices with high packing density to maximize devices per run, 2) co-fabrication of beam leads and side wall-Au plated vias, and 3) simplifying the process by reducing the number of processing steps.",,,2024
557,A 90-125 GHz Stacked PA in 130 nm InP HBT with 18.3% peak PAE at 15.3 dBm Output Power,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kyhUOY4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=kyhUOY4AAAAJ:ghEM2AJqZyQC,"This paper presents a wideband stacked power amplifier implemented in a 130 nm InP HBT process. The phase of the load lines at the two stages are aligned using an interstage matching network to maximize output power. The peak DC power consumption is 160 mW. The amplifier achieves a peak gain of 11.5 dB and a 3 dB bandwidth greater than 50 GHz, measured from 90 GHz to 140 GHz with a peak PAE and output power at 112.5 GHz of 18.3 % and 15.3 dBm respectively. This design demonstrates the viability of the stacked PA topology in improving power output in amplifiers designed in process nodes with low breakdown voltages.",IEEE,,2022
558,Distributed MEMS true-time delay phase shifters and wide-band switches,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hU1rpiEAAAAJ&citation_for_view=hU1rpiEAAAAJ:35N4QoGY0k4C,"Wide-band switches and true-time delay (TTD) phase shifters have been developed using distributed microelectromechanical system (MEMS) transmission lines for applications in phased-array and communication systems. The design consists of a coplanar waveguide (CPW) transmission line (W=G=100 /spl mu/m) fabricated on a 500 /spl mu/m quartz substrate with fixed-fixed beam MEMS bridge capacitors placed periodically over the transmission line, thus creating a slow-wave structure. A single analog control voltage applied to the center conductor of the CPW line can vary the phase velocity of the loaded line by pulling down on the MEMS bridges to increase the distributed capacitive loading. The resulting change in the phase velocity yields a TTD phase shift. Alternatively, the control voltage can be increased beyond the pull-down voltage of the MEMS bridges such that the capacitive loading greatly increases …",IEEE,,1998
559,Optimization of distributed MEMS transmission-line phase shifters-U-band and W-band designs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hU1rpiEAAAAJ&citation_for_view=hU1rpiEAAAAJ:u5HHmVD_uO8C,"The design and optimization of distributed micromechanical system (MEMS) transmission-line phase shifters at both U- and W-band is presented in this paper. The phase shifters are fabricated on 500 /spl mu/m quartz with a center conductor thickness of 8000 /spl Aring/ of gold. The U-band design results in 70/spl deg//dB at 40 GHz and 90/spl deg//dB at 60 GHz with a 17% change in the MEMS bridge capacitance. The W-band design results in 70/spl deg//dB from 75 to 110 GHz with a 15% change in the MEMS bridge capacitance. The W-band phase-shifter performance is limited by the series resistance of the MEMS bridge, which is estimated to be 0.15 /spl Omega/. Calculations demonstrate that the performance of the distributed MEMS phase shifter can be greatly increased if the change in the MEMS bridge capacitance can be increased to 30% or 50%. To our knowledge, these results present the best published …",IEEE,,2002
560,A W-band dielectric-lens-based integrated monopulse radar receiver,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hU1rpiEAAAAJ&citation_for_view=hU1rpiEAAAAJ:d1gkVwhDpl0C,"An integrated monopulse radar receiver has been developed for tracking applications at W-band frequencies. The receiver is based on dielectric-lens-supported, coplanar-waveguide-fed slot-ring antennas integrated with /spl times/2 uniplanar subharmonic mixers. The slot-ring antenna is capable of supporting two orthogonal modes offering the possibility of dual/multiple receive polarizations. The design center frequency is 94 GHz and the IF bandwidth is 2-4 GHz. The measured DSB conversion losses of the individual receiver channels range from 14.4 to 14.7 dB at an LO frequency of 45.0 GHz and an IF of 1.4 GHz. This includes the lens reflection and absorption losses, backside radiation, RF feedline loss, mixer conversion loss, and IF distribution loss. Excellent monopulse patterns are achieved with better than 45 dB difference pattern nulls using IF monopulse processing. This translates to submilliradian …",IEEE,,2002
561,A 60-GHz 2-bit Switched-Line Phase Shifter Using SP4T RF-MEMS Switches,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hU1rpiEAAAAJ&citation_for_view=hU1rpiEAAAAJ:_kc_bZDykSQC,This paper presents a V -band 2-bit switched-line phase shifter using dc-contact single-pole four-throw (SP4T) RF microelectromechanical systems (RF-MEMS) switches for 60-GHz applications. The design and measurements of the SP4T RF-MEMS switches and the phase shifter are presented. The phase shifter demonstrates an average insertion loss of 2.5 dB in the 55-65-GHz band with a return loss better than 12 dB for each state. The phase error for each state of the switched-line phase shifter is less than 1° at 60 GHz.,IEEE,,2011
562,Distributed MEMS tunable matching network using minimal-contact RF-MEMS varactors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hU1rpiEAAAAJ&citation_for_view=hU1rpiEAAAAJ:9yKSN-GCB0IC,"This paper presents the design, fabrication, and measurement of a double-slug tunable matching network based on a distributed microelectromechanical-system (MEMS) transmission line. The tuner is implemented with a new minimal-contact RF-MEMS varactor that largely eliminates stiction while allowing the capacitance ratio to be set anywhere from 2 to 5. The measured performance of the tunable matching network demonstrates complete coverage of the Smith chart out to a maximum voltage standing-wave ratio of 12:1 from 10 to 30 GHz with excellent agreement between measurement and simulation results.",IEEE,,2006
563,A Prototype Millimeter-Wave Reflectionless Diplexer Based on Silicon Micromachining,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hU1rpiEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hU1rpiEAAAAJ:ZzlSgRqYykMC,"Millimeter and submillimeter wave instrumentation operating above 100 GHz typically utilizes rectangular waveguide as the primary propagation medium and, consequently, is limited to operation over restricted bands bound by the cut-off frequencies for single- mode propagation. Diplexers provide an option for overcoming the band limitations imposed by conventional waveguide-based instruments. This paper reports, to our knowledge, the first implementation of a prototype “quasi-reflectionless” diplexer based on the reflectionless filter concept developed by Morgan, operating at millimeter-wave frequencies, and utilizing the integration of passive elements onto a silicon-on-insulator platform.",IEEE,,2025
564,A Millimeter-Wave “Quasi-Reflectionless” Filter Prototype Implemented with Micromachined Silicon,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hU1rpiEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hU1rpiEAAAAJ:GFxP56DSvIMC,"A proof-of-concept “quasi-reflectionless” filter integrated on a micromachined silicon-on-insulator (SOI) substrate platform is described. The filter is designed to have a low-pass response with 3 dB roll-off at 150 GHz. Suspended high-impedance transmission lines are incorporated as inductive elements, in addition to thin-film resistors, and metal-insulator-metal capacitors to realize the complete filter architecture. Through-silicon vias provide access to the circuit ground plane. Measurements of the filter are conducted using a broadband on-wafer measurement setup with dual-band probes covering the dc-to-220 GHz frequency band. The filter exhibits a return loss greater than 15 dB over the measured frequency range and to the authors' knowledge is the first reflectionless filter prototype operating over 100 GHz and implemented on micromachined SOI.",IEEE,,2024
565,IMS2024 Conference Themes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hU1rpiEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hU1rpiEAAAAJ:F9fV5C73w3QC,"IMS2024 will feature a variety of important thematic areas that highlight the symposium’s focus on “capitalizing across the spectrum.” In addition to showcasing a broad spectrum of engaging technical topics, IMS2024 will celebrate the diversity of contributions, talents, and accomplishments across our society’s “human spectrum” throughout the week. Moreover, the major technical themes of the conference will emphasize the role our host city of Washington DC has played in supporting the use and management of the RF-to-THz spectrum, including:",,,2024
566,IMS2024 General Chairs’ Welcome,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hU1rpiEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hU1rpiEAAAAJ:nZcligLrVowC,"Provides society information that may include news, reviews or technical notes that should be of interest to practitioners and researchers.",IEEE,,2024
567,Modelling disease outbreaks in realistic urban social networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNJ-E9UAAAAJ&citation_for_view=MNJ-E9UAAAAJ:HDshCWvjkbEC,"Most mathematical models for the spread of disease use differential equations based on uniform mixing assumptions or ad hoc models for the contact process,,. Here we explore the use of dynamic bipartite graphs to model the physical contact patterns that result from movements of individuals between specific locations. The graphs are generated by large-scale individual-based urban traffic simulations built on actual census, land-use and population-mobility data. We find that the contact network among people is a strongly connected small-world-like graph with a well-defined scale for the degree distribution. However, the locations graph is scale-free, which allows highly efficient outbreak detection by placing sensors in the hubs of the locations network. Within this large-scale simulation framework, we then analyse the relative merits of several proposed mitigation strategies for smallpox spread. Our results suggest …",Nature Publishing Group,,2004
568,Modeling targeted layered containment of an influenza pandemic in the United States,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNJ-E9UAAAAJ&citation_for_view=MNJ-E9UAAAAJ:70eg2SAEIzsC,"Planning a response to an outbreak of a pandemic strain of influenza is a high public health priority. Three research groups using different individual-based, stochastic simulation models have examined the consequences of intervention strategies chosen in consultation with U.S. public health workers. The first goal is to simulate the effectiveness of a set of potentially feasible intervention strategies. Combinations called targeted layered containment (TLC) of influenza antiviral treatment and prophylaxis and nonpharmaceutical interventions of quarantine, isolation, school closure, community social distancing, and workplace social distancing are considered. The second goal is to examine the robustness of the results to model assumptions. The comparisons focus on a pandemic outbreak in a population similar to that of Chicago, with ≈8.6 million people. The simulations suggest that at the expected transmissibility of …",National Acad Sciences,,2008
569,Mobile Data Offloading through Opportunistic Communications and Social Participation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNJ-E9UAAAAJ&citation_for_view=MNJ-E9UAAAAJ:Tyk-4Ss8FVUC,"3G networks are currently overloaded, due to the increasing popularity of various applications for smartphones. Offloading mobile data traffic through opportunistic communications is a promising solution to partially solve this problem, because there is almost no monetary cost for it. We propose to exploit opportunistic communications to facilitate information dissemination in the emerging Mobile Social Networks (MoSoNets) and thus reduce the amount of mobile data traffic. As a case study, we investigate the target-set selection problem for information delivery. In particular, we study how to select the target set with only k users, such that we can minimize the mobile data traffic over cellular networks. We propose three algorithms, called Greedy, Heuristic, and Random, for this problem and evaluate their performance through an extensive trace-driven simulation study. Our simulation results verify the efficiency of these …",IEEE,,2011
570,Cellular traffic offloading through opportunistic communications: a case study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNJ-E9UAAAAJ&citation_for_view=MNJ-E9UAAAAJ:J_g5lzvAfSwC,"Due to the increasing popularity of various applications for smartphones, 3G networks are currently overloaded by mobile data traffic. Offloading cellular traffic through opportunistic communications is a promising solution to partially solve this problem, because there is no monetary cost for it. As a case study, we investigate the target-set selection problem for information delivery in the emerging Mobile Social Networks (MoSoNets). We propose to exploit opportunistic communications to facilitate the information dissemination and thus reduce the amount of cellular traffic. In particular, we study how to select the target set with only k users, such that we can minimize the cellular data traffic. In this scenario, initially the content service providers deliver information over cellular networks to only users in the target set. Then through opportunistic communications, target-users will further propagate the information among all …",ACM,,2010
571,Beating the news' with EMBERS: Forecasting Civil Unrest using Open Source Indicators,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNJ-E9UAAAAJ&citation_for_view=MNJ-E9UAAAAJ:g8uWPOAv7ggC,"We describe the design, implementation, and evaluation of EMBERS, an automated, 24x7 continuous system for forecasting civil unrest across 10 countries of Latin America using open source indicators such as tweets, news sources, blogs, economic indicators, and other data sources. Unlike retrospective studies, EMBERS has been making forecasts into the future since Nov 2012 which have been (and continue to be) evaluated by an independent T&E team (MITRE). Of note, EMBERS has successfully forecast the June 2013 protests in Brazil and Feb 2014 violent protests in Venezuela. We outline the system architecture of EMBERS, individual models that leverage specific data sources, and a fusion and suppression engine that supports trading off specific evaluation criteria. EMBERS also provides an audit trail interface that enables the investigation of why specific predictions were made along with the data …",,,2014
572,Prediction of Hospital Associated Infections During Continuous Hospital Stays,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNJ-E9UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MNJ-E9UAAAAJ:jRIwE-1ttnoC,"The US Centers for Disease Control and Prevention (CDC), in 2019, designated Methicillin-resistant Staphylococcus aureus (MRSA) as a serious antimicrobial resistance threat. The risk of acquiring MRSA and suffering life-threatening consequences due to it remains especially high for hospitalized patients due to a unique combination of factors, including: co-morbid conditions, immuno suppression, antibiotic use, and risk of contact with contaminated hospital workers and equipment. In this paper, we present a novel generative probabilistic model, GenHAI, for modeling sequences of MRSA test results outcomes for patients during a single hospitalization. This model can be used to answer many important questions from the perspectives of hospital administrators for mitigating the risk of MRSA infections. Our model is based on the probabilistic programming paradigm, and can be used to approximately answer a variety of predictive, causal, and counterfactual questions. We demonstrate the efficacy of our model by comparing it against discriminative and generative machine learning models using two real-world datasets.",,,2025
573,Sample Complexity of Linear Regression Models for Opinion Formation in Networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNJ-E9UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MNJ-E9UAAAAJ:uPCvBZYD9qUC,"Consider public health officials aiming to spread awareness about a new vaccine in a community interconnected by a social network. How can they distribute information with minimal resources, so as to avoid polarization and ensure community-wide convergence of opinion? To tackle such challenges, we initiate the study of sample complexity of opinion formation in networks. Our framework is built on the recognized opinion formation game, where we regard each agent’s opinion as a data-derived model, unlike previous works that treat opinions as data-independent scalars. The opinion model for every agent is initially learned from its local samples and evolves game-theoretically as all agents communicate with neighbors and revise their models towards an equilibrium. Our focus is on the sample complexity needed to ensure that the opinions converge to an equilibrium such that every agent’s final model has low generalization error. Our paper has two main technical results. First, we present a novel polynomial time optimization framework to quantify the total sample complexity for arbitrary networks, when the underlying learning problem is (generalized) linear regression. Second, we leverage this optimization to study the network gain which measures the improvement of sample complexity when learning over a network compared to that in isolation. Towards this end, we derive network gain bounds for various network classes including cliques, star graphs, and random regular graphs. Additionally, our framework provides a method to study sample distribution within the network, suggesting that it is sufficient to allocate samples inversely to the …",,,2025
574,UFID: A Unified Framework for Black-box Input-level Backdoor Detection on Diffusion Models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNJ-E9UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MNJ-E9UAAAAJ:YGhAHpnIhDoC,"Diffusion models are vulnerable to backdoor attacks, where malicious attackers inject backdoors by poisoning certain training samples during the training stage. This poses a significant threat to real-world applications in the Model-as-a-Service (MaaS) scenario, where users query diffusion models through APIs or directly download them from the internet. To mitigate the threat of backdoor attacks under MaaS, black-box input-level backdoor detection has drawn recent interest, where defenders aim to build a firewall that filters out backdoor samples in the inference stage, with access only to input queries and the generated results from diffusion models. Despite some preliminary explorations on the traditional classification tasks, these methods cannot be directly applied to the generative tasks due to two major challenges:(1) more diverse failures and (2) a multi-modality attack surface. In this paper, we propose a black-box input-level backdoor detection framework on diffusion models, called UFID. Our defense is motivated by an insightful causal analysis: Backdoor attacks serve as the confounder, introducing a spurious path from input to target images, which remains consistent even when we perturb the input samples with Gaussian noise. We further validate the intuition with theoretical analysis. Extensive experiments across different datasets on both conditional and unconditional diffusion models show that our method achieves superb performance on detection effectiveness and run-time efficiency.",,,2025
575,Graph-Based Prediction of Spatio-Temporal Vaccine Hesitancy From Insurance Claims Data,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNJ-E9UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MNJ-E9UAAAAJ:ynsZFq2pu0MC,"Growing vaccine hesitancy is contributing to the decline in immunization rates for highly contagious, vaccine-preventable childhood diseases. Therefore, there has been a significant interest in understanding how hesitancy is spreading at higher spatio-temporal resolutions, enabling more targeted interventions. Motivated by this, we study the problem of prediction of vaccine hesitancy at the ZIP Code level, referred to as the VaxHesitancy problem. A significant challenge for this problem is the lack of high-resolution data that indicates hesitancy. Here, we develop a hybrid VaxHesSTL framework that combines a Graph Neural Network (GNN) and a Recurrent Neural Network (RNN) to address the VaxHesitancy problem. The GNN uses a ZIP Code-level network to capture spatial signals from neighboring areas, while the RNN models the temporal dynamics present in the data. We train and evaluate VaxHesSTL using a …",IEEE,,2025
576,SimPO: Simple preference optimization with a reference-free reward,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S2-yZKcAAAAJ&citation_for_view=S2-yZKcAAAAJ:TFP_iSt0sucC,"Direct Preference Optimization (DPO) is a widely used offline preference optimization algorithm that reparameterizes reward functions in reinforcement learning from human feedback (RLHF) to enhance simplicity and training stability. In this work, we propose SimPO, a simpler yet more effective approach. The effectiveness of SimPO is attributed to a key design: using the _average_ log probability of a sequence as the implicit reward. This reward formulation better aligns with model generation and eliminates the need for a reference model, making it more compute and memory efficient. Additionally, we introduce a target reward margin to the Bradley-Terry objective to encourage a larger margin between the winning and losing responses, further improving the algorithm's performance. We compare SimPO to DPO and its latest variants across various state-of-the-art training setups, including both base and instruction-tuned models such as Mistral, Llama 3, and Gemma 2. We evaluate on extensive chat-based evaluation benchmarks, including AlpacaEval 2, MT-Bench, and Arena-Hard. Our results demonstrate that SimPO consistently and significantly outperforms existing approaches without substantially increasing response length. Specifically, SimPO outperforms DPO by up to 6.4 points on AlpacaEval 2 and by up to 7.5 points on Arena-Hard. Our top-performing model, built on Gemma-2-9B-it, achieves a 72.4\% length-controlled win rate on AlpacaEval 2, a 59.1\% win rate on Arena-Hard, and ranks 1st on Chatbot Arena among 10 B models with real user votes.",,,2024
577,Large language model as attributed training data generator: A tale of diversity and bias,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S2-yZKcAAAAJ&citation_for_view=S2-yZKcAAAAJ:9ZlFYXVOiuMC,"Large language models (LLMs) have been recently leveraged as training data generators for various natural language processing (NLP) tasks. While previous research has explored different approaches to training models using generated data, they generally rely on simple class-conditional prompts, which may limit the diversity of the generated data and inherit systematic biases of LLM. Thus, we investigate training data generation with diversely attributed prompts (eg, specifying attributes like length and style), which have the potential to yield diverse and attributed generated data. Our investigation focuses on datasets with high cardinality and diverse domains, wherein we demonstrate that attributed prompts outperform simple class-conditional prompts in terms of the resulting model's performance. Additionally, we present a comprehensive empirical study on data generation encompassing vital aspects like bias, diversity, and efficiency, and highlight three key observations: firstly, synthetic datasets generated by simple prompts exhibit significant biases, such as regional bias; secondly, attribute diversity plays a pivotal role in enhancing model performance; lastly, attributed prompts achieve the performance of simple class-conditional prompts while utilizing only 5\% of the querying cost of ChatGPT associated with the latter. The data and code are available on {\url {https://github. com/yueyu1030/AttrPrompt}}.",,,2023
578,Text classification using label names only: A language model self-training approach,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S2-yZKcAAAAJ&citation_for_view=S2-yZKcAAAAJ:aqlVkmm33-oC,"Current text classification methods typically require a good number of human-labeled documents as training data, which can be costly and difficult to obtain in real applications. Humans can perform classification without seeing any labeled examples but only based on a small set of words describing the categories to be classified. In this paper, we explore the potential of only using the label name of each class to train classification models on unlabeled data, without using any labeled documents. We use pre-trained neural language models both as general linguistic knowledge sources for category understanding and as representation learning models for document classification. Our method (1) associates semantically related words with the label names, (2) finds category-indicative words and trains the model to predict their implied categories, and (3) generalizes the model via self-training. We show that our model achieves around 90% accuracy on four benchmark datasets including topic and sentiment classification without using any labeled documents but learning from unlabeled data supervised by at most 3 words (1 in most cases) per class as the label name.",,,2020
579,Generating training data with language models: Towards zero-shot language understanding,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S2-yZKcAAAAJ&citation_for_view=S2-yZKcAAAAJ:hC7cP41nSMkC,"Pretrained language models (PLMs) have demonstrated remarkable performance in various natural language processing tasks: Unidirectional PLMs (eg, GPT) are well known for their superior text generation capabilities; bidirectional PLMs (eg, BERT) have been the prominent choice for natural language understanding (NLU) tasks. While both types of models have achieved promising few-shot learning performance, their potential for zero-shot learning has been underexplored. In this paper, we present a simple approach that uses both types of PLMs for fully zero-shot learning of NLU tasks without requiring any task-specific data: A unidirectional PLM generates class-conditioned texts guided by prompts, which are used as the training data for fine-tuning a bidirectional PLM. With quality training data selected based on the generation probability and regularization techniques (label smoothing and temporal ensembling) applied to the fine-tuning stage for better generalization and stability, our approach demonstrates strong performance across seven classification tasks of the GLUE benchmark (eg, 72.3/73.8 on MNLI-m/mm and 92.8 on SST-2), significantly outperforming zero-shot prompting methods and achieving even comparable results to strong few-shot approaches using 32 training samples per class.",,,2022
580,Weakly-supervised neural text classification,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S2-yZKcAAAAJ&citation_for_view=S2-yZKcAAAAJ:Se3iqnhoufwC,"Deep neural networks are gaining increasing popularity for the classic text classification task, due to their strong expressive power and less requirement for feature engineering. Despite such attractiveness, neural text classification models suffer from the lack of training data in many real-world applications. Although many semi-supervised and weakly-supervised text classification models exist, they cannot be easily applied to deep neural models and meanwhile support limited supervision types. In this paper, we propose a weakly-supervised method that addresses the lack of training data in neural text classification. Our method consists of two modules: (1) a pseudo-document generator that leverages seed information to generate pseudo-labeled documents for model pre-training, and (2) a self-training module that bootstraps on real unlabeled data for model refinement. Our method has the flexibility to handle …",,,2018
581,Aligning Large Language Models via Fully Self-Synthetic Data,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S2-yZKcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=S2-yZKcAAAAJ:RYcK_YlVTxYC,"Traditional reinforcement learning from human feedback (RLHF) for large language models (LLMs) relies on expensive human-annotated datasets, while Reinforcement Learning from AI Feedback (RLAIF) also incurs significant costs, requiring the collection of diverse prompts and corresponding responses, often necessitating external reward models or proprietary models like GPT-4 to annotate preference pairs. In this work, we introduce Self-Alignment Optimization (SAO), a fully self-synthetic framework for LLM alignment, where all training data, including prompts (i.e., user queries), responses, and preferences, are generated by the model itself. Specifically, SAO first instructs the LLM to engage in persona role-play and generate diverse prompts and responses, which are then self-evaluated for preference optimization. Extensive experiments demonstrate that SAO effectively enhances the model's chat capabilities on standard benchmarks like AlpacaEval~2.0, while maintaining strong performance on downstream objective tasks (e.g., question-answering, math reasoning). Our work provides a practical solution for self-improvement in aligning LLMs, and the code for reproducing our results is available at: https://github.com/SJY8460/SAO.",,,2025
582,Beyond Outcome Reward: Decoupling Search and Answering Improves LLM Agents,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S2-yZKcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=S2-yZKcAAAAJ:NaGl4SEjCO4C,"Enabling large language models (LLMs) to utilize search tools offers a promising path to overcoming fundamental limitations such as knowledge cutoffs and hallucinations. Recent work has explored reinforcement learning (RL) for training search-augmented agents that interleave reasoning and retrieval before answering. These approaches usually rely on outcome-based rewards (e.g., exact match), implicitly assuming that optimizing for final answers will also yield effective intermediate search behaviors. Our analysis challenges this assumption: we uncover multiple systematic deficiencies in search that arise under outcome-only training and ultimately degrade final answer quality, including failure to invoke tools, invalid queries, and redundant searches. To address these shortcomings, we introduce DeSA (Decoupling Search-and-Answering), a simple two-stage training framework that explicitly separates search optimization from answer generation. In Stage 1, agents are trained to improve search effectiveness with retrieval recall-based rewards. In Stage 2, outcome rewards are employed to optimize final answer generation. Across seven QA benchmarks, DeSA-trained agents consistently improve search behaviors, delivering substantially higher search recall and answer accuracy than outcome-only baselines. Notably, DeSA outperforms single-stage training approaches that simultaneously optimize recall and outcome rewards, underscoring the necessity of explicitly decoupling the two objectives.",,,2025
583,TruthRL: Incentivizing truthful LLMs via reinforcement learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S2-yZKcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=S2-yZKcAAAAJ:RGFaLdJalmkC,"While large language models (LLMs) have demonstrated strong performance on factoid question answering, they are still prone to hallucination and untruthful responses, particularly when tasks demand information outside their parametric knowledge. Indeed, truthfulness requires more than accuracy -- models must also recognize uncertainty and abstain when unsure to avoid hallucinations. This presents a fundamental challenge for existing methods: approaches that optimize for accuracy often amplify hallucinations, while those that encourage abstention can become overly conservative, sacrificing correct answers. Both extremes ultimately compromise truthfulness. In this work, we present TruthRL, a general reinforcement learning (RL) framework that directly optimizes the truthfulness of LLMs. Specifically, we implement TruthRL using GRPO with a simple yet effective ternary reward that distinguishes correct answers, hallucinations, and abstentions. It incentivizes models to reduce hallucinations not only by providing correct responses, but also by enabling abstention when uncertain, thereby improving truthfulness. Extensive experiments across four knowledge-intensive benchmarks show that, compared to vanilla RL, TruthRL significantly reduces hallucinations by 28.9% and improves truthfulness by 21.1%, with consistent gains across various backbone models (e.g., Qwen, Llama) under both retrieval and non-retrieval setups. In-depth ablation study demonstrates that vanilla accuracy-driven methods, such as supervised fine-tuning or RL with a binary reward, struggle to balance factual correctness and uncertainty. In contrast, our proposed …",,,2025
584,AdaDecode: Accelerating LLM Decoding with Adaptive Layer Parallelism,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S2-yZKcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=S2-yZKcAAAAJ:BqipwSGYUEgC,"Large language models (LLMs) are increasingly used for long-content generation (e.g., long Chain-of-Thought reasoning) where decoding efficiency becomes a critical bottleneck: Autoregressive decoding is inherently limited by its sequential token generation process, where each token must be generated before the next can be processed. This sequential dependency restricts the ability to fully leverage modern hardware's parallel processing capabilities. Existing methods like speculative decoding and layer skipping offer potential speedups but have notable drawbacks: speculative decoding relies on an auxiliary ""drafter"" model, which can be challenging to acquire and increases memory overhead, while layer skipping may introduce discrepancies in the outputs due to the missing key-value cache at skipped layers. In this work, we propose AdaDecode, which accelerates LLM decoding without requiring auxiliary models or changes to the original model parameters, while ensuring output consistency. AdaDecode leverages the insight that many tokens can accurately be generated at intermediate layers, as further layers often do not significantly alter predictions once the model reaches a certain confidence. By adaptively generating tokens at intermediate layers when confidence is high, AdaDecode enables the next token's computation to begin immediately. The remaining layer computations for early-predicted tokens are deferred and executed in parallel with subsequent tokens when needed, maximizing hardware utilization and reducing decoding latency. A final verification step ensures that early predictions match the results of standard …",,,2025
585,The surprising effectiveness of negative reinforcement in LLM reasoning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S2-yZKcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=S2-yZKcAAAAJ:YFjsv_pBGBYC,"Reinforcement learning with verifiable rewards (RLVR) is a promising approach for training language models (LMs) on reasoning tasks that elicit emergent long chains of thought (CoTs). Unlike supervised learning, it updates the model using both correct and incorrect samples via policy gradients. To better understand its mechanism, we decompose the learning signal into reinforcing correct responses and penalizing incorrect ones, referred to as Positive and Negative Sample Reinforcement (PSR and NSR), respectively. We train Qwen2.5-Math-7B and Qwen3-4B on a mathematical reasoning dataset and uncover a surprising result: training with only negative samples -- without reinforcing correct responses -- can be highly effective: it consistently improves performance over the base model across the entire Pass@ spectrum ( up to ), often matching or surpassing PPO and GRPO. In contrast, reinforcing only correct responses improves Pass@ but degrades performance at higher , due to reduced diversity. These inference-scaling trends highlight that solely penalizing incorrect responses may contribute more to performance than previously recognized. Through gradient analysis, we show that NSR works by suppressing incorrect generations and redistributing probability mass toward other plausible candidates, guided by the model's prior beliefs. It refines the model's existing knowledge rather than introducing entirely new behaviors. Building on this insight, we propose a simple variant of the RL objective that upweights NSR, and show that it consistently improves overall Pass@ performance on MATH, AIME 2025, and AMC23. Our code …",,,2025
586,Progress of large‐scale synthesis and electronic device application of two‐dimensional transition metal dichalcogenides,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=urnmv3sAAAAJ&citation_for_view=urnmv3sAAAAJ:u5HHmVD_uO8C,"The recent exploration of semiconducting two‐dimensional (2D) transition metal dichalcogenides (TMDs) with atomic thickness has taken both the scientific and technological communities by storm. Extensively investigated TMD that are accessible by large‐scale synthetic methods materials are remarkably stable, such as MoS2 and WSe2. They allow superior gate control due to their 2D nature and favorable electronic transport properties, thus suggesting a bright future for digital and RF electronics. In this review, the latest developments in the controlled synthesis of large scale TMDs are firstly introduced by discussing various approaches. The major obstacles that must be overcome to achieve wafer‐scale, uniform, and high‐quality TMD films for practical electronic applications are included. Advances in the electronic transport studies of TMDs are presented, such as doping, contact engineering, and mobility …",,Small,2017
587,Transfer learning with Bayesian optimization-aided sampling for efficient AMS circuit modeling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=urnmv3sAAAAJ&citation_for_view=urnmv3sAAAAJ:Y0pCki6q_DkC,"A traditional analog mixed-signal (AMS) design mostly relies on the designer's knowledge and can only afford exploring over a narrow design space due to expensive SPICE simulation. However, a neural network (NN)-based model of an AMS circuit potentially enables fast exploration of the design space thanks to its low computation cost. Unfortunately, to build an NN model with sufficient accuracy, a training dataset is needed, incurring SPICE simulations during different design phases. Therefore, it is prudent to train it with a larger dataset in an earlier design phase (e.g. schematic design) but a significantly reduced dataset in a later design phase (e.g. postlayout design or migration to more advanced technology node), as simulation cost increases sharply in later design phases. In this paper, we propose the use of transfer learning (TL) with Bayesian optimization-aided sampling (BOAS) to reduce the required size …",,,2020
588,A Fractional-N Digital MDLL With Background Two-Point DTC Calibration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=urnmv3sAAAAJ&citation_for_view=urnmv3sAAAAJ:IjCSPb-OGe4C,"This article presents a fractional- digital multiplying delay-locked loop (MDLL) that employs a digital-to-time converter (DTC) to control the reference injection for the fractional- operation. The presented MDLL features a background two-point DTC calibration that simultaneously corrects the DTC gain and offset errors to achieve a low-jitter and low-spur architecture. The DTC errors are sensed using an embedded time-to-digital converter (TDC) and extracted in the digital domain for reduced implementation overhead. A new TDC dithering and dither noise cancellation technique is used to improve the estimation accuracy of the DTC errors at the presence of TDC quantization error and differential nonlinearity (DNL). In addition, the adaptive dither noise cancellation scheme uses a comb filter to decouple the dither noise and DTC error estimations, allowing the two schemes to operate simultaneously. The proof-of …",IEEE,,2021
589,From specification to silicon: Towards analog/mixed-signal design automation using surrogate NN models with transfer learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=urnmv3sAAAAJ&citation_for_view=urnmv3sAAAAJ:Tyk-4Ss8FVUC,"We propose a complete analog mixed-signal circuit design flow from specification to silicon with minimum human-in-the-loop interaction, and verify the flow in a 12nm FinFET CMOS process. The flow consists of three key elements: neural network (NN) modeling of the parameterized circuit component, a search algorithm based on NN models to determine its sizing, and layout automation. To reduce the required training data for NN model creation, we utilize transfer learning to improve the NN accuracy from a relatively small amount of post-layout/silicon data. To prove the concept, we use a voltage-controlled oscillator (VCO) as a test vehicle and demonstrate that our design methodology can accurately model the circuit and generate designs with a wide range of specifications. We show that circuit sizing based on the transfer learned NN model from silicon measurement data yields the most accurate results.",IEEE,,2021
590,Fractional-N digital MDLL with injection-error scrambling and calibration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=urnmv3sAAAAJ&citation_for_view=urnmv3sAAAAJ:5nxA0vEk-isC,"This article presents a fractional- digital multiplying delay-locked loop (MDLL) that uses a digital-to-time converter (DTC) for controlling the reference injection timing to support the fractional- operation. This fractional- MDLL features an injection-error scrambling scheme for DTC error randomization and a background third-order DTC delay equalizer for DTC error calibration, to mitigate reference-injection-induced spurs while keeping a low phase noise floor. The MDLL prototype demonstrates 800-fs rms jitter, −67 dBc fractional spur, and −58 dBc reference spur. With the proposed schemes, the fractional and reference spurs are suppressed by 29 and 32 dB, respectively.",IEEE,,2023
591,Dithering based digital to time converter linearization technique,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=urnmv3sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=urnmv3sAAAAJ:qxL8FJ1GzNcC,"An electrical circuit for clock generation includes a digital-to-time converter error scrambler configured to randomize error in a digital-to-time converter (DTC) and configured to suppress spurs of the electrical circuit, a background error compensator configured to mitigate a timing mismatch between an injection of a reference signal into the DTC at a first point and an injection of the reference signal into the DTC as a second point, and a background delay equalizer configured to calibrate errors of the electrical circuit.",,,2025
592,Transient Hyperlogic Circuit: An Ultrafast and Metastability Self-Loopback Solver for NP-Hard Problems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=urnmv3sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=urnmv3sAAAAJ:M3ejUd6NZC8C,"Realizing the large-scale hyperlogic operation and signal processing in the real-world system paves the way for the next generation of the artificial intelligence architecture. Over the decades, the most widely applied personal computing resource is composed by the classical logic, which is benefit from using the transistor as the all-purpose computing unit with compact size and obvious on-off status difference. However, in the advanced reasoning model, it is intractable for the traditional logical system that makes a brute judgement in black and white to process the conflicts and the ambiguations from the information. Here, we put forward the new concept of hyerlogic operation computing system, which has an extra ‘paradoxical’state to handle the massive conflicts efficiently. And we also verify our concept by implementing the stochastic local search algorithm for the Boolean constraint satisfiability problem in the logic …",,,2025
593,Stochastic TDC Using Common-Mode Time Dithering and Passive Approximate Adders,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=urnmv3sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=urnmv3sAAAAJ:4TOpqqG69KYC,"The stochastic time-to-digital converter (STDC) presents a novel approach to automating the design and implementation process, delivering high performance with strong resilience to process variations and layout-induced artifacts, although with increased silicon area and higher power consumption. To effectively lower these costs, this article presents a 10-bit fully synthesizable STDC design using a removal-free common-mode time dithering technique, which significantly reduces the numbers of delay cells and D-type flip-flops (DFFs) required for requisite levels of stochastic operation. This also reduces the size of the associated backend unary-to-binary (U2B) encoder. In addition, passive approximate adders are used to further reduce the area of the U2B for a compact design and significantly lower time for digital place and route. Two STDC prototypes are implemented in a 12-nm FinFET process with a conventional …",IEEE,,2024
594,Ultrafast Hybrid Computing Systems Enabled by Memristor‐Based Quadratic Programming Circuits,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=urnmv3sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=urnmv3sAAAAJ:YOwf2qJgpHMC,"Implementing algorithms purely on digital computing platforms dramatically halts the performance of conventional computing systems. Revolutionary computing systems with extreme energy efficiency and high accuracy are demanded to handle the growing computing tasks. Here, the research on hybrid analog–digital computing platforms enabled by memristor‐based optimization solvers for achieving ultrafast computations is presented. By utilizing tunable memristors as parameters to solve linear programming (LP) and quadratic programming (QP) problems, a real‐time control algorithm for micro air vehicles (MAVs) and a support vector machine (SVM) algorithm for cancer diagnosis are implemented. These experiments demonstrate over 2000x speed‐up compared to conventional digital platforms, with negligible energy consumption, using a memristor‐based system consisting of six memristors. These findings …",,,2024
595,Synthesizable 10-bit Stochastic TDC Using Common-Mode Time Dithering and Passive Approximate Adder with 0.012 mm 2 Active Area in 12nm FinFET,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=urnmv3sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=urnmv3sAAAAJ:ULOm3_A8WrAC,"This paper presents 10-bit fully synthesizable stochastic TDC (STDC) design with common-mode time dithering and passive approximate adder for lowering implementation cost while maintaining a high linearity. Two STDC prototypes in 12nm FinFET are implemented with conventional adder and passive approximate adder, respectively. STDC prototypes achieve energy efficiency of ∼160dB, while the one using passive approximation adder achieves area efficiency of .",IEEE,,2024
596,Perspectives on thermoelectrics: from fundamentals to device applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D9YBFOYAAAAJ&citation_for_view=D9YBFOYAAAAJ:5nxA0vEk-isC,"This review is an update of a previous review (A. J. Minnich, et al., Energy Environ. Sci., 2009, 2, 466) published two years ago by some of the co-authors, focusing on progress made in thermoelectrics over the past two years on charge and heat carrier transport, strategies to improve the thermoelectric figure of merit, with new discussions on device physics and applications, and assessing challenges on these topics. Understanding of phonon transport in bulk materials has advanced significantly as the first-principles calculations are applied to thermoelectric materials, and experimental tools are being developed. Some new strategies have been developed to improve electron transport in thermoelectric materials. Fundamental questions on phonon and electron transport across interfaces and in thermoelectric materials remain. With thermoelectric materials reaching high ZT values well above one, the field is ready to …",Royal Society of Chemistry,Energy & Environmental Science,2012
597,Heat transport in silicon from first-principles calculations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D9YBFOYAAAAJ&citation_for_view=D9YBFOYAAAAJ:LkGwnXOMwfcC,"Using harmonic and anharmonic force constants extracted from density functional calculations within a supercell, we have developed a relatively simple but general method to compute thermodynamic and thermal properties of any crystal. First, from the harmonic, cubic, and quartic force constants, we construct a force field for molecular dynamics. It is exact in the limit of small atomic displacements and thus does not suffer from inaccuracies inherent in semiempirical potentials such as Stillinger-Weber's. By using the Green-Kubo formula and molecular dynamics simulations, we extract the bulk thermal conductivity. This method is accurate at high temperatures where three-phonon processes need to be included to higher orders, but may suffer from size scaling issues. Next, we use perturbation theory (Fermi golden rule) to extract the phonon lifetimes and compute the thermal conductivity from the relaxation-time …",American Physical Society,,2011
598,High thermoelectric performance by resonant dopant indium in nanostructured SnTe,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D9YBFOYAAAAJ&citation_for_view=D9YBFOYAAAAJ:NJ774b8OgUMC,"From an environmental perspective, lead-free SnTe would be preferable for solid-state waste heat recovery if its thermoelectric figure-of-merit could be brought close to that of the lead-containing chalcogenides. In this work, we studied the thermoelectric properties of nanostructured SnTe with different dopants, and found indium-doped SnTe showed extraordinarily large Seebeck coefficients that cannot be explained properly by the conventional two-valence band model. We attributed this enhancement of Seebeck coefficients to resonant levels created by the indium impurities inside the valence band, supported by the first-principles simulations. This, together with the lower thermal conductivity resulting from the decreased grain size by ball milling and hot pressing, improved both the peak and average nondimensional figure-of-merit (ZT) significantly. A peak ZT of ∼1.1 was obtained in 0.25 atom % In-doped SnTe at …",National Academy of Sciences,,2013
599,Resonant bonding leads to low lattice thermal conductivity,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D9YBFOYAAAAJ&citation_for_view=D9YBFOYAAAAJ:uJ-U7cs_P_0C,"Understanding the lattice dynamics and low thermal conductivities of IV–VI, V2–VI3 and V materials is critical to the development of better thermoelectric and phase-change materials. Here we provide a link between chemical bonding and low thermal conductivity. Our first-principles calculations reveal that long-ranged interaction along the <100> direction of the rocksalt structure exist in lead chalcogenides, SnTe, Bi2Te3, Bi and Sb due to the resonant bonding that is common to all of them. This long-ranged interaction in lead chalcogenides and SnTe cause optical phonon softening, strong anharmonic scattering and large phase space for three-phonon scattering processes, which explain why rocksalt IV–VI compounds have much lower thermal conductivities than zincblende III–V compounds. The new insights on the relationship between resonant bonding and low thermal conductivity will help in the development …",Nature Publishing Group UK,,2014
600,Coherent phonon heat conduction in superlattices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D9YBFOYAAAAJ&citation_for_view=D9YBFOYAAAAJ:PELIpwtuRlgC,"The control of heat conduction through the manipulation of phonons as coherent waves in solids is of fundamental interest and could also be exploited in applications, but coherent heat conduction has not been experimentally confirmed. We report the experimental observation of coherent heat conduction through the use of finite-thickness superlattices with varying numbers of periods. The measured thermal conductivity increased linearly with increasing total superlattice thickness over a temperature range from 30 to 150 kelvin, which is consistent with a coherent phonon heat conduction process. First-principles and Green’s function–based simulations further support this coherent transport model. Accessing the coherent heat conduction regime opens a new venue for phonon engineering for an array of applications.",American Association for the Advancement of Science,,2012
601,"THERMACOND, a code to compute lattice thermal conductivity from harmonic and anharmonic force constants",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D9YBFOYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=D9YBFOYAAAAJ:kVjdVfd2voEC,"THERMACOND is an open-source software for ab initio calculations of phonon thermal transport in crystalline bulk materials. It optimizes computational efficiency by leveraging the crystal symmetry to solve the linearized phonon Boltzmann transport equation (LPBTE) over the irreducible wedge of the Brillouin zone (IBZ). Brillouin zone integrations of δ functions are handled using the thetrahedron method. The code is written in Fortran90, parallelized using MPI to manage the computational costs associated with large k-point meshes, and is distributed under the GNU public license GPLv3. Here we provide an overview of the program structure and present results for three examples: Germanium (Ge), Germanium Selenide (GeSe), and diamond.",Nature Publishing Group UK,,2025
602,Fundamentals and advances in thermal transport in thermoelectric materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D9YBFOYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=D9YBFOYAAAAJ:v1_lew4L6wgC,"This article attempts to summarize our understanding of heat flow in different solid materials and its relationship to atomistic structure of materials. This knowledge can be used to understand and design materials for electricity generation or cooling through the thermoelectric effect. We start with the fundamentals of heat transport in solids: mechanisms of phonon scattering in crystals, the role of interfaces and coherence, and the relationship between chemical bonding and heat transport will be elucidated. Theories used to model thermal conductivity of solids will be exposed next. They include the Green–Kubo formulation, Boltzmann transport equation and its recent quantum extensions, and Allen–Feldman theory of heat diffusion in noncrystalline solids and its recent extensions. In terms of phenomenology, we will distinguish between the kinetic regime based on independent single carriers and the collective or …",Springer International Publishing,MRS Bulletin,2025
603,ALATDYN: A set of Anharmonic LATtice DYNamics codes to compute thermodynamic and thermal transport properties of crystalline solids,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D9YBFOYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=D9YBFOYAAAAJ:48xauSegjOkC,"We introduce a lattice dynamics package which calculates elastic, thermodynamic and thermal transport properties of crystalline materials from data on their force and potential energy as a function of atomic positions. The data can come from density functional theory (DFT) calculations or classical molecular dynamics runs performed in a supercell. First, the model potential parameters, which are anharmonic force constants are extracted from the latter runs. Then, once the anharmonic model is defined, thermal conductivity and equilibrium properties at finite temperatures can be computed using lattice dynamics, Boltzmann transport theories, and a variational principle respectively. In addition, the software calculates the mechanical properties such as elastic tensor, Gruneisen parameters and the thermal expansion coefficient within the quasi-harmonic approximation (QHA). Phonons, elastic constants and …",North-Holland,,2025
604,Molecular dynamics study of sintering of faceted cubic boron nitride nanoparticles at high temperatures,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D9YBFOYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=D9YBFOYAAAAJ:NyGDZy8z5eUC,"The sintering mechanisms and temperature dependence of coalescence of colliding cubic boron nitride (c-BN) nanoparticles are investigated using classical molecular dynamics (MD) simulation. Particle-particle collisions of 2.55 nm octahedral c-BN nanoparticles, consisting solely of the most stable {111} facets, with half of the surface terminations being boron and the other half nitrogen, are analyzed statistically and evaluated to assess the initial temperature range (2500 K to 3100 K) for sintering and its effect on grain growth. At these temperatures, the collision process maximizes contact surface area through interfacial sliding, thereby minimizing free energy and accommodating dangling bonds. Moreover, the exothermic formation of bonds of the coalescing nanoparticles increases the temperature. The alignment of the {111} orientation of the two collided nanoparticles occurs at a temperature slightly above the …",Pergamon,,2024
605,Neuroevolution machine learning potential to study high temperature deformation of entropy-stabilized oxide MgNiCoCuZnO5,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D9YBFOYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=D9YBFOYAAAAJ:jL-93Qbq4QoC,"Entropy stabilized oxide of MgNiCoCuZnO 5, also known as J14, is a material of active research interest due to a high degree of lattice distortion and tunability. Lattice distortion in J14 plays a crucial role in understanding the elastic constants and lattice thermal conductivity within the single-phase crystal. In this work, a neuroevolution machine learning potential (NEP) is developed for J14, and its accuracy has been compared to density functional theory calculations. The training errors for energy, force, and virial are 5.60 meV/atom, 97.90 meV/Å, and 45.67 meV/atom, respectively. Employing NEP potential, lattice distortion, and elastic constants is studied up to 900 K. In agreement with experimental findings, this study shows that the average lattice distortion of oxygen atoms is relatively higher than that of all transition metals in entropy-stabilized oxide. The observed distortion saturation in the J14 arises from the …",AIP Publishing,,2024
606,"M3detr: Multi-representation, multi-scale, mutual-relation 3d object detection with transformers",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uOIgTt8AAAAJ&citation_for_view=uOIgTt8AAAAJ:YFjsv_pBGBYC,"We present a novel architecture for 3D object detection, M3DETR, which combines different point cloud representations (raw, voxels, bird-eye view) with different feature scales based on multi-scale feature pyramids. M3DETR is the first approach that unifies multiple point cloud representations, feature scales, as well as models mutual relationships between point clouds simultaneously using transformers. We perform extensive ablation experiments that highlight the benefits of fusing representation and scale, and modeling the relationships. Our method achieves state-of-the-art performance on the KITTI 3D object detection dataset and Waymo Open Dataset. Results show that M3DETR improves the baseline significantly by 1.48% mAP for all classes on Waymo Open Dataset. In particular, our approach ranks 1st on the well-known KITTI 3D Detection Benchmark for both car and cyclist classes, and ranks 1st on Waymo Open Dataset with single frame point cloud input. Our code is available at: https://github. com/rayguan97/M3DETR.",,,2022
607,Emotions don't lie: An audio-visual deepfake detection method using affective cues,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uOIgTt8AAAAJ&citation_for_view=uOIgTt8AAAAJ:R3hNpaxXUhUC,"We present a learning-based method for detecting real and fake deepfake multimedia content. To maximize information for learning, we extract and analyze the similarity between the two audio and visual modalities from within the same video. Additionally, we extract and compare affective cues corresponding to perceived emotion from the two modalities within a video to infer whether the input video is ""real"" or ""fake"". We propose a deep learning network, inspired by the Siamese network architecture and the triplet loss. To validate our model, we report the AUC metric on two large-scale deepfake detection datasets, DeepFake-TIMIT Dataset and DFDC. We compare our approach with several SOTA deepfake detection methods and report per-video AUC of 84.4% on the DFDC and 96.6% on the DF-TIMIT datasets, respectively. To the best of our knowledge, ours is the first approach that simultaneously exploits audio …",,,2020
608,Traphic: Trajectory prediction in dense and heterogeneous traffic using weighted interactions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uOIgTt8AAAAJ&citation_for_view=uOIgTt8AAAAJ:HoB7MX3m0LUC,"We present a new algorithm for predicting the near-term trajectories of road agents in dense traffic videos. Our approach is designed for heterogeneous traffic, where the road agents may correspond to buses, cars, scooters, bi-cycles, or pedestrians. We model the interactions between different road agents using a novel LSTM-CNN hybrid network for trajectory prediction. In particular, we take into account heterogeneous interactions that implicitly account for the varying shapes, dynamics, and behaviors of different road agents. In addition, we model horizon-based interactions which are used to implicitly model the driving behavior of each road agent. We evaluate the performance of our prediction algorithm, TraPHic, on the standard datasets and also introduce a new dense, heterogeneous traffic dataset corresponding to urban Asian videos and agent trajectories. We outperform state-of-the-art methods on dense traffic datasets by 30%.",,,2019
609,"M3er: Multiplicative multimodal emotion recognition using facial, textual, and speech cues",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uOIgTt8AAAAJ&citation_for_view=uOIgTt8AAAAJ:Wp0gIr-vW9MC,"We present M3ER, a learning-based method for emotion recognition from multiple input modalities. Our approach combines cues from multiple co-occurring modalities (such as face, text, and speech) and also is more robust than other methods to sensor noise in any of the individual modalities. M3ER models a novel, data-driven multiplicative fusion method to combine the modalities, which learn to emphasize the more reliable cues and suppress others on a per-sample basis. By introducing a check step which uses Canonical Correlational Analysis to differentiate between ineffective and effective modalities, M3ER is robust to sensor noise. M3ER also generates proxy features in place of the ineffectual modalities. We demonstrate the efficiency of our network through experimentation on two benchmark datasets, IEMOCAP and CMU-MOSEI. We report a mean accuracy of 82.7% on IEMOCAP and 89.0% on CMU-MOSEI, which, collectively, is an improvement of about 5% over prior work.",,,2020
610,Forecasting trajectory and behavior of road-agents using spectral clustering in graph-lstms,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uOIgTt8AAAAJ&citation_for_view=uOIgTt8AAAAJ:9ZlFYXVOiuMC,"We present a novel approach for traffic forecasting in urban traffic scenarios using a combination of spectral graph analysis and deep learning. We predict both the low-level information (future trajectories) as well as the high-level information (road-agent behavior) from the extracted trajectory of each road-agent. Our formulation represents the proximity between the road agents using a weighted dynamic geometric graph (DGG). We use a two-stream graph-LSTM network to perform traffic forecasting using these weighted DGGs. The first stream predicts the spatial coordinates of road-agents, while the second stream predicts whether a road-agent is going to exhibit overspeeding, underspeeding, or neutral behavior by modeling spatial interactions between road-agents. Additionally, we propose a new regularization algorithm based on spectral clustering to reduce the error margin in long-term prediction (3-5 seconds …",IEEE,,2020
611,Safe In-Context Reinforcement Learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uOIgTt8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=uOIgTt8AAAAJ:7T2F9Uy0os0C,"In-context reinforcement learning (ICRL) is an emerging RL paradigm where the agent, after some pretraining procedure, is able to adapt to out-of-distribution test tasks without any parameter updates. The agent achieves this by continually expanding the input (i.e., the context) to its policy neural networks. For example, the input could be all the history experience that the agent has access to until the current time step. The agent's performance improves as the input grows, without any parameter updates. In this work, we propose the first method that promotes the safety of ICRL's adaptation process in the framework of constrained Markov Decision Processes. In other words, during the parameter-update-free adaptation process, the agent not only maximizes the reward but also minimizes an additional cost function. We also demonstrate that our agent actively reacts to the threshold (i.e., budget) of the cost tolerance. With a higher cost budget, the agent behaves more aggressively, and with a lower cost budget, the agent behaves more conservatively.",,,2025
612,Towards Provable Emergence of In-Context Reinforcement Learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uOIgTt8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=uOIgTt8AAAAJ:_Ybze24A_UAC,"Typically, a modern reinforcement learning (RL) agent solves a task by updating its neural network parameters to adapt its policy to the task. Recently, it has been observed that some RL agents can solve a wide range of new out-of-distribution tasks without parameter updates after pretraining on some task distribution. When evaluated in a new task, instead of making parameter updates, the pretrained agent conditions its policy on additional input called the context, e.g., the agent's interaction history in the new task. The agent's performance increases as the information in the context increases, with the agent's parameters fixed. This phenomenon is typically called in-context RL (ICRL). The pretrained parameters of the agent network enable the remarkable ICRL phenomenon. However, many ICRL works perform the pretraining with standard RL algorithms. This raises the central question this paper aims to address: Why can the RL pretraining algorithm generate network parameters that enable ICRL? We hypothesize that the parameters capable of ICRL are minimizers of the pretraining loss. This work provides initial support for this hypothesis through a case study. In particular, we prove that when a Transformer is pretrained for policy evaluation, one of the global minimizers of the pretraining loss can enable in-context temporal difference learning.",,,2025
613,"Multi-Robot Navigation in Social Mini-Games: Definitions, Taxonomy, and Algorithms",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uOIgTt8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=uOIgTt8AAAAJ:dQ2og3OwTAUC,"The ``Last Mile Challenge'' has long been considered an important, yet unsolved, challenge for autonomous vehicles, public service robots, and delivery robots. A central issue in this challenge is the ability of robots to navigate constrained and cluttered environments that have high agency (e.g., doorways, hallways, corridor intersections), often while competing for space with other robots and humans. We refer to these environments as ``Social Mini-Games'' (SMGs). Traditional navigation approaches designed for MRN do not perform well in SMGs, which has led to focused research on dedicated SMG solvers. However, publications on SMG navigation research make different assumptions (on centralized versus decentralized, observability, communication, cooperation, etc.), and have different objective functions (safety versus liveness). These assumptions and objectives are sometimes implicitly assumed or described informally. This makes it difficult to establish appropriate baselines for comparison in research papers, as well as making it difficult for practitioners to find the papers relevant to their concrete application. Such ad-hoc representation of the field also presents a barrier to new researchers wanting to start research in this area. SMG navigation research requires its own taxonomy, definitions, and evaluation protocols to guide effective research moving forward. This survey is the first to catalog SMG solvers using a well-defined and unified taxonomy and to classify existing methods accordingly. It also discusses the essential properties of SMG solvers, defines what SMGs are and how they appear in practice, outlines how to evaluate SMG …",,,2025
614,System and method for detecting fabricated videos,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uOIgTt8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=uOIgTt8AAAAJ:u_35RYKgDlwC,"G06V10/443—Local feature extraction by analysis of parts of the pattern, eg by detecting edges, contours, loops, corners, strokes or intersections; Connectivity analysis, eg of connected components by matching or filtering",,,2025
615,"Deadlock-free, safe, and decentralized multi-robot navigation in social mini-games via discrete-time control barrier functions",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uOIgTt8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=uOIgTt8AAAAJ:eq2jaN3J8jMC,"We present an approach to ensure safe and deadlock-free navigation for decentralized multi-robot systems operating in constrained environments, including doorways and intersections. Although many solutions have been proposed that ensure safety and resolve deadlocks, optimally preventing deadlocks in a minimally invasive and decentralized fashion remains an open problem. We first formalize the objective as a non-cooperative, non-communicative, partially observable multi-robot navigation problem in constrained spaces with multiple conflicting agents, which we term as social mini-games. Formally, we solve a discrete-time optimal receding horizon control problem leveraging control barrier functions for safe long-horizon planning. Our approach to ensuring liveness rests on the insight that there exists barrier certificates that allow each robot to preemptively perturb their state in a minimally-invasive fashion …",Springer US,,2025
616,Catalytic fast pyrolysis of lignocellulosic biomass,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6mLYoXIAAAAJ&citation_for_view=6mLYoXIAAAAJ:aqlVkmm33-oC,"Increasing energy demand, especially in the transportation sector, and soaring CO2 emissions necessitate the exploitation of renewable sources of energy. Despite the large variety of new energy carriers, liquid hydrocarbon still appears to be the most attractive and feasible form of transportation fuel taking into account the energy density, stability and existing infrastructure. Biomass is an abundant, renewable source of energy; however, utilizing it in a cost-effective way is still a substantial challenge. Lignocellulose is composed of three major biopolymers, namely cellulose, hemicellulose and lignin. Fast pyrolysis of biomass is recognized as an efficient and feasible process to selectively convert lignocellulose into a liquid fuel—bio-oil. However bio-oil from fast pyrolysis contains a large amount of oxygen, distributed in hundreds of oxygenates. These oxygenates are the cause of many negative properties, such as …",Royal Society of Chemistry,Chemical Society Reviews,2014
617,Carbon-supported bimetallic Pd–Fe catalysts for vapor-phase hydrodeoxygenation of guaiacol,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6mLYoXIAAAAJ&citation_for_view=6mLYoXIAAAAJ:roLk4NBRz8UC,"Carbon-supported metal catalysts (Cu/C, Fe/C, Pd/C, Pt/C, PdFe/C, and Ru/C) were characterized and evaluated for vapor-phase hydrodeoxygenation (HDO) of guaiacol (GUA), aiming at the identification/elucidation of active catalysts for high-yield production of completely hydrodeoxygenated products (e.g., benzene). Phenol was found to be the major intermediate on all catalysts. Saturation of the aromatic ring is the major pathway over the precious metal catalysts, forming cyclohexanone and cyclohexanol, followed by ring opening to form gaseous products. Base metal catalysts exhibit lower activity than the precious metal catalysts, but selectively form benzene along with small amounts of toluene, trimethylbenzene (TMB), and cresol without forming ring-saturated or ring-opening products. Compared with Fe/C and Pd/C, PdFe/C catalysts exhibit a substantially enhanced activity while maintaining the high …",Academic Press,,2013
618,Correlating Particle Size and Shape of Supported Ru/γ-Al2O3 Catalysts with NH3 Decomposition Activity,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6mLYoXIAAAAJ&citation_for_view=6mLYoXIAAAAJ:UeHWp8X0CEIC,"While ammonia synthesis and decomposition on Ru are known to be structure-sensitive reactions, the effect of particle shape on controlling the particle size giving maximum turnover frequency (TOF) is not understood. By controlling the catalyst pretreatment conditions, we have varied the particle size and shape of supported Ru/γ-Al2O3 catalysts. The Ru particle shape was reconstructed by combining microscopy, chemisorption, and extended X-ray absorption fine structure (EXAFS) techniques. We show that the particle shape can change from a round one, for smaller particles, to an elongated, flat one, for larger particles, with suitable pretreatment. Density functional theory calculations suggest that the calcination most likely leads to planar structures. We show for the first time that the number of active (here B5) sites is highly dependent on particle shape and increases with particle size up to 7 nm for flat …",American Chemical Society,,2009
619,Identification of the active complex for CO oxidation over single-atom Ir-on-MgAl2O4 catalysts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6mLYoXIAAAAJ&citation_for_view=6mLYoXIAAAAJ:NaGl4SEjCO4C,"Supported single atoms provide an opportunity to design new heterogeneous catalysts while optimizing the utilization of noble metals. However, identification of the active single-atom structure is required for understanding the reaction mechanism and guiding catalyst design. Here, we use in situ infrared spectroscopy, operando X-ray absorption spectroscopy and quantum chemical calculations to identify the active single-atom complex as well as the resting state of the Ir/MgAl2O4 catalysts during the low-temperature CO oxidation. In contrast to poisoning of iridium nanoparticles by CO, here we show that the formation of Ir(CO) on single atoms results in a different reaction mechanism and high activity for low-temperature CO oxidation. This is due to the ability of single atoms to coordinate with multiple ligands, where Ir(CO) provides an interfacial site for facile O2 activation between Ir and Al and lowers the reaction …",Nature Publishing Group UK,,2019
620,Aqueous phase reforming of glycerol for hydrogen production over Pt–Re supported on carbon,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6mLYoXIAAAAJ&citation_for_view=6mLYoXIAAAAJ:2osOgNQ5qMEC,"Hydrogen production from the aqueous phase reforming of glycerol over 3%Pt–Re/C (1 and 3% Re) has been studied in the absence and presence of base, and the results compared with a Re-free 3%Pt/C catalyst. Although the Pt/C catalyst is very selective toward the production of hydrogen, catalytic activity is low. Addition of Re significantly increases the conversion of glycerol, at some loss of hydrogen selectivity to light hydrocarbons and water-soluble oxygenates. Addition of 1%KOH to the feedstock results in a small increase in glycerol conversion with 3%Pt–3%Re/C, an increase in the gas phase product selectivity in terms of H2/CO2 ratio, and an increase in production of aqueous phase oxygenates. A modest increase in hydrogen gas phase selectivity with base addition with 3%Pt–3%Re/C arises primarily from reducing the selectivity toward C2+ alkanes, products that consume H2. In comparison, KOH …",Elsevier,,2010
621,Structural Evolution of Au-Pd Alloys in the Presence of CO,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6mLYoXIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6mLYoXIAAAAJ:WqliGbK-hY8C,,AIChE,,2025
622,Reversible Temperature-Induced Shape Transition of Pt Nanoparticles Supported on Al2O3,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6mLYoXIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6mLYoXIAAAAJ:ye4kPcJQO24C,"Supported platinum catalysts are widely used in industry for hydrogenation reactions. The variations of the electronic and geometric properties of Pt nanoparticles due to temperature can greatly affect their reactivity. In this work, we use in-situ X-ray absorption spectroscopy and environmental transmission electron microscopy to study the effect of H2 and temperature on the shape and electronic properties of 1.8 nm average diameter Pt nanoparticles supported on Al2O3. We utilize actively trained machine learning potentials with uniform acceptance force-bias Monte Carlo (fbMC) to estimate the structural distribution of Pt15/γ-Al2O3(110) clusters at finite temperatures. Our predicted cluster geometries are consistent with experimental data showing the nanoparticles reversibly change shape from 3D hemispheres at low temperatures (35-100 °C) to 2-2.5D rafts at higher temperatures (200-400 °C). Furthermore, experiments and computations indicate that the contraction in Pt-Pt bond distances and higher electron density on Pt at higher temperatures are attributed primarily to the change in nanoparticle shape and associated increased interaction with Al2O3. Our results show the fluxional nature of supported Pt nanoparticles driven by temperature changes.",,,2025
623,Single Metal Atom Catalysts Prepared by Diluted Atomic Layer Deposition,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6mLYoXIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6mLYoXIAAAAJ:LjlpjdlvIbIC,"The scalable and facile preparation of single-atom catalysts remains a critical challenge. Here, we introduce diluted atomic layer deposition (DALD), a unique approach for synthesizing supported metal catalysts with precisely tunable loadings. Unlike conventional metal deposition by ALD which uses pure metal precursors, DALD employs a diluted precursor mixture, combining organometallic precursors with the corresponding free ligand in controlled ratios. The method enables precise control over metal loadings, allowing the synthesis of structures ranging from nanoparticles to isolated single atoms, as exemplified by Ir, Rh, and Pt on high-surface-area γ-Al2O3. With its inherent simplicity and exceptional efficiency in metal precursor utilization, DALD represents a highly scalable strategy, unlocking opportunities for integrating single-atom catalysts into industrial processes.",American Chemical Society,,2025
624,Low Levels of Zinc Exchanged into Cu‐SSZ‐13 Increase Methanol Production in the Partial Oxidation of Methane to Methanol,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6mLYoXIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6mLYoXIAAAAJ:eq2jaN3J8jMC,"Cu‐SSZ‐13 is currently used industrially for the selective catalytic reduction of nitric oxides and has shown potential for the direct oxidation of methane to methanol. Here, how exchanging a small amount of zinc into Cu‐SSZ‐13 impacts the methane to methanol activity is reported. Samples containing only zinc are catalytically inactive. By contrast, small levels of zinc (Zn/Al = 0.06 or less) lead to a marked increase in methanol production. In the best case, Cu,Zn‐SSZ‐13 (Cu/Al = 0.21, Zn/Al = 0.06) has a site time yield (STY) of 26.4 ± 0.42 mmol mol‐Cu‐h−1 and specific activity (SA) of 11.5 ± 0.18 μmol g‐h−1. This is over an 80% increase in both STY and SA over Cu‐SSZ‐13 samples with comparable copper loadings (Cu/Al = 0.2–0.26). A similar, but slightly less significant improvement, is observed for Cu,Zn samples at a copper loading of ≈0.12, where 50% increase in methanol production over just …",,,2025
625,Effect of Metal Nuclearity on Bidirectional Metal-Support Interaction of Pt/CeO2 and Catalytic Properties,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6mLYoXIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6mLYoXIAAAAJ:olpn-zPbct0C,,AIChE,,2025
626,The model of gamification principles for digital health interventions: evaluation of validity and potential utility,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L9V1klwAAAAJ&citation_for_view=L9V1klwAAAAJ:UebtZRa9Y70C,"Background Although gamification continues to be a popular approach to increase engagement, motivation, and adherence to behavioral interventions, empirical studies have rarely focused on this topic. There is a need to empirically evaluate gamification models to increase the understanding of how to integrate gamification into interventions. Objective The model of gamification principles for digital health interventions proposes a set of five independent yet interrelated gamification principles. This study aimed to examine the validity and reliability of this model to inform its use in Web- and mobile-based apps. Methods A total of 17 digital health interventions were selected from a curated website of mobile- and Web-based apps (PsyberGuide), which makes independent and unbiased ratings on various metrics. A total of 133 independent raters trained in gamification evaluation techniques were instructed to evaluate the apps and rate the degree to which gamification principles are present. Multiple ratings (n≥20) were collected for each of the five gamification principles within each app. Existing measures, including the PsyberGuide credibility score, mobile app rating scale (MARS), and the app store rating of each app were collected, and their relationship with the gamification principle scores was investigated. Results Apps varied widely in the degree of gamification implemented (ie, the mean gamification rating ranged from 0.17≤m≤4.65 out of 5). Inter-rater reliability of gamification scores for each app was acceptable (κ≥0.5). There was no significant correlation …",JMIR Publications,,2020
627,Principles of gamification for Internet interventions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L9V1klwAAAAJ&citation_for_view=L9V1klwAAAAJ:u-x6o8ySG0sC,"Gamification is a popular method used to add entertaining and appealing dimensions to nongaming activities. Researchers of technology-based behavioral and mental-health-focused interventions have shown considerable interest in gamification to enhance engagement and adherence. There have been a number of gamification frameworks proposed, each with differences in focus but with overlapping similarities. A review of these frameworks highlight critical issues in gamification—lack of clear definitions, standards, and a need for an overarching model for applying gamification, rather than simply describing gamification. These issues leave researchers challenged to apply gamification to its full potential. This paper explores gamification as a construct and endeavors to define its core features. A useful way of evaluating the potential utility of gamification features in the context of an intervention is by …",Oxford University Press,,2019
628,Recognizing dialogue content in student collaborative conversation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L9V1klwAAAAJ&citation_for_view=L9V1klwAAAAJ:0EnyYjriUFMC,"This paper describes efforts to both promote and recognize student dialogue in free-entry text discussion within an inquiry-learning environment. First, we discuss collaborative tools that enable students to work together and how these tools can potentially focus student effort on subject matter. We then show how our tutor uses an expert knowledge base to recognize (with 88% success rate) when students are discussing content relevant to the problem and to correctly link (with 70% success) that content with an actual topic. Subsets of the data indicate that even better results are possible. This research provides solid support for the concept of using a knowledge base to recognize content in free-entry text discussion. The paper concludes by demonstrating how this content recognition can be used to support students engaged in problem-solving activities.",Springer Berlin Heidelberg,,2010
629,Effects of a pathfinding program visualization on algorithm development,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L9V1klwAAAAJ&citation_for_view=L9V1klwAAAAJ:8k81kl-MbHgC,"Program Visualizations (PVs) have been used as educational tools to allow students to visually inspect the runtime behavior of their code. However, many of these systems act as low-level visual debuggers not high-level abstractions of program behavior. Additionally, evaluations of these systems tend to focus more on student engagement or opinion in using the system and not on artifacts produced using the system. This paper discusses the effectiveness of a PV developed to aide students in an undergraduate Artificial Intelligence class on a pathfinding homework assignment. Students in 4 semesters of the course were tasked to develop pathfinding algorithms for an agent to navigate worlds in cases of both certain and uncertain world information. Students in 2 semesters of the course were given access to a PV that allowed them to see a visual representation of their agent navigating the world in either information …",,,2019
630,Discs: A new sequence segmentation method for open-ended learning environments,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L9V1klwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=L9V1klwAAAAJ:MXK_kJrjxJIC,"Open-ended learning environments afford students opportunities to explore, manipulate, and test concepts, and have the potential to provide students with feedback and support by leveraging the log data generated by them. However, within open-ended contexts, student log data is often noisy and identifying periods of meaningful activity is difficult. This paper introduces a new sequence mining method to overcome this challenge. The Differential Segmentation of Categorical Sequences (DiSCS) algorithm finds segments within a sequence of actions that are maximally or near-maximally different from their immediate neighbors. Segments are then clustered to reveal common periods of student activity. We examine the performance of this method under a variety of conditions to find how well DiSCS can identify where different states of simulated activity start and end. We report that when provided with only the …",Springer International Publishing,,2021
631,Origin of compressive residual stress in polycrystalline thin films,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S-lhuZIAAAAJ&citation_for_view=S-lhuZIAAAAJ:qjMakFHDy7sC,"We present a model for compressive stress generation during thin film growth in which the driving force is an increase in the surface chemical potential caused by the deposition of atoms from the vapor. The increase in surface chemical potential induces atoms to flow into the grain boundary, creating a compressive stress in the film. We develop kinetic equations to describe the stress evolution and dependence on growth parameters. The model is used to explain measurements of relaxation when growth is terminated and the dependence of the steady-state stress on growth rate.",American Physical Society,,2002
632,The dynamic competition between stress generation and relaxation mechanisms during coalescence of Volmer–Weber thin films,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S-lhuZIAAAAJ&citation_for_view=S-lhuZIAAAAJ:u-x6o8ySG0sC,"Real-time measurements of stress evolution during the deposition of Volmer–Weber thin films reveal a complex interplay between mechanisms for stress generation and stress relaxation. We observed a generic stress evolution from compressive to tensile, then back to compressive stress as the film thickened, in amorphous and polycrystalline Ge and Si, as well as in polycrystalline Ag, Al, and Ti. Direct measurements of stress relaxation during growth interrupts demonstrate that the generic behavior occurs even in the absence of stress relaxation. When relaxation did occur, the mechanism depended sensitively on whether the film was continuous or discontinuous, on the process conditions, and on the film/substrate interfacial strength. For Ag films, interfacial shear dominated the early relaxation behavior, whereas this mechanism was negligible in Al films due to the much stronger bonding at the interface …",American Institute of Physics,,2001
633,Extensions of the Stoney formula for substrate curvature to configurations with thin substrates or large deformations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S-lhuZIAAAAJ&citation_for_view=S-lhuZIAAAAJ:2osOgNQ5qMEC,"Two main assumptions which underlie the Stoney formula relating substrate curvature to mismatch strain in a bonded thin film are that the film is very thin compared to the substrate, and the deformations are infinitesimally small. Expressions for the curvature-strain relationship are derived for cases in which these assumptions are relaxed, thereby providing a basis for interpretation of experimental observations for a broader class of film-substrate configurations.",,,1999
634,Spontaneous pattern formation on ion bombarded Si (001),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S-lhuZIAAAAJ&citation_for_view=S-lhuZIAAAAJ:u5HHmVD_uO8C,"Spectroscopic light scattering was used to monitor periodic ripple evolution on Si (001) in situ during Ar+ sputtering. Analysis indicates that under high flux the concentration of mobile species on the surface is temperature and ion flux independent. This is due to an effect of ion collision cascades on the concentration of mobile species. We thereby measure the migration energy on the surface to be 1.2±0.1 eV. The technique is generalizable to any material, including high temperature and insulating materials for which surface migration energies are notoriously difficult to measure.",American Physical Society,,1999
635,Physical origins of intrinsic stresses in Volmer–Weber thin films,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S-lhuZIAAAAJ&citation_for_view=S-lhuZIAAAAJ:zYLM7Y9cAGgC,"As-deposited thin films grown by vapor deposition often exhibit large intrinsic stresses that can lead to film failure. While this is an “old” materials problem, our understanding has only recently begun to evolve in a more sophisticated fashion. Sensitive real-time measurements of stress evolution during thin-film deposition reveal a generic compressive–tensile–compressive behavior that correlates with island nucleation and growth, island coalescence, and postcoalescence film growth. In this article, we review the fundamental mechanisms that can generate stresses during the growth of Volmer–Weber thin films. Compressive stresses in both discontinuous and continuous films are generated by surface-stress effects. Tensile stresses are created during island coalescence and grain growth. Compressive stresses can also result from the flux-driven incorporation of excess atoms within grain boundaries. While …",Cambridge University Press,,2002
636,High thermoelectric power factor in Ni–Fe alloy for active cooling applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S-lhuZIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=S-lhuZIAAAAJ:a9-T7VOCCH8C,"Metallic thermoelectric materials are promising candidates for active cooling applications, where high thermal conductivity and a high thermoelectric power factor are essential to maximize effective thermal conductivity. While metals inherently possess high thermal and electrical conductivities, they typically exhibit low Seebeck coefficients. In this work, we create a database of the Seebeck coefficient of binary metallic alloys and apply machine learning techniques to identify alloys with large Seebeck coefficients. Specifically, we identify Ni–Fe as a promising candidate for active cooling around room temperature. We then fabricate Ni–Fe ingots and demonstrate thermoelectric power factor values as high as 120 μW cm−1 K−2 at 200 K for these stable alloys, which are composed of cost-effective and abundant elements. Furthermore, we demonstrate that the effective thermal conductivity of these alloys, under small …",Royal Society of Chemistry,,2025
637,Ordered-Phase Equilibria in the Eutectoid Region of Bulk Fe-Pd,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S-lhuZIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=S-lhuZIAAAAJ:NXb4pA-qfm4C,"This report is the first analysis of the coexistence and microstructure of the equilibrium phases in the Fe-Pd L10 + L12 eutectoid region. Coexistence of L10 + L12 is observed at higher temperatures (650 ), resulting in L10 polytwin plates with internal boundaries that are decorated by L12. For higher Pd content, the L10 plates are embedded in an extended L12 matrix, but the L12 wetting layers still persist. For aging at low temperatures (525 ), L1’ + L12 coexistence is observed, but the microstructure is essentially similar, except that L10 is replaced by L1’. The two-phase region is found to be much narrower than reported in published phase diagrams, of order 0.6 to 1 at pct in extent. There may be a further re-entrant narrowing below the L1’ formation temperature. This work establishes L1’ as a phase distinguishable from both L10 and L12, but does not yet prove that L1’ is an equilibrium phase. The …",Springer US,,2024
638,Wetting of L10 twin and antiphase boundaries by nanometer-scale L12 in Fe-Pd alloys,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S-lhuZIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=S-lhuZIAAAAJ:LO7wyVUgiFcC,"This paper reports microstructure associated with the L1 0 and L1 2 two-phase coexistence region in magnetic Fe-Pd alloys and analyzes the observed complex nanometer scale wetting layer structures. Fe-61.8 at% Pd samples were continuously cooled from the disordered A1 phase through the eutectoid isotherm and aged at 650° C for various times. X-ray diffraction reveals that the samples first order to L1 2 then transform to L1 0-dominant L1 0+ L1 2 two-phase mixture. It is shown that L1 0 forms {110} polytwin microstructure with straight {1 1¯ 0} antiphase boundaries (APBs), where L1 2 exists as nanometer-scale wetting layers along the twin boundaries and APBs. The variant selection for L1 2/L1 0 wetting layers is discussed, and evidence of closed/open APB structures is shown with high-resolution transmission electron microscopy.",Pergamon,,2024
639,Thermoelectric properties of YbZn 11− x Al x,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S-lhuZIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=S-lhuZIAAAAJ:HtEfBTGE9r8C,"Metallic thermoelectric materials with a high thermoelectric power factor and high thermal conductivity are favorable for transient dynamic active thermal management of microelectronics. Among these, several ytterbium intermetallic compounds demonstrate sharp peaks in their density of states due to contributions from ytterbium f-orbitals. YbZn11 is one of these compounds with a Gaussian-like density of states close to its Fermi level, an advantageous shape to achieve a high thermoelectric power factor. If the Fermi-level can be adjusted, high Seebeck coefficient values are expected following the Wiedemann–Franz law. Here we present YbZn11, a rarely made and studied sample, and for the first time, we report its thermoelectric and transport properties. Band structure calculations confirm the Gaussian function shape of the density of states. However, Seebeck calculations show that the Fermi level is not well …",Royal Society of Chemistry,,2024
640,Direct evidence of the shockley tetragonal L1’phase in a bulk Fe-Pd alloy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=S-lhuZIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=S-lhuZIAAAAJ:GtLg2Ama23sC,"Direct evidence is provided for the existence of the tetragonal L1’phase, first predicted by Shockley in 1938, in bulk Fe-62 at% Pd alloys aged at 525∘ C. L1’existence as the dominant phase is supported by quantitative x-ray diffraction analysis. This is combined with transmission electron microscopy of the polytwinned microstructure, examining the diffracted intensities in specific superlattice reflections where the complete extinction in L1 0 is relaxed in L1’. Ordering to L1’appears to occur directly from the A1 parent phase at 525 ºC, while aging at 650 ºC only produces L1 0. The possibility of L1’ordering may have consequences for the ferromagnetic properties of classic and important binary alloy systems where L1 0 is the assumed equilibrium phase.",Pergamon,,2023
641,High temperature shape memory alloys,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NY-vxbEAAAAJ&citation_for_view=NY-vxbEAAAAJ:WF5omc3nYNoC,"Shape memory alloys (SMAs) with high transformation temperatures can enable simplifications and improvements in operating efficiency of many mechanical components designed to operate at temperatures above 100°C, potentially impacting the automotive, aerospace, manufacturing and energy exploration industries. A wide range of these SMAs exists and can be categorised in three groups based on their martensitic transformation temperatures: group I, transformation temperatures in the range of 100-400°C; group II, in the range of 400-700°C; and group III, above 700°C. In addition to the high transformation temperatures, potential high temperature shape memory alloys (HTSMAs) must also exhibit acceptable recoverable transformation strain levels, long term stability, resistance to plastic deformation and creep, and adequate environmental resistance. These criteria become increasingly more difficult to …",Maney Publishing,,2010
642,Processing parameters in laser powder bed fusion metal additive manufacturing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NY-vxbEAAAAJ&citation_for_view=NY-vxbEAAAAJ:L8Ckcad2t8MC,"As metallic additive manufacturing grew in sophistication, users have requested greater control over the systems, namely the ability to fully change the process parameters. The goal of this manuscript is to review the effects of major process parameters on build quality (porosity, residual stress, and composition changes) and materials properties (microstructure and microsegregation), and to serve as a guide on how these parameters may be modified to achieve specific design goals for a given part. The focus of this paper is on laser powder bed fusion, but elements can be applied to electron beam powder bed fusion or direct energy deposition techniques.",Elsevier,,2020
643,Spatial Control of Functional Response in 4D-Printed Active Metallic Structures,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NY-vxbEAAAAJ&citation_for_view=NY-vxbEAAAAJ:Zph67rFs4hoC,"We demonstrate a method to achieve local control of 3-dimensional thermal history in a metallic alloy, which resulted in designed spatial variations in its functional response. A nickel-titanium shape memory alloy part was created with multiple shape-recovery stages activated at different temperatures using the selective laser melting technique. The multi-stage transformation originates from differences in thermal history, and thus the precipitate structure, at various locations created from controlled variations in the hatch distance within the same part. This is a first example of precision location-dependent control of thermal history in alloys beyond the surface, and utilizes additive manufacturing techniques as a tool to create materials with novel functional response that is difficult to achieve through conventional methods.",Nature Publishing Group,,2017
644,The effect of precipitates on the superelastic response of [100] oriented FeMnAlNi single crystals under compression,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NY-vxbEAAAAJ&citation_for_view=NY-vxbEAAAAJ:hqOjcs7Dif8C,"FeMnAlNi shape memory alloys were recently discovered to have a small temperature dependence of the superelastic critical stress in a large superelastic temperature window from −196 °C to 240 °C. In this work, we investigated the effect of B2 nanoprecipitates on the superelastic characteristics of [1 0 0] oriented Fe43.5Mn34Al15Ni7.5 single crystals under compression, and found that the size, volume fraction and composition of precipitates strongly influence the transformation temperature, superelastic strain, critical stress for stress-induced martensitic transformation and stress hysteresis of the single crystals. The single crystals aged at 200 °C for 3 h show 7.2% superelastic strain with the precipitate size of about 6–10 nm. Longer aging times or higher aging temperature reduces superelastic recovery due to the coarsening of the precipitates.",Pergamon,,2015
645,A comparative study of the cytotoxicity and corrosion resistance of nickel–titanium and titanium–niobium shape memory alloys,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NY-vxbEAAAAJ&citation_for_view=NY-vxbEAAAAJ:2osOgNQ5qMEC,"Nickel–titanium (NiTi) shape memory alloys (SMAs) are commonly used in a range of biomedical applications. However, concerns exist regarding their use in certain biomedical scenarios due to the known toxicity of Ni and conflicting reports of NiTi corrosion resistance, particularly under dynamic loading. Titanium–niobium (TiNb) SMAs have recently been proposed as an alternative to NiTi SMAs due to the biocompatibility of both constituents, the ability of both Ti and Nb to form protective surface oxides, and their superior workability. However, several properties critical to the use of TiNb SMAs in biomedical applications have not been systematically explored in comparison with NiTi SMAs. These properties include cytocompatibility, corrosion resistance, and alterations in alloy surface composition in response to prolonged exposure to physiological solutions. Therefore, the goal of the present work was to …",Elsevier,,2012
646,Heterogeneous Microstructure in Laser-Processed Metastable Ti25Nb Alloy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NY-vxbEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=NY-vxbEAAAAJ:JV2RwH3_ST0C,"The high thermal gradient and solidification velocity associated with the laser powder bed fusion process spurs formation of diverse microstructures in additively manufactured materials. This study focused on the phase composition observed in the microstructure of a laser-processed metastable titanium–niobium alloy. Through transmission electron microscopy experiments, we reveal the microstructures with several metastable phase, among which is a novel orthorhombic phase found in Nb-lean regions that is fundamentally different from the expected orthorhombic phase. Second is the phase and the variant selection phenomenon in laser-processed metastable β-Ti alloys. Microstructural features were found to be highly sensitive to the processing history. We further examine the mechanisms behind these phase formations and discuss how these features can influence the properties of the alloy.",Springer US,,2025
647,Effect of raster orientation on large-scale robotic 3D printing of short carbon fiber-reinforced PLA composites,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NY-vxbEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=NY-vxbEAAAAJ:maZDTaKrznsC,"Additive manufacturing in building construction can be extended for mass customization of building components or even complex mold making. This study examines the process parameters of raster orientation of short carbon fiber-reinforced polylactic acid (SCF-PLA) and neat PLA in large-scale 3D printing. Three raster orientations—unidirectional, cross-ply, and quasi-isotropic layups—were printed using a pellet extruder assembled on an industrial robotic arm. Tensile and flexural tests were conducted to characterize the differences between SCF-PLA and neat PLA across all raster orientations. This study shows that neat PLA has higher tensile strength compared to SCF-PLA, and quasi-isotropic orientation can improve the week mechanical properties of both SCF-PLA and PLA. This research highlights the interface bonding challenges encountered with larger 3D printed filaments, which result in more significant …",Elsevier,,2025
648,Probabilistic printability maps for laser powder bed fusion via functional calibration and uncertainty propagation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NY-vxbEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=NY-vxbEAAAAJ:iH-uZ7U-co4C,"In this work, we develop an efficient computational framework for process space exploration in laser powder bed fusion (LPBF) based additive manufacturing technology. This framework aims to find suitable processing conditions by characterizing the probability of encountering common build defects. We employ a Bayesian approach toward inferring a functional relationship between LPBF processing conditions and the unobserved parameters of laser energy absorption and powder bed porosity. The relationship between processing conditions and inferred laser energy absorption is found to have good correspondence to the literature measurements of powder bed energy absorption using calorimetric methods. The Bayesian approach naturally enables uncertainty quantification and we demonstrate its utility by performing efficient forward propagation of uncertainties through the modified Eagar–Tsai model to …",American Society of Mechanical Engineers,,2024
649,Morphogenic Modeling of Corrosion Reveals Complex Effects of Intermetallic Particles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NY-vxbEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=NY-vxbEAAAAJ:k_IJM867U9cC,"Corrosion processes are often discussed as stochastic events. Here, it is shown that some of these seemingly random processes are not driven by nanoscopic fluctuations but rather by the spatial distribution of micrometer‐scale heterogeneities that trigger fast reactions associated with corrosion. Using a novel excitable reaction‐diffusion model, corrosion waves traveling over the metal surface and the associated material loss are described. This resulting nonuniform corrosion penetration, seen as a height loss in modeling, exposes buried intermetallic particles, which depending on the local electrochemical state of the surface trigger or block new waves. Informed by quantitative experimental data for the Mg–Al–Zn alloy AZ31B, wave speeds, wave widths, and average material loss are accurately captured. Morphogenic mitigation based on wave‐breaking microparticles is also simulated. While AZ31B corrosion is …",,,2024
650,Ampk phosphorylation of Ulk1 is required for targeting of mitochondria to lysosomes in exercise-induced mitophagy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3idq95QAAAAJ&citation_for_view=3idq95QAAAAJ:cFHS6HbyZ2cC,"Mitochondrial health is critical for skeletal muscle function and is improved by exercise training through both mitochondrial biogenesis and removal of damaged/dysfunctional mitochondria via mitophagy. The mechanisms underlying exercise-induced mitophagy have not been fully elucidated. Here, we show that acute treadmill running in mice causes mitochondrial oxidative stress at 3–12 h and mitophagy at 6 h post-exercise in skeletal muscle. These changes were monitored using a novel fluorescent reporter gene, pMitoTimer, that allows assessment of mitochondrial oxidative stress and mitophagy in vivo, and were preceded by increased phosphorylation of AMP activated protein kinase (Ampk) at tyrosine 172 and of unc-51 like autophagy activating kinase 1 (Ulk1) at serine 555. Using mice expressing dominant negative and constitutively active Ampk in skeletal muscle, we demonstrate that Ulk1 activation is …",Nature Publishing Group UK,,2017
651,Mapping macrophage polarization over the myocardial infarction time continuum,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3idq95QAAAAJ&citation_for_view=3idq95QAAAAJ:bFI3QPDXJZMC,"In response to myocardial infarction (MI), cardiac macrophages regulate inflammation and scar formation. We hypothesized that macrophages undergo polarization state changes over the MI time course and assessed macrophage polarization transcriptomic signatures over the first week of MI. C57BL/6 J male mice (3–6 months old) were subjected to permanent coronary artery ligation to induce MI, and macrophages were isolated from the infarct region at days 1, 3, and 7 post-MI. Day 0, no MI resident cardiac macrophages served as the negative MI control. Whole transcriptome analysis was performed using RNA-sequencing on n = 4 pooled sets for each time. Day 1 macrophages displayed a unique pro-inflammatory, extracellular matrix (ECM)-degrading signature. By flow cytometry, day 0 macrophages were largely F4/80highLy6Clow resident macrophages, whereas day 1 macrophages were largely F4/80low …",Springer Berlin Heidelberg,,2018
652,Identification of a novel mitochondrial uncoupler that does not depolarize the plasma membrane,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3idq95QAAAAJ&citation_for_view=3idq95QAAAAJ:M3NEmzRMIkIC,"Dysregulation of oxidative phosphorylation is associated with increased mitochondrial reactive oxygen species production and some of the most prevalent human diseases including obesity, cancer, diabetes, neurodegeneration, and heart disease. Chemical 'mitochondrial uncouplers' are lipophilic weak acids that transport protons into the mitochondrial matrix via a pathway that is independent of ATP synthase, thereby uncoupling nutrient oxidation from ATP production. Mitochondrial uncouplers also lessen the proton motive force across the mitochondrial inner membrane and thereby increase the rate of mitochondrial respiration while decreasing production of reactive oxygen species. Thus, mitochondrial uncouplers are valuable chemical tools that enable the measurement of maximal mitochondrial respiration and they have been used therapeutically to decrease mitochondrial reactive oxygen species production …",Elsevier,,2014
653,"A novel MitoTimer reporter gene for mitochondrial content, structure, stress, and damage in vivo",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3idq95QAAAAJ&citation_for_view=3idq95QAAAAJ:hMod-77fHWUC,"Mitochondrial dysfunction plays important roles in many diseases, but there is no satisfactory method to assess mitochondrial health in vivo. Here, we engineered a MitoTimer reporter gene from the existing Timer reporter gene. MitoTimer encodes a mitochondria-targeted green fluorescent protein when newly synthesized, which shifts irreversibly to red fluorescence when oxidized. Confocal microscopy confirmed targeting of the MitoTimer protein to mitochondria in cultured cells, Caenorhabditis elegans touch receptor neurons, Drosophila melanogaster heart and indirect flight muscle, and mouse skeletal muscle. A ratiometric algorithm revealed that conditions that cause mitochondrial stress led to a significant shift toward red fluorescence as well as accumulation of pure red fluorescent puncta of damaged mitochondria targeted for mitophagy. Long term voluntary exercise resulted in a significant fluorescence shift …",Elsevier,,2014
654,Modeling β-adrenergic control of cardiac myocyte contractility in silico,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3idq95QAAAAJ&citation_for_view=3idq95QAAAAJ:u5HHmVD_uO8C,"The β-adrenergic signaling pathway regulates cardiac myocyte contractility through a combination of feedforward and feedback mechanisms. We used systems analysis to investigate how the components and topology of this signaling network permit neurohormonal control of excitation-contraction coupling in the rat ventricular myocyte. A kinetic model integrating β-adrenergic signaling with excitation-contraction coupling was formulated, and each subsystem was validated with independent biochemical and physiological measurements. Model analysis was used to investigate quantitatively the effects of specific molecular perturbations. 3-Fold overexpression of adenylyl cyclase in the model allowed an 85% higher rate of cyclic AMP synthesis than an equivalent overexpression of β1-adrenergic receptor, and manipulating the affinity of Gsα for adenylyl cyclase was a more potent regulator of cyclic AMP production …",Elsevier,,2003
655,Advances in Drug Discovery for Cardiomyocyte Proliferation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3idq95QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=3idq95QAAAAJ:7T2F9Uy0os0C,"While no therapy has yet fully translated beyond pre-clinical models, significant progress has been made in identifying candidate drugs that stimulate cardiomyocyte proliferation in animal models. Translating these findings into effective therapies requires a rigorous foundation in basic research to clarify the molecular mechanisms of cardiac repair and guide drug development.",Springer US,Current Treatment Options in Cardiovascular Medicine,2025
656,Flexible nanoelectronics reveal arrhythmogenesis in transplanted human cardiomyocytes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3idq95QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=3idq95QAAAAJ:j8SEvjWlNXcC,"The transplantation of human induced pluripotent stem cell-derived cardiomyocytes (hiPSC-CMs) offers a potential treatment for heart failure, but arrhythmogenic automaticity arising from transplanted cells can arise. In this study, we investigated the effects of RADA16, a clinically approved self-assembling peptide that forms nanofibers after injection, on the vascularization, myofibril structure, and electrophysiological adaptation of hiPSC-CMs transplanted into rat hearts. RADA16 accelerated the transition of hiPSC-CMs toward adult-like gene expression profiles, enhanced sarcomere organization, and improved vascularization in the transplanted site. Flexible mesh nanoelectronics revealed fibrillation of transplanted hiPSC-CMs within the beating recipient heart, and RADA16 dramatically reduced the automaticity of hiPSC-CMs. Our findings demonstrate the potential of self-assembling nanofibers to advance cardiac …",American Association for the Advancement of Science,,2025
657,Single-cell dynamics reveal a stress-induced decision between hypertrophy and apoptosis in neonatal rat cardiomyocytes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3idq95QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=3idq95QAAAAJ:tzM49s52ZIMC,"Cardiomyocyte hypertrophy and apoptosis underlie cardiomyopathies and heart failure. While previous studies have reported both hypertrophy and apoptosis at the population level, how individual cells commit to these distinct analog and digital fates is unclear. To elucidate how individual cells decide to grow and/or die, we developed a high-content microscopy approach to track single-cell dynamics of neonatal rat cardiomyocytes. Even untreated cells exhibited substantial single-cell variability in growth and death. Uniform treatments of staurosporine or phenylephrine induced distinctive morphological programs resulting in apoptosis and hypertrophy, respectively, but only in cell subpopulations. Increasing concentrations of the β-adrenergic receptor agonist isoproterenol caused a population-level biphasic induction of hypertrophy and then apoptosis, consistent with either apoptosis in the most hypertrophic cells …",Elsevier,,2025
658,MEF2C controls segment-specific gene regulatory networks that direct heart tube morphogenesis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3idq95QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=3idq95QAAAAJ:NJ774b8OgUMC,"The gene regulatory networks (GRNs) that control early heart formation are beginning to be understood, but lineage-specific GRNs remain largely undefined. We investigated networks controlled by the vital transcription factor MEF2C using a time course of single-nucleus RNA sequencing and ATAC sequencing in wild-type and Mef2c-null embryos. We identified a “posteriorized” cardiac gene signature and chromatin landscape in the absence of MEF2C. Integrating our multiomics data in a deep learning-based model, we constructed developmental trajectories for each of the outflow tract, ventricular, and inflow tract segments and alterations of these in Mef2c-null embryos. We computationally identified segment-specific MEF2C-dependent enhancers with activity in the developing zebrafish heart. Finally, using inferred GRNs, we discovered that the Mef2c-null heart malformations are partly driven by increased …",Cold Spring Harbor Lab,,2025
659,Network Modeling Predicts How DYRK1A Inhibition Promotes Cardiomyocyte Cycling after Ischemic/Reperfusion Injury,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3idq95QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=3idq95QAAAAJ:_Re3VWB3Y0AC,"The adult mammalian heart has a limited ability to regenerate lost myocardium following myocardial infarction (MI), largely due to the poor proliferative capacity of cardiomyocytes. Dual-specificity tyrosine phosphorylation-regulated kinase 1A (DYRK1A) is a known regulator of cell quiescence, though the mechanisms underlying its function remain unclear. Previous studies have shown that pharmacological inhibition of DYRK1A using harmine induces cardiomyocyte cell cycle re-entry after ischemia/reperfusion (I/R) MI. Here, we developed a computational network model of DYRK1A-mediated regulation of the cell cycle, which predicts how DYRK1A inhibition promotes cardiomyocyte re-entry. To validate these predictions, we tested selective DYRK1A inhibitors and observed robust induction of cell cycle activity in neonatal rat cardiomyocytes (NRCMs). Integrating our network model with bulk RNA-sequencing data from DYRK1A inhibitor-treated NRCMs, we identified E2F1 as a key transcriptional driver of cell cycle gene expression. Finally, we demonstrate that both pharmacological and post-developmental inhibition of DYRK1A enhances heart function and increases cardiomyocyte cycling following I/R MI. Our findings suggest that functional recovery induced by small molecule inhibitor of DYRK1A is mediated by the induction of cycling cardiomyocytes. One Sentence Summary Inhibition of DYRK1A through LCTB-92 induces cardiomyocyte cycling and improved heart function in a mouse model of ischemic/reperfusion injury.",Cold Spring Harbor Laboratory,,2025
660,"Young African American children's representations of self, science, and school: Making sense of difference",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Wb7s5QcAAAAJ&citation_for_view=Wb7s5QcAAAAJ:u5HHmVD_uO8C,"We focused on young, low‐income, African American children in first‐ to third‐grade classrooms where they experienced varied forms of interactive, participatory, and dialogic pedagogy in the context of yearlong, integrated science‐literacy instruction. Using conversations that started around children's own science journals, which were an important part of teaching and learning science in their classrooms, we studied 25 children's ideological becoming relative to the practices of science and schooling and the interplay between their selves and others. We found that “doing school” was a dominant narrative intertwined with “doing science.” Following behavioral codes and constructing smartness as a large amount of knowledge seemed to be an important part of their school world, antithetical in some ways to the active, inquisitive, questioning, flexible view of science and science learning that their classroom …","Wiley Subscription Services, Inc., A Wiley Company",,2011
661,Teaching manuals and the blackboard: Accessing historical classroom practices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Wb7s5QcAAAAJ&citation_for_view=Wb7s5QcAAAAJ:9yKSN-GCB0IC,"The blackboard, a useful teaching tool in nineteenth-century England, was transformed into a teaching necessity in the decades follwing 1870, when the Education Acts made school free and mandatory for all children. The resulting huge population of schoolchildren inspired the development of teaching techniques appropriate for large-group learning. Many of these techniques relied on the blackboard as a reusable demonstration space visible to the entire class at once, unlike a book or slate. To share these new practices among teachers, particularly the novice teachers recruited to serve the increased school population, dozens of teaching manuals were published around the turn of the twentieth century. These manuals’ instructions for how to teach reading, writing, arithmetic and nature study to elementary school students offer historians a rare glimpse into teachers’ and students’ school experiences by …",Routledge,,2012
662,‘The artist’s piece is already in the stone’: Constructing creativity in paleontology laboratories,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Wb7s5QcAAAAJ&citation_for_view=Wb7s5QcAAAAJ:zYLM7Y9cAGgC,"Laboratory technicians are typically portrayed as manual workers following routine procedures to produce scientific data. However, technicians in vertebrate paleontology laboratories often describe their work in terms of creativity and artistry. Fossil specimens undergo extensive preparation – including rock removal, damage repair, and reconstruction of missing parts – to become accessible to researchers. Technicians called ‘fossil preparators’ choose, apply, and sometimes invent these preparation methods. They have no formal training, no standard protocols, and few publications to consult on techniques. Despite the resulting diversity of people and practices, preparators and their work are usually absent from research publications, making them ‘invisible technicians’ in Steven Shapin’s sense. But preparators reject the view of their work as predictable or simple; in particular, many preparators value art training …",SAGE Publications,,2015
663,Young black children and science: Chronotopes of narratives around their science journals,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Wb7s5QcAAAAJ&citation_for_view=Wb7s5QcAAAAJ:d1gkVwhDpl0C,"We explored 30 Black Kindergarten‐2nd grade students' spoken narratives around pages of their science journals that the children selected as best for showing them as scientists. Because in all narratives, space–time relationships play an important role not only in situating but also in constituting them, we focused on such relationships using Bakhtin's (1981) construct of chronotopes. Our chronotopical analysis aimed at fleshing out the temporal and spatial features that were present in the children's journal pages, and in the children's ways of talking both about these features and about being scientists. Our goal was to better understand ways in which African‐American children identify with science and scientists in particular contexts: an interview with an adult who had visited their class throughout that year and a class where they were offered various opportunities to engage with science. Using six cases that …","Wiley Subscription Services, Inc., A Wiley Company",,2012
664,Preparing dinosaurs: The work behind the scenes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Wb7s5QcAAAAJ&citation_for_view=Wb7s5QcAAAAJ:0izLItjtcgwC,"An investigation of the work and workers in fossil preparation labs reveals the often unacknowledged creativity and problem-solving on which scientists rely. Those awe-inspiring dinosaur skeletons on display in museums do not spring fully assembled from the earth. Technicians known as preparators have painstakingly removed the fossils from rock, repaired broken bones, and reconstructed missing pieces to create them. These specimens are foundational evidence for paleontologists, and yet the work and workers in fossil preparation labs go largely unacknowledged in publications and specimen records. In this book, Caitlin Wylie investigates the skilled labor of fossil preparators and argues for a new model of science that includes all research work and workers. Drawing on ethnographic observations and interviews, Wylie shows that the everyday work of fossil preparation requires creativity, problem-solving, and craft. She finds that preparators privilege their own skills over technology and that scientists prefer to rely on these trusted technicians rather than new technologies. Wylie examines how fossil preparators decide what fossils, and therefore dinosaurs, look like; how labor relations between interdependent yet hierarchically unequal collaborators influence scientific practice; how some museums display preparators at work behind glass, as if they were another exhibit; and how these workers learn their skills without formal training or scientific credentials. The work of preparing specimens is a crucial component of scientific research, although it leaves few written traces. Wylie argues that the paleontology research community's social …",MIT Press,,2021
665,Earth Sciences from the Perspectives of Science and Technology Studies,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Wb7s5QcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Wb7s5QcAAAAJ:4vMrXwiscB8C,"The discipline of science and technology studies (STS) can provide historians with methodological approaches and theoretical frameworks to access key aspects of the Earth sciences, such as scientific practice, technology, and social values. This chapter outlines these tools as demonstrated by exemplary STS studies of the Earth sciences.",Springer Nature Switzerland,,2025
666,Using REU Program Evaluation to Foster Learning through Reflection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Wb7s5QcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Wb7s5QcAAAAJ:OcBU2YAGkTUC,"Undergraduate research aims to foster transformative learning, but one key element of this experiential learning–reflection1–can be difficult to integrate into the programs. As with any intensive learning activity (such as study abroad) 2, it doesn't happen automatically. Yet NSF’s Research Experience for Undergraduates (REU) programs do require a process that might serve as a tool for doing this work: program evaluation. In a previous paper we explored the possibility of using evaluation as a tool to collect valuable research data about the experience of marginalized and minoritized students. 3 In this paper we ask if we can design evaluation methods to do three things: evaluate, provide research data, and encourage student learning through reflection. It seems worthwhile to try, both to make multi-purpose research more efficient and to make student participation in these evaluations beneficial for them, rather than simply subjecting them to data privacy risks. This paper raises this question, situates it in existing theories and frameworks of reflective learning and metacognition, and offers suggestive data of the effects of evaluation methods on students from a two-year evaluation and study of an undergraduate research program. We wonder if a reflection-focused evaluation process could help students connect their learning with their sociotechnical experiences of working in a research group. The reflection questions we asked, drawn from the Views of Nature of Science instrument4 call attention to the social aspects of research, such as how researchers choose research questions and methods, how they interpret data to propose theories, why …",,,2025
667,We have been here Before: Reflections on Engineering and Authoritarianism,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Wb7s5QcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Wb7s5QcAAAAJ:bKqednn6t2AC,"The United States research and education apparatus was thrown into utter chaos in the days following the inauguration of the 47th president of the United States. The new administration called for a total freeze on the flow of federal funding, backing down only after a district judge halted its implementation and spoke positively about the lawsuit that 22 states filed against it. While this resulted in one memo being rescinded, a series of Executive Orders ‘ending radical and wasteful government DEI programs and preferencing’, 1 ‘ending radical indoctrination in K-12 schooling’, 2 and ‘terminating the green new deal’3 remained in place. In response, the National Institutes of Health cancelled scientific meetings and slashed funds for indirect costs. The National Science Foundation temporarily barred grantees from accessing their funds, impacting their ability to pay their research teams, and rumors circulated on social …",Routledge,Engineering Studies,2025
668,Timing science: The temporal role of scientists in the construction of data,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Wb7s5QcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Wb7s5QcAAAAJ:DJbcl8HfkQkC,"The processes of producing scientific knowledge rely on the temporality of data, yet they also obscure this relationship. Scientists hope that knowledge claims can stand relatively independent from their context of production. Instead, a more realistic and trustworthy view would be to embrace data’s history and “journey”(Leonelli and Tempini 2020) as a component of the knowledge claims that these data inspire. These journeys describe how data and people interact and thereby influence each other’s identity and epistemic worth. In this paper, I propose a model to help philosophers and other analysts pay closer attention to the people who work with scientific data, specifically by considering how these practitioners conceptualize time. I argue that how practitioners experience time reflects the personal, professional, epistemic, and ethical values that guide their decisions about how to do science. These conceptions of time differ by profession, career stage, identity, institutional context, and other factors specific to practitioners’ lives as well as their scientific or disciplinary culture. I draw from two case studies of vertebrate fossils to illustrate how various conceptions of time co-exist for practitioners, as indicators of the values that guide practitioners’ decisions as they do scientific work.",Michigan Publishing,,2024
669,REU Program Evaluation: A Valuable Tool for Studying Undergraduate Socialization in Engineering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Wb7s5QcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Wb7s5QcAAAAJ:cWzG1nlazyYC,"This Work in Progress paper introduces a project investigating whether and how a summer research experience relates to undergraduate students’ sense of identity and belonging in engineering, understanding of research as a process, and research-related academic and professional skills. We draw from theories of situated learning and socialization into professional communities to ask what and how students learn during an NSF-funded Research Experience for Undergraduates (REU) summer program in materials science and engineering.",,,2024
670,Sampling dead block prediction for last-level caches,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MkU_TDAAAAAJ&citation_for_view=MkU_TDAAAAAJ:u-x6o8ySG0sC,"Last-level caches (LLCs) are large structures with significant power requirements. They can be quite inefficient. On average, a cache block in a 2MB LRU-managed LLC is dead 86% of the time, i.e., it will not be referenced again before it is evicted. This paper introduces sampling dead block prediction, a technique that samples program counters (PCs) to determine when a cache block is likely to be dead. Rather than learning from accesses and evictions from every set in the cache, a sampling predictor keeps track of a small number of sets using partial tags. Sampling allows the predictor to use far less state than previous predictors to make predictions with superior accuracy. Dead block prediction can be used to drive a dead block replacement and bypass optimization. A sampling predictor can reduce the number of LLC misses over LRU by 11.7% for memory-intensive single-thread benchmarks and 23% for multi …",IEEE,,2010
671,Adaptive-Latency DRAM: Optimizing DRAM Timing for the Common-Case,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MkU_TDAAAAAJ&citation_for_view=MkU_TDAAAAAJ:hqOjcs7Dif8C,,,,
672,"Accelerating Pointer Chasing in 3D-Stacked Memory: Challenges, Mechanisms, Evaluation",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MkU_TDAAAAAJ&citation_for_view=MkU_TDAAAAAJ:YOwf2qJgpHMC,"Pointer chasing is a fundamental operation, used by many important data-intensive applications (e.g., databases, key-value stores, graph processing workloads) to traverse linked data structures. This operation is both memory bound and latency sensitive, as it (1) exhibits irregular access patterns that cause frequent cache and TLB misses, and (2) requires the data from every memory access to be sent back to the CPU to determine the next pointer to access. Our goal is to accelerate pointer chasing by performing it inside main memory, thereby avoiding inefficient and high-latency data transfers between main memory and the CPU. To this end, we propose the In-Memory PoInter Chasing Accelerator (IMPICA), which leverages the logic layer within 3D-stacked memory for linked data structure traversal. This paper identifies the key design challenges of designing a pointer chasing accelerator in memory, describes …",,,2016
673,AVATAR: A Variable-Retention-Time (VRT) Aware Refresh for DRAM Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MkU_TDAAAAAJ&citation_for_view=MkU_TDAAAAAJ:5nxA0vEk-isC,,,,
674,"Understanding latency variation in modern DRAM chips: Experimental characterization, analysis, and optimization",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MkU_TDAAAAAJ&citation_for_view=MkU_TDAAAAAJ:_kc_bZDykSQC,"Long DRAM latency is a critical performance bottleneck in current systems. DRAM access latency is defined by three fundamental operations that take place within the DRAM cell array: (i) activation of a memory row, which opens the row to perform accesses; (ii) precharge, which prepares the cell array for the next memory access; and (iii) restoration of the row, which restores the values of cells in the row that were destroyed due to activation. There is significant latency variation for each of these operations across the cells of a single DRAM chip due to irregularity in the manufacturing process. As a result, some cells are inherently faster to access, while others are inherently slower. Unfortunately, existing systems do not exploit this variation. The goal of this work is to (i) experimentally characterize and understand the latency variation across cells within a DRAM chip for these three fundamental DRAM operations, and …",,,2016
675,SLOs-Serve: Optimized Serving of Multi-SLO LLMs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MkU_TDAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MkU_TDAAAAAJ:35N4QoGY0k4C,"This paper introduces SLOs-Serve, a system designed for serving multi-stage large language model (LLM) requests with application- and stage-specific service level objectives (SLOs). The key idea behind SLOs-Serve is to customize the allocation of tokens to meet these SLO requirements. SLOs-Serve uses a multi-SLO dynamic programming-based algorithm to continuously optimize token allocations under SLO constraints by exploring the full design space of chunked prefill and (optional) speculative decoding. Leveraging this resource planning algorithm, SLOs-Serve effectively supports multi-SLOs and multi-replica serving with dynamic request routing while being resilient to bursty arrivals. Our evaluation across 6 LLM application scenarios (including summarization, coding, chatbot, tool calling, and reasoning) demonstrates that SLOs-Serve improves per-GPU serving capacity by 2.2x on average compared to prior state-of-the-art systems.",,,2025
676,EdgeRAG: Online-Indexed RAG for Edge Devices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MkU_TDAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MkU_TDAAAAAJ:vV6vV6tmYwMC,"Deploying Retrieval Augmented Generation (RAG) on resource-constrained edge devices is challenging due to limited memory and processing power. In this work, we propose EdgeRAG which addresses the memory constraint by pruning embeddings within clusters and generating embeddings on-demand during retrieval. To avoid the latency of generating embeddings for large tail clusters, EdgeRAG pre-computes and stores embeddings for these clusters, while adaptively caching remaining embeddings to minimize redundant computations and further optimize latency. The result from BEIR suite shows that EdgeRAG offers significant latency reduction over the baseline IVF index, but with similar generation quality while allowing all of our evaluated datasets to fit into the memory.",,,2024
677,CC-NIC: a Cache-Coherent Interface to the NIC,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MkU_TDAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MkU_TDAAAAAJ:J_g5lzvAfSwC,"Emerging interconnects make peripherals, such as the network interface controller (NIC), accessible through the processor's cache hierarchy, allowing these devices to participate in the CPU cache coherence protocol. This is a fundamental change from the separate I/O data paths and read-write transaction primitives of today's PCIe NICs. Our experiments show that the I/O data path characteristics cause NICs to prioritize CPU efficiency at the expense of inflated latency, an issue that can be mitigated by the emerging low-latency coherent interconnects. But, the coherence abstraction is not suited to current host-NIC access patterns. Applying existing signaling mechanisms and data structure layouts in a cache-coherent setting results in extraneous communication and cache retention, limiting performance. Redesigning the interface is necessary to minimize overheads and benefit from the new interactions coherence …",,,2024
678,A Cloud-Scale Characterization of Remote Procedure Calls,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MkU_TDAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MkU_TDAAAAAJ:ns9cj8rnVeAC,"The global scale and challenging requirements of modern cloud applications have led to the development of complex, widely distributed, service-oriented applications. One enabler of such applications is the remote procedure call (RPC), which provides location-independent communication and hides the myriad of cloud communication complexities and requirements within the RPC stack. Understanding RPCs is thus one key to understanding the behavior of cloud applications. While there have been numerous studies of RPCs in distributed systems, as well as attempts to optimize RPC overheads with both software and hardware, there is still a lack of knowledge about the characteristics of RPCs ""in the wild"" in the modern cloud environment. To address this gap, we present, to the best of our knowledge, the first large-scale fleet-wide study of RPCs. Our study is conducted at Google, where we measured the …",,,2023
679,vPIM: Efficient Virtual Address Translation for Scalable Processing-in-Memory Architectures,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MkU_TDAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MkU_TDAAAAAJ:O3NaXMp0MMsC,"3D-stacked memory technologies make it possible to integrate computation logic into the memory stack to reduce data movement between CPU and memory, enabling processing-in-memory (PIM). PIM systems scale in capacity and bandwidth by connecting multiple PIM stacks through a memory network. They also need to be programmable, where having virtual memory support is critical. Existing address translation schemes, however, are not optimized for a scalable PIM system. In this work, we propose VPIM, a virtual address translation scheme for scalable, multi-stack PIM systems. VPIM optimizes contention of the memory network in a PIM system and reduces translation time with pre-translation. Our evaluation shows a speedup of 4.4× and 1.7× compared to conventional radix and cuckoo hash page tables in eight memory-intensive workloads.",IEEE,,2023
680,The internet of things has a gateway problem,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MLx5TCQAAAAJ&citation_for_view=MLx5TCQAAAAJ:Zph67rFs4hoC,"The vision of an Internet of Things (IoT) has captured the imagination of the world and raised billions of dollars, all before we stopped to deeply consider how all these Things should connect to the Internet. The current state-of-the-art requires application-layer gateways both in software and hardware that provide application-specific connectivity to IoT devices. In much the same way that it would be difficult to imagine requiring a new web browser for each website, it is hard to imagine our current approach to IoT connectivity scaling to support the IoT vision. The IoT gateway problem exists in part because today's gateways conflate network connectivity, in-network processing, and user interface functions. We believe that disentangling these functions would improve the connectivity potential for IoT devices. To realize the broader vision, we propose an architecture that leverages the increasingly ubiquitous presence of …",,,2015
681,Multiprogramming a 64kb computer safely and efficiently,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MLx5TCQAAAAJ&citation_for_view=MLx5TCQAAAAJ:UebtZRa9Y70C,"Low-power microcontrollers lack some of the hardware features and memory resources that enable multiprogrammable systems. Accordingly, microcontroller-based operating systems have not provided important features like fault isolation, dynamic memory allocation, and flexible concurrency. However, an emerging class of embedded applications are software platforms, rather than single purpose devices, and need these multiprogramming features. Tock, a new operating system for low-power platforms, takes advantage of limited hardware-protection mechanisms as well as the type-safety features of the Rust programming language to provide a multiprogramming environment for microcontrollers. Tock isolates software faults, provides memory protection, and efficiently manages memory for dynamic application workloads written in any language. It achieves this while retaining the dependability requirements of …",,,2017
682,Graph neural networks in IoT: A survey,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MLx5TCQAAAAJ&citation_for_view=MLx5TCQAAAAJ:35N4QoGY0k4C,"The Internet of Things (IoT) boom has revolutionized almost every corner of people’s daily lives: healthcare, environment, transportation, manufacturing, supply chain, and so on. With the recent development of sensor and communication technology, IoT artifacts, including smart wearables, cameras, smartwatches, and autonomous systems can accurately measure and perceive their surrounding environment. Continuous sensing generates massive amounts of data and presents challenges for machine learning. Deep learning models (e.g., convolution neural networks and recurrent neural networks) have been extensively employed in solving IoT tasks by learning patterns from multi-modal sensory data. Graph neural networks (GNNs), an emerging and fast-growing family of neural network models, can capture complex interactions within sensor topology and have been demonstrated to achieve state-of-the-art …",ACM,ACM Transactions on Sensor Networks,2023
683,Is rust used safely by software developers?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MLx5TCQAAAAJ&citation_for_view=MLx5TCQAAAAJ:M3NEmzRMIkIC,"Rust, an emerging programming language with explosive growth, provides a robust type system that enables programmers to write memory-safe and data-race free code. To allow access to a machine's hardware and to support low-level performance optimizations, a second language, Unsafe Rust, is embedded in Rust. It contains support for operations that are difficult to statically check, such as C-style pointers for access to arbitrary memory locations and mutable global variables. When a program uses these features, the compiler is unable to statically guarantee the safety properties Rust promotes. In this work, we perform a large-scale empirical study to explore how software developers are using Unsafe Rust in real-world Rust libraries and applications. Our results indicate that software engineers use the keyword unsafe in less than 30% of Rust libraries, but more than half cannot be entirely statically checked by …",,,2020
684,"Surepoint: Exploiting ultra wideband flooding and diversity to provide robust, scalable, high-fidelity indoor localization",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MLx5TCQAAAAJ&citation_for_view=MLx5TCQAAAAJ:_kc_bZDykSQC,"We present SurePoint, a system for drop-in, high-fidelity indoor localization. SurePoint builds on recently available commercial ultra-wideband radio hardware. While ultra-wideband radio hardware can provide the timing primitives necessary for a simple adaptation of two-way ranging, we show that with the addition of frequency and spatial diversity, we can achieve a 53% decrease in median ranging error. Because this extra diversity requires many additional packets for each range estimate, we next develop an efficient broadcast ranging protocol for localization that ameliorates this overhead. We evaluate the performance of this ranging protocol in stationary and fast-moving environments and find that it achieves up to 0.08 m median error and 0.53 m 99th percentile error. As ranging requires the tag to have exclusive access to the channel, we next develop a protocol to coordinate the localization of multiple tags in …",,,2016
685,Data Efficient PV based Indoor Event Detection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MLx5TCQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MLx5TCQAAAAJ:OU6Ihb5iCvQC,"In this paper, we argue that instead of indiscriminately transmitting every sensed value, data transmission should prioritize relevance, intelligence, and efficiency. As a case study, we investigate exit/entry event detection through the generation of signature voltage patterns from PV module connected to an IoT platform and placed near entrance. This detection technique facilitates automated appliance management (e.g., lighting and HVAC control) and improves indoor security (e.g., unauthorized entry detection) by leveraging existing devices for sensing purposes. To enhance data efficiency, we propose the implementation of an intelligent on-board event detection algorithm, prioritizing sampling points within specific timeframes based on their significance on classification accuracy and lossless compression technique to further squeeze necessary information for classification. In our testbed evaluation, our approach …",,,2025
686,Atlas: Ensuring Accuracy for Privacy-Preserving Federated IoT Applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MLx5TCQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MLx5TCQAAAAJ:uWQEDVKXjbEC,"In smart Internet of Things (IoT) applications, edge devices often collect and store limited data, which is insufficient for training modern deep learning models. Collaborative training methods like cloud computing and federated learning enable robust models for IoT applications, yet introduce data privacy concerns due to central data collection and model inversion attacks. Remedies such as differential privacy can bring data privacy protection but dramatically degrade the accuracy performance of IoT applications. To safeguard user data privacy while maintaining application quality, it is imperative to establish a framework capable of preserving user privacy without compromising accuracy standards. In this paper, we present Atlas, a private and accurate personalized federated local differential privacy (LDP) framework for IoT applications. We first design a layer-sharing mechanism called the layer importance mask to …",,,2025
687,Detecting Plant VOC Traces Using Indoor Air Quality Sensors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MLx5TCQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MLx5TCQAAAAJ:SP6oXDckpogC,"In the era of growing interest in healthy buildings and smart homes, the importance of sustainable, health conscious indoor environments is paramount. Smart tools, especially VOC sensors, are crucial for monitoring indoor air quality, yet interpreting signals from various VOC sources remains challenging. A promising approach involves understanding how indoor plants respond to environmental conditions. Plants produce terpenes, a type of VOC, when exposed to abiotic and biotic stressors - including pathogens, predators, light, and temperature - offering a novel pathway for monitoring indoor air quality. While prior work often relies on specialized laboratory sensors, our research leverages readily available commercial sensors to detect and classify plant emitted VOCs that signify changes in indoor conditions. We quantified the sensitivity of these sensors by measuring 16 terpenes in controlled experiments, then identified and tested the most promising terpenes in realistic environments. We also examined physics based models to map VOC responses but found them lacking for real world complexity. Consequently, we trained machine learning models to classify terpenes using commercial sensors and identified optimal sensor placement. To validate this approach, we analyzed emissions from a living basil plant, successfully detecting terpene output. Our findings establish a foundation for overcoming challenges in plant VOC detection, paving the way for advanced plant based sensors to enhance indoor environmental quality in future smart buildings.",,,2025
688,Scheduling energy harvesting nodes in a wireless sensor network,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MLx5TCQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MLx5TCQAAAAJ:dshw04ExmUIC,"A system and method for optimizing power consumption of energy harvesting nodes in a wireless sensor network. In one embodiment, a system includes a network coordinator. The network coordinator includes a wireless transceiver and a controller. The wireless transceiver is configured to provide access to the wireless sensor network. The controller is configured to determine whether a wireless device that is wirelessly communicating with the network coordinator is powered via energy harvesting. The controller is also configured to schedule, based on a determination that the wireless device is powered via energy harvesting, the wireless device to communicate via the wireless sensor network using a priority timeslot of a superframe of the wireless sensor network. The priority timeslot is a timeslot occurring in an initial portion of the superframe.",,,2025
689,Injury-induced HDAC5 nuclear export is essential for axon regeneration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WXncrtMAAAAJ&citation_for_view=WXncrtMAAAAJ:2osOgNQ5qMEC,"Reactivation of a silent transcriptional program is a critical step in successful axon regeneration following injury. Yet how such a program is unlocked after injury remains largely unexplored. We found that axon injury in peripheral sensory neurons elicits a back-propagating calcium wave that invades the soma and causes nuclear export of HDAC5 in a PKCμ-dependent manner. Injury-induced HDAC5 nuclear export enhances histone acetylation to activate a proregenerative gene-expression program. HDAC5 nuclear export is required for axon regeneration, as expression of a nuclear-trapped HDAC5 mutant prevents axon regeneration, whereas enhancing HDAC5 nuclear export promotes axon regeneration in vitro and in vivo. Components of this HDAC5 pathway failed to be activated in a model of central nervous system injury. These studies reveal a signaling mechanism from the axon injury site to the soma that …",Elsevier,,2013
690,Avoiding common pitfalls when clustering biological data,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WXncrtMAAAAJ&citation_for_view=WXncrtMAAAAJ:ufrVoPGSRksC,"Clustering is an unsupervised learning method, which groups data points based on similarity, and is used to reveal the underlying structure of data. This computational approach is essential to understanding and visualizing the complex data that are acquired in high-throughput multidimensional biological experiments. Clustering enables researchers to make biological inferences for further experiments. Although a powerful technique, inappropriate application can lead biological researchers to waste resources and time in experimental follow-up. We review common pitfalls identified from the published molecular biology literature and present methods to avoid them. Commonly encountered pitfalls relate to the high-dimensional nature of biological data from high-throughput experiments, the failure to consider more than one clustering method for a given problem, and the difficulty in determining whether clustering …",American Association for the Advancement of Science,Science signaling,2016
691,Phosphoproteomics of collagen receptor networks reveals SHP-2 phosphorylation downstream of wild-type DDR2 and its lung cancer mutants,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WXncrtMAAAAJ&citation_for_view=WXncrtMAAAAJ:WF5omc3nYNoC,"Collagen is an important extracellular matrix component that directs many fundamental cellular processes including differentiation, proliferation and motility. The signalling networks driving these processes are propagated by collagen receptors such as the β1 integrins and the DDRs (discoidin domain receptors). To gain an insight into the molecular mechanisms of collagen receptor signalling, we have performed a quantitative analysis of the phosphorylation networks downstream of collagen activation of integrins and DDR2. Temporal analysis over seven time points identified 424 phosphorylated proteins. Distinct DDR2 tyrosine phosphorylation sites displayed unique temporal activation profiles in agreement with in vitro kinase data. Multiple clustering analysis of the phosphoproteomic data revealed several DDR2 candidate downstream signalling nodes, including SHP-2 (Src homology 2 domain-containing …",Portland Press Ltd.,,2013
692,Different Epidermal Growth Factor Receptor (EGFR) Agonists Produce Unique Signatures for the Recruitment of Downstream Signaling Proteins*♦,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WXncrtMAAAAJ&citation_for_view=WXncrtMAAAAJ:eQOLeE2rZwMC,"The EGF receptor can bind seven different agonist ligands. Although each agonist appears to stimulate the same suite of downstream signaling proteins, different agonists are capable of inducing distinct responses in the same cell. To determine the basis for these differences, we used luciferase fragment complementation imaging to monitor the recruitment of Cbl, CrkL, Gab1, Grb2, PI3K, p52 Shc, p66 Shc, and Shp2 to the EGF receptor when stimulated by the seven EGF receptor ligands. Recruitment of all eight proteins was rapid, dose-dependent, and inhibited by erlotinib and lapatinib, although to differing extents. Comparison of the time course of recruitment of the eight proteins in response to a fixed concentration of each growth factor revealed differences among the growth factors that could contribute to their differing biological effects. Principal component analysis of the resulting data set confirmed that the …",Elsevier,,2016
693,Predicting patient response to the antiarrhythmic mexiletine based on genetic variation: personalized medicine for long QT syndrome,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WXncrtMAAAAJ&citation_for_view=WXncrtMAAAAJ:kNdYIx-mwKoC,"Rationale: Mutations in the SCN5A gene, encoding the α subunit of the Nav1.5 channel, cause a life-threatening form of cardiac arrhythmia, long QT syndrome type 3 (LQT3). Mexiletine, which is structurally related to the Na+ channel-blocking anesthetic lidocaine, is used to treat LQT3 patients. However, the patient response is variable, depending on the genetic mutation in SCN5A. Objective: The goal of this study is to understand the molecular basis of patients’ variable responses and build a predictive statistical model that can be used to personalize mexiletine treatment based on patient’s genetic variant. Methods and Results: We monitored the cardiac Na+ channel voltage-sensing domain (VSD) conformational dynamics simultaneously with other gating properties for the LQT3 variants. To systematically identify the relationship between mexiletine block and channel biophysical properties, we used a system …",Lippincott Williams & Wilkins,,2019
694,Informatics at the Frontier of Cancer Research,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WXncrtMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=WXncrtMAAAAJ:_Qo2XoVZTnwC,"Digitized healthcare data, high-throughput profiling technologies, and data repositories have facilitated the emergence of a new era of cancer research. Each data stream requires specialized analysis methods for interpretation. The data-driven era of cancer research requires the development, enhancement, and sustainment of informatics technology software infrastructure, including fundamental methodology development in artificial intelligence and data science. We review current and emerging informatics technology developments for cancer research and discovery, spanning molecular and cellular characterization, image analysis, informatics, and therapeutics. Summarizing the diverse methods and applications of informatics throughout cancer research identifies themes and emerging areas for the next generation of cancer research.",American Association for Cancer Research,Cancer Research,2025
695,Uncovering the domain language of protein functionality and cell phenotypes using DANSy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WXncrtMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=WXncrtMAAAAJ:-f6ydRqryjwC,"Evolution has developed a set of principles that determine feasible domain combinations, analogous to grammar within natural languages. Treating domains as words and proteins as sentences, made up of domain words, we apply a linguistic approach to represent the human proteome as an n-gram network, which we call hereafter as Domain Architecture Network Syntax (DANSy). Combining DANSy with network theory, we explore the abstract rules of domain word combinations within the human proteome and identify connections that determine feasible protein functionality. We analyze the entropic information content of these domain word connections to establish a DANSy network that balances recovering most of proteome with n-gram complexity. Additionally, we explored subnetwork languages by focusing on reversible post-translational modifications (PTMs) systems that follow a reader-writer-eraser …",,,2025
696,Ten simple rules for effectively assessing lab environments,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WXncrtMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=WXncrtMAAAAJ:e5wmG9Sq2KIC,"Funding: Dr. Naegle was supported, in part, by the National Institute Of General Medical Sciences of the National Institutes of Health under Award Number R35GM138127. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.",Public Library of Science,,2025
697,Systematic analysis of the effects of splicing on the diversity of post-translational modifications in protein isoforms using PTM-POSE,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WXncrtMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=WXncrtMAAAAJ:IWHjjKOFINEC,"Post-translational modifications (PTMs) and splicing are both important regulatory processes controlling protein function; therefore, we developed PTM-POSE (PTM projection onto splice events) to explore the interplay between them. PTM-POSE identifies potential PTM sites associated with alternative isoforms or splice events, enabling comprehensive analysis of how PTMs affect isoform function, protein interactions, and enzymatic regulation. Through systematic analysis of Ensembl transcripts with PTM-POSE, we highlighted two key mechanisms by which splicing diversifies PTMs across isoforms—exclusion of a PTM site (32%) or alteration of the flanking sequences surrounding the PTM (2%). In experiment-specific analysis of PTM-associated splicing events, we identified the potential rewiring of protein-interaction and kinase-substrate networks, suggesting coordinated connections between PTM signaling. We …",Elsevier,,2025
698,Structure-informed theoretical modeling defines principles governing avidity in bivalent protein interactions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WXncrtMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=WXncrtMAAAAJ:4JMBOYKVnBMC,"In signaling cascades, where domain-motif interactions tend to interact with relatively low affinity (allowing for reversibility), signaling proteins often encode multiple domains or motifs, which present the possibility of avidity--drastically increasing the interaction strength and duration as a result of multivalent binding. However, given the large combinatorial space, predicting and validating multivalent interactions that interact with avidity is a challenge. Here, we integrate mechanistic modeling, structure-based analysis, and experimental approaches as a framework for defining the conditions under which avidity plays a role. We explore the tandem SH2 domain family of interactions with bisphosphorylated partners as a multivalent archetype, which encompasses key secondary messengers in tyrosine kinase signaling networks. While certain multivalent interactions have been shown to be necessary in immune receptor recruitment of partners, bivalent recruitment of tandem SH2 domains more broadly is poorly understood. Theoretical modeling suggests that maximum avidity occurs with closely spaced or flexibly linked phosphotyrosine sites, combined with moderate monovalent affinities--exactly around the innate range of SH2 domain affinity. Surprisingly, despite sequence diversity, structure-based analysis showed remarkably conserved three-dimensional spacing between SH2 domains across all tandem SH2 families, which we corroborate experimentally, suggesting evolutionary optimization for avidity interactions. The combination of structure-based analysis of domain spacing with available monovalent experimental data appears to be sufficiently …",,,2025
699,Social sustainability considerations during planning and design: Framework of processes for construction projects,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwxRqBMAAAAJ&citation_for_view=BwxRqBMAAAAJ:eQOLeE2rZwMC,"This research identifies 50 processes and categorizes them into a framework for integrating and evaluating social considerations in construction projects. These processes focus on the planning and design phases because they offer the greatest potential for influencing project performance. The concept mapping research method was applied to develop this framework on the basis of input from 25 experts in academia, industry, and government. Multidimensional scaling and hierarchical cluster analyses were used to organize the experts’ input into six categories defining social sustainability in construction projects: stakeholder engagement, user considerations, team formation, management considerations, impact assessment, and place context. Although previous research has recognized social sustainability as a series of processes, this study is the first to integrate them into a comprehensive framework …",American Society of Civil Engineers,,2013
700,People systematically overlook subtractive changes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwxRqBMAAAAJ&citation_for_view=BwxRqBMAAAAJ:tS2w5q8j5-wC,"Improving objects, ideas or situations—whether a designer seeks to advance technology, a writer seeks to strengthen an argument or a manager seeks to encourage desired behaviour—requires a mental search for possible changes, –. We investigated whether people are as likely to consider changes that subtract components from an object, idea or situation as they are to consider changes that add new components. People typically consider a limited number of promising ideas in order to manage the cognitive burden of searching through all possible ideas, but this can lead them to accept adequate solutions without considering potentially superior alternatives, , , , , –. Here we show that people systematically default to searching for additive transformations, and consequently overlook subtractive transformations. Across eight experiments, participants were less likely to identify advantageous subtractive changes …",Nature Publishing Group UK,,2021
701,A framework for sustainable whole systems design,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwxRqBMAAAAJ&citation_for_view=BwxRqBMAAAAJ:LkGwnXOMwfcC,"A whole systems approach, considering the interrelatedness of both problems and solutions, can help create more sustainable designs. Still, designers often apply exclusively reductionist approaches to generate designs. One way to address this issue is to reduce ambiguity in the whole systems approach. This paper describes research to define and unify elements of whole systems design. Elements were identified through a methodical review of sources describing theories, perspectives, and practices from multiple design disciplines. These elements were coded and then organized using concept mapping. The resulting framework has 20 elements categorized as processes, principles, and methods. This framework is meant to help enable more widespread application of whole systems design in practice.",Elsevier,,2012
702,The impact of process mapping on transparency,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwxRqBMAAAAJ&citation_for_view=BwxRqBMAAAAJ:d1gkVwhDpl0C,Purpose – Process mapping is used to articulate the activities and procedures of business entities in a graphical way as pictorial images readily convey considerable information. The objective of this research is to provide evidence and a methodology to assist organizations in evaluating the early stages of their process mapping efforts. Design/methodology/approach – A review of literature identifies key characteristics of transparency (process visibility) related to process mapping. Quizzes and surveys are used to study the impact of process mapping on transparency in an employee training session. Findings – The paper finds that process mapping increases transparency between 5 percent and 27 percent for the applications discussed in this paper. Research limitations/implications – The research presumes that better understanding and recall of the company's business processes equates to higher transparency …,Emerald Group Publishing Limited,,2008
703,A lean modeling protocol for evaluating green project delivery,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwxRqBMAAAAJ&citation_for_view=BwxRqBMAAAAJ:u5HHmVD_uO8C,"The first vital step to leaning an operation is to model or map the processes used to deliver value in that operation. This allows the requisite understanding of where waste and non value-adding activity exists, and provides the foundation for improvement. Current protocols for modeling operations present the basic tenets for lean mapping, but tend to be based in manufacturing language, and are not easily adapted to capital facilities projects.“Green” or “sustainable” capital projects delivered using current project delivery systems seem to be laden with hidden waste. These projects tend to be more challenging to deliver due increased levels of building system integration, untraditional materials, and requirements such as recycling, total commissioning, and increased project documentation. Penn State’s Lean an d Green Research Initiative has examined the delivery of multi-million dollar green building projects for clients including the Pentagon, Toyota, and Penn State’s Office of Physical Plant. The processes used to complete these projects are difficult to model with current lean techniques. This paper outlines a detailed modeling protocol for evaluating the delivery processes of green projects. Blending existing protocols and the specific needs of green building projects, this protocol will help define the data collection and analysis procedures, as well as the instruments (metrics) of analysis.",Lean Construction Institute,,2007
704,Exploring an intervention to increase psychological safety on student engineering design teams,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwxRqBMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BwxRqBMAAAAJ:mvPsJ3kp5DgC,"Psychological safety, or “the shared belief that a team is safe for interpersonal risk-taking” has been linked to positive outcomes on design teams including improved idea quality, improved learning behavior and knowledge creation, and higher job satisfaction. Research in other fields suggest that psychological safety may also contribute to team creativity and innovation which are important in engineering and design practice and education. Psychological safety has received growing attention in engineering design and education. However, research on interventions to increase psychological safety on engineering and design teams remains limited. Building on a previous Work in Progress paper, we tested an intervention based in improv theater designed to increase psychological safety on engineering design teams. In this work, we conducted an experiment using a randomized controlled trial design. Students from two different engineering courses were randomly assigned to teams of 4 students, and teams were randomly assigned to treatment and control conditions; treatment and control teams were assigned in both classes. We had 92 total participants on 22 teams. The intervention used in the treatment condition consisted of two exercises that we call “Yes, and” and “Thank you, because” which took a total of 25 minutes. Control teams completed parallel activities to ensure that all teams spent the same amount of time together. Following the intervention, participants completed a survey which included Edmondson’s Team Psychological Safety Scale to compare results between the treatment and control groups. We conducted a Welch Two …",,,2024
705,Informing Just Design with Place-Based Racial History,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwxRqBMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BwxRqBMAAAAJ:BrmTIyaxlBUC,"Enhanced designs of the built environment are particularly urgent for frontline communities, who experience the first and worst of climate change. A climate adaptation approach that prioritizes need-based distributive justice, the allocation of resources to meet the basic conditions necessary for continued community existence, may empower frontline communities in the resource allocation process. Need-based distributive justice is often viewed as a supplement to other universal principles of distributive justice, such as merit—the allocation of resources according to individual contributions. The overlooked need principle, however, is especially important because it can address the deficit of resources that frontline communities experience. Frontline communities disproportionately comprise …",American Society of Civil Engineers,,2023
706,Recycling bias and reduction neglect,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwxRqBMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BwxRqBMAAAAJ:D_sINldO8mEC,"Waste generation and mismanagement are polluting the planet at accelerating and unsustainable rates. Reducing waste generation is far more sustainable than managing waste after it has been created, which is why ‘reduce, reuse, recycle’ is ordered the way it is, with reduce first and recycling as a last resort. However, our research finds strong evidence for a recycling bias and reduction neglect. Across two surveys (NTotal = 1,321), most participants perceived recycling as the most sustainable action to manage waste. This error decreased when different waste destinations were emphasized and when choice options were reduced. When asked in study 2 (N = 473), 53.9% of participants recognized that the product design stage offered the greatest potential for mitigating waste and its impacts. However, participants only felt empowered to enact change via their consumption (72.9%) and disposal choices (23.3 …",Nature Publishing Group UK,,2023
707,Community involvement in coastal infrastructure adaptation should balance necessary complexity and perceived effort,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwxRqBMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BwxRqBMAAAAJ:VOx2b1Wkg3QC,"Successful adaptation of coastal infrastructure requires public participation, and it is important to elicit accurate feedback from surveys and in-person interactions. But there remains a need for evidence about the efficacy of potential risk communication design metrics. This online experiment (n = 261) sought to understand the necessity of a multifaceted risk perception questionnaire to capture public input. Using six coastal infrastructure examples, risk perceptions were collected using a questionnaire highlighting multiple types of risk (intervention) or not (control). Public evaluations of risk did not differ in most cases. Moreover, the intervention imposed more cognitive strain on participants, which could unintentionally discourage public participation in the climate adaptation process. In this case, the single question provides the same input, with less effort. This finding is a reminder that effective risk communication for …",Elsevier,,2022
708,Framing to reduce present bias in infrastructure design intentions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwxRqBMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BwxRqBMAAAAJ:8AbLer7MMksC,"Infrastructure professionals (N = 261) were randomly assigned to either a future or present-framed project description and asked to recommend design attributes for an infrastructure project. The future-framed condition led professionals to propose a significantly longer infrastructure design life, useful life to the community, and acceptable return on financial investment. The findings suggest a straightforward and inexpensive way to lessen present bias in various design contexts",Elsevier,,2022
709,Privacy-preserving distributed linear regression on high-dimensional data,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QMbCDtEAAAAJ&citation_for_view=QMbCDtEAAAAJ:qjMakFHDy7sC,"We propose privacy-preserving protocols for computing linear regression models, in the setting where the training dataset is vertically distributed among several parties. Our main contribution is a hybrid multi-party computation protocol that combines Yao's garbled circuits with tailored protocols for computing inner products. Like many machine learning tasks, building a linear regression model involves solving a system of linear equations. We conduct a comprehensive evaluation and comparison of different techniques for securely performing this task, including a new Conjugate Gradient Descent (CGD) algorithm. This algorithm is suitable for secure computation because it uses an efficient fixed-point representation of real numbers while maintaining accuracy and convergence rates comparable to what can be obtained with a classical solution using floating point numbers. Our technique improves on Nikolaenko et al.'s method for privacy-preserving ridge regression (S&P 2013), and can be used as a building block in other analyses. We implement a complete system and demonstrate that our approach is highly scalable, solving data analysis problems with one million records and one hundred features in less than one hour of total running time.",,,2016
710,Scaling ORAM for secure computation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QMbCDtEAAAAJ&citation_for_view=QMbCDtEAAAAJ:UeHWp8X0CEIC,"We design and implement a Distributed Oblivious Random Access Memory (DORAM) data structure that is optimized for use in two-party secure computation protocols. We improve upon the access time of previous constructions by a factor of up to ten, their memory overhead by a factor of one hundred or more, and their initialization time by a factor of thousands. We are able to instantiate ORAMs that hold 234 bytes, and perform operations on them in seconds, which was not previously feasible with any implemented scheme. Unlike prior ORAM constructions based on hierarchical hashing, permutation, or trees, our Distributed ORAM is derived from the new Function Secret Sharing scheme introduced by Boyle, Gilboa and Ishai. This significantly reduces the amount of secure computation required to implement an ORAM access, albeit at the cost of O(n) efficient local memory operations. We implement our …",,,2017
711,Secure two-party threshold ECDSA from ECDSA assumptions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QMbCDtEAAAAJ&citation_for_view=QMbCDtEAAAAJ:IjCSPb-OGe4C,"The Elliptic Curve Digital Signature Algorithm (ECDSA) is one of the most widely used schemes in deployed cryptography. Through its applications in code and binary authentication, web security, and cryptocurrency, it is likely one of the few cryptographic algorithms encountered on a daily basis by the average person. However, its design is such that executing multi-party or threshold signatures in a secure manner is challenging: unlike other, less widespread signature schemes, secure multi-party ECDSA requires custom protocols, which has heretofore implied reliance upon additional cryptographic assumptions such as the Paillier encryption scheme. We propose new protocols for multi-party ECDSA key-generation and signing with a threshold of two, which we prove secure against malicious adversaries in the random oracle model using only the Computational Diffie-Hellman Assumption and the assumptions …",IEEE,,2018
712,Threshold ECDSA from ECDSA assumptions: The multiparty case,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QMbCDtEAAAAJ&citation_for_view=QMbCDtEAAAAJ:zYLM7Y9cAGgC,"Cryptocurrency applications have spurred a resurgence of interest in the computation of ECDSA signatures using threshold protocols---that is, protocols in which the signing key is secret-shared among n parties, of which any subset of size t must interact in order to compute a signature. Among the resulting works to date, that of Doerner et al. requires the most natural assumptions while also achieving the best practical signing speed. It is, however, limited to the setting in which the threshold is two. We propose an extension of their scheme to arbitrary thresholds, and prove it secure against a malicious adversary corrupting up to one party less than the threshold under only the Computational Diffie-Hellman assumption in the Random Oracle model, an assumption strictly weaker than those under which ECDSA is proven. Whereas the best current schemes for threshold-two ECDSA signing use a Diffie-Hellman Key …",IEEE,,2019
713,Revisiting square-root ORAM: efficient random access in multi-party computation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QMbCDtEAAAAJ&citation_for_view=QMbCDtEAAAAJ:u5HHmVD_uO8C,"Hiding memory access patterns is required for secure computation, but remains prohibitively expensive for many interesting applications. Prior work has either developed custom algorithms that minimize the need for data-dependant memory access, or proposed the use of Oblivious RAM (ORAM) to provide a general-purpose solution. However, most ORAMs are designed for client-server scenarios, and provide only asymptotic benefits in secure computation. Even the best prior schemes show concrete benefits over naïve linear scan only for array sizes greater than 100. This immediately implies each ORAM access is 100 times slower than a single access at a known location. Even then, prior evaluations ignore the substantial initialization cost of existing schemes. We show how the classical square-root ORAM of Goldreich and Ostrovsky can be modified to overcome these problems, even though it is asymptotically …",IEEE,,2016
714,From OT to OLE with Subquadratic Communication,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QMbCDtEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=QMbCDtEAAAAJ:L8Ckcad2t8MC,"Oblivious Linear Evaluation (OLE) is an algebraic generalization of oblivious transfer (OT) that forms a critical part of a growing number of applications. An OLE protocol over a modulus enables the receiver party to securely evaluate a line chosen by the sender party on a secret point . Motivated by the big efficiency gap between OLE and OT and by fast OT extension techniques, we revisit the question of reducing OLE to OT, aiming to improve the communication cost of known reductions. We start by observing that the Chinese Remainder Theorem (CRT) can be combined with a prior protocol of Gilboa (Crypto’99) to reduce its communication cost from to bits, for . Unfortunately, whereas Gilboa's protocol is secure against a semi-honest sender and a malicious receiver, a direct application of the CRT technique is only semi-honest secure (it is insecure against malicious receivers). Thus, we employ number-theoretic techniques to protect our CRT-based protocol against malicious receivers, while still retaining a concrete advantage over Gilboa's protocol (eg, less communication for ). Furthermore, we obtain a fully malicious OLE-to-OT reduction by applying either information-theoretic techniques with moderate overhead, or RSA-based cryptographic techniques with very low overhead. We demonstrate the usefulness of our results in the context of OLE applications, including a post-quantum oblivious pseudorandom function (OPRF) and distributed signatures. In particular, assuming pre-existing random OT correlations, we can use our malicious-receiver OLE protocol to realize (a single instance of) the power …",,,2025
715,Sometimes you can’t distribute random-oracle-based proofs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QMbCDtEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=QMbCDtEAAAAJ:M3ejUd6NZC8C,"We investigate the conditions under which straight-line extractable NIZKs in the random oracle model (i.e. without a CRS) permit multiparty realizations that are black-box in the same random oracle. We show that even in the semi-honest setting, any MPC protocol to compute such a NIZK cannot make black-box use of the random oracle or a hash function instantiating it if security against all-but-one corruptions is desired, unless the number of queries made by the verifier to the oracle grows linearly with the number of parties. This presents a fundamental barrier to constructing efficient protocols to securely distribute the computation of NIZKs (and signatures) based on MPC-in-the-head, PCPs/IOPs, and sigma protocols compiled with transformations due to Fischlin, Pass, or Unruh. When the adversary is restricted to corrupt only a constant fraction of parties, we give a positive result by means of a tailored construction …",Springer Nature Switzerland,,2024
716,Secure multiparty computation with identifiable abort via vindicating release,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QMbCDtEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=QMbCDtEAAAAJ:_kc_bZDykSQC,"In the dishonest-majority setting, secure multiparty computation (MPC) with identifiable abort (IA) guarantees that honest parties can identify and agree upon at least one cheating party if the protocol does not produce an output. Known MPC constructions with IA rely on generic zero-knowledge proofs, adaptively secure oblivious transfer (OT) protocols, or homomorphic primitives, and thus incur a substantial penalty with respect to protocols that abort without identifiability. We introduce a new, weaker notion of IA called input-revealing IA (IRIA), which can be constructed through selective revealing of committed input values—a technique we call vindicating release. We show that this weaker form of IA can be achieved with small concrete overheads for many interesting protocols in the literature, including the pre-processing protocols needed for several state-of-the-art MPC protocols. We next show how to assemble …",Springer Nature Switzerland,,2024
717,Threshold ECDSA in three rounds,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QMbCDtEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=QMbCDtEAAAAJ:KlAtU1dfN6UC,"We present a three-round protocol for threshold ECDSA signing with malicious security against a dishonest majority, which information-theoretically UC-realizes a standard threshold signing functionality, assuming only ideal commitment and two-party multiplication primitives. Our protocol combines an intermediate representation of ECDSA signatures that was recently introduced by Abram et al. [2] with an efficient statistical consistency check reminiscent of the ones used by the protocols of Doerner et al. [3], [4]. We show that shared keys for our signing protocol can be generated using a simple commit-release-and-complain procedure, without any proofs of knowledge, and to compute the intermediate representation of each signature, we propose a two-round vectorized multiplication protocol based on oblivious transfer that outperforms all similar constructions. We demonstrate empirically that our protocol …",IEEE,,2024
718,Constant-round simulation-secure coin tossing extension with guaranteed output,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QMbCDtEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=QMbCDtEAAAAJ:qxL8FJ1GzNcC,"Common randomness is an essential resource in many applications. However, Cleve (STOC 86) rules out the possibility of tossing a fair coin from scratch in the presence of a dishonest majority. A second-best alternative is a Coin Tossing Extension (CTE) protocol, which uses an “online” oracle that produces a few common random bits to generate many common random-looking bits. We initiate the systematic study of fully-secure CTE, which guarantees output even in the presence of malicious behavior. A fully-secure two-party statistical CTE protocol with black-box simulation was implicit in Hofheinz et al. (Eurocrypt 06), but its round complexity is nearly linear in its output length. The problem of constant-round CTE with superlogarithmic stretch remained open. We prove that statistical CTE with full black-box security and superlogarithmic stretch must have superconstant rounds. In the computational setting we prove …",Springer Nature Switzerland,,2024
719,Acellular normal and fibrotic human lung matrices as a culture system for in vitro investigation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8jy5ddIAAAAJ&citation_for_view=8jy5ddIAAAAJ:hqOjcs7Dif8C,"Rationale: Extracellular matrix (ECM) is a dynamic tissue that contributes to organ integrity and function, and its regulation of cell phenotype is a major aspect of cell biology. However, standard in vitro culture approaches are of unclear physiologic relevance because they do not mimic the compositional, architectural, or distensible nature of a living organ. In the lung, fibroblasts exist in ECM-rich interstitial spaces and are key effectors of lung fibrogenesis. Objectives: To better address how ECM influences fibroblast phenotype in a disease-specific manner, we developed a culture system using acellular human normal and fibrotic lungs. Methods: Decellularization was achieved using treatment with detergents, salts, and DNase. The resultant matrices can be sectioned as uniform slices within which cells were cultured. Measurements and Main Results: We report that the decellularization process effectively removes …",American Thoracic Society,,2012
720,Maleimide cross-linked bioactive PEG hydrogel exhibits improved reaction kinetics and cross-linking for cell encapsulation and in-situ delivery,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8jy5ddIAAAAJ&citation_for_view=8jy5ddIAAAAJ:LkGwnXOMwfcC,"Engineered polyethylene glycol-maleimide matrices for regenerative medicine exhibit improved reaction efficiency and wider range of Young’s moduli by utilizing maleimide cross-linking chemistry. This hydrogel chemistry is advantageous for cell delivery due to the mild reaction that occurs rapidly enough for in situ delivery, while easily lending itself to “plug-and-play” design variations such as incorporation of enzyme-cleavable cross-links and cell-adhesion peptides.",,,2011
721,Matrix stiffness–induced myofibroblast differentiation is mediated by intrinsic mechanotransduction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8jy5ddIAAAAJ&citation_for_view=8jy5ddIAAAAJ:W7OEmFMy1HYC,The mechanical properties of the extracellular matrix have recently been shown to promote myofibroblast differentiation and lung fibrosis. Mechanisms by which matrix stiffness regulates myofibroblast differentiation are not fully understood. The goal of this study was to determine the intrinsic mechanisms of mechanotransduction in the regulation of matrix stiffness–induced myofibroblast differentiation. A well established polyacrylamide gel system with tunable substrate stiffness was used in this study. Megakaryoblastic leukemia factor-1 (MKL1) nuclear translocation was imaged by confocal immunofluorescent microscopy. The binding of MKL1 to the α-smooth muscle actin (α-SMA) gene promoter was quantified by quantitative chromatin immunoprecipitation assay. Normal human lung fibroblasts responded to matrix stiffening with changes in actin dynamics that favor filamentous actin polymerization. Actin …,American Thoracic Society,,2012
722,Controlling integrin specificity and stem cell differentiation in 2D and 3D environments through regulation of fibronectin domain stability,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8jy5ddIAAAAJ&citation_for_view=8jy5ddIAAAAJ:u-x6o8ySG0sC,"The extracellular matrix (ECM) exerts powerful control over many cellular phenomena, including stem cell differentiation. As such, design and modulation of ECM analogs to ligate specific integrin is a promising approach to control cellular processes in vitro and in vivo for regenerative medicine strategies. Although fibronectin (FN), a crucial ECM protein in tissue development and repair, and its RGD peptide are widely used for cell adhesion, the promiscuity with which they engage integrins leads to difficulty in control of receptor-specific interactions. Recent simulations of force-mediated unfolding of FN domains and sequences analysis of human versus mouse FN suggest that the structural stability of the FN's central cell-binding domains (FN III9–10) affects its integrin specificity. Through production of FN III9–10 variants with variable stabilities, we obtained ligands that present different specificities for the integrin α5β …",Elsevier,,2009
723,Macrophage and fibroblast interactions in biomaterial‐mediated fibrosis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8jy5ddIAAAAJ&citation_for_view=8jy5ddIAAAAJ:Fu2w8maKXqMC,"Biomaterial‐mediated inflammation and fibrosis remain a prominent challenge in designing materials to support tissue repair and regeneration. Despite the many biomaterial technologies that have been designed to evade or suppress inflammation (i.e., delivery of anti‐inflammatory drugs, hydrophobic coatings, etc.), many materials are still subject to a foreign body response, resulting in encapsulation of dense, scar‐like extracellular matrix. The primary cells involved in biomaterial‐mediated fibrosis are macrophages, which modulate inflammation, and fibroblasts, which primarily lay down new extracellular matrix. While macrophages and fibroblasts are implicated in driving biomaterial‐mediated fibrosis, the signaling pathways and spatiotemporal crosstalk between these cell types remain loosely defined. In this review, the role of M1 and M2 macrophages (and soluble cues) involved in the fibrous encapsulation of …",,Advanced healthcare materials,2019
724,Active antigen-specific adaptive immune responses are shared among patients with progressive fibrotic interstitial lung disease,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8jy5ddIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8jy5ddIAAAAJ:YohjEiUPhakC,"Rationale: Enlargement of lung-associated lymph nodes (LNs) predicts worse survival in all patients with interstitial lung disease (ILD). This phenomenon occurs in both connective tissue disease–associated ILD and, surprisingly, idiopathic pulmonary fibrosis (IPF), where immune-driven pathogenesis is controversial. Objectives: To determine whether immune responses in the lung LNs of patients with ILD are antigen-specific and significant to pathology and etiology. Methods: ILD lung LNs excised at transplant (30 IPF, 7 interstitial pneumonia with autoimmune features, 4 hypersensitivity pneumonitis, 5 connective tissue disease–associated ILD, 5 other ILD) and 36 donor control lung LNs were analyzed by spectral flow cytometry. Formalin-fixed lung LNs and OCT-fixed lung samples of patients with IPF were used to determine germinal center (GC) and antigen-specific responses. Serum autoantibody responses …",American Thoracic Society,,2025
725,Compositions and methods for detecting and regulating fibronectin-integrin interaction and signaling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8jy5ddIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8jy5ddIAAAAJ:kh2fBNsKQNwC,"Provided are antibodies that include amino acid sequences of SEQ ID NOs: 2, 4, and 6-12, or amino acid sequences that are about 95% identical thereto, and fragments thereof. Also provided are scFv peptides that include a V H segment having a first amino acid sequence of amino acids 4-113 of any one of SEQ ID NOs: 2 and 8-12, a V L segment having a second amino acid sequence having amino acids 113-237 of SEQ ID NOs. 2 and 8-12, or both; nucleic acids encoding the same; methods for using the same to detect and/or target conformational states of FN in samples; methods for treating diseases and/or disorders and/or for meliorating at least one symptom of consequence of a disease or disorder associated with abnormal expression of a force-induced conformational state of FN in subjects; and methods for screening for compounds having selective binding activities for conformational states of FN.",,,2025
726,Biomechanical properties of the capsule and extracellular matrix play a major role during the Wolffian/epididymal duct development,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8jy5ddIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8jy5ddIAAAAJ:foquWX3nUaYC,"Background The epididymis is important for sperm maturation and without its proper development, male infertility will result. Biomechanical properties of tissues/organs play key roles during their morphogenesis, including the Wolffian duct. It is hypothesized that structural/bulk stiffness of the capsule and mesenchyme/extracellular matrix that surround the duct is a major biomechanical property that regulates Wolffian duct morphogenesis. These data will provide key information as to the mechanisms that regulate the development of this important organ. Objectives To measure the structural/bulk stiffness in Pascals (force/area) of the capsule and the capsule and mesenchyme together that surrounds the Wolffian duct during the development. To examine the relative membrane tension of mesenchymal cells during the Wolffian duct development. Since Ptk7 was previously shown to regulate ECM integrity and Wolffian …",,,2025
727,Multiscale computational model predicts how environmental changes and treatments affect microvascular remodeling in fibrotic disease,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8jy5ddIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8jy5ddIAAAAJ:0N-VGjzr574C,"Investigating the molecular, cellular, and tissue-level changes caused by disease, and the effects of pharmacological treatments across these biological scales, necessitates the use of multiscale computational modeling in combination with experimentation. Many diseases dynamically alter the tissue microenvironment in ways that trigger microvascular network remodeling, which leads to the expansion or regression of microvessel networks. When microvessels undergo remodeling in idiopathic pulmonary fibrosis (IPF), functional gas exchange is impaired and lung function declines. We integrated a multiscale computational model with independent experiments to investigate how combinations of biomechanical and biochemical cues in IPF alter cell fate decisions leading to microvascular remodeling. Our computational model predicted that extracellular matrix (ECM) stiffening reduced microvessel area, which …",Oxford University Press,,2025
728,Fibroblast mechanoperception instructs pulmonary developmental and pattern specification gene expression programs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8jy5ddIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8jy5ddIAAAAJ:hCrLmN-GePgC,"Dysregulation of the cellular mechanisms that coordinate the interpretation and transduction of microenvironmental biophysical signals are a unifying feature of tissue remodeling pathologies such as fibrosis and cancer. While genomic regulation downstream of normal mechanotransduction (i.e. cases where cells sense soft and stiff appropriately) is well studied, significantly less is known about the consequences of abnormal mechanoperception and subsequent misinterpretation of the mechanical environment. Leveraging Thy-1 (a.k.a. CD90) loss as a model of impaired mechanoperception, we employed ATAC- and RNA-sequencing in parallel to characterize the changes in lung fibroblast genomic activity in response to a combination of substrate stiffness and culture time. Notably, we find perturbed mechanoperception elicits a near-complete shutdown of HOXA5, a transcription factor responsible for pattern specification and development in the nascent lung. In vitro investigation of HOXA5 expression reveals a potential mechanism connecting increased αv integrin signaling, cytoskeletal tension, and SRC kinase activity to HOXA5 silencing. These results establish novel links between integrin signaling and the expression dynamics of genes necessary for tissue formation and regeneration in the injured and/or developing lung, particularly HOXA5.",Cold Spring Harbor Laboratory,,2024
729,Reducing food loss and waste to enhance food security and environmental sustainability,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BptBqwMAAAAJ&citation_for_view=BptBqwMAAAAJ:IjCSPb-OGe4C,"While food shortage remains a big concern in many regions around the world, almost one-third of the total food production is discarded as food loss and waste (FLW). This is associated with about one-quarter of land, water, and fertilizer used for crop production, even though resources and environmental constraints are expected to limit food production around the world. FLW reduction represents a potential opportunity to enhance both food security and environmental sustainability and therefore has received considerable attention recently. By reviewing the recent progress and new developments in the literature, this paper highlights the importance of FLW prevention as a complementary solution to address the Grand Challenge of global food security and environmental sustainability. However, raising awareness only is not enough to realize the expected FLW reduction. We identify the knowledge gaps and …",American Chemical Society,Environmental science & technology,2016
730,Understanding and managing the food-energy-water nexus–opportunities for water resources research,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BptBqwMAAAAJ&citation_for_view=BptBqwMAAAAJ:WF5omc3nYNoC,"Studies on the food, energy, and water (FEW) nexus lay a shared foundation for researchers, policy makers, practitioners, and stakeholders to understand and manage linked production, utilization, and security of FEW systems. The FEW nexus paradigm provides the water community specific channels to move forward in interdisciplinary research where integrated water resources management (IWRM) has fallen short. Here, we help water researchers identify, articulate, utilize, and extend our disciplinary strengths within the broader FEW communities, while informing scientists in the food and energy domains about our unique skillset. This paper explores the relevance of existing and ongoing scholarship within the water community, as well as current research needs, for understanding FEW processes and systems and implementing FEW solutions through innovations in technologies, infrastructures, and policies …",Elsevier,,2018
731,Impacts of climate change on agricultural water management: a review,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BptBqwMAAAAJ&citation_for_view=BptBqwMAAAAJ:UeHWp8X0CEIC,"This study provides an overview on the impacts of climate change on agricultural water management, including agricultural water requirement, water availability and water quality, and the transition of those impacts to crop yield, agricultural land suitability and livestock production systems, considering both long‐term trends of climate and extreme climatic events. A synthesis of findings from local, regional, and global studies guides this article's discussion of scientifically based information, implications for managing the risk of water scarcity and food insecurity, and future research. Negative and positive climate change impacts occurring at the local scale may counteract each other at the global scale (e.g., those on irrigation requirement and arable land availability); the impacts from the various factors can be counter‐balanced too (e.g., CO2 and water deficit impact on crop yield). Meanwhile, the shocks at the local and …","John Wiley & Sons, Inc.",Wiley Interdisciplinary Reviews: Water,2015
732,Socio-hydrology: a new understanding to unite or a new science to divide?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BptBqwMAAAAJ&citation_for_view=BptBqwMAAAAJ:aqlVkmm33-oC,"The socio-hydrology community has been very successful in promoting the need for taking the human factor into account in the mainstream hydrology literature since 2012. However, the interest in studying and modeling human-water systems is not new and pre-existed the post-2012 socio-hydrology. So, it is critical to ask what socio-hydrology has been able to offer that would have been unachievable using the existing methods, tools, and analysis frameworks. Thus far, the socio-hydrology studies show a strong overlap with what has already been in the literature, especially in the water resources systems and coupled human and natural systems (CHANS) areas. Nevertheless, the work in these areas has been generally dismissed by the socio-hydrology literature. This paper overviews some of the general concerns about originality, practicality, and contributions of socio-hydrology. It is argued that while in theory, a common sense about the need for considering humans as an integral component of water resources systems models can strengthen our coupled human-water systems research, the current approaches and trends in socio-hydrology can make this interest area less inclusive and interdisciplinary.",MDPI,,2020
733,Assessing the value of seasonal climate forecast information through an end‐to‐end forecasting framework: Application to US 2012 drought in central Illinois,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BptBqwMAAAAJ&citation_for_view=BptBqwMAAAAJ:2osOgNQ5qMEC,"This study proposes an end‐to‐end forecasting framework to incorporate operational seasonal climate forecasts to help farmers improve their decisions prior to the crop growth season, which are vulnerable to unanticipated drought conditions. The framework couples a crop growth model with a decision‐making model for rainfed agriculture and translates probabilistic seasonal forecasts into more user‐related information that can be used to support farmers' decisions on crop type and some market choices (e.g., contracts with ethanol refinery). The regional Climate‐Weather Research and Forecasting model (CWRF) driven by two operational general circulation models (GCMs) is used to provide the seasonal forecasts of weather parameters. To better assess the developed framework, CWRF is also driven by observational reanalysis data, which theoretically can be considered as the best seasonal forecast. The …",,,2014
734,Advancing the Use of Hydroclimatic Forecasts for Water Resources Decision-Making II Oral,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BptBqwMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BptBqwMAAAAJ:blknAaTinKkC,,AGU,,2025
735,End-to-End Graph Neural Networks for Real-Time Hydraulic Prediction in Stormwater Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BptBqwMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BptBqwMAAAAJ:JV2RwH3_ST0C,"Urban stormwater systems (SWS) play a critical role in protecting communities from pluvial flooding, ensuring public safety, and supporting resilient infrastructure planning. As climate variability intensifies and urbanization accelerates, there is a growing need for timely and accurate hydraulic predictions to support real-time control and flood mitigation strategies. While physics-based models such as SWMM provide detailed simulations of rainfall-runoff and flow routing processes, their computational demands often limit their feasibility for real-time applications. Surrogate models based on machine learning offer faster alternatives, but most rely on fully connected or grid-based architectures that struggle to capture the irregular spatial structure of drainage networks, often requiring precomputed runoff inputs and focusing only on node-level predictions. To address these limitations, we present GNN-SWS, a novel end-to-end graph neural network (GNN) surrogate model that emulates rainfall-driven hydraulic behavior across stormwater systems. The model predicts hydraulic states at both junctions and conduits directly from rainfall inputs, capturing the coupled dynamics of runoff generation and flow routing. It incorporates a spatiotemporal encoder–processor–decoder architecture with tailored message passing, autoregressive forecasting, and physics-guided constraints to improve predictive accuracy and physical consistency. Additionally, a training strategy based on the pushforward trick enhances model stability over extended prediction horizons. Applied to a real-world urban watershed, GNN-SWS demonstrates strong potential as a fast, scalable …",Copernicus Publications,,2025
736,Multi-fidelity graph neural networks for efficient and accurate flood hazard mapping,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BptBqwMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BptBqwMAAAAJ:M3NEmzRMIkIC,"Generating high-resolution flood hazard maps with traditional hydrodynamic models is computationally prohibitive. While surrogate models like graph neural networks (GNNs) offer a faster alternative, they require large, expensive-to-generate, high-fidelity training datasets. This study addresses the critical challenge of creating accurate surrogate models with limited high-fidelity data. We propose a novel multi-fidelity graph neural network (MFGNN) framework that integrates numerous inexpensive, coarse-resolution simulations with a few high-fidelity runs. The method uses a hierarchical pipeline where one GNN learns broad flood patterns from low-fidelity data, and a second GNN learns to predict and apply a high-resolution correction based on the residual error. Comprehensive validation across diverse fluvial and pluvial flood scenarios demonstrates that the MFGNN framework significantly reduces prediction …",Elsevier,,2025
737,Evaluating the suitability of direct air carbon capture and storage in Virginia using geospatial multi-criteria decision analysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BptBqwMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BptBqwMAAAAJ:j3f4tGmQtD8C,"Direct Air Carbon Capture and Storage (DACCS) is an emerging technology with significant potential to mitigate climate change by removing carbon dioxide directly from the atmosphere. While past studies have evaluated environmental impacts and economic feasibility of DACCS using Life Cycle Assessment and Techno-Economic Assessment, there is a significant gap in localized assessments of DACCS suitability to better inform and facilitate its implementation in geographic areas where it will be deployed. In this study, we developed a framework that combines geospatial analysis with Multi-Criteria Decision Analysis (MCDA) to facilitate a detailed, localized suitability analysis for DACCS implementation, considering economic, environmental, and social factors. Additionally, we created a web-based decision support tool to streamline the evaluation process for potential DACCS implementation, enhancing …",Pergamon,Renewable and Sustainable Energy Reviews,2025
738,Deep learning-based downscaling of global digital elevation models for enhanced urban flood modeling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BptBqwMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BptBqwMAAAAJ:4JMBOYKVnBMC,"Urban flood modeling depends heavily on the quality of Digital Elevation Models (DEMs). However, accurate, high-resolution DEMs are often expensive and not widely available, particularly in data-limited regions. Consequently, researchers frequently rely on Global Digital Elevation Models (GDEMs), which suffer from vertical biases and limited spatial resolution. This limitation is especially critical in urban settings, where detailed terrain features are essential for accurate flood prediction. In this study, we introduce a novel methodology that leverages Convolutional Neural Network (CNN) architecture (U-Net) and utilizes GDEMs and other publicly available datasets (e.g., Landsat-8, Sentinel-1, and Sentinel-2) to produce an enhanced DEM with a 5-meter spatial resolution. Using USGS high-resolution DEMs as a reference, our results demonstrate that our method is able to generate DEMs with significantly lower …",Elsevier,,2025
739,A 3D model of muscle reveals the causes of nonuniform strains in the biceps brachii,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fxD7IF0AAAAJ&citation_for_view=fxD7IF0AAAAJ:9yKSN-GCB0IC,"Biomechanical models generally assume that muscle fascicles shorten uniformly. However, dynamic magnetic resonance (MR) images of the biceps brachii have recently shown nonuniform shortening along some muscle fascicles during low-load elbow flexion (J. Appl. Physiol. 92 (2002) 2381). The purpose of this study was to uncover the features of the biceps brachii architecture and material properties that could lead to nonuniform shortening. We created a three-dimensional finite-element model of the biceps brachii and compared the tissue strains predicted by the model with experimentally measured tissue strains. The finite-element model predicted strains that were within one standard deviation of the experimentally measured strains. Analysis of the model revealed that the variation in fascicle lengths within the muscle and the curvature of the fascicles were the primary factors contributing to nonuniform …",Elsevier,,2005
740,Three-dimensional representation of complex muscle architectures and geometries,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fxD7IF0AAAAJ&citation_for_view=fxD7IF0AAAAJ:d1gkVwhDpl0C,"Almost all computer models of the musculoskeletal system represent muscle geometry using a series of line segments. This simplification (i) limits the ability of models to accurately represent the paths of muscles with complex geometry and (ii) assumes that moment arms are equivalent for all fibers within a muscle (or muscle compartment). The goal of this work was to develop and evaluate a new method for creating three-dimensional (3D) finite-element models that represent complex muscle geometry and the variation in moment arms across fibers within a muscle. We created 3D models of the psoas, iliacus, gluteus maximus, and gluteus medius muscles from magnetic resonance (MR) images. Peak fiber moment arms varied substantially among fibers within each muscle (e.g., for the psoas the peak fiber hip flexion moment arms varied from 2 to 3 cm, and for the gluteus maximus the peak fiber hip extension …",Kluwer Academic Publishers-Plenum Publishers,,2005
741,Relationships of 35 lower limb muscles to height and body mass quantified using MRI,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fxD7IF0AAAAJ&citation_for_view=fxD7IF0AAAAJ:JV2RwH3_ST0C,"Skeletal muscle is the most abundant tissue in the body and serves various physiological functions including the generation of movement and support. Whole body motor function requires adequate quantity, geometry, and distribution of muscle. This raises the question: how do muscles scale with subject size in order to achieve similar function across humans? While much of the current knowledge of human muscle architecture is based on cadaver dissection, modern medical imaging avoids limitations of old age, poor health, and limited subject pool, allowing for muscle architecture data to be obtained in vivo from healthy subjects ranging in size. The purpose of this study was to use novel fast-acquisition MRI to quantify volumes and lengths of 35 major lower limb muscles in 24 young, healthy subjects and to determine if muscle size correlates with bone geometry and subject parameters of mass and height. It was …",Elsevier,,2014
742,Accuracy of muscle moment arms estimated from MRI‐based musculoskeletal models of the lower extremity,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fxD7IF0AAAAJ&citation_for_view=fxD7IF0AAAAJ:qUcmZB5y_30C,"Objective: Biomechanical models that compute the lengths and moment arms of soft tissues are broadly applicable to the treatment of movement abnormalities and the planning of orthopaedic surgical procedures. The goals of this study were to: (i) develop methods to construct subject-specific biomechanical models from magnetic resonance (MR) images, (ii) create models of three lower-extremity cadaveric specimens, and (iii) quantify the accuracy of muscle-tendon lengths and moment arms estimated using these models. Materials and Methods: Models describing the paths of the medial hamstrings and psoas muscles for a wide range of body positions were developed from MR images in one joint configuration by defining kinematic models of the hip and knee, and by specifying “wrapping surfaces” that simulate interactions between the muscles and underlying structures. Our methods for constructing these …","John Wiley & Sons, Inc.",,2000
743,"Image‐based musculoskeletal modeling: applications, advances, and future opportunities",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fxD7IF0AAAAJ&citation_for_view=fxD7IF0AAAAJ:2osOgNQ5qMEC,"Computer models of the musculoskeletal system are broadly used to study the mechanisms of musculoskeletal disorders and to simulate surgical treatments. Musculoskeletal models have historically been created based on data derived in anatomical and biomechanical studies of cadaveric specimens. MRI offers an abundance of novel methods for acquisition of data from living subjects and is revolutionizing the field of musculoskeletal modeling. The need to create accurate, individualized models of the musculoskeletal system is driving advances in MRI techniques including static imaging, dynamic imaging, diffusion imaging, body imaging, pulse‐sequence design, and coil design. These techniques apply to imaging musculoskeletal anatomy, muscle architecture, joint motions, muscle moment arms, and muscle tissue deformations. Further advancements in image‐based musculoskeletal modeling will expand the …","Wiley Subscription Services, Inc., A Wiley Company",Journal of Magnetic Resonance Imaging: An Official Journal of the International Society for Magnetic Resonance in Medicine,2007
744,A shape-based functional index for objective assessment of pediatric motor function,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fxD7IF0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fxD7IF0AAAAJ:86PQX7AUzd4C,"Clinical assessments for neuromuscular disorders, such as Spinal Muscular Atrophy (SMA) and Duchenne Muscular Dystrophy (DMD), continue to rely on subjective measures to monitor treatment response and disease progression. We introduce a novel method using wearable sensors to objectively assess motor function during daily activities in 19 patients with DMD, 9 with SMA, and 13 age-matched controls. Pediatric movement data is complex due to confounding factors such as limb length variations in growing children and variability in movement speed. Our approach uses Shape-based Principal Component Analysis to align movement trajectories and identify distinct kinematic patterns, including variations in motion speed and asymmetry. Both DMD and SMA cohorts have individuals with motor function on par with healthy controls. Notably, patients with SMA showed greater activation of the motion asymmetry pattern. We further combined projections on these principal components with partial least squares (PLS) to identify a covariation mode with a canonical correlation of r = 0.78 (95% CI: [0.34, 0.94]) with muscle fat infiltration, the Brooke score (a motor function score) and age-related degenerative changes, proposing a novel motor function index. This data-driven method has the potential to inform future home deployments with wearable devices, allowing better longitudinal tracking of treatment efficacy for children with neuromuscular disorders.",Public Library of Science,,2025
745,A deep learning algorithm for automatic 3D segmentation and quantification of hamstrings musculotendon injury from MRI,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fxD7IF0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fxD7IF0AAAAJ:_5tno0g5mFcC,"In high-velocity sports, hamstring strain injuries are common causes of missed play and have high rates of reinjury. Evaluating the severity and location of a hamstring strain injury, currently graded by a clinician using a semiqualitative muscle injury classification score (e.g. as one method, British Athletics Muscle Injury Classification - BAMIC) to describe edema presence and location, aids in guiding athlete recovery. In this study, automated artificial intelligence (AI) models were developed and deployed to automatically segment edema, hamstring muscle and tendon structures using T2-weighted and T1-weighted magnetic resonance images (MRI), respectively. MR scans were collected from collegiate football athletes at time-of-hamstring injury and return to sport. Volume, length, and cross-sectional (CSA) measurements were performed on all structures and subregions (i.e. free tendon and aponeurosis). The …",Nature Publishing Group UK,,2025
746,Electrical impedance myography captures features of muscle structure measured by MRI and transcriptomic analysis in facioscapulohumeral muscular dystrophy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fxD7IF0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fxD7IF0AAAAJ:6ZxmRoH8BuwC,"Background Electrical impedance myography (EIM) has been proposed as an efficient, non-invasive biomarker of muscle composition in facioscapulohumeral muscular dystrophy (FSHD). Objective We investigate whether EIM parameters are associated with muscle structure measured by magnetic resonance imaging (MRI), muscle histology, and transcriptomic analysis as well as strength at the individual leg muscle level. Methods We performed a multi-center cross-sectional study enrolling 33 patients with FSHD. EIM measurements were recorded from bilateral vastus lateralis, tibialis anterior (TA), and medial gastrocnemius muscles and compared to quantitative muscle volume measures by MRI as well as knee extension and ankle dorsiflexion strength by quantitative muscle testing. EIM measurements of the bilateral TA were further compared to histology and transcriptomic analysis (RNAseq) of muscle and fat content …",SAGE Publications,,2025
747,214PMulti-scale machine learning model predicts muscle and functional disease progression in FSHD,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fxD7IF0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fxD7IF0AAAAJ:2VqYfGB8ITEC,"Facioscapulohumeral muscular dystrophy (FSHD) is a genetic neuromuscular disorder characterized by progressive muscle degeneration with substantial variability in severity and progression patterns, which greatly limits the design and execution of clinical trials. This study introduces a multi-scale machine learning framework leveraging whole-body magnetic resonance imaging (MRI) and clinical data to predict regional, muscle, joint, and functional progression in FSHD. The goal this work is to create a ‘digital twin’ of individual FSHD patients that can be leveraged in clinical trials. Using a dataset of over 100 patients from seven studies, MRI-derived metrics - including fat fraction, lean muscle volume, and fat spatial heterogeneity at baseline - were integrated with clinical and functional measures. A 3-stage random forest model was developed to predict annualized changes in muscle composition and a functional …",Elsevier,,2025
748,3D finite element models reveal regional fatty infiltration modulates tibialis anterior force generating capacity in FSHD,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fxD7IF0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fxD7IF0AAAAJ:YohjEiUPhakC,"Facioscapulohumeral muscular dystrophy (FSHD) is a progressive neuromuscular disorder characterized by muscle damage, fibro-fatty infiltration, and ultimately weakness. The tibialis anterior (TA), very often involved relatively early in FSHD, is a primary dorsiflexor and important for ambulation. Recent work using magnetic resonance imaging to quantify fat infiltration in the TA volume observed a steep decline in force generation after fat reached ~20% in volume. Additional imaging studies have identified regional fat infiltration patterns that may contribute to the non-linear relationship between fat volume and muscle strength due to the distribution of fat within the muscle structure. The goals of this study were to 1) develop a pipeline for creating subject-specific models of the TA that include fat infiltration patterns measured from MRI and predict force generation, 2) compare models created using this pipeline with clinical measures of muscle strength, and 3) use the models to investigate the impact of regional fat distribution on muscle force generation. Twelve subject-specific models were created, and the model-predicted forces strongly correlate to clinical measures of strength in the same subjects (manual muscle testing (MMT): r = 0.75, and quantitative muscle testing (QMT): r = 0.54). The models showed fat amount accounts for 48% and muscle volume accounts for 74% of the variation in force. To investigate the impact of fat distribution, we developed eight pseudo maps to systematically vary fat location and amount in all subject-specific geometries. The models revealed that fat location modulates force generation, with the middle region …",Public Library of Science,,2025
749,Roadmap of optical communications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KFLFbWoAAAAJ&citation_for_view=KFLFbWoAAAAJ:vDijr-p_gm4C,"Lightwave communications is a necessity for the information age. Optical links provide enormous bandwidth, and the optical fiber is the only medium that can meet the modern society's needs for transporting massive amounts of data over long distances. Applications range from global high-capacity networks, which constitute the backbone of the internet, to the massively parallel interconnects that provide data connectivity inside datacenters and supercomputers. Optical communications is a diverse and rapidly changing field, where experts in photonics, communications, electronics, and signal processing work side by side to meet the ever-increasing demands for higher capacity, lower cost, and lower energy consumption, while adapting the system design to novel services and technologies. Due to the interdisciplinary nature of this rich research field, Journal of Optics has invited 16 researchers, each a world …",IOP Publishing,Journal of optics,2016
750,Free-space optical MIMO transmission with Q-ary PPM,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KFLFbWoAAAAJ&citation_for_view=KFLFbWoAAAAJ:u5HHmVD_uO8C,"The use of multiple laser transmitters combined with multiple photodetectors (PDs) is studied for terrestrial, line-of-sight optical communication. The resulting multiple-input/multiple-output channel has the potential for combatting fading effects on turbulent optical channels. In this paper, the modulation format is repetition Q-ary PPM across lasers, with intensity modulation. Ideal PDs are assumed, with and without background radiation. Both Rayleigh and log-normal fading models are treated. The focus is upon both symbol-/bit-error probability for uncoded transmission, and on constrained channel capacity.",IEEE,,2005
751,Volterra series transfer function of single-mode fibers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KFLFbWoAAAAJ&citation_for_view=KFLFbWoAAAAJ:O3NaXMp0MMsC,"A nonrecursive Volterra series transfer function (VSTF) approach for solving the nonlinear Schrodinger (NLS) wave equation for a single-mode optical fiber is presented. The derivation of the VSTF is based on expressing the NLS equation In the frequency domain and retaining the most significant terms (Volterra kernels) in the resulting transfer function. Due to its nonrecursive property and closed-form analytic solution, this method can excel as a tool for designing optimal optical communication systems and lumped optical equalizers to compensate for effects such as linear dispersion, fiber nonlinearities and amplified spontaneous emission (ASE) noise from optical amplifiers. We demonstrate that a third-order approximation to the VSTF model compares favorably with the split-step Fourier (recursive) method in accuracy for power levels used in current optical communication systems. For higher power levels, there is …",IEEE,,1997
752,Optical repetition MIMO transmission with multipulse PPM,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KFLFbWoAAAAJ&citation_for_view=KFLFbWoAAAAJ:UeHWp8X0CEIC,"We study the use of multiple laser transmitters combined with multiple photodetectors for atmospheric, line-of-sight optical communication, and focus upon the use of multiple-pulse-position-modulation as a power-efficient transmission format, with signal repetition across the laser array. Ideal (photon counting) photodetectors are assumed, with and without background radiation. The resulting multiple-input/multiple-output channel has the potential for combating fading effects on turbulent optical channels, for which both log-normal and Rayleigh-fading models are treated. Our focus is upon symbol error probability for uncoded transmission, and on capacity for coded transmission. Full spatial diversity is obtained naturally in this application.",IEEE,,2005
753,Monopulse DOA estimation of two unresolved Rayleigh targets,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KFLFbWoAAAAJ&citation_for_view=KFLFbWoAAAAJ:qjMakFHDy7sC,"This paper provides for new approaches to the processing of unresolved measurements as two direction-of-arrival (DOA) measurements for tracking closely spaced targets rather than the conventional single DOA measurement of the centroid. The measurements of the two-closely spaced targets are merged when the target echoes are not resolved in angle, range, or radial velocity (i.e., Doppler processing). The conditional Cramer Rao lower bound (CRLB) is developed for the DOA estimation of two unresolved Rayleigh targets using a standard monopulse radar. Then the modified CRLB is used to give insight into the boresight pointing for monopulse DOA estimation of two unresolved targets. Monopulse processing is considered for DOA estimation of two unresolved Rayleigh targets with known or estimated relative radar cross section (RCS). The performance of the DOA estimator is studied via Monte Carlo …",IEEE,,2002
754,Physical-Layer Impairment Estimation for Arbitrary Spectral-Shaped Signals in C+ L-Band Optical Networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KFLFbWoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=KFLFbWoAAAAJ:sJsF-0ZLhtgC,"Fiber-optic networks are the data transmission foundation of modern communications. Traditional C-band transmission can no longer meet the escalating communication demands, prompting the commercialization of C+L-band fiber-optic networks as a solution. Accurate modeling of physical-layer impairments (PLIs) is crucial for optimizing the performance of backbone fiber-optic networks. The widely-applied inter-channel stimulated Raman scattering-Gaussian noise (ISRS-GN) model has been developed to analytically estimate the accumulation of noise considering the ISRS effects during C+L-band signal transmission in a state-dependent manner. However, this model assumes that signals have rectangular spectra, leading to significant estimation errors when this assumption is violated. In practice, signal spectra are not rectangular; they are typically root-raised-cosine-shaped at transmission and are affected …",IEEE,,2025
755,Modeling Nonlinear Noise for Arbitrary Pulse Shapes in Optical Fiber Communication Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KFLFbWoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=KFLFbWoAAAAJ:4X0JR2_MtJMC,"This paper introduces a modulation-format-dependent nonlinear model that accounts for the impact of non-rectangular pulse shapes on fiber nonlinearity. Our findings reveal that additional nonlinear terms must be considered for such pulse shapes. While previous modulation-format-dependent models align with our model for root-raised cosine pulses with minimal roll-off, they diverge as roll-off increases. Notably, our approach improves NLI estimation accuracy, reducing errors by approximately 0.5 dB for raised cosine pulses with large roll-off factors at high launch powers. Moreover, when compared to a recently proposed GN-based model designed for root-raised cosine pulses, our model demonstrates significantly greater accuracy, with discrepancies reaching up to 1 dB in SNR for a roll-off factor of 0.5.",IEEE,,2025
756,ISRS-Enhanced PLI-Aware Routing for Multi-Band Elastic Optical Networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KFLFbWoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=KFLFbWoAAAAJ:2tRrZ1ZAMYUC,"With the growing demand for high-bandwidth applications, traditional optical networks are reaching their capacity limits. Multi-band elastic optical networks (MB-EONs) have emerged as a cost-effective and promising solution to enhance spectral efficiency by utilizing spectrum slots across multiple bands beyond the C-band. However, the performance of MBEONs is significantly affected by physical layer impairments (PLIs), including amplified spontaneous emission (ASE), nonlinear interference (NLI), and inter-channel stimulated Raman scattering (ISRS), which complicate dynamic resource allocation and degrade the quality of transmission (QoT). To address these challenges, we propose an ISRS-Enhanced PLI-Aware (IE-PLIA) routing algorithm for MB-EON resource allocation, explicitly accounting for PLIs under the influence of ISRS. Unlike prior approaches, IE-PLIA dynamically adjusts routing costs based on …",IEEE,,2025
757,Angle diversity receiver as a key enabler for reliable ORIS-based Visible Light Communication,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KFLFbWoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=KFLFbWoAAAAJ:lvd772isFD0C,"Visible Light Communication (VLC) offers a promising solution to satisfy the increasing demand for wireless data. However, link blockages remain a significant challenge. This paper addresses this issue by investigating the combined use of angle diversity receivers (ADRs) and optical reconfigurable intelligent surfaces (ORISs) in multiuser VLC systems. We consider ORIS elements as small movable mirrors. We demonstrate the complementarity of ADR and ORIS in mitigating link blockages, as well as the advantages of using a larger number of ORIS elements due to the increased field-of-view (FoV) at the receiver enabled by the ADR. An optimization algorithm is proposed to maximize the minimum signal-to-noise power ratio (SNR) to deploy a fair communication network. Numerical results show that integrating ADR and ORIS significantly enhances VLC communication performance, achieving an SNR gain of up to 30 dB compared to a system without ORIS, and mitigating communication outages produced by link blockages or out-of-FoV received signals. We also prove that an ADR with a single tier of photodiodes is sufficient to complement ORIS-assisted VLC.",,,2025
758,Channel-Based ICXT-and NLI-Aware Service Provisioning for Multi-Band Over SDM Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KFLFbWoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=KFLFbWoAAAAJ:AHdEip9mkN0C,"The relentless surge in bandwidth demands fueled by 5G and beyond necessitates a paradigm shift in optical network design. This paper introduces a novel, channel-based resource allocation framework for multi-band over space-division multiplexing optical networks, meticulously addressing the intertwined challenges of inter-core crosstalk (ICXT), inter-channel stimulated Raman scattering (ISRS), and fiber non-linear impairments. By leveraging a sophisticated generalized signal-to-noise ratio model that dynamically accounts for frequency-dependent ICXT and ISRS, we propose two innovative algorithms-Core-Spectrum-Band (CSB) and Band-Spectrum-Core (BSC)-to optimize resource allocation for multi-core fiber (MCF) and compare their performance with bundled multi-fiber pair (BuMFP) architectures. Extensive simulations on the US Backbone network demonstrate the superior performance of our approach …",IEEE,,2025
759,Bayesian networks for system reliability reassessment,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XuS4n6UAAAAJ&citation_for_view=XuS4n6UAAAAJ:roLk4NBRz8UC,"This paper proposes a methodology to apply Bayesian networks to structural system reliability reassessment, with the incorporation of two important features of large structures: (1) multiple failure sequences, and (2) correlations between component-level limit states. The proposed method is validated by analytical comparison with the traditional reliability analysis methods for series and parallel systems. The Bayesian network approach is combined with the branch-and-bound method to improve its efficiency and to facilitate its application to large structures. A framed structure with multiple potential locations of plastic hinges and multiple failure sequences is analyzed to illustrate the proposed method.",Elsevier,,2001
760,Efficient first-order reliability analysis of multidisciplinary systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XuS4n6UAAAAJ&citation_for_view=XuS4n6UAAAAJ:aqlVkmm33-oC,"This paper develops two algorithms that address the reliability evaluation of complex multidisciplinary engineering systems. In particular, systems with feedback coupling – a common characteristic of many multidisciplinary analyses – are considered. In such analyses, iterative convergence loops are needed to resolve inconsistencies in feedback variables. Assessing the reliability of such systems with a traditional 'black box' or fully coupled approach requires Multidisciplinary Analysis (MDA) convergence loops nested inside iterative loops for probabilistic analysis. The resulting computational effort is unacceptable for most high fidelity analyses. Therefore, this paper proposes two first-order reliability analysis methods that efficiently apply probabilistic analysis to multidisciplinary systems with feedback using a decoupling approach. The first method uses a First-Order Second Moment (FOSM) technique to …",Inderscience Publishers,,2006
761,Probabilistic methods for aerospace system conceptual design,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XuS4n6UAAAAJ&citation_for_view=XuS4n6UAAAAJ:MXK_kJrjxJIC,"Nomenclature abf= body-ap area ratio, ft2/ft2 atf= tip-fi n area ratio, ft2/ft2 aw= wing area ratio, ft2/ft2 bl= ballast weight fraction (lb/lb) Cm= pitching moment coeffi cient g= limit state function Pf= probability of failure r f= fuselage fi ness ratio, ft/ft rm= mass ratio (lb/lb) W= vehicle dry weight (lb) X0= vector of reduced normal variables X0¤= most probable point®= direction cosine= reliability index ¹= mean value ¾= standard deviation 8= standard normal cumulative distribution function r= gradient",,,2003
762,Integrating system-level and component-level designs under uncertainty,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XuS4n6UAAAAJ&citation_for_view=XuS4n6UAAAAJ:kNdYIx-mwKoC,"TODAY’S aerospace industry is faced with the challenge of en-gineering complex systems for which cost effectiveness and reliability are given the highest priority. Consider for example two goals for next-generation reusable launch vehicles (RLV): 1) a $1000/lb ($2205/kg) or less cost for payload delivery and 2) a less than 1/10,000 risk of crew loss. 1 This will require significant improvement (10-fold and 100-fold, respectively) over the current generation. Whether these targets are achievable remains to be seen,",,,2005
763,System risk assessment and allocation in conceptual design,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XuS4n6UAAAAJ&citation_for_view=XuS4n6UAAAAJ:4TOpqqG69KYC,"As aerospace systems continue to evolve in addressing newer challenges in air and space transportation, there exists a heightened priority for significant improvement in system performance, cost effectiveness, reliability, and safety. Tools, which synthesize multidisciplinary integration, probabilistic analysis, and optimization, are needed to facilitate design decisions allowing trade-offs between cost and reliability. This study investigates tools for probabilistic analysis and probabilistic optimization in the multidisciplinary design of aerospace systems. A probabilistic optimization methodology is demonstrated for the low-fidelity design of a reusable launch vehicle at two levels, a global geometry design and a local tank design. Probabilistic analysis is performed on a high fidelity analysis of a Navy missile system. Furthermore, decoupling strategies are introduced to reduce the computational effort required for multidisciplinary systems with feedback coupling.",,,2003
764,Teamwork Development and Evaluation for Hybrid Thermal Fluids Laboratory Course,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XuS4n6UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XuS4n6UAAAAJ:KlAtU1dfN6UC,"Laboratory courses provide an opportunity for students to practice engineering skills in ways not possible in a traditional classroom environment. Hands-on activities challenge their creativity, problem-solving, and critical thinking. Beyond that, labs are an ideal platform for developing teamwork and communication.",,,2021
765,Integration of Instructional Technology Tools Including Matlab Grader to Enhance Learning in a Hybrid Vibrations Course,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XuS4n6UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XuS4n6UAAAAJ:M3ejUd6NZC8C,"This paper discusses the delivery of a 4-week summer course in Vibrations to a diverse group of face-to-face and online graduate students, with a focus on how instructional technology tools enabled learning. The tools were selected to engage students in multiple formats: 1) those that attended class in person, 2) those who participated in the live stream class, and 3) those who would watch the recorded class later in the day. The Matlab Grader feature was instrumental in providing students practice with computational solutions to vibrations problems. With this tool, instructors create assignments that students solve with a Matlab script. When the student submits his or her own code, it is automatically graded against the specified output of the instructor solution. Though it would be useful regardless of delivery mode, the Grader was particularly valuable in getting real-time feedback to students in keeping with the fast pace of the summer course. Other homework assignments were peer-graded within the learning management system. Lectures were delivered as ‘live’notes using PDFAnnotator. Note taking has been shown to improve learning, so this was preferred over using premade slides. At the same time, traditional board notes would not have been easy for online students to read. The final instructor notes were then made available to all. Students were able to join the lecture via Zoom, a video conferencing platform. Pauses in lecture allowed for questions and comments from both the live class and via the chat feature within Zoom. The versatility of Zoom was also critical for evening office hours. The ability to screen share was especially valuable …",,,2020
766,Scaffolded Laboratory Sequence: Mechanics Lab,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XuS4n6UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XuS4n6UAAAAJ:5nxA0vEk-isC,"Laboratory courses are a platform for students to practice skills essential to the engineering profession. They should also foster lower-level learning (eg understanding of fundamental concepts) and higher-level synthesis and creativity. The undergraduate programs for Mechanical and Aerospace (MAE) Engineering are being enriched with an updated experimental laboratory sequence, which include three 2-hour courses: 1) Mechanics Laboratory, 2) Thermal Fluids Laboratory, and 3) Aerospace or Mechanical Laboratory. The first two courses are being designed to supplement lecture-based theory courses during the same semester students are taking them. The third course will challenge students to design and execute their own experiments, building upon skills they learn in the earlier labs. Thus, the new sequence includes horizontal integration with discipline courses across the curriculum, and vertical scaffolding of skills related to experiment design and analysis.",,,2020
767,Guided Peer Review of Technical Writing for Large Laboratory Course,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XuS4n6UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XuS4n6UAAAAJ:d1gkVwhDpl0C,"Laboratory courses, and in particular laboratory reports, are logical choices to assess two particular student outcomes:‘the ability to design and conduct experiments, as well as to analyze and interpret data;’and ‘the ability to communicate effectively.’If students can articulate a clear objective, demonstrate a sound experimental procedure, and offer analysis supporting reasoned conclusions, they will have demonstrated proficiency in both outcomes. However, though assessing these outcomes may be straightforward, actually teaching these skills can be a time-intensive challenge, particular when dealing with large sections. Simply engaging a single draft of one report to provide meaningful feedback can easily take 30 minutes (50 hours per 100 papers), if not more. Allowing groups reports can reduce the workload, but may not ensure that everyone is gaining the same level of practice. Delegating this job to teaching assistants is another option but can lead to issues with consistency. A final option is to leverage peer feedback, which has some obvious benefits and significant challenges.",,,2019
768,Design and implementation of a course in experimental design and technical writing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XuS4n6UAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XuS4n6UAAAAJ:LkGwnXOMwfcC,"This paper describes the development, implementation, and refinement of a sophomore level laboratory course entitled “Experimental Design and Technical Writing.” The course was created to meet multiple objectives for a Bachelor of Science in Engineering (BSE) program at []. First, stakeholders on the program advisory board affirmed the importance and need for improvement in the communication skills of early career engineers. They expressed a desire for employees to excel with various formats of written memoranda and reports and to have the ability to comfortably deliver formal and informal oral presentations. Second, the prior curriculum lacked any courses in the sophomore year with a significant experiential learning component. Experiential learning is a highly valued component of the program with a positive effect on student retention and success. Outcome assessment activities had also identified a need to cover ethics during the sophomore year. Finally, in 2014, the university revamped the general education curriculum required for all bachelor degree programs; a component of the new curriculum requires students have two “Writing Intensive” embedded experience courses, the first of which is intended to be at a sophomore level, after they have completed two English composition courses.",,,2018
769,Identifying wireless users via transmitter imperfections,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hB0D494AAAAJ&citation_for_view=hB0D494AAAAJ:u5HHmVD_uO8C,"Variations in the RF chain of radio transmitters can be used as a signature to uniquely associate wireless devices with a given transmission. Previous approaches, which have varied from transient analysis to machine learning, do not provide verifiable accuracy, which is essential for admissibility of the methods in the court. Here we detail a first step toward a model-based approach, which uses statistical models of RF transmitter components that are amenable for analysis. Algorithms based on statistical signal processing methods are developed to exploit non-linearities of wireless transmitters for the purpose of user identification in wireless systems. The decision rules are derived and their performance is analyzed. In order to establish the viability of the proposed approach, the practical variations of transmitter chain components are analyzed based on simulations, measurements and manufacturers' specifications …",IEEE,,2011
770,Fc glycan-mediated regulation of placental antibody transfer,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hB0D494AAAAJ&citation_for_view=hB0D494AAAAJ:YsMSGLbcyi4C,"Despite the worldwide success of vaccination, newborns remain vulnerable to infections. While neonatal vaccination has been hampered by maternal antibody-mediated dampening of immune responses, enhanced regulatory and tolerogenic mechanisms, and immune system immaturity, maternal pre-natal immunization aims to boost neonatal immunity via antibody transfer to the fetus. However, emerging data suggest that antibodies are not transferred equally across the placenta. To understand this, we used systems serology to define Fc features associated with antibody transfer. The Fc-profile of neonatal and maternal antibodies differed, skewed toward natural killer (NK) cell-activating antibodies. This selective transfer was linked to digalactosylated Fc-glycans that selectively bind FcRn and FCGR3A, resulting in transfer of antibodies able to efficiently leverage innate immune cells present at birth. Given …",Elsevier,,2019
771,Exploring approaches for predictive cancer patient digital twins: opportunities for collaboration and innovation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hB0D494AAAAJ&citation_for_view=hB0D494AAAAJ:ULOm3_A8WrAC,"We are rapidly approaching a future in which cancer patient digital twins will reach their potential to predict cancer prevention, diagnosis, and treatment in individual patients. This will be realized based on advances in high performance computing, computational modeling, and an expanding repertoire of observational data across multiple scales and modalities. In 2020, the US National Cancer Institute, and the US Department of Energy, through a trans-disciplinary research community at the intersection of advanced computing and cancer research, initiated team science collaborative projects to explore the development and implementation of predictive Cancer Patient Digital Twins. Several diverse pilot projects were launched to provide key insights into important features of this emerging landscape and to determine the requirements for the development and adoption of cancer patient digital twins. Projects included exploring approaches to using a large cohort of digital twins to perform deep phenotyping and plan treatments at the individual level, prototyping self-learning digital twin platforms, using adaptive digital twin approaches to monitor treatment response and resistance, developing methods to integrate and fuse data and observations across multiple scales, and personalizing treatment based on cancer type. Collectively these efforts have yielded increased insights into the opportunities and challenges facing cancer patient digital twin approaches and helped define a path forward. Given the rapidly growing interest in patient digital twins, this manuscript provides a valuable early progress report of several CPDT pilot projects commenced …",Frontiers Media SA,,2022
772,Small-molecule control of antibody N-glycosylation in engineered mammalian cells,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hB0D494AAAAJ&citation_for_view=hB0D494AAAAJ:Y0pCki6q_DkC,"N-linked glycosylation in monoclonal antibodies (mAbs) is crucial for structural and functional properties of mAb therapeutics, including stability, pharmacokinetics, safety and clinical efficacy. The biopharmaceutical industry currently lacks tools to precisely control N-glycosylation levels during mAb production. In this study, we engineered Chinese hamster ovary cells with synthetic genetic circuits to tune N-glycosylation of a stably expressed IgG. We knocked out two key glycosyltransferase genes, α-1,6-fucosyltransferase (FUT8) and β-1,4-galactosyltransferase (β4GALT1), genomically integrated circuits expressing synthetic glycosyltransferase genes under constitutive or inducible promoters and generated antibodies with concurrently desired fucosylation (0–97%) and galactosylation (0–87%) levels. Simultaneous and independent control of FUT8 and β4GALT1 expression was achieved using orthogonal small …",Nature Publishing Group US,,2019
773,Dissecting N-glycosylation dynamics in Chinese hamster ovary cells fed-batch cultures using time course omics analyses,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hB0D494AAAAJ&citation_for_view=hB0D494AAAAJ:W7OEmFMy1HYC,"N-linked glycosylation affects the potency, safety, immunogenicity, and pharmacokinetic clearance of several therapeutic proteins including monoclonal antibodies. A robust control strategy is needed to dial in appropriate glycosylation profile during the course of cell culture processes accurately. However, N-glycosylation dynamics remains insufficiently understood owing to the lack of integrative analyses of factors that influence the dynamics, including sugar nucleotide donors, glycosyltransferases, and glycosidases. Here, an integrative approach involving multi-dimensional omics analyses was employed to dissect the temporal dynamics of glycoforms produced during fed-batch cultures of CHO cells. Several pathways including glycolysis, tricarboxylic citric acid cycle, and nucleotide biosynthesis exhibited temporal dynamics over the cell culture period. The steps involving galactose and sialic acid addition were …",Elsevier,,2019
774,A flexible systems analysis pipeline for elucidating spatial relationships in the tumor microenvironment linked with cellular phenotypes and patient-level features,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hB0D494AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hB0D494AAAAJ:hFOr9nPyWt4C,"Introduction Quantitative investigation of how the spatial organization of cells within the tumor microenvironment associates with disease progression, patient outcomes, and that cell’s phenotypic state remains a key challenge in cancer biology. High-dimensional multiplexed imaging offers an opportunity to explore these relationships at single-cell resolution. Methods We developed a computational pipeline to quantify and analyze the neighborhood profiles of individual cells in multiplexed immunofluorescence images. The pipeline characterizes spatial co-localization patterns within the tumor microenvironment and applies interpretable supervised machine learning models, specifically orthogonal partial least squares analysis (OPLS), to identify spatial relationships predictive of cell states and clinical phenotypes. Results We applied this framework to a previously published non-small cell lung cancer (NSCLC) cohort across four applications. At the cellular level, we identified neighborhood features associated with lymphocyte activation states. At the tumor-immune interface, we demonstrated that the immune cell composition surrounding major histocompatibility complex class I-expressing (MHC I+) tumor cells could distinguish adenocarcinoma from squamous cell carcinoma. At the patient level, spatial features predicted tumor grade. Discussion By integrating cell-segmented imaging data with interpretable modeling, our pipeline reveals key spatial determinants of tumor biology. These findings generate testable mechanistic hypotheses about intercellular interactions and support the development of spatially informed prognostic and therapeutic …",Frontiers,,2025
775,Uncovering Cellular Interactome Drivers of Immune Checkpoint Inhibitor Response in Advanced Melanoma Patients,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hB0D494AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hB0D494AAAAJ:mB3voiENLucC,"Purpose Despite the success of immune checkpoint inhibitors (ICIs) that target immunosuppressive interactions, treatment resistance remains a major clinical challenge. The tumor microenvironment is comprised of tumor, immune, and stromal cell types that communicate through secreted and cell surface proteins. This can be represented by a weighted, directed network where pairs of cell types communicate via multiple ligand-receptor interactions with varying strengths. Identifying interaction network motifs that are linked with outcome or evolve pre-to post-ICI presents a rational framework to identify combination therapeutic targets. Methods Interaction inference was performed on publicly available single-cell RNA-sequencing data from melanoma patients. The constructed patient-specific networks were input to multivariate statistical learning approaches to identify network motifs that predicted response pre …",Springer International Publishing,,2025
776,LAG3+ CD8+ T cell subset drives HR+/HER2− breast cancer reduction in bispecific antibody armed activated T cell therapy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hB0D494AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hB0D494AAAAJ:-f6ydRqryjwC,"Tumor clearance by T cells is impaired by insufficient tumor antigen recognition, insufficient tumor infiltration, and the immunosuppressive tumor microenvironment. Although targeted T cell therapy circumvents failures in tumor antigen recognition, suppression by the tumor microenvironment and failure to infiltrate the tumor can hinder tumor clearance. Checkpoint inhibitors (CPIs) promise to reverse T cell suppression and can be combined with bispecific antibody armed T cell (BAT) therapy to improve clinical outcomes. We hypothesize that adoptively transferred T cell function may be improved by the addition of CPIs if the inhibitory pathway is functionally active. This study develops a kinetic-dynamic model of killing of hormone receptor–positive breast cancer cells mediated by BATs using single-cell transcriptomic and temporal protein data to identify T cell phenotypes and quantify inhibitory receptor …",Oxford University Press,,2025
777,Abstract 2046 The long and winding road that led me to my systems immunology laboratory,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hB0D494AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hB0D494AAAAJ:qUcmZB5y_30C,"From solving circuits to unraveling the complexities of the immune system, my career has been anything but linear. While my biosketch might suggest a straightforward progression-from a BS in Electrical Engineering to a Ph. D., postdoctoral research in Biological Engineering, and leading a Systems Immunology lab at the University of Virginia-the reality is a journey shaped by unexpected twists, interdisciplinary exploration, and personal growth. These choices didn't just enrich my personal life; they profoundly influenced where I live, the communities I engage with, and the perspectives I bring to my work. Each decision along the way, from branching into a new fields of study to relocating for opportunities, required me to embrace uncertainty and adapt to change. In this talk, I will share pivotal moments that redefined my scientific vision and relationships, illustrating how curiosity, resilience, and an openness to the …",Elsevier,,2025
778,Distinct type 1 immune networks underlie the severity of restrictive lung disease after COVID-19,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hB0D494AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hB0D494AAAAJ:qxL8FJ1GzNcC,"The variable origins of persistent breathlessness after coronavirus disease 2019 (COVID-19) have hindered efforts to decipher the immunopathology of lung sequelae. Here we analyzed hundreds of cellular and molecular features in the context of discrete pulmonary phenotypes to define the systemic immune landscape of post-COVID lung disease. Cluster analysis of lung physiology measures highlighted two phenotypes of restrictive lung disease that differed according to their impaired diffusion and severity of fibrosis. Machine learning revealed marked CCR5+CD95+CD8+ T cell perturbations in milder lung disease but attenuated T cell responses hallmarked by elevated CXCL13 in more severe disease. Distinct sets of cells, mediators and autoantibodies distinguished each restrictive phenotype and differed from those of patients without substantial lung involvement. These differences were reflected in divergent …",Nature Publishing Group US,,2025
779,Structural determinants of glomerular permeability,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WrLYcHIAAAAJ&citation_for_view=WrLYcHIAAAAJ:u5HHmVD_uO8C,"Recent progress in relating the functional properties of the glomerular capillary wall to its unique structure is reviewed. The fenestrated endothelium, glomerular basement membrane (GBM), and epithelial filtration slits form a series arrangement in which the flow diverges as it enters the GBM from the fenestrae and converges again at the filtration slits. A hydrodynamic model that combines morphometric findings with water flow data in isolated GBM has predicted overall hydraulic permeabilities that are consistent with measurements in vivo. The resistance of the GBM to water flow, which accounts for roughly half that of the capillary wall, is strongly dependent on the extent to which the GBM surfaces are blocked by cells. The spatial frequency of filtration slits is predicted to be a very important determinant of the overall hydraulic permeability, in keeping with observations in several glomerular diseases in humans …",American Physiological Society,American Journal of Physiology-Renal Physiology,2001
780,Reactivation of ERK signaling causes resistance to EGFR kinase inhibitors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WrLYcHIAAAAJ&citation_for_view=WrLYcHIAAAAJ:YsMSGLbcyi4C,"The clinical efficacy of epidermal growth factor receptor (EGFR) kinase inhibitors is limited by the development of drug resistance. The irreversible EGFR kinase inhibitor WZ4002 is effective against the most common mechanism of drug resistance mediated by the EGFR T790M mutation. Here, we show, in multiple complementary models, that resistance to WZ4002 develops through aberrant activation of extracellular signal-regulated kinase (ERK) signaling caused by either an amplification of mitogen-activated protein kinase 1 (MAPK1) or by downregulation of negative regulators of ERK signaling. Inhibition of MAP–ERK kinase (MEK) or ERK restores sensitivity to WZ4002 and prevents the emergence of drug resistance. We further identify MAPK1 amplification in an erlotinib-resistant EGFR-mutant non–small cell lung carcinoma patient. In addition, the WZ4002-resistant MAPK1-amplified cells also show an …",American Association for Cancer Research,,2012
781,ERK1/2 blockade prevents epithelial–mesenchymal transition in lung cancer cells and promotes their sensitivity to EGFR inhibition,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WrLYcHIAAAAJ&citation_for_view=WrLYcHIAAAAJ:MXK_kJrjxJIC,"Overcoming cellular mechanisms of de novo and acquired resistance to drug therapy remains a central challenge in the clinical management of many cancers, including non–small cell lung cancer (NSCLC). Although much work has linked the epithelial–mesenchymal transition (EMT) in cancer cells to the emergence of drug resistance, it is less clear where tractable routes may exist to reverse or inhibit EMT as a strategy for drug sensitization. Here, we demonstrate that extracellular signal-regulated kinase (ERK) 1/2 (mitogen-activated protein kinase 3/1, MAPK3/1) signaling plays a key role in directing the mesenchymal character of NSCLC cells and that blocking ERK signaling is sufficient to heighten therapeutic responses to EGF receptor (EGFR) inhibitors. MEK1/2 (MAPKK1/2) inhibition promoted an epithelial phenotype in NSCLC cells, preventing induction of EMT by exogenous TGF-β. Moreover, in cells …",American Association for Cancer Research,,2014
782,"Cell signaling regulation by protein phosphorylation: a multivariate, heterogeneous, and context-dependent process",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WrLYcHIAAAAJ&citation_for_view=WrLYcHIAAAAJ:QIV2ME_5wuYC,"Highlights Protein phosphorylation controls protein activity, localization, and complex formation. Multivariate protein phosphorylation dynamics control cell phenotypes. Phosphorylation-dependent signaling can occur heterogeneously among cells. Phosphorylation-dependent signaling processes are influenced by the microenvironment. Different measurement techniques can capture these complexities of signaling. Proper spatiotemporal regulation of protein phosphorylation in cells and tissues is required for normal development and homeostasis, but aberrant protein phosphorylation regulation leads to various diseases. The study of signaling regulation by protein phosphorylation is complicated in part by the sheer scope of the kinome and phosphoproteome, dependence of signaling protein functionality on cellular localization, and the complex multivariate relationships that exist between protein phosphorylation …",Elsevier Current Trends,Current opinion in biotechnology,2016
783,p53Ψ is a transcriptionally inactive p53 isoform able to reprogram cells toward a metastatic-like state,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WrLYcHIAAAAJ&citation_for_view=WrLYcHIAAAAJ:Zph67rFs4hoC,"Although much is known about the underlying mechanisms of p53 activity and regulation, the factors that influence the diversity and duration of p53 responses are not well understood. Here we describe a unique mode of p53 regulation involving alternative splicing of the TP53 gene. We found that the use of an alternative 3′ splice site in intron 6 generates a unique p53 isoform, dubbed p53Ψ. At the molecular level, p53Ψ is unable to bind to DNA and does not transactivate canonical p53 target genes. However, like certain p53 gain-of-function mutants, p53Ψ attenuates the expression of E-cadherin, induces expression of markers of the epithelial-mesenchymal transition, and enhances the motility and invasive capacity of cells through a unique mechanism involving the regulation of cyclophilin D activity, a component of the mitochondrial inner pore permeability. Hence, we propose that p53Ψ encodes a separation …",National Academy of Sciences,,2014
784,The kinase ERK plays a conserved dominant role in the heterogeneity of epithelial-mesenchymal transition in pancreatic cancer cells,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WrLYcHIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=WrLYcHIAAAAJ:l7t_Zn2s7bgC,"Epithelial-mesenchymal transition (EMT) occurs heterogeneously among carcinoma cells to promote chemoresistance. Identifying the signaling pathways involved will nominate drug combinations to promote chemoresponse, but cell population–level studies can be misleading, and single-cell transcriptomics are limited to indirect ontology-based inferences. To understand EMT heterogeneity at a signaling protein level, we combined iterative indirect immunofluorescence imaging of pancreas cancer cells and tumors and mutual information (MI) analysis. Focusing first on mitogen-activated protein kinase pathways, MI indicated that cell-to-cell variation in ERK activity determined EMT heterogeneity in response to different growth factors and chemotherapeutics but that JNK compensated when MEK was inhibited. Population-level models could not capture these experimentally validated MI inferences. The dominant …",American Association for the Advancement of Science,,2025
785,Engineering suicide gene approaches to improve chemotherapeutic response in cancer,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WrLYcHIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=WrLYcHIAAAAJ:K3LRdlH-MEoC,"Disclosed are compositions and methods for treating a disease or disorder such as cancer in a subject in need thereof. In some embodiments, the methods include administering to the subject a vector that has a first nucleic acid sequence encoding a promoter operably linked to each of a second nucleic acid sequence encoding a therapeutic polypeptide, and a third nucleic acid sequence encoding a peptide domain that is stabilized when phosphorylated by kinase activity in a target cell and/or tissue. In some embodiments, the target cell and/or tissue can be a cell and/or tissue undergoing a stress response. In some embodiments, the target cell and/or tissue can be a cell and/or tissue in which a CK2 kinase is active. The kinase activity can be elevated extracellular regulated kinase (ERK) activity, p38 MAP kinase activity, and/or CK2 activity.",,,2025
786,Synergistic activity of simvastatin and irinotecan chemotherapy against glioblastoma converges on TGF-β signaling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WrLYcHIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=WrLYcHIAAAAJ:SP6oXDckpogC,"Purpose This study investigates the synergistic therapeutic potential of a novel combination of the repurposed drug simvastatin with irinotecan chemotherapy towards glioblastoma (GBM) and the underlying molecular mechanisms. Methods In vitro efficacy of simvastatin and irinotecan alone and in combination against diverse GBM lines (U251MG, G34, SB28) was assessed using mechanistically distinct cell viability assays. RNA-Sequencing was performed to uncover the top pathways and genes affected by these drugs, followed by validation of promising pathways (TGF-β signaling and cell death) using targeted phosphoproteomics and in vitro genetic manipulation and functional assays. Results We observed robust in vitro synergy at nanomolar concentrations between simvastatin and irinotecan across diverse GBM lines. Notably, irinotecan alone and in combination with simvastatin reduced mRNA expression of …",Springer US,,2025
787,ERK plays a conserved dominant role in pancreas cancer cell EMT heterogeneity driven by diverse growth factors and chemotherapies,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WrLYcHIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=WrLYcHIAAAAJ:dshw04ExmUIC,"Epithelial-mesenchymal transition (EMT) occurs heterogeneously among malignant carcinoma cells to promote chemoresistance. Identifying the signaling pathways involved will nominate drug combinations to promote chemoresponse, but cell population-level studies are inherently fraught, and single-cell transcriptomics are limited to indirect ontology-based inferences. To understand EMT heterogeneity at a signaling protein level, we combined iterative indirect immunofluorescence imaging of pancreas cancer cells and tumors and mutual information (MI) modeling. Focusing first on MAP kinase pathways, MI predicted that cell-to-cell variation in ERK activity surprisingly dominated control of EMT heterogeneity in response to diverse growth factors and chemotherapeutics, but that JNK compensated when MEK was inhibited. Population-level models could not capture these experimentally validated MI predictions. The dominant role of ERK was predicted by MI even when analyzing seven potential EMT-regulating signaling nodes. More generally, this work provides an approach for studying highly multivariate signaling/phenotype relationships based on protein measurements in any setting.",Cold Spring Harbor Laboratory,,2025
788,Hypoxia-induced histone methylation and NF-κB activation in pancreas cancer fibroblasts promote EMT-supportive growth factor secretion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WrLYcHIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=WrLYcHIAAAAJ:KxtntwgDAa4C,"The pancreatic ductal adenocarcinoma (PDAC) tumor microenvironment contains hypoxic tissue subdomains and cancer-associated fibroblasts (CAFs) of multiple subtypes that play tumor-promoting and -restraining roles. Here, we demonstrate that hypoxia promotes an inflammatory-like CAF phenotype and that hypoxic CAFs selectively promote epithelial-mesenchymal transition (EMT) in PDAC cancer cells through growth factor-mediated cell crosstalk. By analyzing patient tumor single-cell transcriptomics and conducting an inhibitor screen, we identified IGF-2 and HGF as specific EMT-inducing growth factors produced by hypoxic CAFs. We further found that reactive oxygen species-activated NF-κB cooperates with hypoxia-dependent histone methylation to promote IGF-2 and HGF expression in hypoxic CAFs. In lineage-traced autochthonous PDAC mouse tumors, hypoxic CAFs resided preferentially near hypoxic, mesenchymal cancer cells. However, in subcutaneous tumors engineered with hypoxia fate-mapped CAFs, once-hypoxic re-oxygenated CAFs lacked a spatial correlation with mesenchymal cancer cells. Thus, hypoxia promotes reversible CAF-malignant cell interactions that drive EMT through druggable signaling pathways. One-sentence summary We show that hypoxic fibroblasts in pancreas cancer leverage histone methylation and ROS-mediated NF-κB activation to produce growth factors that drive epithelial-mesenchymal transition in malignant cells, demonstrating how tumor stromal features cooperate to initiate a signaling process for disease progression.",Cold Spring Harbor Laboratory,,2025
789,Robustness of attack-resilient state estimators,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lyNOlzoAAAAJ&citation_for_view=lyNOlzoAAAAJ:LkGwnXOMwfcC,"The interaction between information technology and phys ical world makes Cyber-Physical Systems (CPS) vulnerable to malicious attacks beyond the standard cyber attacks. This has motivated the need for attack-resilient state estimation. Yet, the existing state-estimators are based on the non-realistic assumption that the exact system model is known. Consequently, in this work we present a method for state estimation in presence of attacks, for systems with noise and modeling errors. When the the estimated states are used by a state-based feedback controller, we show that the attacker cannot destabilize the system by exploiting the difference between the model used for the state estimation and the real physical dynamics of the system. Furthermore, we describe how implementation issues such as jitter, latency and synchronization errors can be mapped into parameters of the state estimation procedure that …",IEEE,,2014
790,Design and implementation of attack-resilient cyberphysical systems: With a focus on attack-resilient state estimators,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lyNOlzoAAAAJ&citation_for_view=lyNOlzoAAAAJ:Wp0gIr-vW9MC,"Recent years have witnessed a significant increase in the number of security-related incidents in control systems. These include high-profile attacks in a wide range of application domains, from attacks on critical infrastructure, as in the case of the Maroochy Water breach [1], and industrial systems (such as the StuxNet virus attack on an industrial supervisory control and data acquisition system [2], [3] and the German Steel Mill cyberattack [4], [5]), to attacks on modern vehicles [6]-[8]. Even high-assurance military systems were shown to be vulnerable to attacks, as illustrated in the highly publicized downing of the RQ-170 Sentinel U.S. drone [9]-[11]. These incidents have greatly raised awareness of the need for security in cyberphysical systems (CPSs), which feature tight coupling of computation and communication substrates with sensing and actuation components. However, the complexity and heterogeneity of this …",IEEE,,2017
791,Attack resilient state estimation for autonomous robotic systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lyNOlzoAAAAJ&citation_for_view=lyNOlzoAAAAJ:hqOjcs7Dif8C,"In this paper we present a methodology to control ground robots under malicious attack on sensors. Within the term attack we intend any malicious disturbance injection on sensors, actuators, and controller that would compromise the safety of a robot. In order to guarantee resilience against attacks, we use a control-level technique implemented within a recursive algorithm that takes advantage of redundancy in the information received by the controller. We use the case study of a vehicle cruise-control, however, the strategy we present in this work is general for several applications. Our methodology relays on redundancy in the sensor measurements: specifically we consider N velocity measurements and use a recursive filtering technique that estimates the state of the system while being resilient against sensor attacks by acting on the variance of the measurements noise. Finally, we move our focus on hardware …",IEEE,,2014
792,A cooperative heterogeneous mobile wireless mechatronic system,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lyNOlzoAAAAJ&citation_for_view=lyNOlzoAAAAJ:2osOgNQ5qMEC,"This paper describes a framework for controlling a heterogeneous wireless robotic network consisting of aerial and ground vehicles. By use of the term heterogeneous, we imply the synergy of multiple robotic platforms characterized by different dynamics and specialized sensing capabilities. Two main scenarios concerning wireless communications are presented: 1) a decentralized connectivity strategy in which a mesh of ground mobile routers swarms in a cluttered environment maintaining communication constraints based on spring-mass virtual physics, potential functions, and routing optimization and 2) an autonomous communications relay in GPS-denied environments via antenna diversity and extremum-seeking SNR optimization. For both scenarios, we validate the proposed methodologies by numerical simulations and experiments. One important feature of our test bed is that it can be used for both indoor …",IEEE,,2012
793,Online planning for energy-efficient and disturbance-aware uav operations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lyNOlzoAAAAJ&citation_for_view=lyNOlzoAAAAJ:mVmsd5A6BfQC,"In this paper we consider an online planning problem for unmanned aerial vehicle (UAV) operations. Specifically, a UAV has the task of reaching a goal from a set of possible goals while minimizing the amount of energy required. Due to unforeseen disturbances, it is possible that initially attractive goals might end up being very expensive during the execution. Thus, two main problems are investigated here: i) how to predict and plan the motion of the UAV at run time to minimize its energy consumption and ii) when to schedule next replanning time to avoid unnecessary periodic re-evaluation executions. Our approach considers a nonlinear model of the system for which a model predictive controller is used to determine the desired control inputs for each possible goal. These control inputs are then used to estimate the energy required to reach the different goals. Finally, a self-triggered scheduling policy determines …",IEEE,,2016
794,Corridor-based Adaptive Control Barrier and Lyapunov Functions for Safe Mobile Robot Navigation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lyNOlzoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=lyNOlzoAAAAJ:sSrBHYA8nusC,"Safe navigation in unknown and cluttered environments remains a challenging problem in robotics. Model Predictive Contour Control (MPCC) has shown promise for performant obstacle avoidance by enabling precise and agile trajectory tracking, however, existing methods lack formal safety assurances. To address this issue, we propose a general Control Lyapunov Function (CLF) and Control Barrier Function (CBF) enabled MPCC framework that enforces safety constraints derived from a free-space corridor around the planned trajectory. To enhance feasibility, we dynamically adapt the CBF parameters at runtime using a Soft Actor-Critic (SAC) policy. The approach is validated with extensive simulations and an experiment on mobile robot navigation in unknown cluttered environments.",,,2025
795,Optimal reference tracking with arbitrary sampling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lyNOlzoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=lyNOlzoAAAAJ:08ZZubdj9fEC,"It is a standard engineering practice to design feedback-based control to have a system follow a given trajectory. While the trajectory is continuous-time, the sequence of references is varied at discrete times, which may not be periodic. In this paper, we propose a method to determine the discrete-time references which minimizes a weighted L 2 distance between the achieved trajectory and the target trajectory. Also, we consider any arbitrary sequence of sampling instants. The proposed method is then assessed over different simulation results, analyzing the design parameters’ effects, and over an unmanned aerial vehicle (UAV) use case.",Pergamon,,2025
796,Take Your Best Shot: Sampling-Based Planning for Autonomous Photography,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lyNOlzoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=lyNOlzoAAAAJ:vRqMK49ujn8C,"Autonomous mobile robots (AMRs) equipped with high-quality cameras are revolutionizing the field of autonomous photography by delivering efficient and cost-effective methods for capturing dynamic visual content. As AMRs are deployed in increasingly diverse environments, the challenge of consistently producing high-quality photographic content remains. Traditional approaches often involve AMRs following a predetermined path while capturing data-intensive imagery, which can be suboptimal, especially in environments with limited connectivity or physical obstructions. These drawbacks necessitate intelligent decision-making to pinpoint optimal vantage points for image capture. Inspired by Next Best View studies, we propose a novel autonomous photography framework that enhances image quality and minimizes the number of photos needed. This framework incorporates a proposed evaluation metric that …",IEEE,,2025
797,A Schwarz-Christoffel Mapping-based Framework for Sim-to-Real Transfer in Autonomous Robot Operations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lyNOlzoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=lyNOlzoAAAAJ:tOudhMTPpwUC,"Despite the remarkable acceleration of robotic development through advanced simulation technology, robotic applications are often subject to performance reductions in real-world deployment due to the inherent discrepancy between simulation and reality, often referred to as the “sim-to-real gap"". This gap arises from factors like model inaccuracies, environmental variations, and unexpected disturbances. Similarly, model discrepancies caused by system degradation over time or minor changes in the system’s configuration also hinder the effectiveness of the developed methodologies. Effectively closing these gaps is critical and remains an open challenge. This work proposes a lightweight conformal mapping framework to transfer control and planning policies from an expert teacher to a degraded less capable learner. The method leverages Schwarz-Christoffel Mapping (SCM) to geometrically map teacher control …",Springer Netherlands,,2025
798,Toward Robotic Triage: a Distributed Task and Motion Planning Framework for Efficient Human-Robot Emergency Response,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lyNOlzoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=lyNOlzoAAAAJ:4fKUyHm3Qg0C,"This paper proposes a novel human-robot coordination framework to enhance medical assistance during urgent disaster relief operations. Specifically, we propose to leverage a heterogeneous robotic system in which multiple UGVs and a UAV seamlessly coordinate with a medic to find and assist victims. The UGVs are tasked with exploring the environment, finding victims, performing basic triage operations, and reporting to a UAV. The UAV operates as a relay to quickly inform the medic about the location and status of victims, while providing an optimized route to follow. A task and motion planning (TAMP) approach is proposed to coordinate UGVs and the UAV with the medic. The problem is then cast as a Traveling Salesman Problem (TSP) incorporating medical policies from domain experts to define the best route for the medic to follow considering victims’ locations and their severity. Extensive simulations and …",IEEE,,2025
799,Genetic and clinical heterogeneity in eIF2B-related disorder,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n7fLjFwAAAAJ&citation_for_view=n7fLjFwAAAAJ:zYLM7Y9cAGgC,"Eukaryotic initiation factor 2B (eIF2B)-related disorders are heritable white matter disorders with a variable clinical phenotype (including vanishing white matter disease and ovarioleukodystrophy) and an equally heterogeneous genotype. We report 9 novel mutations in the EIF2B genes in our subject population, increasing the number of known mutations to more than 120. Using homology modeling, we have analyzed the impact of novel mutations on the 5 subunits of the eIF2B protein. Although recurrent mutations have been found at CpG dinucleotides in the EIF2B genes, the high incidence of private or low frequency mutations increases the challenge of providing rapid genetic confirmation of this disorder, and limits the application of EIF2B screening in cases of undiagnosed leukodystrophy.",Sage Publications,,2008
800,Nature and etiology of hollow-organ abdominal injuries in frontal crashes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n7fLjFwAAAAJ&citation_for_view=n7fLjFwAAAAJ:0EnyYjriUFMC,"Injuries to the hollow organs of the lower digestive system carry substantial risk of complication due to infection and blood loss, and commonly require invasive abdominal surgery to diagnose and treat. The causes of, and risk factors for, lower abdomen injury in automobile collisions are poorly understood. The goal of this study was to investigate the risk factors and potential mechanisms of hollow-organ, lower abdomen injury in belted automobile occupants in frontal collisions. A field survey data analysis was performed to examine the relationship between various occupant and collision factors and the risk of moderate or greater severity injury (i.e., Abbreviated Injury Scale, AIS 2+) to the small intestine, large intestine, or mesentery among belted occupants involved in frontal collisions. Descriptive and comparative risk factor analyses were performed with data originating from that National Automotive Sampling …",Pergamon,,2015
801,Inherited disorders of GABA metabolism,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n7fLjFwAAAAJ&citation_for_view=n7fLjFwAAAAJ:hqOjcs7Dif8C,"The inherited disorders of γ-amino butyric acid (GABA) metabolism require an increased index of clinical suspicion. The known genetic disorders are GABA-transaminase deficiency, succinic semialdehyde dehydrogenase (SSADH) deficiency and homocarnosinosis. A recent link has also been made between impaired GABA synthesis and nonsyndromic cleft lip, with or without cleft palate. SSADH deficiency is the most commonly occurring of the inherited disorders of neurotransmitters. The disorder has a nonspecific phenotype with myriad neurological and psychiatric manifestations, and usually has a nonprogressive temporal course. Diagnosis is made by the detection of γ-hydroxybutyrate excretion on urine organic acid testing. The most consistent magnetic resonance imaging abnormality is an increased signal in the globus pallidus. Magnetic resonance spectroscopy has demonstrated the first example of …",Taylor & Francis,Future Neurology,2006
802,"Effectiveness of barrier devices, high-volume evacuators, and extraoral suction devices on reducing dental aerosols for the dental operator: A pilot study",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n7fLjFwAAAAJ&citation_for_view=n7fLjFwAAAAJ:3fE2CSJIrl8C,"Background The COVID-19 pandemic has increased the importance of minimizing exposure to aerosols generated during dental procedures. The authors’ objective was to measure the aerosolized particles in the breathing zone of operators using several facial protection and filtration methods. Methods Twenty-one dentists performed maxillary anterior incisor veneer preparations using a microscope and drape and loupes with or without a face shield. In each test condition, the following 3 levels of filtration were tested: no filtration, a high-volume evacuator [HVE], and an HVE with an extraoral suction device. Measurements were made using a mass monitor attached to the operator’s chest with inlet within 10 inches of the operator’s face. Results The authors found that the microscope and drape provided the lowest levels of aerosolized particles compared with loupes with or without a face shield (P < .001). There was no …",Elsevier,,2022
803,Diagnosis and treatment of neurotransmitter disorders,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n7fLjFwAAAAJ&citation_for_view=n7fLjFwAAAAJ:YsMSGLbcyi4C,"Opinion statement The neurotransmitter disorders represent an enigmatic and enlarging group of neurometabolic conditions caused by abnormal neurotransmitter metabolism or transport. A high index of clinical suspicion is important, given the availability of therapeutic strategies. This article covers disorders of monoamine (catecholamine and serotonin) synthesis, glycine catabolism, pyridoxine dependency, and ã -aminobutyric acid (GABA) metabolism. The technological aspects of appropriate cerebrospinal fluid (CSF) collection, shipment, study, and interpretation merit special consideration. Diagnosis of disorders of monoamines requires analysis of CSF homovanillic acid, 5-hydroxyindoleacetic acid, ortho-methyldopa, BH4, and neopterin. The delineation of new disorders with important therapeutic implications, such as cerebral folate deficiency and PNPO deficiency, serves to highlight the value of measuring …",Current Medicine Group,Current Treatment Options in Neurology,2006
804,"Injury patterns and seat belt effectiveness in pregnant motor vehicle occupants: evidence from US crash data, 1998–2021",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n7fLjFwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=n7fLjFwAAAAJ:L8Ckcad2t8MC,"Motor vehicle collisions (MVCs) are the most common etiology of trauma and non-obstetric fetal death among pregnant individuals. Seat belts prevent MVC-related injuries; however, some pregnant individuals do not wear a seat belt due to discomfort and concerns about belt-related safety for their fetus. Highlighted by stagnating seat belt use rates over time and potential for incorrect usage, seat belt effectiveness among pregnant occupants requires further study. Here, crash data 1998–2021 for pregnant occupants from National Automotive Sampling System – Crashworthiness Data System (NASS-CDS) and the Crash Investigation Sampling System (CISS) were analyzed to: 1) evaluate the effectiveness of seat belts on preventing whole-body injury outcomes; 2) evaluate the effectiveness of seat belts on preventing body region-specific injuries; and 3) investigate vehicle- and occupant-specific factors that modify …",BioMed Central,,2025
805,Relationship with sex-based anatomical differences to lower extremity injury severity in frontal crashes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n7fLjFwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=n7fLjFwAAAAJ:7PzlFSSx8tAC,"Objective Multiple studies have demonstrated an increased risk of lower extremity injuries for females in frontal crashes. This study aimed to investigate whether sex-based anatomical differences, as measured on computed tomography (CT) scans of the abdomen and pelvis, contribute to lower extremity injury risk. Methods The Crash Injury Research and Engineering Network (CIREN) database (2017–2023) was queried for frontal collisions. Cases were included if the occupant was an adult (≥18 years), seated in the front row, properly restrained, and had an analyzable CT scan of the abdomen and pelvis. Anatomical measurements included soft tissue over the anterior superior iliac spine (ASIS) along three vectors, thigh diameter, thigh anterior soft tissue, subcutaneous adipose tissue (SAT) area, psoas area, lumbar spine bone mineral density (BMD), femur cortical thickness, height, weight, and body mass index …",Taylor & Francis,,2025
806,Congruency of crash-and hospital-reported injuries among child passengers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n7fLjFwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=n7fLjFwAAAAJ:4DMP91E08xMC,"Introduction Prior work has found incongruencies in injury information reported by crash and hospital records. However, no work has focused on child passengers. The objective of this study was to compare crash scene and hospital-reported injury information for crash-involved child passengers. This study also explored injury location and severity by child age and restraint type. Methods Utilizing linked New Jersey data from 2017 through 2019, the authors identified crash-involved child passengers <13 years old and their injuries in crash and hospital reports. Then, they characterized the congruency of injury frequency, severity, and location, as well as the frequency of injuries by child age and restraint type. Analyses were conducted from December 2023 through February 2024. Results Of 84,060 crash-involved child passengers, crash reports documented 7,858 (9%) children with at least “possible” injuries, while 2 …",Elsevier,,2024
807,Intact window glass predicts low risk of serious injury in pediatric patients after a motor vehicle collision,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n7fLjFwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=n7fLjFwAAAAJ:mVmsd5A6BfQC,"Objective: Window glazings, the glass portion of a vehicle's windows, typically do not crack or shatter during low-speed motor vehicle collisions. Therefore, intact window glazings can indicate that a crash was not high energy, and the occupants have a low risk of injury. This study aimed to determine the risk of a moderate or greater severity injury in pediatric occupants if all the window glazings in their vehicle were undamaged after a collision. Methods: This retrospective cohort study used data from the National Automotive Sampling System Crashworthiness Data System (NASS-CDS) for MVCs from 1998-2015. Pediatric occupants under 18 years of age in standard passenger vehicles were included, with exclusions for unknown injury severity, ejection from the vehicle, preexisting window damage, and unknown post-crash window status. The primary outcome measures were the rates of moderate (MAIS 2+) and …",TAYLOR & FRANCIS INC,,2024
808,Comparison of deep learning approaches to estimate injury severity from the International Classification of Diseases codes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n7fLjFwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=n7fLjFwAAAAJ:Wp0gIr-vW9MC,"Objective The injury severity classification based on the Abbreviated Injury Scale (AIS) provides information that allows for standardized comparisons for injury research. However, the majority of injury data is captured using the International Classification of Diseases (ICD), which lacks injury severity information. It has been shown that the encoder-decoder-based neural machine translation (NMT) model is more accurate than other methods for determining injury severity from ICD codes. The objectives of this project were to determine if feed-forward neural networks (FFNN) perform as well as NMT and to determine if direct estimation of injury severity is more accurate than using AIS codes as an intermediary (indirect method). Methods Patient data from the National Trauma Data Bank were used to develop and test the four models (NMT/Indirect, NMT/Direct, FFNN/Indirect, FFNN/Direct). There were 2,031,793 cases …",Taylor & Francis,,2024
809,On-the-fly machine-learning for high-throughput experiments: search for rare-earth-free permanent magnets,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fbKAPbgAAAAJ&citation_for_view=fbKAPbgAAAAJ:j3f4tGmQtD8C,"Advanced materials characterization techniques with ever-growing data acquisition speed and storage capabilities represent a challenge in modern materials science and new procedures to quickly assess and analyze the data are needed. Machine learning approaches are effective in reducing the complexity of data and rapidly homing in on the underlying trend in multi-dimensional data. Here, we show that by employing an algorithm called the mean shift theory to a large amount of diffraction data in high-throughput experimentation, one can streamline the process of delineating the structural evolution across compositional variations mapped on combinatorial libraries with minimal computational cost. Data collected at a synchrotron beamline are analyzed on the fly and by integrating experimental data with the inorganic crystal structure database (ICSD), we can substantially enhance the accuracy in classifying …",Nature Publishing Group UK,,2014
810,Architecture and magnetism of alnico,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fbKAPbgAAAAJ&citation_for_view=fbKAPbgAAAAJ:mB3voiENLucC,"A rare-earth supply crisis has stimulated an intensive search for alternative permanent magnets. Alnico materials, alloys containing Al, Ni, Co and Fe, are functional nanostructured alloys, which show great potential for replacing the best commercial Nd-based rare-earth alloys for applications above 200 °C. However, their coercivity is ∼2–3× below theoretical limits. The coercivity of alnico depends on the nanostructure developed during spinodal decomposition. In this work, atom probe tomography, combined with advanced electron microcopy, indicate that the microstructure of alnico is sensitive to the introduction of alloying elements such as Ti and Cu, as well as the crystallographic orientation of the parent phase with respect to the direction of the imposed magnetic field during spinodal decomposition. The alnico coercivity mechanism involves interplay of size, chemistry and possibly stress at interfaces. Control of …",Pergamon,,2014
811,Competing Magnetic Interactions in the Antiferromagnetic Topological Insulator,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fbKAPbgAAAAJ&citation_for_view=fbKAPbgAAAAJ:SpbeaW3--B0C,"The antiferromagnetic (AFM) compound is suggested to be the first realization of an AFM topological insulator. We report on inelastic neutron scattering studies of the magnetic interactions in that possess ferromagnetic triangular layers with AFM interlayer coupling. The spin waves display a large spin gap and pairwise exchange interactions within the triangular layer are long ranged and frustrated by large next-nearest neighbor AFM exchange. The degree of frustration suggests proximity to a variety of magnetic phases, potentially including skyrmion phases, which could be accessed in chemically tuned compounds or upon the application of symmetry-breaking fields.",American Physical Society,,2020
812,Exploring the structural complexity of intermetallic compounds by an adaptive genetic algorithm,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fbKAPbgAAAAJ&citation_for_view=fbKAPbgAAAAJ:Zph67rFs4hoC,"Solving the crystal structures of novel phases with nanoscale dimensions resulting from rapid quenching is difficult due to disorder and competing polymorphic phases. Advances in computer speed and algorithm sophistication have now made it feasible to predict the crystal structure of an unknown phase without any assumptions on the Bravais lattice type, atom basis, or unit cell dimensions, providing a novel approach to aid experiments in exploring complex materials with nanoscale grains. This approach is demonstrated by solving a long-standing puzzle in the complex crystal structures of the orthorhombic, rhombohedral, and hexagonal polymorphs close to the intermetallic compound. From our calculations, we identified the hard magnetic phase and the origin of high coercivity in this compound, thus guiding further development of these materials for use as high performance permanent magnets without …",American Physical Society,,2014
813,Defect-driven ferrimagnetism and hidden magnetization in,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fbKAPbgAAAAJ&citation_for_view=fbKAPbgAAAAJ:8d8msizDQcsC,"(MBT) materials are promising antiferromagnetic topological insulators in which field-driven ferromagnetism is predicted to cause a transition between axion insulator and Weyl semimetallic states. However, the presence of antiferromagnetic coupling between Mn/Bi antisite defects and the main Mn layer can reduce the low-field magnetization, and it has been shown that such defects are more prevalent in the structurally identical magnetic insulator (MST). We use high-field magnetization measurements to show that the magnetization of MBT and MST occur in stages and full saturation requires fields of  T. As a consequence, the low-field magnetization plateau state in MBT, where many determinations of the quantum anomalous Hall state are studied, actually consists of ferrimagnetic septuple blocks containing both uniform and staggered magnetization components.",American Physical Society,,2021
814,"Three-dimensional nature of anomalous Hall conductivity in YMn6Sn6−xGax, x ≈ 0.55",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fbKAPbgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fbKAPbgAAAAJ:LdasjJ6CEcoC,"The unique geometry of kagome lattices leads to topological features such as flat bands and Dirac cones. When paired with ferromagnetism and a Fermi level near Dirac points, they offer a platform for realizing topological Chern magnetotransport. This prospect recently drew interest in the ferrimagnetic kagome metal TbMn6Sn6. However, density functional theory (DFT) calculations indicate that its 2D Chern gap lies well above the Fermi energy, raising questions about its role in anomalous Hall conductivity. Here, we study YMn6Sn5.45Ga0.55, a structurally and electronically similar material, and find that its intrinsic anomalous Hall effect is three-dimensional. This demonstrates that the Hall response in such compounds does not originate from 2D Chern gaps. Additionally, we confirm that the newly proposed empirical scaling relation for extrinsic Hall conductivity is universally governed by spin fluctuations.",Nature Publishing Group UK,,2025
815,Giant coercivity and enhanced intrinsic anomalous Hall effect at vanishing magnetization in a compensated kagome ferrimagnet,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fbKAPbgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fbKAPbgAAAAJ:7wO8s98CvbsC,"Ferrimagnets that can be driven to magnetic compensation show promise for use in spintronics as they exhibit a finite anomalous Hall effect at zero magnetic field without having a substantial magnetic moment. Compensated ferrimagnet spintronic devices with both a large anomalous Hall effect and a high coercivity would be simultaneously easy to read and difficult to erase. The kagome ferrimagnet TbMn6Sn6 has been reported to host a large intrinsic anomalous Hall effect. Here, we demonstrate that doping the Mn sites with Cr drives the system toward magnetic compensation. For nearly compensated compositions at low temperatures, giant coercive fields exceeding 14 T are observed. Additionally, Cr doping markedly enhances the intrinsic anomalous Hall effect, which can be attributed to a shift in the Fermi level. Our results extend the range of unique magnetic states observed in kagome materials …",American Association for the Advancement of Science,,2025
816,Accurate calculation of light rare-earth magnetic anisotropy with density functional theory,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fbKAPbgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fbKAPbgAAAAJ:-mN3Mh-tlDkC,"Density functional theory (DFT) has long struggled to treat light rare-earth magnetism. We show that this difficulty arises from an overestimate of the charge asphericity, and thus the magnetic anisotropy energy, due to the inadequacy of single Slater-determinant representations. We propose an effective solution by combining constrained DFT+U with crystal field theory and a systematic many-body correction to the charge asphericity. We confirm the validity of this combination on TbVSn and TbCo, and then show how the many-body correction adjusts the calculated magnetic anisotropy energy of SmCo to match experiment. Our method is an efficient DFT-based approach to address light-rare-earth magnetism.",,,2025
817,Importance of enforcing Hund’s rules in density functional theory calculations of rare earth magnetocrystalline anisotropy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fbKAPbgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fbKAPbgAAAAJ:jU7OWUQzBzMC,"Density functional theory (DFT) and its extensions, such as DFT+U and DFT+dynamical mean-field theory, are invaluable for studying magnetic properties in solids. However, rare-earth (R) materials remain challenging due to self-interaction errors and the lack of proper orbital polarization. We show how the orbital dependence of self-interaction error contradicts Hund’s rules and plagues magnetocrystalline anisotropy (MA) calculations, and how analyzing DFT states that respect Hund’s rules can mitigate this issue. We benchmark MA in RCo5, R2Fe14B, and RFe12, extending prior work on RMn6Sn6, achieving excellent agreement with experiments. Additionally, we illustrate a semi-analytical perturbation approach that treats crystal fields as a perturbation in the large spin-orbit coupling limit. Using Gd-4f crystal-field splitting, this method provides a microscopic understanding of MA and enables rapid screening of …",Nature Publishing Group UK,,2025
818,Oscillating Grain Boundaries and Their Effects on Grain Growth: Observations in Skyrmion Bicrystals,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fbKAPbgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fbKAPbgAAAAJ:7H_MAutzIkAC,"Grain boundary migration is usually considered to occur through the consistent motion of grain boundaries toward their centers of curvature, ultimately leading to grain growth. However, we show that in 2D skyrmion bicrystals comprising individual grains of hexagonal symmetry, grain boundaries can undergo large amplitude oscillations while maintaining their basic geometric features. Wave-like boundary motion, triggered by individual and collective motion of particles at the grain boundaries, is a behavior that is not accounted for in traditional models of grain boundary migration. Our findings highlight the need for further investigation into the dynamics of grain boundaries during grain growth.",Pergamon,,2025
819,Cell-specific targeting of nanoparticles by multivalent attachment of small molecules,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NaxdZBMAAAAJ&citation_for_view=NaxdZBMAAAAJ:u5HHmVD_uO8C,"Nanomaterials with precise biological functions have considerable potential for use in biomedical applications. Here we investigate whether multivalent attachment of small molecules can increase specific binding affinity and reveal new biological properties of such nanomaterials. We describe the parallel synthesis of a library comprising 146 nanoparticles decorated with different synthetic small molecules. Using fluorescent magnetic nanoparticles, we rapidly screened the library against different cell lines and discovered a series of nanoparticles with high specificity for endothelial cells, activated human macrophages or pancreatic cancer cells. Hits from the last-mentioned screen were shown to target pancreatic cancer in vivo. The method and described materials could facilitate development of functional nanomaterials for applications such as differentiating cell lines, detecting distinct cellular states and targeting …",Nature Publishing Group US,,2005
820,Noninvasive vascular cell adhesion molecule-1 imaging identifies inflammatory activation of cells in atherosclerosis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NaxdZBMAAAAJ&citation_for_view=NaxdZBMAAAAJ:u-x6o8ySG0sC,"Background— Noninvasive imaging of adhesion molecules such as vascular cell adhesion molecule-1 (VCAM-1) may identify early stages of inflammation in atherosclerosis. We hypothesized that a novel, second-generation VCAM-1–targeted agent with enhanced affinity had sufficient sensitivity to enable real-time detection of VCAM-1 expression in experimental atherosclerosis in vivo, to quantify pharmacotherapy-induced reductions in VCAM-1 expression, and to identify activated cells in human plaques. Methods and Results— In vivo phage display in apolipoprotein E–deficient mice identified a linear peptide affinity ligand, VHPKQHR, homologous to very late antigen-4, a known ligand for VCAM-1. This peptide was developed into a multivalent agent detectable by MRI and optical imaging (denoted VINP-28 for VCAM-1 internalizing nanoparticle 28, with 20 times higher affinity than previously reported for …",Lippincott Williams & Wilkins,,2006
821,Detection of vascular adhesion molecule-1 expression using a novel multimodal nanoparticle,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NaxdZBMAAAAJ&citation_for_view=NaxdZBMAAAAJ:d1gkVwhDpl0C,"Endothelial vascular adhesion molecule-1 (VCAM-1) is a critical component of the leukocyte–endothelial adhesion cascade, and its strict temporal and spatial regulation make it an ideal target for imaging and therapy. The goal of this study was to develop novel VCAM-1–targeted imaging agents detectable by MRI and fluorescence imaging using phage display–derived peptide sequences and multimodal nanoparticles (NPs). We hypothesized that VCAM-1–mediated cell internalization of phage display–selected peptides could be harnessed as an amplification strategy to chaperone and trap imaging agents inside VCAM-1–expressing cells, thus improving target-to-background ratios. To accomplish our goal, iterative phage display was performed on murine endothelium under physiological flow conditions to identify a family of VCAM-1–mediated cell-internalizing peptides. One specific sequence, containing the …",Lippincott Williams & Wilkins,,2005
822,Early detection of sporadic pancreatic cancer: summative review,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NaxdZBMAAAAJ&citation_for_view=NaxdZBMAAAAJ:l7t_Zn2s7bgC,"Pancreatic cancer (PC) is estimated to become the second leading cause of cancer death in the United States by 2020. Early detection is the key to improving survival in PC. Addressing this urgent need, the Kenner Family Research Fund conducted the inaugural Early Detection of Sporadic Pancreatic Cancer Summit Conference in 2014 in conjunction with the 45th Anniversary Meeting of the American Pancreatic Association and Japan Pancreas Society. This seminal convening of international representatives from science, practice, and clinical research was designed to facilitate challenging interdisciplinary conversations to generate innovative ideas leading to the creation of a defined collaborative strategic pathway for the future of the field. An in-depth summary of current efforts in the field, analysis of gaps in specific areas of expertise, and challenges that exist in early detection is presented within distinct areas …",LWW,Pancreas,2015
823,Plectin-1 as a novel biomarker for pancreatic cancer,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NaxdZBMAAAAJ&citation_for_view=NaxdZBMAAAAJ:hqOjcs7Dif8C,"Purpose: We are in great need of specific biomarkers to detect pancreatic ductal adenocarcinoma (PDAC) at an early stage, ideally before invasion. Plectin-1 (Plec1) was recently identified as one such biomarker. However, its suitability as a specific biomarker for human pancreatic cancer, and its usability as an imaging target, remain to be assessed. Experimental Design: Specimens of human PDAC, chronic pancreatitis, and normal pancreata were evaluated by immunohistochemistry and Western blot analysis. To validate Plec1 as an imaging target, Plec1-targeting peptides (tPTP) were used as a contrast agent for single photon emission computed tomography in an orthotopic and liver metastasis murine model of PDAC. Results: Plec1 expression was noted to be positive in all PDACs but negative in benign tissues. Plec1 expression increases during pancreatic carcinogenesis. It was found to be …",American Association for Cancer Research,,2011
824,Abstract P2-02-17: Race and outcomes in HR+/HER2-breast cancer: how tissue morphology and molecular pathways contribute to worse outcomes in Black women,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NaxdZBMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=NaxdZBMAAAAJ:Ug5p-4gJ2f0C,"Background: Black women with breast cancer (BC) have a 40% higher relative risk of BC death than White women. Previous analyses from the RxPonder study have shown that differences in tumor biology, particularly higher proliferation axis scores in tumors from Black women, may contribute to these poorer outcomes (Abdou et al. ASCO24). However, a comprehensive understanding of the underlying tumor biology necessitates further investigation. To this end, we conducted an in-depth analysis of tissue morphology and molecular pathways in Black and White women with early-stage hormone receptor-positive (HR+) BC, aiming to elucidate the biological factors driving these disparities. Methods: We used the SIMBIOSYS PhenoScope Discovery software suite to investigate (HR+) BCs using paired MRIs and gene expression data from the ISPY-2 trial (N = 309 patients, 272 White and 37 Black). PhenoScope …",American Association for Cancer Research,,2025
825,An integrative analysis of circulating and tumor microenvironment (TME) determinants of patient response in the Checkmate 9ER (CM 9ER) trial of nivolumab and cabozantinib …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NaxdZBMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=NaxdZBMAAAAJ:XoXfffV-tXoC,"4511 Background: The CM 9ER trial demonstrated increased objective response rate (ORR), progression-free and overall survival in patients with aRCC treated with NIVO+CABO compared to sunitinib (SUN). For vascular modulating therapies (e.g. CABO and SUN) and immunotherapies (like NIVO), the state of the TME and activity of stromal cells can modulate tumor response to therapy. Methods: We investigated how the TME and circulating factors were associated with response to NIVO+CABO using pre-treatment tumor PD-L1 staining, human interpretable features (HIF) derived from H&E tissue sections, circulating immune cell populations quantified by flow cytometry, and circulating extracellular matrix (ECM) markers quantified by competitive ELISAs from 150 patients (23% of ITT) enrolled in CM 9ER. We employed principal component analysis, varimax rotation, and Feature Set Enrichment Analysis (FSEA) to …",American Society of Clinical Oncology,Journal of Clinical Oncology,2025
826,Imaging Cell Surface Plectin in PDAC Patients–A First-In-Human Phase 0 Study Report,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NaxdZBMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=NaxdZBMAAAAJ:foquWX3nUaYC,"Purpose Plectin is traditionally an intracellular cytoskeletal protein that maintains cell structure and stability. However, we and others have identified its surface-localized form in cancer (CSP), where it influences cell adhesion, migration, immune response, and tumor signaling. CSP-positive tumors (pancreatic, lung, ovarian, and breast cancers) contribute to over 3 million annual deaths, highlighting its clinical relevance. This phase 0 study aimed to evaluate PTP-01’s ability to target CSP in pancreatic tumors, despite their dense desmoplastic stroma, and to estimate CSP density and tumor vascularity. Methods Pancreatic cancer patients (n= 3) received an intravenous injection of 100 µg PTP-01 labeled with 370 MBq 111 In one day before resection. Whole-body planar scintigraphy and SPECT imaging were performed at multiple time points. Resected tumors and adjacent tissues were collected 28 h post-injection …",Springer International Publishing,,2025
827,Plectin as a novel therapeutic target for pancreatic cancer,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NaxdZBMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=NaxdZBMAAAAJ:q3CdL3IzO_QC,"Pancreatic ductal adenocarcinoma (PDAC) is the 3rd deadliest cancer in the United States with only a 5-year survival rate of 13%, demonstrating a desperate need for novel therapeutic targets to significantly enhance options for patients. In 2008, Kelly et al. pioneered a phage-display-based functional-proteomic approach and identified a cytolinker protein, plectin, which was mislocalized and ubiquitously expressed on the membrane of PDAC. This unique localization of plectin, called cell surface plectin (CSP), has since been found to be expressed on the cell surface of many cancer subtypes, including PDAC, ovarian carcinoma and cholangiocarcinoma, but remains cytoplasmic in normal tissues. Knockdown of plectin and an anti-CSP functional monoclonal antibody revealed the importance of CSP to proliferation, migration, and invasion in cancers. Recently, a phase 1 clinical trial using an anti-CSP antibody …",American Association for Cancer Research,,2025
828,Cancer specific plectin-1 specific antibodies and methods of use thereof,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NaxdZBMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=NaxdZBMAAAAJ:xtoqd-5pKcoC,FJHBVJOVLFPMQE-QFIPXVFZSA-N 7-Ethyl-10-Hydroxy-Camptothecin Chemical compound C1= C (O) C= C2C (CC)= C (CN3C (C4= C ([C@@](C (= O) OC4)(O) CC) C= C33)= O) C3= NC2= C1 FJHBVJOVLFPMQE-QFIPXVFZSA-N 0.000 claims description 20 AOJJSUZBOXZQNB-TZSSRYMLSA-N Doxorubicin Chemical compound O ([C@ H] 1C [C@@](O)(CC= 2C (O)= C3C (= O) C= 4C= CC= C (C= 4C (= O) C3= C (O) C= 21) OC) C (= O) CO)[C@ H] 1C [C@ H](N)[C@ H](O)[C@ H](C) O1 AOJJSUZBOXZQNB-TZSSRYMLSA-N 0.000 claims description 19,,,2025
829,Targeting adenovirus to the serotype 3 receptor increases gene transfer efficiency to ovarian cancer cells,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1QsUwH8AAAAJ&citation_for_view=1QsUwH8AAAAJ:ufrVoPGSRksC,"Gene delivery efficiency in clinical cancer gene therapy trials with recombinant adenoviruses (Ads) based on serotype 5 (Ad5) has been limited partly because of variable expression of the primary Ad5 receptor, the coxsackie and adenovirus receptor (CAR), on human primary cancer cells. As a means of circumventing CAR deficiency, Ad vectors have been retargeted by creating chimeric fibers possessing knob domains of alternate Ad serotypes. In this study, we have constructed an Ad5-based vector, Ad5/3luc1, with a chimeric fiber protein featuring a knob domain derived from Ad3. This virus is retargeted to the Ad3 receptor and, therefore, has different tissue tropism. A novel knob binding assay was used to measure expression of CAR and the Ad3 receptor. Further, to evaluate the correlation of receptor expression and infectivity by Ad, a panel of ovarian cancer cell lines and purified primary cancer cells …",American Association for Cancer Research,,2002
830,Adenoviral gene therapy for cancer: from vectors to targeted and replication competent agents,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1QsUwH8AAAAJ&citation_for_view=1QsUwH8AAAAJ:roLk4NBRz8UC,"Gene therapy is an exciting novel approach for treating cancers resistant to currently available modalities. Treatment approaches are based on taking advantage of molecular differences between normal and tumor cells. Various strategies are currently in clinical development, with some promising early results reported with mutation compensation, molecular chemotherapy and replication competent viruses. Adenoviruses are among the most popular vehicles and there is a wealth of clinical data suggesting excellent safety for treatment of cancer patients. Current developments include improving targeting strategies for gene delivery to tumor cells with tumor specific promoters. Another rapidly developing field is replication competent agents, which allow improved tumor penetration and local amplification of the anti-tumor effect. Further, infectivity enhancement strategies can overcome variable expression of the …",Spandidos Publications,International journal of oncology,2002
831,Transcriptional targeting of tumors with a novel tumor-specific survivin promoter,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1QsUwH8AAAAJ&citation_for_view=1QsUwH8AAAAJ:qjMakFHDy7sC,"It has been demonstrated that survivin, a novel member of the inhibitor of apoptosis (IAP) protein family, is expressed in human cancers but is undetectable in normal differentiated tissues. We employed a recombinant adenoviral vector (reAdGL3BSurvivin) in which a tumor-specific survivin promoter and a luciferase reporter gene were inserted into the E1-deleted region of adenovirus vector. Luciferase activity was measured in both multiple tumor cell lines and two primary melanoma cells infected with reAdGL3BSurvivin. Human fibroblast and mammary epithelial cell lines were used as negative controls. A reAdGL3CMV, containing the CMV promoter and luciferase gene, was used as a positive control to normalize the luciferase activity generated by the survivin promoter. Our data revealed that the survivin promoter showed high activity in both established tumor cell lines and the primary melanoma cells. In contrast …",Nature Publishing Group,,2004
832,The secretory leukoprotease inhibitor (SLPI) promoter for ovarian cancer gene therapy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1QsUwH8AAAAJ&citation_for_view=1QsUwH8AAAAJ:IjCSPb-OGe4C,"Background Adenoviruses allow efficient transduction of dividing and non‐dividing cells and their safety for the treatment of cancer has been established in clinical trials. However, one disadvantage is their promiscuous tropism. In this regard, tissue‐specific promoters (TSPs) could be useful for directing transgene expression to target tissues and for reducing adverse effects in non‐target tissues. We hypothesize that selective adenovirus‐mediated transgene expression could be achieved through the use of the secretory leukoprotease inhibitor (SLPI) promoter in the context of ovarian cancer. Methods Adenoviruses containing the SLPI promoter driving reporter and suicide gene expression were created and tested in ovarian cancer cell lines and primary tumor cells isolated from patients. To evaluate the in vivo activation of the SLPI promoter in comparison to a ubiquitous promoter, intraperitoneal delivery was …","John Wiley & Sons, Ltd.",,2003
833,Viral-based modelling and correction of neurodegenerative diseases by RNA interference,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1QsUwH8AAAAJ&citation_for_view=1QsUwH8AAAAJ:hqOjcs7Dif8C,"Experimental recapitulation of recessive human genetic neurodegenerative disease in rodents can be classically addressed through genetic disruption of the related gene. Although very informative, this specific gene targeting is restricted to mice and precludes a species scale-up towards non-human primates. Concomitantly, this requirement to silence a specific gene in a broad range of animal models is important in the design of therapeutic approaches to dominantly inherited neurodegenerative diseases. The emergence of RNA interference (RNAi), a highly specific mechanism of post-translational gene silencing, has opened a plethora of biological application ranging from reverse genetic analysis to therapeutic schemes. Recombinant viral vectors, by promoting a long-lasting delivery of genetic instructions in a broad range of cellular types of different species origins, represent potential platforms mandating …",Nature Publishing Group,Gene therapy,2006
834,The use of healthcare disparities as a tool to teach BME undergraduates about the importance of social justice in biomedical design.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1QsUwH8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1QsUwH8AAAAJ:L8Ckcad2t8MC,"Biomedical engineers (BME) apply engineering principles to solve problems in biology and medicine and have contributed to revolutionary and life-saving outcomes, such as artificial organs, advanced prosthetics, and new pharmaceuticals. As their impact on healthcare and society is significant, how they learn to approach a problem is critical. Exposing engineering students to non-technical proficiencies such as empathy, ethics, inclusivity, and social justice has been linked to more cutting-edge problem-solving, that incorporates the technical with the social, cultural, economic, political, and historical aspects of those affected by the problem; thereby generating more broadly applicable, accessible, and socially just solutions.",,,2025
835,"A introductory-level, student-taught biomedical neuroengineering course for 1st year undeclared engineering undergraduate students",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1QsUwH8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1QsUwH8AAAAJ:dhFuZR0502QC,"In engineering schools, common introductory courses (ie physics, computer science, and calculus) are designed to equip students with the foundational skills necessary to succeed in advanced coursework upon specializing in a subject area. However, programs often neglect to expose students early-on to the research, applications, ethical/social concerns, and career/internship opportunities available within individual engineering fields and related subdisciplines, often resulting in uninformed major selection. Consequently, students may pursue an academic path that does not adequately align with their interests and aptitudes. To help remedy this issue, a 1-credit, survey-style student-taught course within the biomedical engineering department, BME 1501: Innovations in Neuroscience, was designed to introduce undergraduate students (primarily those in their first and second year) to clinical applications, research, and professional opportunities within the fields of neuroscience and biomedical engineering. Student-taught courses are unique in that the curriculum can be designed to fulfill the students’ interests and foster a supportive environment that facilitates interactions between both the instructors and the students. For this student-taught course, neuroscience was selected as the course topic because it is a multidisciplinary field that integrates biology with engineering and healthcare. This topic not only introduces students to physiology fundamentals and research/clinical innovation but also highlights the importance for engineers to consider inequities and disparities while developing technologies.",,,2024
836,Teaching engineering design through a team-based multi-disciplinary humanitarian engineering project: effects on engineering identity and sense of belonging,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1QsUwH8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1QsUwH8AAAAJ:mVmsd5A6BfQC,"Humanitarian engineering is the application of skills or services for humanitarian aid purposes; and with crises occurring at an ever-increasing rate, more and more people and systems are being affected. There are global challenges facing the world with regard to accessible clean water, shelter, waste disposal, food security, and health. These challenges present opportunities for engineers to address real-world problems in collaborative teams, and propose viable solutions that take into account not only technical issues, but also issues of equity, culture, religion, society, and politics. Humanitarian academic exercises like the one described here, introduces students to the many of these skills that are necessary to better address today’s complex societal challenges.",,,2023
837,Creating Inclusive Classrooms: Work Developed during the ASEE Year of Impact on Racial Equity (YIRE),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1QsUwH8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1QsUwH8AAAAJ:Wp0gIr-vW9MC,"As part of the ASEE Year of Impact on Racial Equity (YIRE), a subcommittee of the Faculty and Administrators Pillar focused on creating inclusive classrooms that actively incorporate antiracist pedagogy. To define the commitment and intent of the work, the subcommittee members initially developed the following tenets.",,,2023
838,A historical context of municipal solid waste management in the United States,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=OhaBhRcAAAAJ&citation_for_view=OhaBhRcAAAAJ:u5HHmVD_uO8C,"Municipal solid waste management (MSWM) in the United States is a system comprised of regulatory, administrative, market, technology, and social subcomponents, and can only be understood in the context of its historical evolution. American cities lacked organized public works for street cleaning, refuse collection, water treatment, and human waste removal until the early 1800s. Recurrent epidemics forced efforts to improve public health and the environment. The belief in anticontagionism led to the construction of water treatment and sewerage works during the nineteenth century, by sanitary engineers working for regional public health authorities. This infrastructure was capital intensive and required regional institutions to finance and administer it. By the time attention turned to solid waste management in the 1880s …",Sage Publications,,2004
839,"What do science, technology, and innovation mean from Africa?",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=OhaBhRcAAAAJ&citation_for_view=OhaBhRcAAAAJ:_xSYboBqXhAC,"Clapperton Mavhunga's collection of essays about science, technology, and innovation (STI) from an African perspective opens with the idea, ""Things do not (always) mean the same from everywhere; when we insist that only ‘our’ meaning is the meaning, we silence other people’s meanings."" Mavhunga and his contributors argue that our contemporary definitions of STI are those of countries and cultures that have acquired their dominance of others through global empires, and as a counter to that, Mavhunga seeks to put the concepts of STI into question, exploring what the technological, scientific, and innovative might mean from Africa in lieu of outside introductions or influences. We strongly feel that this book is suited to the Knowledge Unlatched program because of the difficulty of reaching markets and readers in Africa with print books. We feel unlatching would go a long way toward helping Mavhunga reach an important audience for this work that we have been previously unable to reach.",The MIT Press,,2017
840,Capacity factor analysis for evaluating water and sanitation infrastructure choices for developing communities,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=OhaBhRcAAAAJ&citation_for_view=OhaBhRcAAAAJ:iH-uZ7U-co4C,"40% of the world's population lacks access to adequate supplies of water and sanitation services to sustain human health. In fact, more than 780 million people lack access to safe water supplies and about 2.5 billion people lack access to basic sanitation. Appropriate technology for water supply and sanitation (Watsan) systems is critical for sustained access to these services. Current approaches for the selection of Watsan technologies in developing communities have a high failure rate. It is estimated that 30%–60% of Watsan installed infrastructures in developing countries are not operating. Inappropriate technology is a common explanation for the high rate of failure of Watsan infrastructure, particularly in lower-income communities (Palaniappan et al., 2008). This paper presents the capacity factor analysis (CFA) model, for the assessment of a community's capacity to manage and sustain access to water supply …",Academic Press,,2015
841,"Integrating ethics & engineering: A graduate option in systems engineering, ethics, and technology studies",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=OhaBhRcAAAAJ&citation_for_view=OhaBhRcAAAAJ:u-x6o8ySG0sC,"This paper describes an engineering graduate option in Systems Engineering designed to overcome some of the effects of specialization and compartmentalization by building a link between technical and ethical training. Students in this option produce case studies that emphasize ethical issues in the design process. The goal of the program is to turn out ethical professionals who are able to reflect on the moral implications of technology. The proposed approach uses realistic or real‐hypothetical hybrid case studies as a type of vicarious mentoring, and, when supplemented with readings in ethical theory and codes, may serve as a starting point for a deeper understanding of behavioral dilemmas. The developers of this approach are a multi‐disciplinary team from the Engineering School and the Darden Graduate School of Business Administration at the University of Virginia. The paper describes how the graduate …",Blackwell Publishing Ltd,,2000
842,"A decision model for selecting sustainable drinking water supply and greywater reuse systems for developing communities with a case study in Cimahi, Indonesia",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=OhaBhRcAAAAJ&citation_for_view=OhaBhRcAAAAJ:2osOgNQ5qMEC,"Capacity Factor Analysis is a decision support system for selection of appropriate technologies for municipal sanitation services in developing communities. Developing communities are those that lack the capability to provide adequate access to one or more essential services, such as water and sanitation, to their residents. This research developed two elements of Capacity Factor Analysis: a capacity factor based classification for technologies using requirements analysis, and a matching policy for choosing technology options. First, requirements analysis is used to develop a ranking for drinking water supply and greywater reuse technologies. Second, using the Capacity Factor Analysis approach, a matching policy is developed to guide decision makers in selecting the appropriate drinking water supply or greywater reuse technology option for their community. Finally, a scenario-based informal hypothesis test is …",Academic Press,,2011
843,"Addressing social equity in coastal climate adaptation planning: A case study of Norfolk, Virginia",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=OhaBhRcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=OhaBhRcAAAAJ:V3AGJWp-ZtQC,"The consequences of climate change, such as flooding, storms, heat waves, and other climate disasters, have had severe economic and health impacts, with vulnerable communities bearing a disproportionate burden. In Norfolk, Virginia, historical injustices such as redlining contribute to these disparities. This highlights the need to integrate social equity and community engagement into efforts to achieve environmental justice in climate risk management. Although relevant indices and diversity, equity, and inclusion officers have popularized social equity, a shared definition remains elusive. Localized solutions for coastal climate resilience allow governments to make decisions for their communities. However, they also risk contributing to differential outcomes, which may neglect some populations altogether, or limit the effectiveness of resource allocation because of missed opportunities for regional cooperation. This research used Norfolk, Virginia as a case study, conducting stakeholder interviews with representatives from various government levels, non-governmental organizations, and academic institutions to characterize social equity in coastal adaptation planning. The differences in stakeholder feedback and the tools they use for planning and program implementation may be instructive to other coastal communities seeking to integrate social equity in their climate risk management planning.",Public Library of Science,,2024
844,Portfolio Agriculture: A Model for Resilient Regional Agricultural Planning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=OhaBhRcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=OhaBhRcAAAAJ:q3oQSFYPqjQC,"Food security is threatened by climate change worldwide; consequently, agriculture and farming livelihoods must adapt to new and unpredictable conditions. These conditions vary along spatial scales, and since agricultural yields are sensitive to microclimate conditions, a locally tailored data‑driven approach may be helpful. Further‑more, limited agricultural resources like water and labor increasingly constrain food production. This research proposes a regional portfolio model for identifying crop choices and regional portfolio compositions that align with known and forecasted microclimate variation in temperature and humidity. The model will enable farmers to as‑sess tradeoffs between the inancial returns and agricultural production risks. The goal of this work is to provide new insights into agricultural planning in the face of climate risk and limited access to water and labor resources. Three steps are taken. Firstly, regional agricultural land is divided into farming subunits, with each representing a terroir characterized by temperature and humidity. Then a simulated yield coef icient is used to assess the effect of microclimate variables on the yield of the different crops in the portfolio of each subunit. Secondly, farming re‑source allocation, represented by water and labor, across crops and farming subunits is optimized to maximize the yield and associated inancial return from farming across the agricultural region. Finally, a resilient agricultural planning model is developed based on the assumed data for regional microclimate and agricultural resources. The results of this research can be used by regional farmers as a reference for selecting crop …",,,2024
845,Ethics Case Study Project: Broadening STEM Participation by Normalizing Immersion of Diverse Groups in Peer to Near Peer Collaborations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=OhaBhRcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=OhaBhRcAAAAJ:BrmTIyaxlBUC,"To successfully broaden the participation of underrepresented racially minoritized students in science, technology, engineering, and math (STEM), students from all demographic groups must routinely work together in STEM as a cohesive community. A Mutual Benefit Approach (MBA) is a way to create longstanding partnerships between members of the community, academia, nongovernmental organizations (NGO) to develop equitable opportunities for students from all demographic groups to engage together in STEM. One of the primary objectives for MBA is to provide a continuous series of immersions in deliberately diverse STEM environments for students from K-12 up through the PhD. This will normalize STEM as a diverse experience for students and build their self-efficacy in STEM. The MBA also hypothesizes that peer to nearpeer interactions are critical for students to progress continuously through all the levels of STEM, from K-12 to the PhD and STEM workforce. This paper discusses one example of a “normalizing immersion”–a team-based case study project in Ethics. The teams consisted of African American high school students, African American undergraduate students from a Historically Black College or University (HBCU)–Hampton University, and predominantly White graduate students from a PWI–University of Virginia. Student teams were guided by high school teachers in the Charlottesville Virginia area, university faculty members and community mentors–a holistic approach involving STEM in the context of students’ respective communities. The team-based Ethics case study project included visits and campus tours at both …",ASEE,,2024
846,"Optimal control strategies for water, sanitation, and hygiene in mitigating spread of waterborne diseases",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=OhaBhRcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=OhaBhRcAAAAJ:LPZeul_q3PIC,"Improving access to water, sanitation and hygiene (WASH) can help to eliminate the root cause of waterborne disease transmission. WASH has the potential to function as a sustained and effective mechanism for controlling enteric diarrheal disease (EDD) over the long term. To address this question, we formulate a mathematical model to study the impact of WASH services on reducing the transmission of waterborne diseases. The model is analyzed using the stability theory of differential equations in order to determine the threshold condition in disease control. We utilize optimal control theory to find the right balance in WASH interventions, ensuring a decrease in waterborne disease over a specific planning period. The total number of EDD cases is minimized when there are specific financial restrictions. To analyze the outcomes, we employed numerical simulations and conducted a sensitivity analysis on different …",Elsevier,,2024
847,Harnessing the Power of Convolutional Neural Networks for Algal Blooms Forecasting,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=OhaBhRcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=OhaBhRcAAAAJ:eJXPG6dFmWUC,"Algal blooms present significant threats to our environment, public health, and economy, extending across diverse geographical regions. Accurate and timely predictions are critical for managing these biological phenomena. Historically, mechanistic algal bloom forecasting models have been complex, demanding a wide range of water quality and climatic variables, and yet, they often struggle to provide accurate forecasts, especially for longer time windows such as seven days in advance. However, recent breakthroughs in deep learning technologies offer a promising alternative with potential to transform our prediction capabilities.",,,2023
848,Strategic online advertising: Modeling Internet user behavior with Advertising. com,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7O9F5FMAAAAJ&citation_for_view=7O9F5FMAAAAJ:u5HHmVD_uO8C,"We investigated how online advertising could be made more receptive to Internet users' needs, thereby improving the efficacy. Only three to five viewers in a thousand click on a given online banner advertisement. To improve the low response rate, marketers need to reach the right audience, which will yield a higher return on advertising dollars by eliminating wasted ads and maximizing campaign effectiveness. Users see relevant ads based on their preferences and fewer ads that do not interest them. We identified and modeled user behavior and characterized a subpopulation of users to help predict advertising response. We then developed an exploratory optimization and targeting technology for use by advertising.com by serving users ads probabilistically on the basis of their online behaviors. After preliminary algorithm validation, the increase in early user clicks indicates the potential effectiveness of these …",IEEE,,2006
849,Extending the Markowitz model with dimensionality reduction: Forecasting efficient frontiers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7O9F5FMAAAAJ&citation_for_view=7O9F5FMAAAAJ:2osOgNQ5qMEC,"The Markowitz model is an established approach to portfolio optimization that constructs efficient frontiers allowing users to make optimal tradeoffs between risk and return. However, a limitation of this approach is that it assumes future asset returns and covariances will be identical to the asset's historical data, or that these model parameters can be accurately estimated, a notion which often does not hold in practice. Markowitz efficient frontiers are square root second-order polynomials that can be represented by three parameters, thus providing a significant dimensionality reduction of the lookback covariances and growth of the assets. Using this dimensionality reduction, we propose an extension to the Markowitz model that accounts for the nonstationary behavior of the portfolio assets' return and covariance without the necessity to forecast the complex covariance matrix and assets growths, something that has …",IEEE,,2021
850,A Fundamental Misunderstanding of Risk: The Bias Associated with the Annualized Calculation of Standard Deviation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7O9F5FMAAAAJ&citation_for_view=7O9F5FMAAAAJ:9yKSN-GCB0IC,"Quantifiable, measurable risk is of critical importance when making data-driven decisions in finance and investment management, but what if the generally accepted practice of the investment industry for calculating risk possessed incorrect mathematical assumptions and embedded biases? This piece revisits the discussion surrounding the methodology used to calculate annualized standard deviation statistics commonly used when reporting the performance of investment products. It goes on to present a new example illustrating the bias when applied to an efficient frontier.",Cogent,,2020
851,Are financial market states recurrent and persistent?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7O9F5FMAAAAJ&citation_for_view=7O9F5FMAAAAJ:d1gkVwhDpl0C,"Market participants often invoke the concept of discrete state when discussing financial markets. Bull market, bear market, depression, and recession are all terms that map to discrete market states. Mental models of how markets behave in each state and transition between states are then applied to decision-making. Implicit to that approach is the assumption that states are persistent and recurrent over time. This article seeks to formalize notions of discrete market states by proposing a parsimonious and innovative approach to segmenting periods of time into discrete states. The technique is demonstrated and evaluated in a series of case studies.",Cogent,,2019
852,The Current State and Future Needs of Systems Engineering Education: A Proposed Curriculum *,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7O9F5FMAAAAJ&citation_for_view=7O9F5FMAAAAJ:u-x6o8ySG0sC,"Since the first use of the term ""systems engineering"" in the 1940’s, the discipline has progressed significantly as the complexity of systems and the development of technology continue to increase. This paper examines the current state and evolution of systems engineering and systems engineering education. The paper first identifies the current state of systems engineering by recognizing systems engineers' roles, responsibilities, and expectations. Following the current state of systems engineering, the changes needed are addressed through multiple frameworks and skill sets that will be critical to the evolving industry. The paper also explores the future of systems education focusing on content, content delivery, cost, and student cooperation. The analysis suggests that universities could adjust their curriculum to better align with the demands of the industry. The paper concludes with an overview of potential …",IEEE,,2023
853,Portfolio design and management through state-based analytics: A probabilistic approach,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7O9F5FMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7O9F5FMAAAAJ:qjMakFHDy7sC,"This paper presents an innovative new approach to investment portfolio design, which applies a discrete, state-based methodology to defining market states and making asset allocation decisions with respect to both current and future state membership. State membership is based on attributes taken from traditional finance and portfolio theory namely expected growth, and covariance. The transitional dynamics of the derived states are modeled as a Markovian process. Asset weighting and portfolio allocation decisions are made through an optimization-based approach coupled with heuristics that account for the probability of state membership and the quality of the state in terms of information provided.",Cogent,,2020
854,Novel carbon nanotube− polystyrene foam composites for electromagnetic interference shielding,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oqJlgpUAAAAJ&citation_for_view=oqJlgpUAAAAJ:q3oQSFYPqjQC,"A novel carbon nanotube−polystyrene foam composite has been fabricated successfully. The electromagnetic interference (EMI) shielding effectiveness measurements indicated that such foam composites can be used as very effective, lightweight shielding materials. The correlation between the shielding effectiveness and electrical conductivity and the EMI shielding mechanism of such foam composites are also discussed.",American Chemical Society,,2005
855,Conductive carbon nanofiber–polymer foam structures,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oqJlgpUAAAAJ&citation_for_view=oqJlgpUAAAAJ:abG-DnoFyZgC,"Polymer foams have many attractive features including low density, flexibility, perfect thermal insulation, and impactdamping properties. Polymer foams have been widely utilized in a range of applications such as packaging, protective equipment, thermal and acoustic insulation, medical devices, furniture, construction, and transportation.[1ą3] Past reported research work has focused on the mechanical properties, deformation mechanisms, and the relationship between cell morphology and foam properties.[4ą10] Although polymer foams have been developed and used for many years in various areas, the preparation and applications of polymer foams filled with conductive fillers have not been reported. The aim of the current study is to develop conductive carbon-nanofiber-filled polymer-foam structures to target electromagnetic interference (EMI) shielding applications. EMI shielding materials are important for …",WILEY‐VCH Verlag,,2005
856,The handbook of photonics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oqJlgpUAAAAJ&citation_for_view=oqJlgpUAAAAJ:B3FOqHPlNUQC,"Reflecting changes in the field in the ten years since the publication of the first edition, The Handbook of Photonics, Second Edition explores recent advances that have affected this technology. In this new, updated second edition editor Mool Gupta is joined by John Ballato, strengthening the handbook with their combined knowledge and the continued contributions of world-class researchers.New in the Second Edition:Information on optical fiber technology and the economic impact of photonicsCoverage of emerging technologies in nanotechnologySections on optical amplifiers, and polymeric optical materialsThe book covers photonics materials, devices, and systems, respectively. An introductory chapter, new to this edition, provides an overview of photonics technology, innovation, and economic development. Resting firmly on the foundation set by the first edition, this new edition continues to serve as a source …",CRC press,,2018
857,Self-organized micro/nano structures in metal surfaces by ultrafast laser irradiation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oqJlgpUAAAAJ&citation_for_view=oqJlgpUAAAAJ:RYcK_YlVTxYC,"Ultrafast laser pulse interaction with matter, leading to formation of self-organized conical micro/nano structures in various metals like Ti, Al, Cu, and stainless steel have been observed. Influence of laser parameters such as fluence, number of shots, and gaseous environments on micro/nano structure formation have been investigated. The critical fluence required for well-developed structure formation is dependent on the optical and thermo-physical properties of the materials. By changing the number of laser shots to generate micro/nano structures, surface reflectance of Ti surface could be tailored from their original value (over 50%) to near zero over the wavelength range of 500–1000nm. Also, we have demonstrated that arrays of micro/nano holes could be formed in thin Ti foils by direct laser treatment.",Elsevier,Optics and Lasers in Engineering,2010
858,A comparative study of EMI shielding properties of carbon nanofiber and multi-walled carbon nanotube filled polymer composites,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oqJlgpUAAAAJ&citation_for_view=oqJlgpUAAAAJ:e5wmG9Sq2KIC,"Electromagnetic interference shielding properties of carbon nanofiber– and multi-walled carbon nanotube–filled polystyrene composites were investigated in the frequency range of 8.2–12.4 GHz (X-band). It was observed that the shielding effectiveness of composites was frequency independent, and increased with the increase of carbon nanofiber or nanotube loading. At the same filler loading, multi-walled carbon nanotube–filled polystyrene composites exhibited higher shielding effectiveness compared to those filled with carbon nanofibers. In particular, carbon nanotubes were more effective than nanofibers in providing high EMI shielding at low filler loadings. The experimental data showed that the shielding effectiveness of the composite containing 7 wt% carbon nanotubes could reach more than 26 dB, implying that such a composite can be used as a potential electromagnetic interference shielding material …",American Scientific Publishers,,2005
859,"A High Spatial and Depth Resolution Deep-UV 266 nm Wavelength Laser-Based Integrated LIBS, Fluorescence, and Raman System for Probing Lunar and Planetary Simulants and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oqJlgpUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oqJlgpUAAAAJ:q-HalDI95KYC,"A high spatial and depth resolution deep-ultraviolet (UV) 266 nm wavelength laser-based integrated laser-induced breakdown spectroscopy (LIBS), fluorescence, and Raman (LFR) system was developed for qualitatively probing lunar and planetary simulants and geological materials. The LFR system involves the use of a simple, low-weight, and compact LFR optical head (6 cm × 3 cm × 5 cm) consisting of common optics (filters, lens, and optical fibers) while being supported by an external single deep-UV pulsed laser source at 266 nm wavelength and a shared spectrometer for multifunctional Raman, fluorescence, and LIBS spectroscopy. A spatial resolution of about 15 μm was achieved and can be further decreased to under a μm. The submicron depth resolution was achieved by the 266 nm wavelength laser ablation process and can be further improved to tens of nanometers. The performance of the integrated …",American Chemical Society,,2025
860,Mixture Detection Using a Deep-UV Raman-LIBS Autofocus-Based Compact Chemical Spectroscopic Sensor,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oqJlgpUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oqJlgpUAAAAJ:DBa1UEJaJKAC,"We present a compact, multifunctional chemical sensor that seamlessly integrates deep-UV Raman and laser-induced breakdown spectroscopy (LIBS) modalities into a single lightweight hand-held unit. By employing a single 266 nm laser source (1.5 ns pulse width, 10 mW average power) and an integrated autofocus mechanism, this design overcomes the complexities associated with systems that rely on dual or multiple laser wavelengths (e.g., 532 or 1064 nm). The 3D-printed sensor body weighs only 38 g and occupies a compact volume of 70 × 60 × 40 mm3 (that can fit within a palm of a hand) enabling comfortable hand-held operation in both laboratory and field environments. When combined with a 215 g deep-UV compact laser unit and a 90 g compact but high-resolution spectrometer (which is possible only with deep-UV operation), the overall system weight remains under 500 g, reinforcing its suitability …",American Chemical Society,,2025
861,Laser fabrication of lead selenide thin film,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oqJlgpUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oqJlgpUAAAAJ:48xauSegjOkC,"A laser sintering deposition method is provided for disposing lead selenide onto a substrate. The method includes: wet-milling a lead selenide ingot mixed with methanol into a colloidal slurry containing nanocrystals; separating the colloidal slurry into nanocrystal particles and the methanol; depositing the nanocrystal particles to a substrate; and emitting coherent infrared light onto the nanocrystal particles for fusing into a lead selenide crystalline film. Afterwards, the lead selenide film can be exposed to oxygen to form a lead selenite layer, and subsequently to iodine gas to produce a lead iodide layer onto the lead selenite layer.",,,2025
862,Gold Metal Recovery from Electronic Waste through Laser Generation of Micro and Nanoparticles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oqJlgpUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oqJlgpUAAAAJ:CdxZDUztZiMC,"Electronic waste (E-waste) is the fastest-growing waste stream globally, reaching 74.7 tonnes by 2030, containing significant amounts of valuable metals such as gold, silver, platinum, and copper. Mechanical, hydrometallurgical, pyrometallurgical, electrochemical, and biotechnological methods for recovering these metals from E-waste are often inefficient, costly, and environmentally harmful. This study presents the first demonstrations of laser ablation in recovering gold in the form of micro and higher-valued nanoparticles from E-waste. The ablation threshold is identified using modeling performed using the two-temperature model (TTM). Printed Circuit Boards (PCBs) with gold-plated electrodes were used as the target material. The laser ablation process was conducted using a picosecond UV-355 nm laser at maximum average laser power (18 W). The analysis, using UV–visible spectroscopy, shows the surface …",American Chemical Society,,2025
863,Laser Recycling of Silver in Bulk and nanoparticle Form from Silicon Solar Cells and Deep Learning for Process Automation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oqJlgpUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=oqJlgpUAAAAJ:LPtt_HFRSbwC,"This study advances the green recycling of silver from silicon solar cells by selectively removing silver from electrical contact lines through laser ablation. The laser ablation process, conducted in the air and in the water medium, provided microparticles and higher-value silver nanoparticles, respectively. Optical microscopy and energy dispersive X-ray spectroscopy (EDS) analysis confirmed the successful removal and recovery of silver. A basic understanding of laser removal of Ag is provided. Comprehensive characterization revealed the nanoparticles' size, shape, and elemental composition, with optimized laser parameters achieving 93% purity by weight, with the remaining 7% primarily silicon. Additionally, convolutional neural networks (CNNs) trained with TensorFlow accurately detected silver lines on broken silicon solar cells. A comprehensive training dataset enabled high accuracy across diverse …",Pergamon,,2025
864,Ultra-fast germanium photodiode with 3-dB bandwidth of 265 GHz,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=l8jYBLUAAAAJ&citation_for_view=l8jYBLUAAAAJ:kzcSZmkxUKAC,"On a scalable silicon technology platform, we demonstrate photodetectors matching or even surpassing state-of-the-art III–V devices. As key components in high-speed optoelectronics, photodetectors with bandwidths greater than 100 GHz have been a topic of intense research for several decades. Solely InP-based detectors could satisfy the highest performance specifications. Devices based on other materials, such as germanium-on-silicon devices, used to lag behind in speed, but enabled complex photonic integrated circuits and co-integration with silicon electronics. Here we demonstrate waveguide-coupled germanium photodiodes with optoelectrical 3-dB bandwidths of 265 GHz and 240 GHz at a photocurrent of 1 mA. This outstanding performance is achieved by a novel device concept in which a germanium fin is sandwiched between complementary in situ-doped silicon layers. Our photodetectors …",Nature Publishing Group UK,,2021
865,High-saturation-current modified uni-traveling-carrier photodiode with cliff layer,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=l8jYBLUAAAAJ&citation_for_view=l8jYBLUAAAAJ:_Ybze24A_UAC,"We demonstrate two modified uni-traveling carrier photodiode (MUTC) structures that incorporate a charge or “cliff” layer to attain high-saturation-current. MUTC1 achieved responsivity of 0.82 A/W and 134 mA saturation current at -6-V and 20 GHz. The MUTC2 structure, which has higher doping density in the cliff layer and thinner absorption region, exhibited a higher saturation current of 144 mA (at -5-V) and an improved 3 dB bandwidth of 24 GHz; however, the responsivity was reduced to 0.69 A/W. For MUTC2, a high-saturation-current bandwidth product of 3456 GHz mA has been achieved. An intermodulation distortion figure of merit, IP3, > dBm at 20 GHz was observed for both MUTC structures.",IEEE,,2010
866,"High-power, high-linearity photodiodes",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=l8jYBLUAAAAJ&citation_for_view=l8jYBLUAAAAJ:_OXeSy2IsFwC,"Microwave photonics and optics-based analog links are technologies that are being developed for a growing number of applications. Photodetectors that operate at high power levels are key components. Additionally, it is important for many of these applications that the photodiodes have millimeter-wave bandwidths and highly linear response. This paper reviews the performance of modified uni-traveling carrier photodiodes with respect to these characteristics.",Optical Society of America,Optica,2016
867,Integrated optical frequency division for microwave and mmWave generation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=l8jYBLUAAAAJ&citation_for_view=l8jYBLUAAAAJ:k_7cPK9k7w8C,"The generation of ultra-low-noise microwave and mmWave in miniaturized, chip-based platforms can transform communication, radar and sensing systems, –. Optical frequency division that leverages optical references and optical frequency combs has emerged as a powerful technique to generate microwaves with superior spectral purity than any other approaches, , –. Here we demonstrate a miniaturized optical frequency division system that can potentially transfer the approach to a complementary metal-oxide-semiconductor-compatible integrated photonic platform. Phase stability is provided by a large mode volume, planar-waveguide-based optical reference coil cavity, and is divided down from optical to mmWave frequency by using soliton microcombs generated in a waveguide-coupled microresonator, –. Besides achieving record-low phase noise for integrated photonic mmWave oscillators, these devices …",Nature Publishing Group UK,,2024
868,Integrated lithium niobate photonic computing circuit based on efficient and high-speed electro-optic conversion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=l8jYBLUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=l8jYBLUAAAAJ:wE-fMHVdjMkC,"The surge in artificial intelligence applications calls for scalable, high-speed, and low-energy computation methods. Computing with photons is promising due to the intrinsic parallelism, high bandwidth, and low latency of photons. However, current photonic computing architectures are limited by the speed and energy consumption associated with electronic-to-optical data transfer, i.e., electro-optic conversion. Here, we demonstrate a thin-film lithium niobate (TFLN) computing circuit that addresses this challenge, leveraging both highly efficient electro-optic modulation and the spatial scalability of TFLN photonics. Our circuit is capable of computing at 43.8 GOPS/channel while consuming 0.0576 pJ/OP, and we demonstrate various inference tasks with high accuracy, including the classification of binary data and complex images. Heightening the integration level, we show another TFLN computing circuit that is …",Nature Publishing Group UK,,2025
869,Universal electronic synthesis by microresonator-soliton photomixing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=l8jYBLUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=l8jYBLUAAAAJ:isU91gLudPYC,"Access to electrical signals across the millimeter-wave (mmW) and terahertz (THz) bands offers breakthroughs for high-performance applications. Despite generations of revolutionary development, integrated electronics are challenging to operate beyond 100 GHz. Therefore, new technologies that generate wideband and tunable electronic signals would advance wireless communication, high-resolution imaging and scanning, spectroscopy, and network formation. Photonic approaches have been demonstrated for electronic signal generation, but at the cost of increased size and power consumption. Here, we describe a chip-scale, universal mmW frequency synthesizer, which uses integrated nonlinear photonics and high-speed photodetection to exploit the nearly limitless bandwidth of light. We use a photonic-integrated circuit to generate dual, microresonator-soliton frequency combs whose interferogram is fundamentally composed of harmonic signals spanning the mmW and THz bands. By phase coherence of the dual comb, we precisely stabilize and synthesize the interferogram to generate any output frequency from DC to >1000 GHz. Across this entire range, the synthesizer exhibits exceptional absolute fractional frequency accuracy and precision, characterized by an Allan deviation of 3*10^(-12) in 1 s measurements. We use a modified uni-traveling-carrier (MUTC) photodiode with an operating frequency range to 500 GHz to convert the interferogram to an electrical signal, generating continuously tunable tones across the entire mmW band. The synthesizer phase noise at a reference frequency of 150 GHz is -83 dBc/Hz at 100 kHz offset …",,,2025
870,Community-based game design: experiments on social games for commonsense data collection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pNkyRs4AAAAJ&citation_for_view=pNkyRs4AAAAJ:u5HHmVD_uO8C,"Games with A Purpose have successfully harvested information from web users. However, designing games that encourage sustainable and quality data contribution remains a great challenge. Given that many online communities have enjoyed active participation from a loyal following, this research explores how human computation games may benefit from rich interactions inherent in a community. We experimented by implementing two games for commonsense data collection on the leading social community platforms: the Rapport Game on Facebook and the Virtual Pet Game on PTT. In this paper, we present the choices of interaction mode and goal-oriented user model for building a community-based game. The data quality, collection efficiency, player retention, concept diversity, and game stability of both games are analyzed quantitatively from data collected since August/November 2008. Our findings should …",,,2009
871,Mmtom-qa: Multimodal theory of mind question answering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pNkyRs4AAAAJ&citation_for_view=pNkyRs4AAAAJ:hC7cP41nSMkC,"Theory of Mind (ToM), the ability to understand people's mental states, is an essential ingredient for developing machines with human-level social intelligence. Recent machine learning models, particularly large language models, seem to show some aspects of ToM understanding. However, existing ToM benchmarks use unimodal datasets - either video or text. Human ToM, on the other hand, is more than video or text understanding. People can flexibly reason about another person's mind based on conceptual representations (e.g., goals, beliefs, plans) extracted from any available data. To address this, we introduce a multimodal Theory of Mind question answering (MMToM-QA) benchmark. MMToM-QA comprehensively evaluates machine ToM both on multimodal data and on different kinds of unimodal data about a person's activity in a household environment. To engineer multimodal ToM capacity, we propose a novel method, BIP-ALM (Bayesian Inverse Planning Accelerated by Language Models). BIP-ALM extracts unified representations from multimodal data and utilizes language models for scalable Bayesian inverse planning. We conducted a systematic comparison of human performance, BIP-ALM, and state-of-the-art models, including GPT-4. The experiments demonstrate that large language models and large multimodal models still lack robust ToM capacity. BIP-ALM, on the other hand, shows promising results, by leveraging the power of both model-based mental inference and language models.",,,2024
872,Encoding formulas as deep networks: Reinforcement learning for zero-shot execution of LTL formulas,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pNkyRs4AAAAJ&citation_for_view=pNkyRs4AAAAJ:hqOjcs7Dif8C,"We demonstrate a reinforcement learning agent which uses a compositional recurrent neural network that takes as input an LTL formula and determines satisfying actions. The input LTL formulas have never been seen before, yet the network performs zero-shot generalization to satisfy them. This is a novel form of multi-task learning for RL agents where agents learn from one diverse set of tasks and generalize to a new set of diverse tasks. The formulation of the network enables this capacity to generalize. We demonstrate this ability in two domains. In a symbolic domain, the agent finds a sequence of letters that is accepted. In a Minecraft-like environment, the agent finds a sequence of actions that conform to the formula. While prior work could learn to execute one formula reliably given examples of that formula, we demonstrate how to encode all formulas reliably. This could form the basis of new multitask agents …",IEEE,,2020
873,Learning a natural-language to LTL executable semantic parser for grounded robotics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pNkyRs4AAAAJ&citation_for_view=pNkyRs4AAAAJ:8k81kl-MbHgC,"Children acquire their native language with apparent ease by observing how language is used in context and attempting to use it themselves. They do so without laborious annotations, negative examples, or even direct corrections. We take a step toward robots that can do the same by training a grounded semantic parser, which discovers latent linguistic representations that can be used for the execution of natural-language commands. In particular, we focus on the difficult domain of commands with a temporal aspect, whose semantics we capture with Linear Temporal Logic, LTL. Our parser is trained with pairs of sentences and executions as well as an executor. At training time, the parser hypothesizes a meaning representation for the input as a formula in LTL. Three competing pressures allow the parser to discover meaning from language. First, any hypothesized meaning for a sentence must be permissive enough to reflect all the annotated execution trajectories. Second, the executor—a pretrained end-to-end LTL planner—must find that the observed trajectories are likely executions of the meaning. Finally, a generator, which reconstructs the original input, encourages the model to find representations that conserve knowledge about the command. Together these ensure that the meaning is neither too general nor too specific. Our model generalizes well, being able to parse and execute both machine-generated and human-generated commands, with near-equal accuracy, despite the fact that the human-generated sentences are much more varied and complex with an open lexicon. The approach presented here is not specific to LTL: it can …",,,2020
874,Reconstructing action-conditioned human-object interactions using commonsense knowledge priors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pNkyRs4AAAAJ&citation_for_view=pNkyRs4AAAAJ:Wp0gIr-vW9MC,"We present a method for inferring diverse 3D models of human-object interactions from images. Reasoning about how humans interact with objects in complex scenes from a single 2D image is a challenging task given ambiguities arising from the loss of information through projection. In addition, modeling 3D interactions requires the generalization ability towards diverse object categories and interaction types. We propose an action-conditioned modeling of interactions that allows us to infer diverse 3D arrangements of humans and objects without supervision on contact regions or 3D scene geometry. Our method extracts high-level commonsense knowledge from large language models (such as GPT-3), and applies them to perform 3D reasoning of human-object interactions. Our key insight is priors extracted from large language models can help in reasoning about human-object contacts from textural prompts …",IEEE,,2022
875,Class: Contrastive learning via action sequence supervision for robot manipulation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pNkyRs4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pNkyRs4AAAAJ:M3NEmzRMIkIC,"Recent advances in Behavior Cloning (BC) have led to strong performance in robotic manipulation, driven by expressive models, sequence modeling of actions, and large-scale demonstration data. However, BC faces significant challenges when applied to heterogeneous datasets, such as visual shift with different camera poses or object appearances, where performance degrades despite the benefits of learning at scale. This stems from BC’s tendency to overfit individual demonstrations rather than capture shared structure, limiting generalization. To address this, we introduce Contrastive Learning via Action Sequence Supervision (CLASS), a method for learning behavioral representations from demonstrations using supervised contrastive learning. CLASS leverages weak supervision from similar action sequences identified via Dynamic Time Warping (DTW) and optimizes a soft InfoNCE loss with similarity …",PMLR,,2025
876,OAfford: One-Shot 3D Object-to-Object Affordance Grounding for Generalizable Robotic Manipulation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pNkyRs4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pNkyRs4AAAAJ:JV2RwH3_ST0C,"Grounding object affordance is fundamental to robotic manipulation as it establishes the critical link between perception and action among interacting objects. However, prior works predominantly focus on predicting single-object affordance, overlooking the fact that most real-world interactions involve relationships between pairs of objects. In this work, we address the challenge of object-to-object affordance grounding under limited data contraints. Inspired by recent advances in few-shot learning with 2D vision foundation models, we propose a novel one-shot 3D object-to-object affordance learning approach for robotic manipulation. Semantic features from vision foundation models combined with point cloud representation for geometric understanding enable our one-shot learning pipeline to generalize effectively to novel objects and categories. We further integrate our 3D affordance representation with large language models (LLMs) for robotics manipulation, significantly enhancing LLMs' capability to comprehend and reason about object interactions when generating task-specific constraint functions. Our experiments on 3D object-to-object affordance grounding and robotic manipulation demonstrate that our OAfford significantly outperforms existing baselines in terms of both accuracy and generalization capability.",,,2025
877,Moving Out: Physically-grounded Human-AI Collaboration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pNkyRs4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pNkyRs4AAAAJ:maZDTaKrznsC,"The ability to adapt to physical actions and constraints in an environment is crucial for embodied agents (e.g., robots) to effectively collaborate with humans. Such physically grounded human-AI collaboration must account for the increased complexity of the continuous state-action space and constrained dynamics caused by physical constraints. In this paper, we introduce Moving Out, a new human-AI collaboration benchmark that resembles a wide range of collaboration modes affected by physical attributes and constraints, such as moving heavy items together and maintaining consistent actions to move a big item around a corner. Using Moving Out, we designed two tasks and collected human-human interaction data to evaluate models' abilities to adapt to diverse human behaviors and unseen physical attributes. To address the challenges in physical environments, we propose a novel method, BASS (Behavior Augmentation, Simulation, and Selection), to enhance the diversity of agents and their understanding of the outcome of actions. Our experiments show that BASS outperforms state-of-the-art models in AI-AI and human-AI collaboration. The project page is available at https://live-robotics-uva.github.io/movingout_ai/.",,,2025
878,Towards Physically-grounded Human-AI Collaboration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pNkyRs4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pNkyRs4AAAAJ:TFP_iSt0sucC,"Creating physically-grounded human-AI collaboration remains challenging because of continuous state-action spaces, constrained physical transitions, and diverse human behaviors. Successful collaboration in physical environments requires an agent to generalize their learned policies across three key collaboration modes: coordination, where agents must coordinate subtasks or movements and avoid collision; awareness, where agents need to recognize when another agent needs help and offer assistance; and action consistency, where agents must align their actions toward the same goals when engaging in joint actions. We designed Moving Out, a physical human-AI collaboration environment to illustrate these challenges and collaboration modes. We observe that existing AI agents often fail to assist appropriately, align actions, or generalize to unseen physical settings. Our findings suggest future research directions in physical reasoning, behavior adaptation, and reliable and scalable evaluation of human-AI collaboration.",,,2025
879,CaseEdit: Enhancing Localized Commonsense Reasoning via Null-Space Constrained Knowledge Editing in Small Parameter Language Models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pNkyRs4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pNkyRs4AAAAJ:bEWYMUwI8FkC,"Large language models (LLMs) exhibit strong performance on factual recall and general reasoning but struggle to adapt to user-specific, commonsense knowledge, a challenge particularly acute in small-parameter settings where computational efficiency is prioritized. We introduce CaseEdit, a new dataset and generation pipeline for evaluating localized, personalized commonsense knowledge editing in small LLMs to address this. Built upon the ATOMIC20/20 commonsense graph, CaseEdit uses a multi-stage inference process to generate both typical and atypical contextual edits for household objects, paired with targeted evaluation questions across four axes: reliability, generalization, locality, and portability. We evaluate established knowledge editing methods using CaseEdit and demonstrate that AlphaEdit, a technique employing null-space projection to minimize interference with unrelated knowledge, consistently outperforms other methods when applied to an LLaMA 3.2 3B model, even in scalability tests, showing minimal ripple effects. Our results indicate that using CaseEdit with effective editing techniques like AlphaEdit allows small models to internalize high-quality, context-sensitive common-sense knowledge, paving the way for lightweight, personalized assistants.",,,2025
880,Generative models for molecular discovery: Recent advances and challenges,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hOj9jT4AAAAJ&citation_for_view=hOj9jT4AAAAJ:_kc_bZDykSQC,"Development of new products often relies on the discovery of novel molecules. While conventional molecular design involves using human expertise to propose, synthesize, and test new molecules, this process can be cost and time intensive, limiting the number of molecules that can be reasonably tested. Generative modeling provides an alternative approach to molecular discovery by reformulating molecular design as an inverse design problem. Here, we review the recent advances in the state‐of‐the‐art of generative molecular design and discusses the considerations for integrating these models into real molecular discovery campaigns. We first review the model design choices required to develop and train a generative model including common 1D, 2D, and 3D representations of molecules and typical generative modeling neural network architectures. We then describe different problem statements for …","Wiley Periodicals, Inc.",Wiley Interdisciplinary Reviews: Computational Molecular Science,2022
881,"Autonomous, multiproperty-driven molecular discovery: From predictions to measurements and back",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hOj9jT4AAAAJ&citation_for_view=hOj9jT4AAAAJ:aqlVkmm33-oC,"A closed-loop, autonomous molecular discovery platform driven by integrated machine learning tools was developed to accelerate the design of molecules with desired properties. We demonstrated two case studies on dye-like molecules, targeting absorption wavelength, lipophilicity, and photooxidative stability. In the first study, the platform experimentally realized 294 unreported molecules across three automatic iterations of molecular design-make-test-analyze cycles while exploring the structure-function space of four rarely reported scaffolds. In each iteration, the property prediction models that guided exploration learned the structure-property space of diverse scaffold derivatives, which were realized with multistep syntheses and a variety of reactions. The second study exploited property models trained on the explored chemical space and previously reported molecules to discover nine top-performing …",American Association for the Advancement of Science,,2023
882,Predicting small molecule transfer free energies by combining molecular dynamics simulations and deep learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hOj9jT4AAAAJ&citation_for_view=hOj9jT4AAAAJ:LkGwnXOMwfcC,"Accurately predicting small molecule partitioning and hydrophobicity is critical in the drug discovery process. There are many heterogeneous chemical environments within a cell and entire human body. For example, drugs must be able to cross the hydrophobic cellular membrane to reach their intracellular targets, and hydrophobicity is an important driving force for drug–protein binding. Atomistic molecular dynamics (MD) simulations are routinely used to calculate free energies of small molecules binding to proteins, crossing lipid membranes, and solvation but are computationally expensive. Machine learning (ML) and empirical methods are also used throughout drug discovery but rely on experimental data, limiting the domain of applicability. We present atomistic MD simulations calculating 15,000 small molecule free energies of transfer from water to cyclohexane. This large data set is used to train ML models …",American Chemical Society,,2020
883,Toward in silico CMC: An industrial collaborative approach to model‐based process development,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hOj9jT4AAAAJ&citation_for_view=hOj9jT4AAAAJ:_FxGoFyzp5QC,"The Third Modeling Workshop focusing on bioprocess modeling was held in Kenilworth, NJ in May 2019. A summary of these Workshop proceedings is captured in this manuscript. Modeling is an active area of research within the biotechnology community, and there is a critical need to assess the current state and opportunities for continued investment to realize the full potential of models, including resource and time savings. Beyond individual presentations and topics of novel interest, a substantial portion of the Workshop was devoted toward group discussions of current states and future directions in modeling fields. All scales of modeling, from biophysical models at the molecular level and up through large scale facility and plant modeling, were considered in these discussions and are summarized in the manuscript. Model life cycle management from model development to implementation and sustainment are …",,Biotechnology and bioengineering,2020
884,Machine learning for predicting the viscosity of binary liquid mixtures,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hOj9jT4AAAAJ&citation_for_view=hOj9jT4AAAAJ:M3ejUd6NZC8C,"Viscosity is an important parameter in process engineering and is a key design objective for application areas including the coatings, lubricants, personal care, and pharmaceutical industries. The lack of reliable and general methods for predicting the viscosities of mixtures creates a barrier for modern process engineering and product design. In this work, we developed a graph-based neural network architecture and applied it to the problem of predicting the viscosity of binary liquid mixtures as a function of composition and temperature. To obtain a high-quality training dataset, we also developed an automated curation pipeline and applied it to a large dataset collected from the literature by the National Institute of Standards and Technology (NIST) to be used as training data. The resulting model predicts viscosity with an MAE of 0.043 and an RMSE of 0.080 in log cP units (base 10). To improve the dependability of …",Elsevier,,2023
885,The Future of Artificial Intelligence and the Mathematical and Physical Sciences (AI+ MPS),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hOj9jT4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hOj9jT4AAAAJ:iH-uZ7U-co4C,"This community paper developed out of the NSF Workshop on the Future of Artificial Intelligence (AI) and the Mathematical and Physics Sciences (MPS), which was held in March 2025 with the goal of understanding how the MPS domains (Astronomy, Chemistry, Materials Research, Mathematical Sciences, and Physics) can best capitalize on, and contribute to, the future of AI. We present here a summary and snapshot of the MPS community's perspective, as of Spring/Summer 2025, in a rapidly developing field. The link between AI and MPS is becoming increasingly inextricable; now is a crucial moment to strengthen the link between AI and Science by pursuing a strategy that proactively and thoughtfully leverages the potential of AI for scientific discovery and optimizes opportunities to impact the development of AI by applying concepts from fundamental science. To achieve this, we propose activities and strategic priorities that: (1) enable AI+MPS research in both directions; (2) build up an interdisciplinary community of AI+MPS researchers; and (3) foster education and workforce development in AI for MPS researchers and students. We conclude with a summary of suggested priorities for funding agencies, educational institutions, and individual researchers to help position the MPS community to be a leader in, and take full advantage of, the transformative potential of AI+MPS.",,,2025
886,Energy-Based Models for Predicting Mutational Effects on Proteins,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hOj9jT4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hOj9jT4AAAAJ:r0BpntZqJG4C,"Predicting changes in binding free energy (ΔΔ G) is a vital task in protein engineering and protein-protein interaction (PPI) engineering for drug discovery. Previous works have observed a high correlation between ΔΔ G and entropy, using probabilities of biologically important objects such as side chain angles and residue identities to estimate ΔΔ G. However, estimating the full conformational distribution of a protein complex is generally considered intractable. In this work, we propose a new approach to ΔΔ G prediction that avoids this issue by instead leveraging energy-based models for estimating the probability of a complex's conformation. Specifically, we novelly decompose ΔΔ G into a sequence-based component estimated by an inverse folding model and a structure-based component estimated by an energy model. This decomposition is made tractable by assuming equilibrium between the bound and …",,,2025
887,Deep Interactions for Multimodal Molecular Property Prediction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hOj9jT4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hOj9jT4AAAAJ:HDshCWvjkbEC,"Multi-modal learning by means of leveraging both 2D graph and 3D point cloud information has become a prevalent method to improve model performance in molecular property prediction. However, many recent techniques focus on specific pre-training tasks such as contrastive learning, feature blending, and atom/subgraph masking in order to learn multi-modality even though design of model architecture is also impactful for both pre-training and downstream task performance. Relying on pre-training tasks to align 2D and 3D modalities lacks direct interaction which may be more effective in multimodal learning. In this work, we propose MolInteract, which takes a simple yet effective architecture-focused approach to multimodal molecule learning which addresses these challenges. MolInteract leverages an interaction layer for fusing 2D and 3D information and fostering cross-modal alignment, showing strong …",Springer Nature Singapore,,2025
888,CAREER: Peptide-Functionalized Surfaces for Designing Tunable Nanoscale Patterns,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hOj9jT4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hOj9jT4AAAAJ:_Qo2XoVZTnwC,"This CAREER award supports computational and theoretical research aimed at designing peptide-functionalized surfaces with tunable nano-scale patterns. Controlling how surfaces interact with water is critical for engineering many useful properties. For example, modulating surface stickiness plays an important role in designing surfaces to serve as artificial tissue scaffolds, inducing water evaporation is valuable for manufacturing electronic components, and controlling selective surface interactions is important purifying drugs. A powerful strategy for altering surface properties is attaching molecules with desirable properties to the surface. A major challenge with designing such molecules, however, is that they often change their behavior when tethered to a surface. The goal of this project is to understand how molecules change their behaviors when tethered to a surface, and how these molecular behaviors control …",,,2025
889,PepMNet: a hybrid deep learning model for predicting peptide properties using hierarchical graph representations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hOj9jT4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=hOj9jT4AAAAJ:TQgYirikUcIC,"Peptides are a powerful class of molecules that can be applied to a range of problems including biomaterials development and drug design. Currently, machine learning-based property prediction models for peptides primarily rely on amino acid sequence, resulting in two key limitations: first, they are not compatible with non-natural peptide features like modified sidechains or staples, and second, they use human-crafted features to describe the relationships between different amino acids, which reduces the model's flexibility and generalizability. To address these challenges, we have developed PepMNet, a deep learning model that integrates atom-level and amino acid-level information through a hierarchical graph approach. The model first learns from an atom-level graph and then generates amino acid representations based on the atomic information captured in the first stage. These amino acid representations …",Royal Society of Chemistry,,2025
890,Electron-phonon coupling and electron heat capacity of metals under conditions of strong electron-phonon nonequilibrium,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kDoVrCgAAAAJ&citation_for_view=kDoVrCgAAAAJ:UeHWp8X0CEIC,"The dependence of the strength of the electron-phonon coupling and the electron heat capacity on the electron temperature is investigated for eight representative metals, Al, Cu, Ag, Au, Ni, Pt, W, and Ti, for the conditions of strong electron-phonon nonequilibrium. These conditions are characteristic of metal targets subjected to energetic ion bombardment or short-pulse laser irradiation. Computational analysis based on first-principles electronic structure calculations of the electron density of states predicts large deviations (up to an order of magnitude) from the commonly used approximations of linear temperature dependence of the electron heat capacity and a constant electron-phonon coupling. These thermophysical properties are found to be very sensitive to details of the electronic structure of the material. The strength of the electron-phonon coupling can either increase (Al, Au, Ag, Cu, and W), decrease (Ni …",American Physical Society,,2008
891,Combined atomistic-continuum modeling of short-pulse laser melting and disintegration of metal films,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kDoVrCgAAAAJ&citation_for_view=kDoVrCgAAAAJ:u-x6o8ySG0sC,"The kinetics and microscopic mechanisms of laser melting and disintegration of thin Ni and Au films irradiated by a short, from 200 fs to 150 ps, laser pulse are investigated in a coupled atomistic-continuum computational model. The model provides a detailed atomic-level description of fast nonequilibrium processes of laser melting and film disintegration and, at the same time, ensures an adequate description of the laser light absorption by the conduction band electrons, the energy transfer to the lattice due to the electron-phonon coupling, and the fast electron heat conduction in metals. The interplay of two competing processes, the propagation of the liquid-crystal interfaces (melting fronts) from the external surfaces of the film and homogeneous nucleation and growth of liquid regions inside the crystal, is found to be responsible for melting of metal films irradiated by laser pulses at fluences close to the melting …",American Physical Society,,2003
892,"Atomistic modeling of short pulse laser ablation of metals: connections between melting, spallation, and phase explosion",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kDoVrCgAAAAJ&citation_for_view=kDoVrCgAAAAJ:mVmsd5A6BfQC,"The mechanisms of short pulse laser interactions with a metal target are investigated in simulations performed with a model combining the molecular dynamics method with a continuum description of laser excitation, electron−phonon equilibration, and electron heat conduction. Three regimes of material response to laser irradiation are identified in simulations performed with a 1 ps laser pulse, which corresponds to the condition of stress confinement: melting and resolidification of a surface region of the target, photomechanical spallation of a single or multiple layers or droplets, and an explosive disintegration of an overheated surface layer (phase explosion). The processes of laser melting, spallation, and phase explosion are taking place on the same time scale and are closely intertwined with each other. The transition to the spallation regime results in a reduction of the melting zone and a sharp drop in the …",American Chemical Society,,2009
893,Microscopic mechanisms of laser ablation of organic solids in the thermal and stress confinement irradiation regimes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kDoVrCgAAAAJ&citation_for_view=kDoVrCgAAAAJ:u5HHmVD_uO8C,"The results of large-scale molecular dynamics simulations demonstrate that the mechanisms responsible for material ejection as well as most of the parameters of the ejection process have a strong dependence on the rate of the laser energy deposition. For longer laser pulses, in the regime of thermal confinement, a phase explosion of the overheated material is responsible for the collective material ejection at laser fluences above the ablation threshold. This phase explosion leads to a homogeneous decomposition of the expanding plume into a mixture of liquid droplets and gas phase molecules. The decomposition proceeds through the formation of a transient structure of interconnected liquid clusters and individual molecules and leads to the fast cooling of the ejected plume. For shorter laser pulses, in the regime of stress confinement, a lower threshold fluence for the onset of ablation is observed and attributed …",American Institute of Physics,,2000
894,Effects of temperature and disorder on thermal boundary conductance at solid–solid interfaces: Nonequilibrium molecular dynamics simulations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kDoVrCgAAAAJ&citation_for_view=kDoVrCgAAAAJ:_FxGoFyzp5QC,"Thermal transport across interfaces is becoming increasingly important with the advent of nanostructures and nanocomposite materials. A nonequilibrium molecular dynamics (NEMD) approach is developed to investigate thermal transport across solid–solid interfaces. Thermal boundary conductance is calculated for a range of mismatched interfaces and compared to the diffuse mismatch model (DMM). The interfacial conductance decreased with increasing mismatch, as expected. The DMM fits the NEMD results well for poorly matched interfaces at a temperature approximately half of the melting temperature of the material, but it underpredicts the conductance for highly matched interfaces. One of the key findings of this study is that there is a significant interfacial thermal transport dependence on temperature in the NEMD simulations, which is not accounted for by the mismatch models where only elastic scattering …",Pergamon,,2007
895,Effects of material density and structural anisotropy on thermal transport in carbon nanotube materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kDoVrCgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=kDoVrCgAAAAJ:PaBasH6fAo0C,"The scaling of thermal conductivity of carbon nanotube (CNT) materials with density has been a subject of active debates, with contradictory experimental and theoretical claims reflecting intrinsic difficulties in the fabrication or in silico generation of material samples with uniform network structures in a broad density range. In the present work, the effects of material density and structural anisotropy on thermal conductivity of CNT aerogels, films, and fibers are studied in large-scale mesoscopic simulations. For all three material types, the calculated thermal conductivity is found to follow a nearly linear scaling law with respect to material density. The results of the calculations are consistent with a large array of diverse experimental data but are in a sharp contrast with quadratic scaling with density predicted theoretically for systems consisting of straight and dispersed CNTs, where the conductivity is controlled by point …",Pergamon,,2025
896,Time-resolved probing and modeling of optical signatures of ultrashort-pulse laser spallation and phase explosion in iron-nickel targets,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kDoVrCgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=kDoVrCgAAAAJ:7BrZ7Jt4UNcC,"Time-resolved microscopy is an established technique for probing the dynamics of laser ablation, thus enabling the exploration of material behavior under extreme conditions produced by laser excitation. Decoding the time-resolved data on the rapid variation of optical properties of a material undergoing nonequilibrium phase decomposition and ejection, however, presents a significant challenge. In this paper, a closely integrated computational and experimental study of laser ablation of FeNi targets is used to establish direct links between the dynamics of laser ablation and the evolution of optical signal in pump-probe experimental measurements. The experiments and large-scale atomistic simulations are performed for a range of fluences covering the onset of material ejection at the threshold for photomechanical spallation and the transition to the phase explosion regime of laser ablation. The connections …",American Physical Society,,2025
897,Dynamics of nanoscale phase decomposition in laser ablation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kDoVrCgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=kDoVrCgAAAAJ:v1_lew4L6wgC,"Laser ablation is a process that bears both fundamental physics interest and has wide industrial applications. For decades, the lack of probes on the relevant time and length scales has prevented access to the highly nonequilibrium phase decomposition processes triggered by laser excitation. In this study, a close integration of time-resolved probing by intense femtosecond X-ray pulses with large-scale atomistic modeling has yielded unique insights into the ablation dynamics of thin gold films irradiated by femtosecond laser pulses. The emergence and growth of nanoscale density heterogeneities in the expanding ablation plume, predicted in the simulations, are mapped to the rapid evolution of distinct small angle diffraction features. This mapping enables identification of the characteristic signatures of different phase decomposition processes occurring simultaneously in the plume, which are driven by …",Nature Publishing Group UK,,2025
898,Thermal conductivity of three-dimensional disordered isotropic fibrous materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kDoVrCgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=kDoVrCgAAAAJ:7Hz3ACDFbsoC,"Thermal conductivity of three-dimensional isotropic disordered fibrous materials is studied both numerically and theoretically based on a model of random thermal contacts between soft-core spherocylinders with finite intrinsic conductivity. Numerical results are obtained in a broad range of governing parameters that include fiber density, varying from the percolation threshold up to values characteristic of dense networks, fiber aspect ratio, and Biot number for a single contact. Near the percolation threshold, direct calculations of the material thermal conductivity as a function of reduced density parameter show that the conductivity follows a universal power law with exponent close to 2 independently on the fiber aspect ratio. For dense networks, a theoretical equation for the thermal conductivity of materials composed of spherocylinders with an arbitrary aspect ratio is derived. Both the theoretical solution and numerical …",Pergamon,,2025
899,Atomistic modelling of femtosecond laser melting of Pb nanoparticles embedded in Al film,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kDoVrCgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=kDoVrCgAAAAJ:nRpfm8aw39MC,"Ultrashort pulse laser irradiation of nanoparticles embedded into a matrix with a higher melting point presents a case study for investigation of the kinetics and mechanisms of nanoscale melting occurring in the absence of surface nucleation of liquid phase. The ultrahigh heating rates induced by femtosecond laser irradiation, ∼1015 K/s, create conditions of substantial superheating prior to the onset of rapid homogeneous melting. The suppression of surface nucleation of liquid phase in the embedded nanoparticles can further increase the maximum values of superheating, but the detailed understanding of the kinetics and mechanisms of melting under confinement by the matrix material is still lacking. In this study, the melting of an octahedral 20 nm Pb nanoparticle embedded into a 30-nm-thick Al film and irradiated by a 110 fs laser pulse is investigated in a series of molecular dynamics simulations. The heating of …",Elsevier,,2025
900,Estimating static models of strategic interactions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QB_fwL8AAAAJ&citation_for_view=QB_fwL8AAAAJ:u-x6o8ySG0sC,"We study the estimation of static games of incomplete information with multiple equilibria. A static game is a generalization of a discrete choice model, such as a multinomial logit or probit, which allows the actions of a group of agents to be interdependent. While the estimator we study is quite flexible, in most cases it can be easily implemented using standard statistical packages such as STATA. We also propose an algorithm for simulating the model which finds all equilibria to the game. As an application of our estimator, we study recommendations for high technology stocks between 1998–2003. We find that strategic motives, typically ignored in the empirical literature, appear to be an important consideration in the recommendations submitted by equity analysts.",Taylor & Francis,,2010
901,Machine learning methods for demand estimation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QB_fwL8AAAAJ&citation_for_view=QB_fwL8AAAAJ:hC7cP41nSMkC,"We survey and apply several techniques from the statistical and computer science literature to the problem of demand estimation. To improve out-of-sample prediction accuracy, we propose a method of combining the underlying models via linear regression. Our method is robust to a large number of regressors; scales easily to very large data sets; combines model selection and estimation; and can flexibly approximate arbitrary non-linear functions. We illustrate our method using a standard scanner panel data set and find that our estimates are considerably more accurate in out-of-sample predictions of demand than some commonly used alternatives.",American Economic Association,,2015
902,Nonlinear models of measurement errors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QB_fwL8AAAAJ&citation_for_view=QB_fwL8AAAAJ:9yKSN-GCB0IC,"Measurement errors in economic data are pervasive and nontrivial in size. The presence of measurement errors causes biased and inconsistent parameter estimates and leads to erroneous conclusions to various degrees in economic analysis. While linear errors-in-variables models are usually handled with well-known instrumental variable methods, this article provides an overview of recent research papers that derive estimation methods that provide consistent estimates for nonlinear models with measurement errors. We review models with both classical and nonclassical measurement errors, and with misclassification of discrete variables. For each of the methods surveyed, we describe the key ideas for identification and estimation, and discuss its application whenever it is currently available. (JEL C20, C26, C50)",American Economic Association,,2011
903,A structural model of sponsored search advertising auctions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QB_fwL8AAAAJ&citation_for_view=QB_fwL8AAAAJ:2osOgNQ5qMEC,"A Structural Model of Sponsored Search Advertising Auctions Page 1 A Structural Model of Sponsored Search Advertising Auctions S. Athey and D. Nekipelov presented by Marcelo A. Fernández February 26, 2014 Page 2 Page 3 Page 4 Remarks ▶ The search engine does not sell specific positions on the page.▶ The search engine only gets paid if you click on the ad. ▶ Instead of selling a lottery, it is selling a contingent good, which it does not own or control. 1 or at least not explicitly, it can be the case in equilibrium. Page 5 Sponsored Search Auctions - Overview ▶ Bidders enter per-click (standing) bids into a database. ▶ Each time a user enters that query, the bids for that query are called from the database and enter an auction ▶ Bids are ranked(*) and per-click prices are determined. ▶ Ads are displayed in rank order for a fixed number of slots. Page 6 Sponsored Search Auctions - Rank ▶ The search engine …",,,2010
904,Econometrics for learning agents,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QB_fwL8AAAAJ&citation_for_view=QB_fwL8AAAAJ:_Qo2XoVZTnwC,"The main goal of this paper is to develop a theory of inference of player valuations from observed data in the generalized second price auction without relying on the Nash equilibrium assumption. Existing work in Economics on inferring agent values from data relies on the assumption that all participant strategies are best responses of the observed play of other players, i.e. they constitute a Nash equilibrium. In this paper, we show how to perform inference relying on a weaker assumption instead: assuming that players are using some form of no-regret learning. Learning outcomes emerged in recent years as an attractive alternative to Nash equilibrium in analyzing game outcomes, modeling players who haven't reached a stable equilibrium, but rather use algorithmic learning, aiming to learn the best way to play from previous observations. In this paper we show how to infer values of players who use algorithmic …",,,2015
905,Suggested searches,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QB_fwL8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=QB_fwL8AAAAJ:geHnlv5EZngC,"Chromosomal abnormalities are a common cause of human miscarriage but rarely reported in any other species. As a result, there are currently inadequate animal models available to study this condition. Horses present one potential model since mares receive...",,,2024
906,Statistical inference of optimal allocations I: Regularities and their implications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QB_fwL8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=QB_fwL8AAAAJ:eflP2zaiRacC,"In this paper, we develop a functional differentiability approach for solving statistical optimal allocation problems. We derive Hadamard differentiability of the value functions through analyzing the properties of the sorting operator using tools from geometric measure theory. Building on our Hadamard differentiability results, we apply the functional delta method to obtain the asymptotic properties of the value function process for the binary constrained optimal allocation problem and the plug-in ROC curve estimator. Moreover, the convexity of the optimal allocation value functions facilitates demonstrating the degeneracy of first order derivatives with respect to the policy. We then present a double / debiased estimator for the value functions. Importantly, the conditions that validate Hadamard differentiability justify the margin assumption from the statistical classification literature for the fast convergence rate of plug-in methods.",,,2024
907,The key role of absolute risk in the disclosure risk assessment of public data releases,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QB_fwL8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=QB_fwL8AAAAJ:sSrBHYA8nusC,"We welcome Jarmin et al.’s (1) desire to engage with our article (2). We argued that absolute disclosure risk should be used to assess privacy risk. Jarmin et al. disagree and argue that differential privacy (DP) is superior. We find their arguments unpersuasive; our views are unaltered by their article. In addition, Jarmin et al. often muddled our article’s arguments. Interested parties should read our article to understand our arguments. A major point unmentioned by Jarmin et al. is that individuals care about the absolute disclosure risk with the public release of data, which is needed to assess the benefits and costs of such a release. We illustrated this with a public health example. Jarmin et al. mention this example but do not make its point clear. In the context of data privacy, individuals may care about how much their privacy is reduced if they participate in a publicly released data set in the sense of relative disclosure …",National Academy of Sciences,,2024
908,Human vs. generative AI in content creation competition: symbiosis or conflict?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QB_fwL8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=QB_fwL8AAAAJ:B3FOqHPlNUQC,"The advent of generative AI (GenAI) technology produces transformative impact on the content creation landscape, offering alternative approaches to produce diverse, high-quality content across media, thereby reshaping online ecosystems but also raising concerns about market over-saturation and the potential marginalization of human creativity. Our work introduces a competition model generalized from the Tullock contest to analyze the tension between human creators and GenAI. Our theory and simulations suggest that despite challenges, a stable equilibrium between human and AI-generated content is possible. Our work contributes to understanding the competitive dynamics in the content creation industry, offering insights into the future interplay between human creativity and technological advancements in GenAI.",,,2024
909,The econometrics of static and dynamic models of strategic interactions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QB_fwL8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=QB_fwL8AAAAJ:8AbLer7MMksC,"This chapter provides a review of the literature on the econometric analysis of static and dynamic models of both single agent choices and strategic interactions. Empirical models consistent with rational choice behavior and game theoretic Nash equilibrium behavior have many empirical applications in applied microeconomic analysis. Econometric methods of identification and estimation allow researchers to use observed data on individual choice behavior and on the conditional transition distribution of state variables to recover the underlying structural parameters and to make counter-factual policy forecasts. Depending on the information and payoff structures, some of these models can be nonparametrically identified and estimated, while others are more suitable for parametric estimation. We focus on the baseline models, but also discuss how the literature generalizes the baseline models to allow for unobserved heterogeneity, nonstationarity, time aggregation, multiple equilibria, and other directions.",,,2024
910,"Numerical approaches for motion of dispersed particles, droplets and bubbles",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AqEcQtYAAAAJ&citation_for_view=AqEcQtYAAAAJ:u5HHmVD_uO8C,"Recent advances in computational approaches for two-phase flow motion of solid particles, liquid particles, and gas bubbles are reviewed in the context of engineering calculations. The surrounding fluid is assumed to behave in a continuum and the dispersed-fluid is assumed to be dilute such that particle–particle interactions and two-way coupling effects can be ignored. The key process considered herein is momentum transfer to the particles with emphasis on turbulent diffusion. Computational approaches are classified by their particular treatment of the continuous-phase (surrounding liquid or gas) and of the dispersed-phase (solid particles, droplets, or bubbles). The most appropriate point-volume descriptions for interphase transfer of momentum are described based on current research and experimental data. Modern Lagrangian and Eulerian treatments of the dispersed-phase motion are then considered for …",Pergamon,Progress in energy and combustion science,2000
911,Recent advances in the mechanical durability of superhydrophobic materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AqEcQtYAAAAJ&citation_for_view=AqEcQtYAAAAJ:w0F2JDEymm0C,"Large majority of superhydrophobic surfaces have very limited mechanical wear robustness and long-term durability. This problem has restricted their utilization in commercial or industrial applications and resulted in extensive research efforts on improving resistance against various types of wear damage. In this review, advances and developments since 2011 in this field will be covered. As such, we summarize progress on fabrication, design and understanding of mechanically durable superhydrophobic surfaces. This includes an overview of recently published diagnostic techniques for probing and demonstrating tribo-mechanical durability against wear and abrasion as well as other effects such as solid/liquid spray or jet impact and underwater resistance. The review is organized in terms of various types of mechanical wear ranging from substrate adhesion, tangential surface abrasion, and dynamic impact to …",Elsevier,Advances in colloid and interface science,2016
912,Drag of non-spherical solid particles of regular and irregular shape,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AqEcQtYAAAAJ&citation_for_view=AqEcQtYAAAAJ:d1gkVwhDpl0C,"The drag of a non-spherical particle was reviewed and investigated for a variety of shapes (regular and irregular) and particle Reynolds numbers (Rep). Point-force models for the trajectory-averaged drag were discussed for both the Stokes regime (Rep≪1) and Newton regime (Rep≫1 and sub-critical with approximately constant drag coefficient) for a particular particle shape. While exact solutions were often available for the Stokes regime, the Newton regime depended on: aspect ratio for spheroidal particles, surface area ratio for other regularly-shaped particles, and min–med–max area for irregularly shaped particles. The combination of the Stokes and Newton regimes were well integrated using a general method by Ganser (developed for isometric shapes and disks). In particular, a modified Clift–Gauvin expression was developed for particles with approximately cylindrical cross-sections relative to the flow, e.g …",Elsevier,,2008
913,Inherently superoleophobic nanocomposite coatings by spray atomization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AqEcQtYAAAAJ&citation_for_view=AqEcQtYAAAAJ:u-x6o8ySG0sC,"We describe a technique to fabricate, for the first time, superoleophobic coatings by spray casting nanoparticle−polymer suspensions. The method involves the use of ZnO nanoparticles blended with a waterborne perfluoroacrylic polymer emulsion using cosolvents. Acetone is shown to be an effective compatibilizing cosolvent to produce self-assembling nanocomposite slurries that form hierarchical nanotextured morphology upon curing. Fabricated coating surface morphology is investigated with an environmental scanning electron microscope (ESEM), and surface wettability is characterized by static and dynamic contact angle measurements. The coatings can be applied to large and/or flexible substrates by spray coating with ease and require no additional surface treatments of commonly used hydrophobic molecules such as fluorosilanes; i.e., the nanocomposites are inherently superoleophobic. The …",American Chemical Society,,2009
914,Quasi-steady shape and drag of deformable bubbles and drops,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AqEcQtYAAAAJ&citation_for_view=AqEcQtYAAAAJ:2osOgNQ5qMEC,"The quasi-steady shape and drag of isolated drops and bubbles are reviewed in terms of quantitative results, particularly for deformed conditions. Data in the literature were investigated to provide a comprehensive description of observed theoretical, experimental and numerical trends. New descriptions of the aspect ratio and quasi-steady drag coefficient were developed which approach the theoretical limits for creeping flow and attached thin boundary layer conditions, while representing experimental data and resolved-surface simulations at other conditions (many of which are only recently available). These relationships are novel in the sense that they are formulated in terms of the local Weber and Reynolds numbers (as well as density and viscosity ratios), as opposed to static parameters only valid at terminal velocity conditions (e.g. Bond number and Morton numbers). The results indicate that aspect ratio is a …",Pergamon,International Journal of Multiphase Flow,2008
915,Spray-based Near-Isothermal Compression and Expansion for an Offshore Wind Energy Storage System,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AqEcQtYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=AqEcQtYAAAAJ:h168fVGZblEC,"Compressed air energy storage is a potential solution to the challenges of intermittency for wind turbines. Herein a novel concept is explored, Turbine-Integrated Isothermal Compressed Air Energy Storage (TICAES) which employs the wind-driven rotor as the motor for energy storage and employs the existing nacelle generator for energy regeneration. TICAES also achieved high efficiency by compressing and expanding the air with near-isothermal processes. In this study, this near-isothermal air compression and expansion is explored for an offshore wind turbine by using reciprocating compressor/expander with sprayed water droplets so the processes are nearly isothermal. The goal for such a spray-based system is to mitigate heat loss in the system by utilizing the high heat capacity and large surface area of water in the form of small droplets. A direct-drive approach is employed whereby the rotor speed is also used for the compressor and expander speeds to avoid the need for a gearbox, since gearboxes can be problematic for offshore wind turbines. The slower speed of the rotor also allows higher heat transfer. This work also expands on previous spray-based studies by considering higher pressure ratios and by considering full-scale conditions consistent with a direct-drive offshore wind turbine for turbine-integrated compressed air energy storage. The spray-based numerical model is validated with experiments and is then used to assess the performance of a Megawatt-scale compression/expansion system for a various droplet mass loadings and droplet diameters. The results suggest a range of system parameters that can yield isothermal …",,,2025
916,Effects of freestream turbulence on energy harvesting of a single semi-passive oscillating hydrofoil,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AqEcQtYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=AqEcQtYAAAAJ:JH5k92_tO-AC,"Rivers pose challenges for renewable energy device deployment due to shallow depths and variable, unsteady flow conditions. Vertically oscillating hydrofoil turbines appear well suited to accommodate changing flow conditions, produce high efficiencies, and reduce impact on wildlife. However, no studies exist on the impact of freestream turbulence on oscillating hydrofoil turbine performance. In this study, a semi-passive hydrofoil turbine is experimentally tested in a water channel, operating at chord-based Reynolds numbers ranging from 69000 to 91000. A passive turbulence grid was incorporated upstream to assess performance in a nearly uniform turbulence intensity profile with a turbulence intensity of approximately 5% and turbulent integral length scales on the order of 0.01 m. The velocity field just upstream of the hydrofoil was first characterized using hot-wire anemometry. Baffle boards were placed on …",AIP Publishing,,2025
917,Icing on Compressors and Fans,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AqEcQtYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=AqEcQtYAAAAJ:E7VqQtBCVmcC,"Icing on Compressors and Fans | Progress in Astronautics and Aeronautics Skip to main content AIAA ARC logo Search Search Anywhere Find by Paper Quick Search anywhere Enter words / phrases / DOI / ISBN / keywords / authors / etc Search Quick Search fdjslkfh Enter words / phrases / DOI / ISBN / keywords / authors / etc Search Advanced search Cart Join AIAA Institution Login Log In Login Join AIAA Institution Login Skip main navigation Open Drawer MenuClose Drawer Menu Menu Home Journals AIAA Journal Journal of Aerospace Information Systems Journal of Air Transportation Journal of Aircraft Journal of Guidance, Control, and Dynamics Journal of Propulsion and Power Journal of Spacecraft and Rockets Journal of Thermophysics and Heat Transfer Browse All Journals Browse All Virtual Collections Browse Editor's Choice Books AIAA Education Series Library of Flight Progress in Astronautics and …","American Institute of Aeronautics and Astronautics, Inc.",,2025
918,Substructure Optimization for a Semi-Submersible Floating Wind Turbine Under Extreme Environmental Conditions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AqEcQtYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=AqEcQtYAAAAJ:0sTkTiv_uMkC,"A barrier to the adoption of floating offshore wind turbines is their high cost relative to conventional fixed-bottom wind turbines. The largest contributor to this cost disparity is generally the floating substructure, due to its large size and complexity. Typically, a primary driver of the geometry and size of a floating substructure is the extreme environmental load case of Region 4, where platform loads are the greatest due to the impact of extreme wind and waves. To address this cost issue, a new concept for a floating offshore wind turbine’s substructure, its moorings, and anchors was optimized for a reference 10-MW turbine under extreme load conditions using OpenFAST. The levelized cost of energy was minimized by fixing the above-water turbine design and minimizing the equivalent substructure mass, which is based on the mass of all substructure components (stem, legs, buoyancy cans, mooring, and anchoring system) and associated costs of their materials, manufacturing, and installation. A stepped optimization scheme was used to allow an understanding of their influence on both the system cost and system dynamic responses for the extreme parked load case. The design variables investigated include the length and tautness ratio of the mooring lines, length and draft of the cans, and lengths of the legs and the stem. The dynamic responses investigated include the platform pitch, platform roll, nacelle horizontal acceleration, and can submergence. Some constraints were imposed on the dynamic responses of interest, and the metacentric height of the floating system was used to ensure static stability. The results offer insight into the parametric …",MDPI,,2025
919,Experimental characterization of an axisymmetric-sector inertial particle separator wind tunnel,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AqEcQtYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=AqEcQtYAAAAJ:xyvS_IvSCKsC,"To prevent particles from entering aircraft engines, Inertial Particle Separators (IPS) use a flow bend to split the intake into a particle-rich scavenge flow and an ideally clean core flow. While planar IPS configurations have been widely studied, they do not capture the axisymmetric nature of operational systems. To address this, a novel, vertically oriented, axisymmetric-sector IPS wind tunnel was built and characterized. The test section is a 50-degree sector geometry viewed from the incoming plane that enables detailed optical access while preserving realistic flow features of a full-scale and fully axisymmetric design, scaled to 37% of nominal dimensions. Surface oil streak visualizations, a high-fidelity control system for scavenge-to-core flow management, and particle separation efficiency tests with two test dusts (ISO 12103-1 A4 Coarse Test Dust and C-Spec) were conducted. Flow visualization revealed larger and …",Elsevier Masson,,2025
920,High strength and ductility of additively manufactured 316L stainless steel explained,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bXldkXkAAAAJ&citation_for_view=bXldkXkAAAAJ:LPZeul_q3PIC,"Structure–property relationships of an additively manufactured 316L stainless steel were explored. A scanning electron microscope and electron backscattered diffraction (EBSD) analysis revealed a fine cellular-dendritic (0.5 to 2 μm) substructure inside large irregularly shaped grains (~ 100 μm). The cellular structure grows along the <100> crystallographic directions. However, texture analysis revealed that the main <100> texture component is inclined by ~15 deg from the building direction. X-ray diffraction line profile analysis indicated a high dislocation density of ~1 × 1015 m−2 in the as-built material, which correlates well with the observed EBSD microstructure and high-yield strength, via the traditional Taylor hardening equation. Significant variations in strain hardening behavior and ductility were observed for the horizontal (HB) and vertical (VB) built samples. Ductility of HB and VB samples measured 49 and …",Springer US,,2018
921,A novel laser transfer process for direct writing of electronic and sensor materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bXldkXkAAAAJ&citation_for_view=bXldkXkAAAAJ:u5HHmVD_uO8C,"MAPLE direct write (MAPLE DW) is a new laser-based direct-write technique which combines the basic approach employed in laser-induced forward transfer (LIFT) with the unique advantages of matrix-assisted pulsed-laser evaporation (MAPLE). MAPLE DW utilizes an optically transparent substrate coated on one side with a matrix consisting of the material to be transferred mixed with a polymer or organic binder. As in LIFT, the laser is focused through the transparent substrate onto the matrix. When a laser pulse strikes the matrix, the binder decomposes and aids the transfer of the material of interest to an acceptor substrate placed parallel to the matrix surface. MAPLE DW is a maskless deposition process which operates in air and at room temperature. Powders of Ag, BaTiO3, SrTiO3, and Y3Fe5O12 with average diameters of 1 μm were transferred onto the surfaces of alumina, glass, silicon, and printed circuit …",Springer-Verlag,,1999
922,New approach to laser direct writing active and passive mesoscopic circuit elements,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bXldkXkAAAAJ&citation_for_view=bXldkXkAAAAJ:d1gkVwhDpl0C,"We have combined some of the major positive advantages of laser-induced forward transfer (LIFT) and matrix-assisted pulsed laser evaporation (MAPLE), to produce a novel excimer laser driven direct writing technique which has demonstrated the deposition in air and at room temperature and with sub-10 μm resolution of active and passive prototype circuit elements on planar and nonplanar substrates. We have termed this technique MAPLE DW (matrix-assisted pulsed laser evaporation direct write) and present its historical evolution from pulsed laser deposition. This paper describes the simplistic approach to carry out MAPLE DW, gives experimental conditions, and physical characterization results for the deposition of NiCr thin film resistors, Au conducting lines, and multilayer depositions of Au conductors and BaTiO3 dielectrics to produce prototype capacitors. In general, the electrical properties of the materials …",North-Holland,,2000
923,Pulsed laser deposition vs. matrix assisted pulsed laser evaporation for growth of biodegradable polymer thin films,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bXldkXkAAAAJ&citation_for_view=bXldkXkAAAAJ:u-x6o8ySG0sC,"Thin films of poly (lactide-co-glycolide) (PLGA), a biodegradable polymer, were deposited on Si wafers by both conventional pulsed laser deposition (PLD) and matrix assisted pulsed laser evaporation (MAPLE) using chloroform (CHCl3) as a matrix solvent. This research represents an initial study to investigate the deposition characteristics of each technique at comparable conditions to gain insight into the transport and degradation mechanisms of each approach. The deposited materials were characterized by scanning electron microscopy (SEM), Fourier transform infrared spectroscopy (FTIR), proton nuclear magnetic resonance (1H NMR), and gel permeation chromatography (GPC) with refractive index (RI) detection. While FTIR and NMR results do not show a measurable departure from the native, in sharp contrast GPC results show a significant change (up to 95%) in molecular weight for both deposition …",Springer Berlin Heidelberg,,2005
924,Engineered interfaces for adherent diamond coatings on large thermal-expansion coefficient mismatched substrates,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bXldkXkAAAAJ&citation_for_view=bXldkXkAAAAJ:9yKSN-GCB0IC,"Adhesion of thin or thick films on substrates is a critical issue in systems where the thermal-expansion coefficients of the coating and bulk material are significantly different from each other. The large mismatch of the expansion coefficients results in the generation of very high stresses in the coating that may lead to delamination, cracking, or other deleterious effects. A method to increase the adherence of diamond coatings on tungsten-carbide and stainless steel substrates is reported based on a substrate-modification process that creates a three-dimensional thermally and compositionally graded interface. Scratch and indentation tests on diamond-coated steel and tungsten-carbide samples did not exhibit film fracture at the interface and concomitant catastrophic propagation of interfacial cracks.",American Association for the Advancement of Science,,1996
925,Utilizing Strain Rate Jump Testing to Predict Incremental Spin Formability of Al Alloys Sensitive to Portevin–Le Chatelier Instabilities,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bXldkXkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bXldkXkAAAAJ:zLWjf1WUPmwC,"Predicting the formability of Al alloys for spin/flow forming is challenging due to the incremental deformation, complex loading path, and wide range of strain rates characteristic of the processes. Customarily, research efforts have focused on formability metrics derived from ambient temperature, quasistatic uniaxial tensile testing, most notably tensile reduction in area. However, Al alloys in formable tempers tend to exhibit serrated Portevin–Le Chatelier (PLC) flow, associated with dynamic strain aging (DSA) and negative strain rate sensitivity (SRS). Such characteristics are also linked with a loss of tensile area reduction capacity and thus decreased formability. In this study, moderate (1 s−1) strain rate tensile tests and strain rate jump tests of three Al alloys were conducted with a mild steel as a benchmark. Specifically, the effects of rapid changes in strain rate (analogous to a forming increment by a passing roller) on …",Springer International Publishing,,2025
926,Thermophysical modeling of niobium alloys informs materials selection and design for high-temperature applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bXldkXkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bXldkXkAAAAJ:ipzZ9siozwsC,"There is renewed interest in refractory alloys that possess higher service temperatures than incumbent Ni-based superalloys (⪆1100 °C). Thermophysical property data for six Nb-alloys are gathered from the literature and reviewed, and new data are provided for two Hf-containing Nb-alloys; elastic modulus, thermal expansion, thermal conductivity, and heat capacity are presented for C103, and new thermal conductivity data are provided for a higher strength alloy, WC-3009. Comparisons with Ni-superalloys and other refractory-metal based alloys provide context. Physics-based models are provided that describe the temperature dependencies of the Young’s modulus, coefficient of thermal expansion and density, and thermal conductivity; such that fair comparisons can be made across alloys for any given condition. The results suggest a need for improved understanding of the temperature dependence of the …",Elsevier,,2024
927,A unified model of tensile and creep deformation for use in niobium alloy materials selection and design for high-temperature applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bXldkXkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bXldkXkAAAAJ:uc_IGeMz5qoC,"There is renewed interest in refractory alloys that possess higher service temperatures than incumbent Ni-based superalloys (eg,⪆ 1100° C). This study provides a review of the high-temperature constitutive responses of Nb-alloys measured over a wide range of temperatures (≈ 860° C< T<≈ 1760° C) and strain rates (≈ 10–9 s-1< ε˙<≈ 10–1 s-1). Nevertheless, the extant data is sparse and informed materials selection decisions require constitutive expressions to interpolate and reliably extrapolate. The Larson-Miller parameter approach to describe creep-life provides a conservative estimate of material response at the highest temperatures and lowest strain rates, whereas the Sellars-Tegart model describes both steady-state creep and high-temperature tensile test data with a single, universal equation. A minimum flow stress based on the combination of these two models is proposed for design considerations to …",Elsevier,,2024
928,Utilizing Strain Rate Jump Testing to Predict Flow Formability of Al Alloys Sensitive to Portevin-Le Chatelier Instabilities,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bXldkXkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bXldkXkAAAAJ:EkHepimYqZsC,"Predicting the flow formability of Al alloys is challenging due to the incremental deformation, complex loading path, and wide range of strain rates characteristic of the process. State-of-the-art research efforts have primarily focused on formability metrics derived from ambient temperature, constant strain rate uniaxial tensile testing. However, Al alloys in formable tempers tend to exhibit serrated Portevin-Le Chatelier (PLC) flow. The appearance of PLC instabilities implies a negative strain rate sensitivity, loss of tensile area reduction capacity, and decreased formability. Elevated temperature and interrupted strain rate tensile tests of relevant Al alloys were conducted to investigate the effects of rapid changes in strain rate (analogous to a forming increment by a passing roller) on common formability metrics. Emphasis was placed on the character/extent of PLC instabilities using digital image correlation strain measurements. The outcome of this work highlights the possibility of predicting flow formability using strain rate jump testing.",,,2024
929,Software reflexion models: Bridging the gap between source and high-level models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2-jY1SQAAAAJ&citation_for_view=2-jY1SQAAAAJ:u5HHmVD_uO8C,"Software engineers often use high-level models(for instance, box and arrow sketches) to reason and communicate about an existing software system. One problem with high-level models is that they are almost always inaccurate with respect to the system’s source code. We have developed an approach that helps an engineer use a high-level model of the structure of an existing software system as a lens through which to see a model of that system’s source code. In particular, an engineer defines a high-level model and specifies how the model maps to the source. A tool then computes a software reflexion model that shows where the engineer’s high-level model agrees with and where it differs from a model of the source. The paper provides a formal characterization of reflexion models, discusses practical aspects of the approach, and relates experiences of applying the approach and tools to a number of different …",,,1995
930,Ultra-large-scale systems: The software challenge of the future,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2-jY1SQAAAAJ&citation_for_view=2-jY1SQAAAAJ:IjCSPb-OGe4C,"The U. S. Department of Defense DoD has a goal of information dominance to achieve and exploit superior collection, fusion, analysis, and use of information to meet mission objectives. This goal depends on increasingly complex systems characterized by thousands of platforms, sensors, decision nodes, weapons, and warfighters connected through heterogeneous wired and wireless networks. These systems will push far beyond the size of today s systems and systems of systems by every measure number of lines of code number of people employing the system for different purposes amount of data stored, accessed, manipulated, and refined number of connections and interdependencies among software components and number of hardware elements. They will be ultra-largescale ULS systems. The sheer scale of ULS systems will change everything. ULS systems will necessarily be decentralized in a variety of ways, developed and used by a wide variety of stakeholders with conflicting needs, evolving continuously, and constructed from heterogeneous parts. People will not just be users of a ULS system they will be elements of the system. Software and hardware failures will be the norm rather than the exception. The acquisition of a ULS system will be simultaneous with its operation and will require new methods for control. These characteristics are beginning to emerge in today s DoD systems of systems in ULS systems they will dominate. Consequently, ULS systems will place unprecedented demands on software acquisition, production, deployment, management, documentation, usage, and evolution practices.",,,2006
931,Managing technical debt in software-reliant systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2-jY1SQAAAAJ&citation_for_view=2-jY1SQAAAAJ:7PzlFSSx8tAC,"Delivering increasingly complex software-reliant systems demands better ways to manage the long-term effects of short-term expedients. The technical debt metaphor is gaining significant traction in the agile development community as a way to understand and communicate such issues. The idea is that developers sometimes accept compromises in a system in one dimension (e.g., modularity) to meet an urgent demand in some other dimension (e.g., a deadline), and that such compromises incur a ""debt"": on which ""interest"" has to be paid and which the ""principal"" should be repaid at some point for the long-term health of the project. We argue that the software engineering research community has an opportunity to study and improve this concept. We can offer software engineers a foundation for managing such trade-offs based on models of their economic impacts. Therefore, we propose managing technical debt …",,,2010
932,Software reflexion models: Bridging the gap between design and implementation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2-jY1SQAAAAJ&citation_for_view=2-jY1SQAAAAJ:u-x6o8ySG0sC,"The artifacts constituting a software system often drift apart over time. We have developed the software reflexion model technique to help engineers perform various software engineering tasks by exploiting, rather than removing, the drift between design and implementation. More specifically, the technique helps an engineer compare artifacts by summarizing where one artifact (such as a design) is consistent with and inconsistent with another artifact (such as source). The technique can be applied to help a software engineer evolve a structural mental model of a system to the point that it is ""good enough"" to be used for reasoning about a task at hand. The software reflexion model technique has been applied to support a variety of tasks, including design conformance, change assessment, and an experimental reengineering of the million-lines-of-code Microsoft Excel product. We provide a formal characterization of …",IEEE,,2001
933,The structure and value of modularity in software design,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2-jY1SQAAAAJ&citation_for_view=2-jY1SQAAAAJ:d1gkVwhDpl0C,"The concept of information hiding modularity is a cornerstone of modern software design thought, but its formulation remains casual and its emphasis on changeability is imperfectly related to the goal of creating added value in a given context. We need better explanatory and prescriptive models of the nature and value of information hiding. We evaluate the potential of a new theory---developed to account for the influence of modularity on the evolution of the computer industry---to inform software design. The theory uses design structure matrices to model designs and real options techniques to value them. To test the potential utility of the theory for software we apply it to Parnas's KWIC designs. We contribute an extension to design structure matrices, and we show that the options results are consistent with Parnas's conclusions. Our results suggest that such a theory does have potential to help inform software design.",ACM,,2001
934,Realism Constructs for ADS Simulation Testing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2-jY1SQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2-jY1SQAAAAJ:jE2MZjpN3IcC,"As Automated Driving Systems (ADSs) continue to expand into the public sphere, so too must our efforts to sufficiently validate their safety. Given the wide range of scenarios over which ADSs must operate and the inherent dangers in these scenarios, developers often rely on simulation testing to exercise the system. However, the well-documented simulation-reality gap limits the transfer of results from simulation testing to real world operation, hindering the ability to build sufficient assurance cases based on validation in simulation alone. This is a fundamental issue in the construct validity of simulation-based methods for validation of ADS systems. Recent efforts have sought to decrease the simulation-reality gap through improved simulation fidelity and developing methods for generating synthetic data from real data. However, these efforts do not provide a method to assure the construct validity achieved by these …",IEEE,,2025
935,Systems and methods for data warehousing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2-jY1SQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2-jY1SQAAAAJ:6_hjMsCP8ZoC,"G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR",,,2024
936,Semantic image fuzzing of AI perception systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2-jY1SQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2-jY1SQAAAAJ:WC23djZS0W4C,"Perception systems enable autonomous systems to interpret raw sensor readings of the physical world. Testing of perception systems aims to reveal misinterpretations that could cause system failures. Current testing methods, however, are inadequate. The cost of human interpretation and annotation of real-world input data is high, so manual test suites tend to be small. The simulation-reality gap reduces the validity of test results based on simulated worlds. And methods for synthesizing test inputs do not provide corresponding expected interpretations. To address these limitations, we developed semSensFuzz, a new approach to fuzz testing of perception systems based on semantic mutation of test cases that pair real-world sensor readings with their ground-truth interpretations. We implemented our approach to assess its feasibility and potential to improve software testing for perception systems. We used it to …",,,2022
937,Fuzzing mobile robot environments for fast automated crash detection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2-jY1SQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2-jY1SQAAAAJ:FiytvqdAVhgC,"Testing mobile robots is difficult and expensive, and many faults go undetected. In this work we explore whether fuzzing, an automated test input generation technique, can more quickly find failure inducing inputs in mobile robots. We developed a simple fuzzing adaptation, BASE-FUZZ, and one specialized for fuzzing mobile robots, PHYS-FUZZ. PHYS-FUZZ is unique in that it accounts for physical attributes such as the robot dimensions, estimated trajectories, and time to impact measures to guide the test input generation process. The results of evaluating PHYS-FUZZ suggest that it has the potential to speed up the discovery of input scenarios that reveal failures, finding 56.5% more than uniform random input selection and 7.0% more than BASE-FUZZ during 7 days of testing.",IEEE,,2021
938,Ultra Large Scale (ULS) Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2-jY1SQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2-jY1SQAAAAJ:NDuN12AVoxsC,"A simple question: Given the issues with software engineering today, how can we build systems of the future likely to have billions of lines of code?",,,2021
939,Improving network management with software defined networking,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DUEglv4AAAAJ&citation_for_view=DUEglv4AAAAJ:L8Ckcad2t8MC,"Network management is challenging. To operate, maintain, and secure a communication network, network operators must grapple with low-level vendor-specific configuration to implement complex high-level network policies. Despite many previous proposals to make networks easier to manage, many solutions to network management problems amount to stop-gap solutions because of the difficulty of changing the underlying infrastructure. The rigidity of the underlying infrastructure presents few possibilities for innovation or improvement, since network devices have generally been closed, proprietary, and vertically integrated. A new paradigm in networking, software defined networking (SDN), advocates separating the data plane and the control plane, making network switches in the data plane simple packet forwarding devices and leaving a logically centralized software program to control the behavior of the …",IEEE,,2013
940,Procera: A language for high-level reactive network control,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DUEglv4AAAAJ&citation_for_view=DUEglv4AAAAJ:eQOLeE2rZwMC,"Our previous experience building systems for implementing network policies in home and enterprise networks has revealed that the intuitive notion of network policy in these domains is inherently dynamic and stateful. Current configuration languages, both in traditional network architectures and in OpenFlow systems, are not expressive enough to capture these policies. As a result, most prototype OpenFlow systems lack a configurable interface and instead require operators to program in the system implementation language, often C++. We describe Procera, a control architecture for software-defined networking (SDN) that includes a declarative policy language based on the notion of functional reactive programming; we extend this formalism with both signals relevant for expressing high-level network policies in a variety of network settings, including home and enterprise networks, and a collection of constructs …",,,2012
941,Kinetic: Verifiable Dynamic Network Control,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DUEglv4AAAAJ&citation_for_view=DUEglv4AAAAJ:JV2RwH3_ST0C,"Network conditions are dynamic; unfortunately, current approaches to configuring networks are not. Network operators need tools to express how a network’s data-plane behavior should respond to a wide range of events and changing conditions, ranging from unexpected failures to shifting traffic patterns to planned maintenance. Yet, to update the network configuration today, operators typically rely on a combination of manual intervention and ad hoc scripts. In this paper, we present Kinetic, a domain specific language and network control system that enables operators to control their networks dynamically in a concise, intuitive way. Kinetic also automatically verifies the correctness of these control programs with respect to userspecified temporal properties. Our user study of Kinetic with several hundred network operators demonstrates that Kinetic is intuitive and usable, and our performance evaluation shows that realistic Kinetic programs scale well with the number of policies and the size of the network.",,,2015
942,Coronet: Fault tolerance for software defined networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DUEglv4AAAAJ&citation_for_view=DUEglv4AAAAJ:dhFuZR0502QC,"Software Defined Networking, or SDN, based networks are being deployed not only in testbed networks, but also in production networks. Although fault-tolerance is one of the most desirable properties in production networks, there are not much study in providing fault-tolerance to SDN-based networks. The goal of this work is to develop a fault tolerant SDN architecture that can rapidly recover from faults and scale to large network sizes. This paper presents CORONET, a SDN fault-tolerant system that recovers from multiple link failures in the data plane. We describe a prototype implementation based on NOX that demonstrates fault recovery for emulated topologies using Mininet. We also discuss possible extensions to handle control plane and controller faults.",IEEE,,2012
943,The evolution of network configuration: A tale of two campuses,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DUEglv4AAAAJ&citation_for_view=DUEglv4AAAAJ:u-x6o8ySG0sC,"Studying network configuration evolution can improve our understanding of the evolving complexity of networks and can be helpful in making network configuration less error-prone. Unfortunately, the nature of changes that operators make to network configuration is poorly understood. Towards improving our understanding, we examine and analyze five years of router, switch, and firewall configurations from two large campus networks using the logs from version control systems used to store the configurations. We study how network configuration is distributed across different network operations tasks and how the configuration for each task evolves over time, for different types of devices and for different locations in the network. To understand the trends of how configuration evolves over time, we study the extent to which configuration for various tasks are added, modified, or deleted. We also study whether certain …",,,2011
944,Scalable Video Conferencing Using SDN Principles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DUEglv4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DUEglv4AAAAJ:43bX7VzcjpAC,"Video-conferencing applications face an unwavering surge in traffic, stressing their underlying infrastructure in unprecedented ways. This paper rethinks the key building block for conferencing infrastructures — selective forwarding units (SFUs). SFUs relay and adapt media streams between participants and, today, run in software on general-purpose servers. Our main insight, discerned from dissecting the operation of production SFU servers, is that SFUs largely mimic traditional packet-processing operations such as dropping and forwarding. Guided by this, we present Scallop, an SDN-inspired SFU that decouples video-conferencing applications into a hardware-based data plane for latency-sensitive and frequent media operations, and a software control plane for the (infrequent) remaining tasks, such as analyzing feedback signals and session management. Scallop is a general design that is suitable for a variety …",,,2025
945,Spotlight: Shining a Light on Pivot Attacks Using In-network Computing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DUEglv4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DUEglv4AAAAJ:zCSUwVk65WsC,"Pivoting remains an economical and practical penetration method as it allows a malevolent actor to obtain access to a private network through compromised devices. There are various tools both on the web and native to many operating systems, making pivoting simple to execute, even with limited system access. Preventing these attacks is traditionally performed with detection software running on end hosts or with perimeter devices, e.g., firewalls. However, not all end-host devices are under administrator control, and attackers can work around defences using SSH tunnels or obscuring their IP addresses. Rather than relying on middleboxes or end hosts, we leverage a programmable data plane for both their unique vantage point and traffic processing capabilities. Our system makes no assumptions about the underlying traffic and requires no cooperation from end hosts. We showcase Spotlight, a P4-based system …",ACM,,2025
946,Automating Distributed In-network Classification with Runtime Programmability,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DUEglv4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DUEglv4AAAAJ:BzfGm06jWhQC,"This paper presents ACORN, a distributed system for in-network machine-learning classification applications. ACORN automatically translates user-level Python ML programs into network-level programs and deploys them with runtime programmability.",,,2024
947,Nap: Programming data planes with approximate data structures,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DUEglv4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DUEglv4AAAAJ:U4n9YNQMCAIC,"Many applications that run on programmable data planes rely on approximate data structures, due to insufficient in-network memory. However, programming with approximate data structures is challenging because it requires (1) expertise in streaming algorithms to select the data structures that best match an application's requirements, (2) meticulous configuration to minimize approximation error while fitting within the hardware constraints, and (3) proficiency in the low-level P4 language. To address these issues, we propose NAP, a high-level network programming language. The core of NAP is the versatile approximate dictionary abstraction that captures a wide range of compact data structures, while allowing programmers to simply specify the kinds of error an application can tolerate. We demonstrate the language's expressiveness, conciseness, and efficiency through a variety of network applications, each …",,,2023
948,Hydra: Effective runtime network verification,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DUEglv4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DUEglv4AAAAJ:jgBuDB5drN8C,"It is notoriously difficult to verify that a network is behaving as intended, especially at scale. This paper presents Hydra, a system that uses ideas from runtime verification to check that every packet is correctly processed with respect to a specification in real time. We propose a domain-specific language for writing properties, called Indus, and we develop a compiler that turns properties thus specified into executable P4 code that runs alongside the forwarding code at line rate. To evaluate our approach, we used Indus to model a range of properties, showing that it is expressive enough to capture examples studied in prior work. We also deployed Hydra checkers for validating paths in source routing and for enforcing slice isolation in Aether, an open-source cellular platform. We confirmed a subtle bug in Aether's 5G mobile core that would have been hard to detect using static techniques. We also evaluated the …",,,2023
949,Chemically Exfoliated MoS2 as Near‐Infrared Photothermal Agents,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xxOg1X4AAAAJ&citation_for_view=xxOg1X4AAAAJ:uWQEDVKXjbEC,"The near-infrared (NIR) window refers to a range of wavelengths (700–1300 nm) in which biological tissues are highly transparent.[1] Consequently, biological imaging and therapy modalities employ light at these wavelengths for the monitoring [1] and triggering [2] of biological events invitro and in vivo. For instance, photothermal ablation takes advantage of NIR absorbing materials for transducing light into heat.[2] The resultant thermal energy can be used for a number of applications, such as tissue ablation and drug release. Despite the intense interest in NIR photothermal agents, their development has suffered from considerable challenges. In particular, few nanomaterials display the requisite absorption profiles required for NIR photothermal transduction. The initial development of NIR photothermal agents largely focused on anisotropic gold particles [3] such as nanorods,[2] nanocages,[4] and nanostars.[5 …",WILEY‐VCH Verlag,,2013
950,Phase stability and mechanical properties of novel high entropy transition metal carbides,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xxOg1X4AAAAJ&citation_for_view=xxOg1X4AAAAJ:-mN3Mh-tlDkC,"Twelve different equiatomic five-metal carbides of group IVB, VB, and VIB refractory transition metals are synthesized via high-energy ball milling and spark plasma sintering. Implementation of a newly developed ab initio entropy descriptor aids in selection of candidate compositions for synthesis of high entropy and entropy stabilized carbides. Phase formation and composition uniformity are analyzed via XRD, EDS, S/TEM-EDS, and EXAFS. Nine of the twelve candidates form true single-phase materials with the rocksalt (B1) structure when sintered at 2473 K and can therefore be investigated as high entropy carbides (HECs). The composition (V0.2Nb0.2Ta0.2Mo0.2W0.2)C is presented as a likely candidate for further investigation as an entropy stabilized carbide. Seven of the carbides are examined for mechanical properties via nanoindentation. The HECs show significantly enhanced hardness when compared …",Pergamon,,2019
951,High-entropy fluorite oxides,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xxOg1X4AAAAJ&citation_for_view=xxOg1X4AAAAJ:48xauSegjOkC,"Eleven fluorite oxides with five principal cations (in addition to a four-principal-cation (Hf0.25Zr0.25Ce0.25Y0.25)O2-δ as a start point and baseline) were fabricated via high-energy ball milling, spark plasma sintering, and annealing in air. Eight of the compositions, namely (Hf0.25Zr0.25Ce0.25Y0.25)O2-δ, (Hf0.25Zr0.25Ce0.25)(Y0.125Yb0.125)O2-δ, (Hf0.2Zr0.2Ce0.2)(Y0.2Yb0.2)O2-δ, (Hf0.25Zr0.25Ce0.25)(Y0.125Ca0.125)O2-δ, (Hf0.25Zr0.25Ce0.25)(Y0.125Gd0.125)O2-δ, (Hf0.2Zr0.2Ce0.2)(Y0.2Gd0.2)O2-δ, (Hf0.25Zr0.25Ce0.25)(Yb0.125Gd0.125)O2-δ, and (Hf0.2Zr0.2Ce0.2)(Yb0.2Gd0.2)O2-δ, possess single-phase solid solutions of the fluorite crystal structure with high configurational entropies (on the cation sublattices), akin to those high-entropy alloys and ceramics reported in prior studies. Most high-entropy fluorite oxides (HEFOs), except for the two containing both Yb and Gd, can be sintered to high …",Elsevier,,2018
952,Crossover from incoherent to coherent phonon scattering in epitaxial oxide superlattices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xxOg1X4AAAAJ&citation_for_view=xxOg1X4AAAAJ:D_sINldO8mEC,"Elementary particles such as electrons, or photons, are frequent subjects of wave-nature-driven investigations, unlike collective excitations such as phonons. The demonstration of wave–particle crossover, in terms of macroscopic properties, is crucial to the understanding and application of the wave behaviour of matter. We present an unambiguous demonstration of the theoretically predicted crossover from diffuse (particle-like) to specular (wave-like) phonon scattering in epitaxial oxide superlattices, manifested by a minimum in lattice thermal conductivity as a function of interface density. We do so by synthesizing superlattices of electrically insulating perovskite oxides and systematically varying the interface density, with unit-cell precision, using two different epitaxial-growth techniques. These observations open up opportunities for studies on the wave nature of phonons, particularly phonon interference effects …",Nature Publishing Group UK,,2014
953,Reduction in the thermal conductivity of single crystalline silicon by phononic crystal patterning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xxOg1X4AAAAJ&citation_for_view=xxOg1X4AAAAJ:IjCSPb-OGe4C,"Phononic crystals (PnCs) are the acoustic wave equivalent of photonic crystals, where a periodic array of scattering inclusions located in a homogeneous host material causes certain frequencies to be completely reflected by the structure. In conjunction with creating a phononic band gap, anomalous dispersion accompanied by a large reduction in phonon group velocities can lead to a massive reduction in silicon thermal conductivity. We measured the cross plane thermal conductivity of a series of single crystalline silicon PnCs using time domain thermoreflectance. The measured values are over an order of magnitude lower than those obtained for bulk Si (from 148 W m−1 K−1 to as low as 6.8 W m−1 K−1). The measured thermal conductivity is much smaller than that predicted by only accounting for boundary scattering at the interfaces of the PnC lattice, indicating that coherent phononic effects are causing an …",American Chemical Society,,2011
954,Interfacial thermal transport via plasmon polaritons in a hyperbolic metamaterial,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xxOg1X4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xxOg1X4AAAAJ:oAywNP-vUhwC,"Rapid miniaturization of electronics demands deeper insight into nanoscale heat transport. Metamaterials offer new ways to control radiative heat flow, especially in the near field, where flux can exceed the blackbody limit. By fine-tuning interfaces, we can channel radiative energy into bulk carriers for advanced thermal management. Here, we employ an ultrafast pump-probe technique with a sub-picosecond resolution to measure near-field heat transfer across metamaterial interfaces and dielectric gaps. A tunable mid-IR probe interacts directly with plasmonic heat carriers, illuminating polariton dynamics at the nanoscale. We demonstrate the thermal excitation of hyperbolic plasmon-polaritons (HPPs) in a CdO-based hyperbolic metamaterial using a green laser that generates ballistic electrons in a gold pad. Thermalized electrons at the gold/HMM interface couple directly to HPPs. We then examine near-field …",SPIE,,2025
955,In-plane thermal conductivity and the applicability of the Wiedemann–Franz law in dilute AlCu thin films,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xxOg1X4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xxOg1X4AAAAJ:wkm4DBaukwsC,"The Wiedemann–Franz (WF) law correlates heat and charge transport in metals. However, the validity of this correlation remains an open-ended question, especially in the context of inelastic scattering at room temperature. To address this gap in knowledge, we perform independent measurements of the in-plane thermal and electrical conductivities across four AlCu (0.5% Cu) films [thickness (⁠ h⁠)≈ 174, 98, 53, and 24 nm] using optical pump–probe metrologies and four-point probe techniques, respectively. For in-plane thermal conductivity measurements, we utilize time-domain thermoreflectance, in both concentric and beam-offset configurations, and the time-resolved magneto-optic Kerr effect. Our results show that the WF law overpredicts the thermal conductivity by at least∼ 10% in all films, thus demonstrating modest deviations in predicted thermal conductivity when applying the WF law to dilute AlCu films …",AIP Publishing,,2025
956,Topology-Driven Vibrations in a Chiral Polar Vortex Lattice,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xxOg1X4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xxOg1X4AAAAJ:It0W0vAlS5QC,"The ordering of magnetic or electric dipoles leading to real-space topological structures is at the forefront of materials research as their quantum mechanical nature often lends itself to emergent properties. Atomic lattice vibrations (phonons) are often a key contributor to the formation of long-range dipole textures based on ferroelectrics and impact the properties of the emergent phases. Here, using monochromated, momentum-resolved electron energy-loss spectroscopy (qEELS) with nanometer spatial resolution and meV-spectral-precision, we demonstrate that polar vortex lattices in PbTiO spatially modulate the material's vibrational spectrum in patterns that directly reflect the overlying symmetry of the topological patterns. Moreover, by combining experiments with molecular dynamics simulations using machine learned potentials we reveal how these structures modify phonon modes across the vibrational spectrum. Beyond simple intensity modulation, we find that the chirality of the vortex topology imparts its unique symmetry onto phonons, producing a distinctive asymmetrical spectral shift across the vortex unit cell. Finally, the high spatial resolution of the technique enables topological defects to be probed directly, demonstrating a return to trivial PbTiO modes at vortex dislocation cores. These findings establish a fundamental relationship between ferroelectric-ordering-induced topologies and phonon behavior, opening new avenues for engineering thermal transport, electron-phonon coupling, and other phonon-mediated properties in next-generation nanoscale devices.",,,2025
957,Characterisation by phase mappings of microstructural-thermal-mechanical properties in equimolar refractory high-entropy alloys with reduced neutron cross-section,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xxOg1X4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xxOg1X4AAAAJ:yZoBfgUKqwcC,"High-entropy alloys (HEA) hold promising potential as advanced technology fuel cladding materials for nuclear fission reactors. The HEAs typically exhibit low thermal conductivity, influencing substantially thermal spikes caused by nuclear collisions. In this framework, we screened over fifteen million combinations of quaternary and quinary equimolar HEAs to select the best alloy candidates for lower thermal neutron absorption cross-section combined with propensity to form a single-phase solid solution at high temperatures. Three of these HEAs NbZrTiMo, NbZrTiVMo, and NbZrTiV were arc-melted and characterised after thermal annealing at 1200 °C for 100 h. While a single-phase field was not achieved, each alloy exhibited a predominant bcc phase. We employed a unique combination of co-located advanced mapping techniques, including scanning electron microscopy, time-domain thermoreflectance …",Elsevier,,2025
958,Time-domain thermoreflectance,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xxOg1X4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xxOg1X4AAAAJ:HqhvjgTjE9cC,"Time-domain thermoreflectance (TDTR) has been instrumental in measuring the heat transfer properties of bulk and nanostructured materials over the past two decades. In this Primer, we describe the optical and thermal aspects of TDTR, with an in-depth discussion on the theory, apparatus design and implementation. We present examples that illustrate the ability of TDTR to measure thermal conductivity tensors, thermal conductance across material interfaces, and volumetric heat capacity of thin films, 2D materials and bulk materials. The ability of TDTR to spatially resolve thermal properties is useful for studying heterogeneous material systems, such as materials processed in or subjected to extreme environments. We consider current limitations of pump–probe metrologies and discuss recent advancements of TDTR, such as time-resolved magneto-optic Kerr effect (TR-MOKE), beam-offset TDTR/TR-MOKE …",Nature Publishing Group UK,Nature Reviews Methods Primers,2025
959,Merkel cells are essential for light-touch responses,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ibBUGLAAAAAJ&citation_for_view=ibBUGLAAAAAJ:u5HHmVD_uO8C,"The peripheral nervous system detects different somatosensory stimuli, including pain, temperature, and touch. Merkel cell-neurite complexes are touch receptors composed of sensory afferents and Merkel cells. The role that Merkel cells play in light-touch responses has been the center of controversy for over 100 years. We used Cre-loxP technology to conditionally delete the transcription factor Atoh1 from the body skin and foot pads of mice. Merkel cells are absent from these areas in Atoh1CKO animals. Ex vivo skin/nerve preparations from Atoh1CKO animals demonstrate complete loss of the characteristic neurophysiologic responses normally mediated by Merkel cell-neurite complexes. Merkel cells are, therefore, required for the proper encoding of Merkel receptor responses, suggesting that these cells form an indispensible part of the somatosensory system.",American Association for the Advancement of Science,,2009
960,Distinction of self-produced touch and social touch at cortical and spinal cord levels,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ibBUGLAAAAAJ&citation_for_view=ibBUGLAAAAAJ:xtRiw3GOFMkC,"Differentiation between self-produced tactile stimuli and touch by others is necessary for social interactions and for a coherent concept of “self.” The mechanisms underlying this distinction are unknown. Here, we investigated the distinction between self- and other-produced light touch in healthy volunteers using three different approaches: fMRI, behavioral testing, and somatosensory-evoked potentials (SEPs) at spinal and cortical levels. Using fMRI, we found self–other differentiation in somatosensory and sociocognitive areas. Other-touch was related to activation in several areas, including somatosensory cortex, insula, superior temporal gyrus, supramarginal gyrus, striatum, amygdala, cerebellum, and prefrontal cortex. During self-touch, we instead found deactivation in insula, anterior cingulate cortex, superior temporal gyrus, amygdala, parahippocampal gyrus, and prefrontal areas. Deactivation extended into …",National Academy of Sciences,,2019
961,Providing a sense of touch to prosthetic hands,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ibBUGLAAAAAJ&citation_for_view=ibBUGLAAAAAJ:RYcK_YlVTxYC,"Each year, approximately 185,000 Americans suffer the devastating loss of a limb. The effects of upper limb amputations are profound because a person’s hands are tools for everyday functioning, expressive communication, and other uniquely human attributes. Despite the advancements in prosthetic technology, current upper limb prostheses are still limited in terms of complex motor control and sensory feedback. Sensory feedback is critical to restoring full functionality to amputated patients because it would relieve the cognitive burden of relying solely on visual input to monitor motor commands and provide tremendous psychological benefits. This article reviews the latest innovations in sensory feedback and argues in favor of peripheral nerve interfaces. First, the authors examine the structure of the peripheral nerve and its importance in the development of a sensory interface. Second, the authors discuss …",LWW,Plastic and reconstructive surgery,2015
962,The regularity of sustained firing reveals two populations of slowly adapting touch receptors in mouse hairy skin,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ibBUGLAAAAAJ&citation_for_view=ibBUGLAAAAAJ:IjCSPb-OGe4C,"Touch is initiated by diverse somatosensory afferents that innervate the skin. The ability to manipulate and classify receptor subtypes is prerequisite for elucidating sensory mechanisms. Merkel cell–neurite complexes, which distinguish shapes and textures, are experimentally tractable mammalian touch receptors that mediate slowly adapting type I (SAI) responses. The assessment of SAI function in mutant mice has been hindered because previous studies did not distinguish SAI responses from slowly adapting type II (SAII) responses, which are thought to arise from different end organs, such as Ruffini endings. Thus we sought methods to discriminate these afferent types. We developed an epidermis-up ex vivo skin–nerve chamber to record action potentials from afferents while imaging Merkel cells in intact receptive fields. Using model-based cluster analysis, we found that two types of slowly adapting receptors …",American Physiological Society,,2010
963,The effect of fingertip microstructures on tactile edge perception,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ibBUGLAAAAAJ&citation_for_view=ibBUGLAAAAAJ:u-x6o8ySG0sC,"People rely on tactile edge localization to ascertain the location and structure of edges. When pressure is applied to the skin, skin mechanoreceptors convert compressive stress/strain into neural signals. Many attempts to model this conversion neglect intermediate ridges, on the inside of the stiff epidermis. The receptors associated with detecting compressive and shear stresses reside at the tips of these ridges, suggesting a functional importance in the detection of stress. This work considers how underlying microstructure affects the mechanical propagation of stress to receptors. Two unique indenters are applied to two finite element models of idealized, fingerpad skin - one with ridge microstructure. Findings indicate that microstructure produces high, local stress concentrations at ridge tips near receptors. Because stress is focused at ridges beneath edges, there is a higher contrast of stress between ridge tips near …",IEEE,,2005
964,Strain-based biomarkers at the skin surface detect changes in soft tissue mobility linked to myofascial pain following soft tissue manipulation intervention,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ibBUGLAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ibBUGLAAAAAJ:WqliGbK-hY8C,"Soft tissue manipulation is a widely used massage-based intervention in treating myofascial pain, yet its efficacy in increasing tissue mobility is evaluated primarily through subjective observations. To establish objective measures of tissue mobility, this study captures patterns of skin surface deformation during hands-on clinician assessment using digital image correlation. Nineteen participants underwent an established soft tissue manipulation (STM) intervention protocol targeting the cervicothoracic region. Tissue mobility was assessed bilaterally (left v. right) and directionally (superior v. inferior) before and after the STM intervention using eleven strain-based biomarkers. Post-intervention, those biomarkers associated with tissue deformation and glide exhibited systematic changes, indicating increased mobility. Notably, 88% of participants demonstrated improved tissue mobility, especially on the more restricted body side. Among participants reporting more pain on one side of the body, 90% exhibited greater post-intervention improvement on the more painful side. Moreover, distinctions in the strain-based biomarkers well aligned with self-reported pain, supporting their potential for objective assessment of myofascial dysfunction. This study highlights the feasibility of optical skin surface tracking as a tool for evaluating the efficacy of STM intervention, offering a quantitative, low-cost, and realistic clinical approach. NEW & NOTEWORTHY This study demonstrates that optical capture of skin surface movements provides a robust and clinically compatible approach for assessing the mobility of soft tissue. Strain-based biomarkers derived from digital …",Cold Spring Harbor Laboratory Press,,2025
965,Capturing 3D Skin Deformation and Finger Kinematics in Active Touch with Compliant Materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ibBUGLAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ibBUGLAAAAAJ:ye4kPcJQO24C,"In touch interactions with compliant materials, such as soft fruits and tissues, an individual's finger movements elicit unique and nuanced cutaneous and kinesthetic cues. The qualities of such cues are key to our perceptual judgments, but due to the spatiotemporal complexity of human touch, its contact interactions are difficult to capture and analyze. Prior efforts to quantify these cues have mostly been limited to passive touch, which constrains one's finger orientation, point of contact, forces, and displacements. Moreover, studies in active touch paradigms often only consider contact with rigid plates. This work describes a novel approach to measure cutaneous skin deformation and kinesthetic digit movements while exploring compliant materials in active touch. We use digital image correlation to track 3D skin surface deformation and quantify its compressive and tensile strain, cross-sectional curvature, and contact …",IEEE,,2025
966,Evaluating the Importance of Demographic and Technical Factors in Creating Authentic-Sounding AI-Generated Human Voice Clones,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ibBUGLAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ibBUGLAAAAAJ:5awf1xo2G04C,"Business and governmental institutions face growing threats from synthetic audio deepfakes due to advances in voice cloning and artificial intelligence. By accessing a short recording of a person’s voice, malicious actors can clone it to say anything they like. This poses serious risks of fraud, identity theft, and loss of trust. While much prior research has explored defensive postures, limited works have considered the factors that make a cloned voice sound authentic. This effort investigates factors leading to more authentic sounding AI-generated clones of the human voice. A voice library of about 350 short samples was created, spanning a range of demographic (age, gender, ethnicity) and technical factors (cloning tool, training time, background noise). Using optimization techniques, a subset of 81 voices (67 cloned and 14 authentic) were selected for an online survey with human listeners (). Each voice was …",IEEE,,2025
967,3-D Reconstruction of Fingertip Deformation during Contact Initiation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ibBUGLAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ibBUGLAAAAAJ:SdhP9T11ey4C,"Dexterous manipulations rely on tactile feedback from the fingertips, which provides crucial information about contact events, object geometry, interaction forces, friction, and more. Accurately measuring skin deformations during tactile interactions can shed light on the mechanics behind such feedback. To address this, we developed a novel setup using 3-D digital image correlation (DIC) to both reconstruct the bulk deformation and local surface skin deformation of the fingertip under natural loading conditions. Here, we studied the local spatiotemporal evolution of the skin surface during contact initiation. We showed that, as soon as contact occurs, the skin surface deforms very rapidly and exhibits high compliance at low forces (<0.05 N). As loading and thus the contact area increases, a localized deformation front forms just ahead of the moving contact boundary. Consequently, substantial deformation extending beyond the contact interface was observed, with maximal amplitudes ranging from 5% to 10% at 5 N, close to the border of the contact. Furthermore, we found that friction influences the partial slip caused by these deformations during contact initiation, as previously suggested. Our setup provides a powerful tool to get new insights into the mechanics of touch and opens avenues for a deeper understanding of tactile afferent encoding.",Cold Spring Harbor Laboratory,,2025
968,Strain-based biomarkers at the skin surface differentiate asymmetries in soft tissue mobility associated with myofascial pain,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ibBUGLAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ibBUGLAAAAAJ:9vf0nzSNQJEC,"Objective Soft tissue manipulation is used widely to assess myofascial tissue qualitatively but lacks objective measures. To quantify the mobility of myofascial tissue, this effort derives optical biomarkers from the skin surface, as observed in the hands-on workflow of clinicians. Methods Digital image correlation using three high-resolution cameras captures the cervicothoracic region as a clinician deeply engages and stretches the skin and myofascial tissue. Nineteen participants were positioned prone and marked with semi-permanent tattoos, optimized for tracking tissue without compromising its natural mechanics. Tissue mobility was then clinically assessed both bilaterally (left and right sides of body) and directionally (superior and inferior directions of pull). Results Eleven strain-based biomarkers were derived per tissue pull. With participants’ data aggregated, the sides of the body were indistinct, though pull in the superior direction was distinct from that in the inferior direction. Given substantial variance in the biomarkers’ absolute values between participants, we then evaluated each person individually. Therein, distinct tissue behaviors were observed. In particular, bilateral differences were identified in nine participants, eight of whom reported discrepancies in pain between their left and right sides, while directional distinctions were observed in sixteen participants, as expected given similar anatomical tissue structures between individuals. Conclusion In our sample of participants, optical skin surface tracking and derived strain-based biomarkers identified asymmetrical distinctions in bilateral mobility, which correspond with self-reported pain …",Cold Spring Harbor Laboratory Press,,2024
969,Direct 3D Printing of Shear‐Thinning Hydrogels into Self‐Healing Hydrogels,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mdJzLNQAAAAJ&citation_for_view=mdJzLNQAAAAJ:eQOLeE2rZwMC,"Supramolecular hydrogels are used in the 3D printing of high-resolution, multi-material structures. The non-covalent bonds allow the extrusion of the inks into support gels to directly write structures continuously in 3D space. This material system supports the patterning of multiple inks, cells, and void spaces.",,,2015
970,Biofabrication strategies for 3D in vitro models and regenerative medicine,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mdJzLNQAAAAJ&citation_for_view=mdJzLNQAAAAJ:YOwf2qJgpHMC,"Organs are complex systems composed of different cells, proteins and signalling molecules that are arranged in a highly ordered structure to orchestrate a myriad of functions in our body. Biofabrication strategies can be applied to engineer 3D tissue models in vitro by mimicking the structure and function of native tissue through the precise deposition and assembly of materials and cells. This approach allows the spatiotemporal control over cell–cell and cell–extracellular matrix communication and thus the recreation of tissue-like structures. In this Review, we examine biofabrication strategies for the construction of functional tissue replacements and organ models, focusing on the development of biomaterials, such as supramolecular and photosensitive materials, that can be processed using biofabrication techniques. We highlight bioprinted and bioassembled tissue models and survey biofabrication techniques for …",Nature Publishing Group,Nature Reviews Materials,2018
971,3D Printing of Shear-Thinning Hyaluronic Acid Hydrogels with Secondary Cross-Linking,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mdJzLNQAAAAJ&citation_for_view=mdJzLNQAAAAJ:LkGwnXOMwfcC,"The development of printable biomaterial inks is critical to the application of 3D printing in biomedicine. To print high-resolution structures with fidelity to a computer-aided design, materials used in 3D printing must be capable of being deposited on a surface and maintaining a printed structure. A dual-cross-linking hyaluronic acid system was studied here as a printable hydrogel ink, which encompassed both shear-thinning and self-healing behaviors via guest–host bonding, as well as covalent cross-linking for stabilization using photopolymerization. When either guest–host assembly or covalent cross-linking was used alone, long-term stable structures were not formed, because of network relaxation after printing or dispersion of the ink filaments prior to stabilization, respectively. The dual-cross-linking hydrogel filaments formed structures with greater than 16 layers that were stable over a month with no loss in …",American Chemical Society,,2016
972,Recent advances in hyaluronic acid hydrogels for biomedical applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mdJzLNQAAAAJ&citation_for_view=mdJzLNQAAAAJ:ufrVoPGSRksC,"Highlights New modifications to hyaluronic acid (HA) enable both covalent crosslinking and supramolecular assembly. Composite HA hydrogels permit controlled drug delivery and mechanical toughness. Processing such as electrospinning, 3D printing, and photopatterning allow the formation of complex structures in HA hydrogels. HA hydrogels are engineered to influence the fate of encapsulated or endogenous cells. HA hydrogels continue to advance basic science and translational biomedical research. Hyaluronic acid (HA) is widely used in the design of engineered hydrogels, due to its biofunctionality, as well as numerous sites for modification with reactive groups. There are now widespread examples of modified HA macromers that form either covalent or physical hydrogels through crosslinking reactions such as with click chemistry or supramolecular assemblies of guest-host pairs. HA hydrogels range from …",Elsevier Current Trends,,2016
973,A Generalizable Strategy for the 3D Bioprinting of Hydrogels from Nonviscous Photo‐crosslinkable Inks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mdJzLNQAAAAJ&citation_for_view=mdJzLNQAAAAJ:hqOjcs7Dif8C,"DOI: 10.1002/adma. 201604983 of interest in applications ranging from cartilage tissue engineering [12] to the expansion of embryonic stem cells.[13] Precrosslinking (applying 10 mW cm− 2 UV-irradiation for 30 s before extrusion) resulted in high and inconsistent extrusion forces (Figure 1C), heterogeneous printed material structures (Figure 1D and Movie S1, Supporting Information), and low cell viabilty (≈ 47%, Figure 1E). Shorter UV-irradiation times of 10 and 20 s improved cell viability, but still led to heterogeneous printed structures (Figure S2, Supporting Information). Post-crosslinking with light exposure after extrusion of the material improved cell viability and lowered the extrusion force; however, the bioink flowed prior to stabilization (Figure 1D and Movie S1, Supporting Information). In a previous study,[14] postcrosslinking was performed with a higher MeHA concentration of up to 20 wt% and higher UV intensity (15 mW cm− 2) and the bioink was still unable to maintain the filament structure. To address these challenges in printing photo-crosslinkable materials, here we present a generalizable bioprinting method to enable 3D printing of hydrogel structures from photocrosslinkable precursors. In this approach, we introduce the light through a photopermeable capillary (eg, silicone tubing, glass) to crosslink the hydrogel immediately prior to deposition (Figure 1A and Figure S3A, Supporting Information), which we termed “in situ-crosslinking”. Using MeHA, the forces for extrusion were low and consistent (Figure 1C), the printed filament was uniform (Figure 1D and Movie S1, Supporting Information), and high encapsulated cell viability (≈ …",,,2017
974,Computational Fluid Dynamic Model Prediction of Enhanced Glymphatic Clearance in Response to Focused Ultrasound‐Mediated Blood‐Brain Barrier Opening,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mdJzLNQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=mdJzLNQAAAAJ:4JMBOYKVnBMC,"Focused Ultrasound (FUS) is the concentration of acoustic energy into a small region to produce therapeutic bioeffects. FUS‐induced blood‐brain barrier opening (BBBO), a strategy to deliver drugs and genes to the brain, also enhances glymphatic drainage, the brain‐specific waste clearance system. Thus, FUS BBBO is a promising strategy for addressing the accumulation of neurotoxic solutes that are characteristic of many neurodegenerative diseases. However, the biotransport mechanisms by which FUS augments glymphatic drainage are not well understood. To address this knowledge gap, a 3D finite element COMSOL model of a single penetrating arteriole‐venule vascular unit in the brain is engineered. The model predicts that i) FUS greatly improves waste clearance by increasing both diffusion and convection, ii) the convection‐mediated movement of cerebrospinal fluid (CSF) and solute from the arteriole …",,,2025
975,Focused Ultrasound Crosslinkable Granular Hydrogels,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mdJzLNQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=mdJzLNQAAAAJ:_Qo2XoVZTnwC,"Minimally invasive delivery of biomaterials for tissue regeneration can be achieved using biomaterials delivered by injection that rapidly stabilize at the delivery site. Tissue regeneration has been shown to be dependent on material properties, with porosity strongly supporting revascularization and tissue regrowth. Here, a highly porous granular hydrogel system was designed that is compatible with the unique strengths of highly penetrating, minimal invasive focused ultrasound (FUS), to address this challenge. FUS offers well-defined spatial and temporal control over hydrogel crosslinking. We developed a composite granular hydrogel scaffold composed of two polyethylene glycol (PEG)-based components, microgels and fibers with FUS-responsive chemistry, and a pore-defining gelatin microgel component. Upon applying FUS, the bulk granular hydrogel stabilized through the formation of crosslinks between PEG components, with porosity designed by gelatin microgel melting. FUS-crosslinking parameters were determined that resulted in crosslinking both in vitro and a mouse cadaver model of minimally invasive delivery. The resulting granular hydrogels’ stability depended on the presence of fibers and exhibited viscoelastic properties comparable to granular hydrogels that were photocrosslinked. Hydrogels were highly porous and cytocompatible. This work defines a FUS-responsive granular system and extends the potential of FUS as a novel, noninvasive method for crosslinking regenerative hydrogel systems.",Cold Spring Harbor Laboratory,,2025
976,Engineering Granular Hydrogels without Interparticle Cross-Linking to Support Multicellular Organization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mdJzLNQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=mdJzLNQAAAAJ:e5wmG9Sq2KIC,"Advancing three-dimensional (3D) tissue constructs is central to creating in vitro models and engineered tissues that recapitulate biology. Materials that are permissive to cellular behaviors, including proliferation, morphogenesis of multicellular structures, and motility, will support the emergence of tissue structures. Granular hydrogels in which there is no interparticle cross-linking exhibit dynamic properties that may be permissive to such cellular behaviors. However, designing granular hydrogels that lack interparticle cross-linking but support cellular self-organization remains underexplored relative to granular systems stabilized by interparticle cross-linking. In this study, we developed a polyethylene glycol-based granular hydrogel system, with average particle diameters under 40 μm. This granular hydrogel exhibited bulk stress-relaxing behaviors and compatibility with custom microdevices to sustain cell cultures …",American Chemical Society,,2024
977,Conformal encapsulation of mammalian stem cells using modified hyaluronic acid,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mdJzLNQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=mdJzLNQAAAAJ:R3hNpaxXUhUC,"Micro- and nanoencapsulation of cells has been studied as a strategy to protect cells from environmental stress and promote survival during delivery. Hydrogels used in encapsulation can be modified to influence cell behaviors and direct assembly in their surroundings. Here, we report a system that conformally encapsulated stem cells using hyaluronic acid (HA). We successfully modified HA with lipid, thiol, and maleimide pendant groups to facilitate a hydrogel system in which HA was deposited onto cell plasma membranes and subsequently crosslinked through thiol-maleimide click chemistry. We demonstrated conformal encapsulation of both neural stem cells (NSCs) and mesenchymal stromal cells (MSCs), with viability of both cell types greater than 90% after encapsulation. Additional material could be added to the conformal hydrogel through alternating addition of thiol-modified and maleimide-modified HA in …",Royal Society of Chemistry,,2024
978,Supramolecular fibrous hydrogel augmentation of uterosacral ligament suspension for treatment of pelvic organ prolapse,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mdJzLNQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=mdJzLNQAAAAJ:hFOr9nPyWt4C,"Uterosacral ligament suspension (USLS) is a common surgical treatment for pelvic organ prolapse (POP). However, the relatively high failure rate of up to 40% underscores a strong clinical need for complementary treatment strategies, such as biomaterial augmentation. Herein, the first hydrogel biomaterial augmentation of USLS in a recently established rat model is described using an injectable fibrous hydrogel composite. Supramolecularly‐assembled hyaluronic acid (HA) hydrogel nanofibers encapsulated in a matrix metalloproteinase (MMP)‐degradable HA hydrogel create an injectable scaffold showing excellent biocompatibility and hemocompatibility. The hydrogel can be successfully delivered and localized to the suture sites of the USLS procedure, where it gradually degrades over six weeks. In situ mechanical testing 24 weeks post‐operative in the multiparous USLS rat model shows the ultimate load …",,,2023
979,Dynamic optimal control for groundwater remediation with flexible management periods,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZHRAnVcAAAAJ&citation_for_view=ZHRAnVcAAAAJ:u5HHmVD_uO8C,"A successive approximation linear quadratic regulator (SALQR) method with management periods is combined with a finite element groundwater flow and transport simulation model to determine optimal time‐varying groundwater pump‐and‐treat reclamation policies. Management periods are groups of simulation time steps during which the pumping policy remains constant. In an example problem, management periods reduced the total computational demand, as measured by the CPU time, by as much as 85% compared to the time needed for the SALQR solution without management periods. Conversely, the optimal costs increased as the number of times that the control can change is reduced. With two simulation periods per management period, the optimal cost increased by less than 1% compared to the optimal cost with no management periods, yet the computational work was reduced by a third. The …",,,1992
980,Modeling the desorption of organic contaminants from long-term contaminated soil using distributed mass transfer rates,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZHRAnVcAAAAJ&citation_for_view=ZHRAnVcAAAAJ:u-x6o8ySG0sC,"Simulation models for the fate and transport of groundwater contaminants are important tools for testing our understanding of transport phenomena at long-term contaminated sites and for designing remedial action plans. A finite difference formulation for contaminant transport including a distribution of contaminant mass-transfer rates between the water and soil is developed. Optimal model simulations using both log-normal and γ distributions of mass transfer rates are compared to the two-site equilibrium/kinetic model. In all cases, optimal sorption parameters were determined by best fit to laboratory data. For desorption of trichloroethene from long-term contaminated soils, the distributed mass-transfer rate model provided significantly improved simulations of aqueous concentrations, as compared to the two-site model, for both batch and soil column experiments. However, use of an apparent partition coefficient …",American Chemical Society,,1997
981,Constraint handling for genetic algorithms in optimal remediation design,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZHRAnVcAAAAJ&citation_for_view=ZHRAnVcAAAAJ:d1gkVwhDpl0C,"There often is difficulty enforcing the given constraints when applying a genetic algorithm (a flexible stochastic search method) to optimal ground-water remediation design problems. This paper compares two methods for constraint handling within the genetic algorithm framework. The first method, the additive penalty method (APM), is a commonly used penalty function approach in which a penalty cost proportional to the total constraints violation is added to the objective function. The second method, the multiplicative penalty method (MPM), multiplies the objective function by a factor proportional to the total constraints violation. The APM and MPM, using constant and generation-varying constraint weights, are applied to two pump-and-treat design examples. Overall, the application of the APM resulted in infeasible solutions with small-to-moderate total constraints violations. With the MPM, a set of feasible and near …",American Society of Civil Engineers,,2000
982,Groundwater remediation design under uncertainty using genetic algorithms,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZHRAnVcAAAAJ&citation_for_view=ZHRAnVcAAAAJ:qjMakFHDy7sC,"In groundwater problems, there always is some uncertainty associated with appropriate values for aquifer parameters. Therefore an optimal remediation strategy identified by assuming a deterministic description of the system may not yield an optimal and feasible design. This work develops a robust genetic algorithm (GA) approach that takes into account the uncertainty of hydraulic conductivity values when determining the best remediation design possible. Within a generation of the robust GA, all designs are evaluated using the same realization of the heterogeneous hydraulic conductivity field, but the realizations vary between GA generations. Ongoing performance of the designs is measured and is used in the GA evolution process. While the robust GA is a multiple realization method, minimal additional computation effort over that of a basic GA is required to identify robust designs. The robust GA is applied to …",American Society of Civil Engineers,,2005
983,Optimal control for groundwater remediation by differential dynamic programming with quasi‐Newton approximations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZHRAnVcAAAAJ&citation_for_view=ZHRAnVcAAAAJ:2osOgNQ5qMEC,"Differential dynamic programming with quasi‐Newton approximations (QNDDP) is combined with a finite element groundwater quality simulation model to determine optimal time‐varying pumping policies for reclamation of a contaminated aquifer. The purpose of the QNDDP model is to significantly reduce the large computational effort associated with calculation of optimal time‐varying policies. A Broyden rank‐one quasi‐Newton technique is developed to approximate the second derivatives of the groundwater quality model; these second derivatives are difficult to calculate directly. The performance of the QNDDP algorithm is compared to the successive approximation linear quadratic regulator (SALQR) technique, which sets the complicated second derivatives to 0. QNDDP converged to the optimal pumping policy in approximately half the time that the SALQR technique required. The QNDDP algorithm thus …",,,1993
984,Validating Nitrogen Removal Models with Field Bioretention Data,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZHRAnVcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ZHRAnVcAAAAJ:UxriW0iASnsC,"Bioretention is a type of stormwater best management practice that can reduce stormwater runoff volume, and with appropriate design, simultaneously reduce nitrogen loads. To meet the water quality potential of bioretention systems, improved simulation models of the transport and transformations of nitrogen are needed. In this work, two versions of a three-nitrogen-pool (3P) model (3P-1 and 3P-m) are applied to simulate observed nitrogen transport through a field bioretention system. The 3P models provide predictions of net export of dissolved organic carbon, dissolved organic nitrogen, and inorganic nitrogen species. The 3P-m model has promising results: (1) relative to the Storm Water Management Model (SWMM), it reduced the prediction error of percent removal of total dissolved nitrogen by up to 10.6% and reduces the scaled root-mean square error of total dissolved nitrogen loads by up to 53.0%; (2) it …",American Society of Civil Engineers,,2024
985,Assessing and improving the outcomes of nonpoint source water quality trading policies in urban areas: A case study in Virginia,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZHRAnVcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ZHRAnVcAAAAJ:KxtntwgDAa4C,"Nonpoint source (NPS) water quality trading (WQT) is a market-based approach to improving water quality. Past work has shown that these programs could increase localized pollutant loadings, in part by exporting water quality controls from urban to rural areas. Virginia's NPS WQT program has enabled thousands of transactions and may provide a model for other programs, but its impacts on urban water quality have not been thoroughly assessed. We quantify the impact of NPS WQT purchases in Virginia on water quality and hydrology in an urban catchment. We go on to assess outcomes of a policy alternative where buyers and sellers are collocated in the urban catchment. Simulation results show that NPS WQT increased total phosphorus (TP) loading by an average of 0.8 lbs TP/year for each 1.0 offsite credits purchased in the analyzed catchment. The TP loading increased in years with greater rainfall, such …",Academic Press,,2023
986,Developing nitrogen removal models for stormwater bioretention systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZHRAnVcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ZHRAnVcAAAAJ:nb7KW1ujOQ8C,"Bioretention systems have the potential of simultaneous runoff volume reduction and nitrogen removal. Internal water storage (IWS) layers and real-time control (RTC) strategies may further improve performance of bioretention systems. However, optimizing the design of these systems is limited by the lack of effective models to simulate nitrogen transformations under the influences of IWS design and environment conditions including soil moisture and temperature. In this study, nitrogen removal models (NRMs) are developed with two complexity levels of nitrogen cycling: the Single Nitrogen Pool (SP) models and the more complex 3 Nitrogen Pool (3P) models. The 0-order kinetics, 1st order kinetics, and the Michaelis-Menten equations are applied to both SP and 3P models, creating six different NRMs. The Storm Water Management Model (SWMM), in combination with each NRM, is calibrated and validated with a …",Pergamon,,2023
987,Integrating social equity into multiobjective optimization of urban stormwater low-impact development,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZHRAnVcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ZHRAnVcAAAAJ:P5F9QuxV20EC,"Recent studies have demonstrated some advantages of using advanced heuristic algorithms to identify near-Pareto-optimal future locations, types, and sizes for stormwater low-impact development and green infrastructure (LID/GI) across a given urban landscape. However, previous optimization studies did not consider social equity as an objective, which poses problems because urban green infrastructure often is distributed inequitably. Increasing access to LID/GI in historically marginalized areas is a prominent environmental justice issue, and increasingly is becoming a primary consideration when prioritizing future locations, types, and sizes of urban LID/GI. This study integrated a novel spatial social equity objective [LID/GI–Social Vulnerability Index (SVI) correlation objective, ] into a multiobjective LID/GI optimization model. The LID/GI-SVI correlation is an objective that directs the optimization algorithm to …",American Society of Civil Engineers,,2023
988,Assessing the Impact of Antecedent Dry Period and Storm Volume on Nitrogen Transport in Biochar-Amended and Compost-Amended Roadway Soils,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZHRAnVcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ZHRAnVcAAAAJ:1sJd4Hv_s6UC,"Roadside soil amendments, like compost and biochar, are used to mitigate the impact of stormwater runoff on the transport of pollutants, like nitrogen, to waterways. However, biochar and compost may leach nitrogen, and the leaching mechanism could be exacerbated by climate change-driven increases to storm volume and antecedent dry period (ADP). Despite this, neither amendment has been evaluated under these climate change scenarios. To properly implement these materials, it is crucial to characterize leachate from biochar-amended and compost-amended soils. We compared nitrogen concentrations in outflow from biochar-amended and compost-amended roadside soils following a series of simulated large volume storm events and a series of intermittent storm events with increasing ADPs. First, columns of roadside soil and biochar (30% by volume and 4% by weight) or compost (30% by volume) were …",,,2023
989,Predicting near-term train schedule performance and delay using bi-level random forests,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lDDZYr0AAAAJ&citation_for_view=lDDZYr0AAAAJ:N5tVd3kTz84C,"Accurate near-term passenger train delay prediction is critical for optimal railway management and providing passengers with accurate train arrival times. In this work, a novel bi-level random forest approach is proposed to predict passenger train delays in the Netherlands. The primary level predicts whether a train delay will increase, decrease, or remain unchanged in a specified time frame. The secondary level then estimates the actual delay (in minutes), given the predicted delay category at primary level. For validation purposes, the proposed model has been compared with several alternative statistical and machine-learning approaches. The results show that the proposed model provides the best prediction accuracy compared with other alternatives. Moreover, constructing the proposed bi-level model is computationally cheap, thereby being easily applicable.",SAGE Publications,,2019
990,Hurricane-induced power outage risk under climate change is primarily driven by the uncertainty in projections of future hurricane frequency,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lDDZYr0AAAAJ&citation_for_view=lDDZYr0AAAAJ:uLbwQdceFCQC,"Nine in ten major outages in the US have been caused by hurricanes. Long-term outage risk is a function of climate change-triggered shifts in hurricane frequency and intensity; yet projections of both remain highly uncertain. However, outage risk models do not account for the epistemic uncertainties in physics-based hurricane projections under climate change, largely due to the extreme computational complexity. Instead they use simple probabilistic assumptions to model such uncertainties. Here, we propose a transparent and efficient framework to, for the first time, bridge the physics-based hurricane projections and intricate outage risk models. We find that uncertainty in projections of the frequency of weaker storms explains over 95% of the uncertainty in outage projections; thus, reducing this uncertainty will greatly improve outage risk management. We also show that the expected annual fraction of affected …",Nature Publishing Group UK,,2020
991,Divide and conquer: An incremental sparsity promoting compressive sampling approach for polynomial chaos expansions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lDDZYr0AAAAJ&citation_for_view=lDDZYr0AAAAJ:2osOgNQ5qMEC,"This paper introduces an efficient sparse recovery approach for Polynomial Chaos (PC) expansions, which promotes the sparsity by breaking the dimensionality of the problem. The proposed algorithm incrementally explores sub-dimensional expansions for a sparser recovery, and shows success when removal of uninfluential parameters that results in a lower coherence for measurement matrix, allows for a higher order and/or sparser expansion to be recovered. The incremental algorithm effectively searches for the sparsest PC approximation, and not only can it decrease the prediction error, but it can also reduce the dimensionality of PCE model. Four numerical examples are provided to demonstrate the validity of the proposed approach. The results from these examples show that the incremental algorithm substantially outperforms conventional compressive sampling approaches for PCE, in terms of both …",Elsevier,,2017
992,Survival analysis at multiple scales for the modeling of track geometry deterioration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lDDZYr0AAAAJ&citation_for_view=lDDZYr0AAAAJ:UeHWp8X0CEIC,"Defects in track geometry have a notable impact on the safety of rail transportation. In order to make the optimal maintenance decisions to ensure the safety and efficiency of railroads, it is necessary to analyze the track geometry defects and develop reliable defect deterioration models. In general, standard deterioration models are typically developed for a segment of track. As a result, these coarse-scale deterioration models may fail to predict whether the isolated defects in a segment will exceed the safety limits after a given time period or not. In this paper, survival analysis is used to model the probability of exceeding the safety limits of the isolated defects. These fine-scale models are then used to calculate the probability of whether each segment of the track will require maintenance after a given time period. The model validation results show that the prediction quality of the coarse-scale segment-based models …",SAGE Publications,,2018
993,A near-optimal sampling strategy for sparse recovery of polynomial chaos expansions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lDDZYr0AAAAJ&citation_for_view=lDDZYr0AAAAJ:eq2jaN3J8jMC,"Compressive sampling has become a widely used approach to construct polynomial chaos surrogates when the number of available simulation samples is limited. Originally, these expensive simulation samples would be obtained at random locations in the parameter space. It was later shown that the choice of sample locations could significantly impact the accuracy of resulting surrogates. This motivated new sampling strategies or design-of-experiment approaches, such as coherence-optimal sampling, which aim at improving the coherence property. In this paper, we propose a sampling strategy that can identify near-optimal sample locations that lead to improvement in local-coherence property and also enhancement of cross-correlation properties of measurement matrices. We provide theoretical motivations for the proposed sampling strategy along with several numerical examples that show that our near …",Academic Press,,2018
994,Bayesian theory of probabilistic forecasting via deterministic hydrologic model,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_m_ofYAAAAAJ&citation_for_view=_m_ofYAAAAAJ:u5HHmVD_uO8C,"Rational decision making (for flood warning, navigation, or reservoir systems) requires that the total uncertainty about a hydrologic predictand (such as river stage, discharge, or runoff volume) be quantified in terms of a probability distribution, conditional on all available information and knowledge. Hydrologic knowledge is typically embodied in a deterministic catchment model. Fundamentals are presented of a Bayesian forecasting system (BFS) for producing a probabilistic forecast of a hydrologic predictand via any deterministic catchment model. The BFS decomposes the total uncertainty into input uncertainty and hydrologic uncertainty, which are quantified independently and then integrated into a predictive (Bayes) distribution. This distribution results from a revision of a prior (climatic) distribution, is well calibrated, and has a nonnegative ex ante economic value. The BFS is compared with Monte Carlo simulation …",,,1999
995,The case for probabilistic forecasting in hydrology,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_m_ofYAAAAAJ&citation_for_view=_m_ofYAAAAAJ:u-x6o8ySG0sC,"That forecasts should be stated in probabilistic, rather than deterministic, terms has been argued from common sense and decision-theoretic perspectives for almost a century. Yet most operational hydrological forecasting systems produce deterministic forecasts and most research in operational hydrology has been devoted to finding the ‘best’ estimates rather than quantifying the predictive uncertainty. This essay presents a compendium of reasons for probabilistic forecasting of hydrological variates. Probabilistic forecasts are scientifically more honest, enable risk-based warnings of floods, enable rational decision making, and offer additional economic benefits. The growing demand for information about risk and the rising capability to quantify predictive uncertainties create an unparalleled opportunity for the hydrological profession to dramatically enhance the forecasting paradigm.",Elsevier,,2001
996,A bivariate meta-Gaussian density for use in hydrology,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_m_ofYAAAAAJ&citation_for_view=_m_ofYAAAAAJ:d1gkVwhDpl0C,"Convenient bivariate densities found in the literature are often unsuitable for modeling hydrologic variates. They either constrain the range of association between variates, or fix the form of the marginal distributions. The bivariate meta-Gaussian density is constructed by embedding the normal quantile transform of each variate into the Gaussian law. The density can represent a full range of association between variates and admits arbitrarily specified marginal distributions. Modeling and estimation can be decomposed into i) independent analyses of the marginal distributions, and ii) investigation of the dependence structure. Both statistical and judgmental estimation procedures are possible. Some comparisons to recent applications of bivariate densities in the hydrologic literature motivate and illustrate the model.",Springer-Verlag,,1997
997,Bayesian system for probabilistic river stage forecasting,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_m_ofYAAAAAJ&citation_for_view=_m_ofYAAAAAJ:9yKSN-GCB0IC,"The purpose of this analytic-numerical Bayesian forecasting system (BFS) is to produce a short-term probabilistic river stage forecast based on a probabilistic quantitative precipitation forecast as an input and a deterministic hydrologic model (of any complexity) as a means of simulating the response of a headwater basin to precipitation. The BFS has three structural components: the precipitation uncertainty processor, the hydrologic uncertainty processor, and the integrator. A series of articles described the Bayesian forecasting theory and detailed each component of this particular BFS. This article presents a synthesis: the total system, operational expressions, estimation procedures, numerical algorithms, a complete example, and all design requirements, modeling assumptions, and operational attributes.",Elsevier,,2002
998,Hydrologic uncertainty processor for probabilistic river stage forecasting,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_m_ofYAAAAAJ&citation_for_view=_m_ofYAAAAAJ:2osOgNQ5qMEC,"The hydrologic uncertainty processor (HUP) is a component of the Bayesian forecasting system that produces a short‐term probabilistic river stage forecast based on a probabilistic quantitative precipitation forecast (PQPF). The task of the HUP is to quantify the hydrologic uncertainty under the hypothesis that there is no precipitation uncertainty. The hydrologic uncertainty is the aggregate of all uncertainties arising from sources other than those quantified by the PQPF; these sources include the hydrologic model (model and parameter uncertainties), inputs estimated deterministically (measurement, estimation, and prediction uncertainties), and inputs not forecasted (e.g., precipitation beyond the period covered by the PQPF). Bayesian theory for the HUP is presented, and a meta‐Gaussian model is developed. This parametric model allows for (1) any form of marginal distributions of river stages, (2) a nonlinear and …",,,2000
999,Probabilistic forecasts and optimal decisions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_m_ofYAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_m_ofYAAAAAJ:35r97b3x0nAC,"Account for uncertainties and optimize decision-making with this thorough exposition Decision theory is a body of thought and research seeking to apply a mathematical-logical framework to assessing probability and optimizing decision-making. It has developed robust tools for addressing all major challenges to decision making. Yet the number of variables and uncertainties affecting each decision outcome, many of them beyond the decider’s control, mean that decision-making is far from a ‘solved problem’. The tools created by decision theory remain to be refined and applied to decisions in which uncertainties are prominent. Probabilistic Forecasts and Optimal Decisions introduces a theoretically-grounded methodology for optimizing decision-making under conditions of uncertainty. Beginning with an overview of the basic elements of probability theory and methods for modeling continuous variates, it proceeds to survey the mathematics of both continuous and discrete models, supporting each with key examples. The result is a crucial window into the complex but enormously rewarding world of decision theory. Readers of Probablistic Forecasts and Optimal Decisions will also find: Extended case studies supported with real-world data Mini-projects running through multiple chapters to illustrate different stages of the decision-making process End of chapter exercises designed to facilitate student learning Probabilistic Forecasts and Optimal Decisions is ideal for advanced undergraduate and graduate students in the sciences and engineering, as well as predictive analytics and decision analytics professionals.",John Wiley & Sons,,2024
1000,Ensemble Bayesian forecasting system Part II: Experiments and properties,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_m_ofYAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_m_ofYAAAAAJ:VL0QpB8kHFEC,"A typical deficiency of ensemble forecasts is the lack of calibration; eg, ensemble members are under-dispersed and, consequently, probabilities estimated from them cannot be taken at their face values. Self-calibration is one of the unique theoretic properties of the Bayesian forecasting system, BFS. Its ensemble version, EBFS, inherits this property, provided the ensemble size is large enough. That requirement motivated the version with randomization, EBFSR, presented in part I. Its unique advantage is the operational feasibility of generating a hydrologic ensemble forecast of large size, M (having hundreds or even thousands of members), from a meteorologic input ensemble forecast of small size, M I (having only tens or hundreds of members): M I< M, with M= M I R, where R stands for randomization factor (R> 1 and integer). This R-fold enlargement of the ensemble size is achieved through a Monte Carlo …",Elsevier,,2019
1001,A Bayesian Approach to Statistical Post-Processing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_m_ofYAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_m_ofYAAAAAJ:LjlpjdlvIbIC,"Weather affects a wide range of individual and institutional activities. Users seek the most skillful and calibrated forecasts available, hence weather agencies must be prepared to provide information on any aspect of future weather, in any form requested. Today, most weather forecasts are based on Numerical Weather Prediction (NWP) model output. Such guidance (eg, single or ensemble forecasts) is (1) available from multiple sources (with partially independent information); and due to modeling limitations,(2) they suffer from lead-time dependent miscalibration (systematic errors), and (3) are limited to some basic coarser scale variables that may not be of direct interest to most users. Hence the three main objectives of statistical post-processing of NWP output are:(1) Combine all predictive information into a single guidance product;(2) Calibrate such guidance; and (3) Provide additional information beyond that …",,,2018
1002,Stochastic models of severe weather watches and warnings: transition probabilities,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_m_ofYAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_m_ofYAAAAAJ:tkaPQYYpVKoC,"To alert the public to the possibility of tornado (T), hail (H), or convective wind (C), the National Weather Service (NWS) issues watches (V) and warnings (W). There are severe thunderstorm watches (SV), tornado watches (TV), and particularly dangerous situation watches (PV); and there are severe thunderstorm warnings (SW), and tornado warnings (TW). Two stochastic models are formulated that quantify uncertainty in severe weather alarms for the purpose of making decisions: a one-stage model for deciders who respond to warnings, and a two-stage model for deciders who respond to watches and warnings. The models identify all possible sequences of watches, warnings, and events, and characterize the associated uncertainties in terms of transition probabilities. The modeling approach is demonstrated on data from the NWS Norman, Oklahoma, warning area, years 2000–2007. The major findings are these. (i) Irrespective …",Springer Berlin Heidelberg,,2017
1003,Bringing It All Together: A Prototype for a Probabilistic National Blend of Models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_m_ofYAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_m_ofYAAAAAJ:j8SEvjWlNXcC,"It is well understood that Numerical Weather Prediction (NWP) output (a) suffers from lead-time dependent systematic errors,(b) lacks fine scale User Specific Variables (USV), and (c) proliferates due to a diverse set of data sources. Traditionally, each guidance is statistically calibrated independent of the others. The National Weather Service (NWS) recognized the unsustainability of such an approach and launched the National Blend of Models (NBM) project. The present, NGGPS (Next Generation Global Prediction System) supported study of the Bayesian Processor of Ensemble (BPE, Krzysztofowicz and Toth 2008) aims at prototyping a future probabilistic version of NBM.",,,2017
1004,Review of resource-constrained scheduling algorithms,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YmSChwYAAAAJ&citation_for_view=YmSChwYAAAAJ:u5HHmVD_uO8C,"On a regular basis, project managers concentrate their efforts on critical and near-critical activities. However, the concepts of total float and critical path lose their significance after applying resource-constrained scheduling (RCS) techniques. RCS techniques mitigate the resource supply-demand problem but break the critical path. As a result, several algorithms have been developed to identify a continuous critical path in resource-constrained schedules. This study reviews and evaluates the performance of eight RCS-related algorithms with the purpose of identifying the shortcomings that must be addressed so they can be applied for delay analysis. The review shows that a systematic procedure is needed to (1) incorporate and handle dynamic resource links when the schedule is updated, and (2) select a potential resource links configuration. Addressing these limitations will make the algorithms more practical for …",American Society of Civil Engineers,Journal of Construction Engineering and Management,2019
1005,Performance of resource-constrained scheduling heuristics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YmSChwYAAAAJ&citation_for_view=YmSChwYAAAAJ:u-x6o8ySG0sC,"Over the years, the study of resource-constrained scheduling heuristics has focused on testing different sets of priority rules without paying attention to the conditions under which each heuristic produces better results. Although some authors have recommended the use of specific heuristics over any other rule, these recommendations are general and do not encompass all possible project characteristics in terms of resources and network topology. Without a guidance system, schedulers must try several combinations of rules until they find one that compares favorably (shortest duration) with the results of the other priority rules. This study proposes a new tiebreaker (priority number) that enhances the performance of an existing heuristic and classifies the heuristics’ performance based on specific project characteristics. The results show that, as a tiebreaker of the late finish rule, the priority number leads to obtain …",American Society of Civil Engineers,,2020
1006,Assessing the Cost Forecasting Performance in Construction Projects through Data Envelopment Analysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YmSChwYAAAAJ&citation_for_view=YmSChwYAAAAJ:Y0pCki6q_DkC,"Forecasting methods, as a control tool, aim to predict final project outcomes and play an important role in assessing the performance of construction projects. In construction, accuracy has been the most important criterion used to assess forecasting performance. However, in addition to accuracy, forecasting systems must provide timely information about project status so corrective action can be taken when required. Therefore, researchers have introduced timeliness as an additional forecasting performance measure. A preliminary study found that some forecasting methods with good timeliness indices do not necessary predict deviations with precision. Furthermore, the cost predictability indices proposed in the literature do not provide sufficient information upon these two desirable features of forecasting methods (timeliness and accuracy). Currently, researchers and practitioners are looking for appropriate …",,,2016
1007,Reemplazo del agregado fino por escoria de horno de cubilote para la fabricación de concreto,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YmSChwYAAAAJ&citation_for_view=YmSChwYAAAAJ:0EnyYjriUFMC,"Este trabajo presenta las propiedades físico-mecánicas obtenidas de un concreto fabricado con escoria de horno de cubilote (EHC), la cual se utilizó como sustituto del agregado fino (arena) en diferentes proporciones: 0, 10, 15 y 20%. La evaluación de la granulometría, densidad, absorción, humedad natural y contenido de material férrico de la EHC permitió caracterizarla como arena gruesa bien gradada, con poca cantidad de finos. Para una resistencia de diseño de 14 MPa del concreto modificado (CM) se realizaron ensayos de resistencia a la compresión, módulo de rotura, absorción, módulo de elasticidad y densidad de material endurecido. Los resultados obtenidos evidencian un comportamiento favorable del CM en su resistencia a compresión, al sustituir el 20% de arena por escoria. Asimismo, se encontró que la densidad mantiene una relación proporcional con el porcentaje de sustitución y el valor de su masa unitaria se encuentra dentro del rango de valores aceptable para un concreto de peso normal.",Universidad de la Costa,,2014
1008,Phantom float in commercial scheduling software,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YmSChwYAAAAJ&citation_for_view=YmSChwYAAAAJ:9yKSN-GCB0IC,"On a regular basis, construction professionals use scheduling software to resource load the schedules without paying attention to the resulting critical path. Current scheduling software fix the resource supply-demand problem by performing a Resource-Constrained Scheduling (RCS) technique, but they report incorrect total float values and a broken critical path. RCS calculations suggest that activities have float but much of this float does not exist (phantom float). Phantom float is created in resource-constrained schedules because the existing RCS methodologies neglect the resource relationships that arise between activities when competing for the same but unavailable resources. This paper illustrates the presence of phantom float in Primavera's P6 and Microsoft's Project schedules. After removing phantom float from the schedule, non-critical activities may become resource critical and the actual float may be …",Elsevier,,2019
1009,WIP: Developing an arts-informed approach to understand students’ perceptions of engineering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YmSChwYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=YmSChwYAAAAJ:YsMSGLbcyi4C,"This work in progress paper describes preliminary results of a methodology used at three different universities to explore students’ perceptions of engineering through drawings. One of the primary objectives of introductory and foundational engineering courses is to help students develop a sense of identity and belonging within the field of engineering, and understand basic engineering knowledge and skills. Hence, it is crucial to understand students’ preconceptions of the engineering discipline when they start their academic program. However, many students entering the program have narrow preconceptions or limited knowledge about the field. One challenge instructors face is how to facilitate students’ thinking about their own perceptions of engineering in a meaningful way. A typical activity to help the students understand their perceptions of the engineering discipline is to ask them, ""What is engineering?"" …",IEEE,,2022
1010,"An experimental comparison of four unit test criteria: Mutation, edge-pair, all-uses and prime path coverage",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8SujlDwAAAAJ&citation_for_view=8SujlDwAAAAJ:u5HHmVD_uO8C,"With recent increased expectations for quality, and the growth of agile processes and test driven development, developers are expected to do more and more effective unit testing. Yet, our knowledge of when to use the various unit level test criteria is incomplete. The paper presents results from a comparison of four unit level software testing criteria. Mutation testing, prime path coverage, edge pair coverage, and all-uses testing were compared on two bases: the number of seeded faults found and the number of tests needed to satisfy the criteria. The comparison used a collection of Java classes taken from various sources and hand-seeded faults. Tests were designed and generated mostly by hand with help from tools that compute test requirements and muJava. The findings are that mutation tests detected more faults and the other three criteria were very similar. The paper also presents a secondary measure, a …",IEEE,,2009
1011,Applying mutation testing to web applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8SujlDwAAAAJ&citation_for_view=8SujlDwAAAAJ:u-x6o8ySG0sC,"As our awareness of the complexities inherent in web applications grows, we find an increasing need for more sophisticated ways to test them. Many web application faults are a result of how web software components interact; sometimes client-server and sometimes server-server. This paper presents a novel solution to the problem of integration testing of web applications by using mutation analysis. New mutation operators are defined, a tool (webMuJava) that implements these operators is presented, and results from a case study applying the tool to test a small web application are presented. The results show that mutation analysis can help create tests that are effective at finding web application faults, as well as indicating several directions for improvement.",IEEE,,2010
1012,An experimental evaluation of web mutation operators,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8SujlDwAAAAJ&citation_for_view=8SujlDwAAAAJ:WF5omc3nYNoC,"While modern web development technologies enhance the capabilities of web applications, they introduce challenges for testers. This paper introduces, evaluates, and refines web mutation operators that target interaction faults in web applications. An experimental study is conducted on 11 subject web applications using 15 web mutation operators. The effectiveness of 12 independently developed test sets are analyzed in terms of how well they kill web mutants. Web mutation adequate tests are compared with independently created test sets to evaluate the web mutation operators. Tests designed to satisfy the web mutation testing criterion provide 100% coverage while the tests designed to satisfy traditional testing criteria provide, on average, 47%coverage. The paper also analyzes which mutants and mutation operators the traditional tests had difficulty killing. We found that some types of mutants that are not …",IEEE,,2016
1013,A logic mutation approach to selective mutation for programs and queries,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8SujlDwAAAAJ&citation_for_view=8SujlDwAAAAJ:2osOgNQ5qMEC,"Context Program mutation testing is a technique for measuring and generating high quality test data. However, traditional mutation operators are not necessarily efficient or effective. We address three specific issues. One, test data that kills all mutants generated by current mutation tools can still miss detection of some common logic faults because such tools lack appropriate logic mutation operators. Two, the number of mutants generated is often unnecessarily large. Three, many equivalent mutants can be generated and these can be difficult to eliminate. Objective This paper explores the idea of addressing these issues by selectively generating only specially engineered subsuming higher order logic mutants. However, such an approach is only useful if a test set that kills all such mutants also kills a high percentage of general mutants. Method An empirical study was conducted using a tool that generates only …",Elsevier,,2011
1014,Performance analysis of an asynchronous web server,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8SujlDwAAAAJ&citation_for_view=8SujlDwAAAAJ:9yKSN-GCB0IC,"Concurrency can be implemented in a Web server using synchronous and asynchronous mechanisms offered by the underlying operating system. Compared to the synchronous mechanisms, the asynchronous mechanisms are attractive because they provide the benefit of concurrency while alleviating much of the overhead and complexity of multithreading. The proactor pattern in middleware, which effectively encapsulates the asynchronous mechanisms supported by the operating system, can be used to implement a high performance Web server. In this paper, we present a queuing model of an asynchronous Web server implemented using the proactor pattern. We then describe a decomposition strategy to enable the application of the model in practical scenarios. We demonstrate the use of the model to guide configuration and provisioning decisions with several examples",IEEE,,2006
1015,Report from the 4th Int. Workshop on Education through Advanced Software Engineering and Artificial Intelligence (EASEAI'22),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8SujlDwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8SujlDwAAAAJ:kNdYIx-mwKoC,"The growth of digital technologies has drastically altered daily life. Both the general public and specialized groups must continuously acquire new knowledge and skills. The EASEAI workshop series addresses this issue by examining the fields of software engineering, education, and AI research to discover ways they can be integrated. This workshop gathers researchers, educators, and practitioners who apply advanced software engineering and AI in education, and allows for a cross-generational and interdisciplinary exchange of ideas among students, to examine current practices and establish new future goals. More details at https://easeai.github.io.",ACM,,2023
1016,EASEAI’22,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8SujlDwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8SujlDwAAAAJ:MXK_kJrjxJIC,"Welcome to the fourth edition of the International Workshop on Education through Advanced Software Engineering and Artificial Intelligence (EASEAI 2022) to be held virtually on November 18, 2022, as a post-conference workshop of ESEC/FSE 2022.",,,2022
1017,Welcome from the Chairs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8SujlDwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8SujlDwAAAAJ:3fE2CSJIrl8C,"Welcome from the Chairs - the Research Portal - University of Namur Skip to main navigation Skip to search Skip to main content the Research Portal - University of Namur Home the Research Portal - University of Namur Logo English Français Home Profiles Research units Projects Research output Student theses Equipment Datasets Prizes Activities Press/Media Search by expertise, name or affiliation Welcome from the Chairs Andreea Vescan, Camelia Serban, Julie Henry, Upsorn Praphamontripong Faculty of Computer Science Research output: Contribution in Book/Catalog/Report/Conference proceeding › Foreword/postscript Overview Original language English Title of host publication EASEAI 2022 Subtitle of host publication Proceedings of the 4th International Workshop on Education through Advanced Software Engineering and Artificial Intelligence Editors Andreea Vesan, Camelia Serban, Julie Henry, …",ACM Press,,2022
1018,Report from the 3rd Int. Workshop on Education through Advanced Software Engineering and Artificial Intelligence (EASEAI'21),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8SujlDwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8SujlDwAAAAJ:8k81kl-MbHgC,"With the development and widespread of digital technologies, ev- eryday life has been profoundly transformed. The general public, as well as specialized audiences, have to face an ever-increasing amount of knowledge and learn new abilities. The EASEAI work- shop series addresses that challenge by looking at software en- gineering, education, and arti cial intelligence research elds to explore how they can be combined. Speci cally, this workshop brings together researchers, teachers, and practitioners who use advanced software engineering tools and arti cial intelligence tech- niques in the education eld and through a transgenerational and transdisciplinary range of students to discuss the current state of the art and practices, and establish new future directions. More information at https://easeai.github.io.",ACM,,2022
1019,Analysis of the transition to a virtual learning semester in a college software testing course,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8SujlDwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8SujlDwAAAAJ:5nxA0vEk-isC,"This report presents observations from two semesters of the same course, Software Testing, within the same department, in different school years. The first semester, Fall 2019, was the last semester completely in-person before the COVID-19 pandemic made it so that our courses changed to a virtual setting. The second semester, Spring 2021, is the most recent virtual semester at the time that this report is being written (in May of 2021). Though the course was modified to some extent for the purpose of it being online, we had a goal for it to remain largely the same. In both versions of the course, there was a heavy emphasis on interactive exercises as a means to increase engagement and performance within the class and in regards to software testing as a whole. The virtual semester gave us an opportunity to try out a variety of new avenues of learning and an exercise in trying to keep consistency from an in-person …",,,2021
1020,Current progress and future challenges in rare-earth-free permanent magnets,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3VDU0iAAAAAJ&citation_for_view=3VDU0iAAAAAJ:kz9GbA2Ns4gC,"Permanent magnets (PM) are critical components for electric motors and power generators. Key properties of permanent magnets, especially coercivity and remanent magnetization, are strongly dependent on microstructure. Understanding metallurgical processing, phase stability and microstructural changes are essential for designing and improving permanent magnets. The widely used PM for the traction motor in electric vehicles and for the power generator in wind turbines contain rare earth elements Nd and Dy due to their high maximum energy product. Dy is used to sustain NdFeB's coercivity at higher temperature. Due to the high supply risk of rare earth elements (REE) such as Dy and Nd, these elements are listed as critical materials by the U.S. Department of Energy and other international institutes. Other than Dy, finer grain size is also found to have effect on sustaining coercivity at higher temperature. A …",Pergamon,Acta Materialia,2018
1021,Pt nanoclusters confined within metal–organic framework cavities for chemoselective cinnamaldehyde hydrogenation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3VDU0iAAAAAJ&citation_for_view=3VDU0iAAAAAJ:2P1L_qKh6hAC,"A highly selective and robust catalyst based on Pt nanoclusters (NCs) confined inside the cavities of an amino-functionalized Zr-terephthalate metal–organic framework (MOF), UiO-66-NH2 was developed. The Pt NCs are monodisperse and confined in the cavities of UiO-66-NH2 even at 10.7 wt % Pt loading. This confinement was further confirmed by comparing the catalytic performance of Pt NCs confined inside and supported on the external surface of the MOF in the hydrogenation of ethylene, 1-hexene, and 1,3-cyclooctadiene. The benefit of confining Pt NCs inside UiO-66-NH2 was also demonstrated by evaluating their performance in the chemoselective hydrogenation of cinnamaldehyde. We found that both high selectivity to cinnamyl alcohol and high conversion of cinnamaldehyde can be achieved using the MOF-confined Pt nanocluster catalyst, while we could not achieve high cinnamyl alcohol selectivity …",American Chemical Society,,2014
1022,Fatigue-resistant high-performance elastocaloric materials made by additive manufacturing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3VDU0iAAAAAJ&citation_for_view=3VDU0iAAAAAJ:Ri6SYOTghG4C,"Elastocaloric cooling, a solid-state cooling technology, exploits the latent heat released and absorbed by stress-induced phase transformations. Hysteresis associated with transformation, however, is detrimental to efficient energy conversion and functional durability. We have created thermodynamically efficient, low-hysteresis elastocaloric cooling materials by means of additive manufacturing of nickel-titanium. The use of a localized molten environment and near-eutectic mixing of elemental powders has led to the formation of nanocomposite microstructures composed of a nickel-rich intermetallic compound interspersed among a binary alloy matrix. The microstructure allowed extremely small hysteresis in quasi-linear stress-strain behaviors—enhancing the materials efficiency by a factor of four to seven—and repeatable elastocaloric performance over 1 million cycles. Implementing additive manufacturing to …",American Association for the Advancement of Science,,2019
1023,Cerium: An Unlikely Replacement of Dysprosium in High Performance Nd-Fe-B Permanent Magnets,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3VDU0iAAAAAJ&citation_for_view=3VDU0iAAAAAJ:zA6iFVUQeVQC,,,,2015
1024,Reactive metal–support interactions at moderate temperature in two-dimensional niobium-carbide-supported platinum catalysts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3VDU0iAAAAAJ&citation_for_view=3VDU0iAAAAAJ:SpbeaW3--B0C,"The reactive metal–support interaction (RMSI) offers electronic, geometric and compositional effects that can be used to tune catalytic active sites. Generally, supports other than oxides are disregarded as candidates for RMSI. Here, we report an example of non-oxide-based RMSI between platinum and Nb2CTx MXene—a recently developed, two-dimensional metal carbide. The surface functional groups of the two-dimensional carbide can be reduced, and a Pt–Nb surface alloy is formed at a moderate temperature (350 °C). Such an alloy exhibits weaker CO adsorption than monometallic platinum. Water-gas shift reaction kinetics reveals that the RMSI stabilizes the nanoparticles and creates alloy–MXene interfaces with higher H2O activation ability compared with a non-reducible support or a bulk niobium carbide. This RMSI between platinum and the niobium MXene support can be extended to other members of …",Nature Publishing Group,,2018
1025,Terahertz near-field imaging of sidewall-induced losses in superconducting qubits,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3VDU0iAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=3VDU0iAAAAAJ:uDGL6kOW6j0C,"Correlating superconducting qubit performance with advanced materials analysis is a key strategy for improving coherence. Existing diagnostics for key properties, such as dielectric loss, structural discontinuity, and interface heterogeneity, often rely on destructive electron microscopy or low-throughput millikelvin measurements. Here, we demonstrate noninvasive terahertz (THz) nano-imaging/spectroscopy of encapsulated niobium transmon qubits as a high-throughput proxy for performance evaluation. We identify large variations in sidewall near-field signals, implicating sidewall loss and discontinuity as major coherence limiters, and also use THz hyperspectral line scans to probe dielectric responses and field participation at Al junction interfaces.",AIP Publishing,,2025
1026,Decoupling size and surface effects of intermetallic CuPd nanocrystals for electrocatalytic nitrate reduction to ammonia,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3VDU0iAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=3VDU0iAAAAAJ:4xDN1ZYqzskC,"Nitrate pollution poses a major environmental challenge, but its electrochemical conversion to ammonia offers a sustainable waste-to-value solution. Here, we synthesized monodisperse, size-tunable B2-phase CuPd intermetallic nanocrystals (6–46 nm) and studied their performance in the electrochemical nitrate reduction reaction (eNO3RR). By using bromide ions to modulate Pd reduction and applying mild annealing, we achieved phase-pure B2 structures across all sizes. Catalytic testing revealed a volcano-like trend in ammonia yield, peaking at 33 nm nanocubes with a rate of 6.97 mol h−1 g−1 at −0.6 V vs. reversible hydrogen electrode (RHE). This optimum reflects a balance between the increased surface area of smaller particles and the enhanced exposure of active (100) facets in larger ones. Theoretical calculations indicated that the B2-CuPd (100) facet is favorable for nitrate adsorption, thereby …",Elsevier,,2025
1027,Optimizing Superconducting Qubits: Insights into Oxides Microstructures,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3VDU0iAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=3VDU0iAAAAAJ:wMgC3FpKEyYC,"Improving qubit lifetime is essential for fault-tolerant quantum computing. It is widely acknowledged that intricate processing techniques introduce defects at the interfaces and surfaces of superconducting quantum circuits, which can create sources of decoherence. Therefore, a precise understanding of how a material’s structure contributes to decoherence is critical for enhancing the performance of superconducting qubits. This talk highlights our recent advancements in understanding surface oxides in resonators and ultrathin aluminum oxide barriers in Josephson junctions (JJs) using transmission electron microscopy and spectroscopy techniques [1-4]. The Superconducting Quantum Materials & Systems Center (SQMS) demonstrated that encapsulating niobium surfaces with a∼ 10nm tantalum layer results in 2-5x longer T1 than bare niobium [2]. Our collaborative investigation shows that this improvement is …",Oxford University Press,,2025
1028,Topological Defect Mediated Helical Phase Reorientation by Uniaxial Stress,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3VDU0iAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=3VDU0iAAAAAJ:NyGDZy8z5eUC,"Strain engineering enables precise, energy-efficient control of nanoscale magnetism. However, unlike well-studied strain-dislocation interactions in mechanical deformation, the spatial evolution of strain-induced spin rearrangement remains poorly understood. Using in situ Lorentz transmission electron microscopy, we manipulate and observe helical domain reorientation under quantitatively applied uniaxial tensile stress. Our findings reveal striking similarity to plastic deformation in metals, where the critical stress for propagation vector (Q) reorientation depends on its angle with the stress direction. Magnetic defects mediate reorientation via “break-and-reconnect” or “dislocation gliding–annihilation” processes. Simulations confirm that strain-induced anisotropic Dzyaloshinskii-Moriya interaction may play a key role. These insights advance strain-driven magnetism and offer a promising route for energy-efficient …",American Physical Society,,2025
1029,Reactivity of the gold/water interface during selective oxidation catalysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HbM22NQAAAAJ&citation_for_view=HbM22NQAAAAJ:f2IySw72cVMC,The selective oxidation of alcohols in aqueous phase over supported metal catalysts is facilitated by high-pH conditions. We have studied the mechanism of ethanol and glycerol oxidation to acids over various supported gold and platinum catalysts. Labeling experiments with 18O2 and H218O demonstrate that oxygen atoms originating from hydroxide ions instead of molecular oxygen are incorporated into the alcohol during the oxidation reaction. Density functional theory calculations suggest that the reaction path involves both solution-mediated and metal-catalyzed elementary steps. Molecular oxygen is proposed to participate in the catalytic cycle not by dissociation to atomic oxygen but by regenerating hydroxide ions formed via the catalytic decomposition of a peroxide intermediate.,American Association for the Advancement of Science,,2010
1030,Fundamentals of chemical reaction engineering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HbM22NQAAAAJ&citation_for_view=HbM22NQAAAAJ:q3CdL3IzO_QC,"Appropriate for a one-semester undergraduate or first-year graduate course, this text introduces the quantitative treatment of chemical reaction engineering. It covers both homogeneous and heterogeneous reacting systems and examines chemical reaction engineering as well as chemical reactor engineering. Each chapter contains numerous worked-out problems and real-world vignettes involving commercial applications, a feature widely praised by reviewers and teachers. 2003 edition.",Courier Corporation,,2013
1031,Selective oxidation of alcohols and aldehydes over supported metal nanoparticles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HbM22NQAAAAJ&citation_for_view=HbM22NQAAAAJ:0EnyYjriUFMC,"Oxidation is a key reaction in organic synthesis and will likely play a significant role in the development of value-added chemicals from biomass. The application of heterogeneous catalysis and molecular oxygen to oxidation reactions offers a green alternative to traditional, toxic chemical oxidants. However, making comparisons of catalyst performance (reaction rate, product selectivity) between reports in the literature is difficult because of inconsistencies in the ways results are reported. Herein, we examine the literature on supported metal catalysts for the oxidation of molecules of interest in biomass conversion (primary alcohols, polyols, 5-hydroxymethylfurfural, and various sugars). Reaction rates are calculated and compared in a consistent manner and recommendations for avoiding common pitfalls in kinetic investigations are made.",Royal Society of Chemistry,Green Chemistry,2013
1032,Hydrogenolysis of glycerol over carbon-supported Ru and Pt catalysts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HbM22NQAAAAJ&citation_for_view=HbM22NQAAAAJ:qUcmZB5y_30C,"Commercial carbon-supported Ru and Pt catalysts were evaluated in the batchwise hydrogenolysis of glycerol in aqueous solution at 473 K and 40 bar H2, with and without added base. At neutral pH, Ru was more active than Pt at converting glycerol to glycols. However, Ru favored the production of ethylene glycol over propylene glycol and also catalyzed methane formation. Although less active, Pt catalyzed propylene glycol formation with high selectivity. Addition of base enhanced the reactivity of Pt to a greater extent than Ru, but lactate formation was significant at high pH in the presence of either Pt or Ru. The cleavage of CC bonds leading to the formation of ethylene glycol from glycerol is proposed to occur primarily through a metal-catalyzed reaction on Ru, whereas this cleavage is thought to occur through a base-catalyzed reaction in the presence of Pt. An overall reaction network for glycerol …",Academic Press,,2007
1033,Selective hydrogenolysis of polyols and cyclic ethers over bifunctional surface sites on rhodium–rhenium catalysts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HbM22NQAAAAJ&citation_for_view=HbM22NQAAAAJ:D_sINldO8mEC,"A ReOx-promoted Rh/C catalyst is shown to be selective in the hydrogenolysis of secondary C–O bonds for a broad range of cyclic ethers and polyols, these being important classes of compounds in biomass-derived feedstocks. Experimentally observed reactivity trends, NH3 temperature-programmed desorption (TPD) profiles, and results from theoretical calculations based on density functional theory (DFT) are consistent with the hypothesis of a bifunctional catalyst that facilitates selective hydrogenolysis of C–O bonds by acid-catalyzed ring-opening and dehydration reactions coupled with metal-catalyzed hydrogenation. The presence of surface acid sites on 4 wt % Rh–ReOx/C (1:0.5) was confirmed by NH3 TPD, and the estimated acid site density and standard enthalpy of NH3 adsorption were 40 μmol g–1 and −100 kJ mol–1, respectively. Results from DFT calculations suggest that hydroxyl groups on rhenium …",American Chemical Society,,2011
1034,Catalytic Methanation of CO2 over Ni Nanoparticles for Production of Renewable Natural Gas from Biogas,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HbM22NQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=HbM22NQAAAAJ:U4n9YNQMCAIC,,AIChE,,2025
1035,Advanced Biogas Methanation Catalysts for Generating Renewable Natural Gas,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HbM22NQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=HbM22NQAAAAJ:BzfGm06jWhQC,,AIChE,,2025
1036,Utilizing Site-Dependent NO Reduction to Probe Step Sites on Supported Pt Nanoparticles: A Combined Theoretical and Experimental Study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HbM22NQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=HbM22NQAAAAJ:43bX7VzcjpAC,,AIChE,,2025
1037,Combined Experimental and Theoretical Analysis for the Low-Temperature Formation of Nitrous Oxide on Pt/Al2O3,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HbM22NQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=HbM22NQAAAAJ:buQ7SEKw-1sC,,AIChE,,2024
1038,Revisiting the influence of Ni particle size on the hydrogenation of CO2 to CH4 over Ni/CeO2,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HbM22NQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=HbM22NQAAAAJ:QD3KBmkZPeQC,"Nickel nanoparticles were supported on CeO2 and evaluated in the hydrogenation of CO2 to CH4 at 538 K and 1 atm. Chemisorption of H2 was used to estimate the average Ni particle size, which ranged from 1.3 to 17 nm. The apparent activation energy for CH4 formation and turnover frequency for CO2 conversion was independent of Ni particle size. The smallest Ni particles (1.3 nm) were less selective to CH4. Comparisons to alumina-supported Ni reveal the same performance as Ni/CeO2 when normalized to active Ni atoms counted by H2 chemisorption. A beneficial effect of ceria relative to alumina is the enhanced reducibility of Ni as evaluated by H2 temperature-programmed reduction. The constancy of the turnover frequency on Ni particles suggests the acid-base and/or redox properties of the support do not play a significant role in the CO2 methanation reaction under the conditions of study, which …",Academic Press,,2024
1039,In search of integration: Mapping conceptual efforts to apply STS to engineering education,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2rtYKcMAAAAJ&citation_for_view=2rtYKcMAAAAJ:Tyk-4Ss8FVUC,"As David Edge points out in his introduction to the Handbook of Science and Technology Studies (Sage, 1995), the field of Science, Technology, and Society (STS) is a diverse enterprise that developed in response to a heterogeneous set of desires ranging from a more rational basis for science policy to the democratization of science and the reform of engineering and science education. In this paper, we focus on STS as it can be applied in the practice of engineering to foster both socially responsible and commercially successful innovation. In an academic context, applying STS to engineering practice frequently takes the form of integrating a sociotechnical systems perspective into educational enterprises such as the major design experience mandated by ABET. Leaving aside the practical challenges of such integration, we focus here on what we learn about STS when we teach it to upper-level engineering students and expect them to use STS frameworks and approaches to inform the design and research that they undertake as part of their engineering education. We draw on two sources of evidence from which such lessons can be extrapolated:(1) the discourse of ASEE as captured in the PEER document repository and (2) our experience in mentoring hundreds of students in all engineering disciplines through the process of using STS perspectives and research to inform their major design experience. Quantitative analysis of papers suggests that STS entered the discourse of ASEE in the period from 2004-2007, with another burst of activity in 2010-2011 (2011 being the year that “Engineering and Society” was added to “Liberal Education …",,,2019
1040,Teaching STS to engineers: A comparative study of embedded STS programs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2rtYKcMAAAAJ&citation_for_view=2rtYKcMAAAAJ:d1gkVwhDpl0C,"The field of Science, Technology, and Society (STS) draws from a full range of disciplines in the social sciences and humanities to examine how science and technology simultaneously shape and are shaped by society, including politics and culture. Although engineering educators and employers have recognized the importance of professional (nontechnical) skills for over 100 years, the instructional strategies and institutional arrangements necessary to help students develop these skills have not yet settled into a widely adopted standard. Many engineering programs have turned to STS to provide students with conceptual tool kits to think about engineering problems and solutions in more sophisticated ways. Some programs feature standalone courses on the sociocultural aspects of technology and engineering, often taught by faculty from outside the engineering school. Others incorporate STS material into traditional engineering courses, eg, by making ethical or societal impact assessments part of capstone projects. This work in progress paper draws on the research team’s personal experience to examine the character of an atypical, but potentially very powerful, model: STS programs embedded in engineering schools in the United States and Canada. The authors expand on previous scholarship by Kathryn Neeley, Caitlin Wylie, and Bryn Seabrook in “In Search of Integration: Mapping Conceptual Efforts to Apply STS to Engineering Education,” as presented at the 2019 ASEE annual conference, to examine how STS is incorporated in engineering education. While Neeley, Wylie, and Seabrook focused on broad trends within a single, large …",,,2020
1041,Using generative ai as an active learning tool to refine professional engineering skills,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2rtYKcMAAAAJ&citation_for_view=2rtYKcMAAAAJ:u5HHmVD_uO8C,"Nontechnical engineering skills are integral to the successful practice of the engineering profession. However, the dominant image of engineering rarely evokes ideas of typing pages of prose. A field that has been adopted into the engineering curriculum to help engage engineering students in higher education is Science, Technology, and Society (STS). As an interdisciplinary field, STS offers an active-learning environment to refine nontechnical engineering skills like problem-solving and communication. One recent question amongst STS scholars for engineers is: what role will generative AI play in the learning process for written communication? Perhaps one question that has not received as much attention is how this kind of AI could be beneficial in university-level nontechnical engineering classrooms. The purpose of this study is to underscore the importance of nontechnical engineering skills that are learned through the lens of Science, Technology, and Society (STS). The author builds on previous scholarship to demonstrate how discussion-based courses challenge undergraduate engineering students to think more critically about the integration of the social dimensions of engineering problems into the engineering design process. Active learning modules like “Tinkering with ChatGPT” demonstrate the implications and applications of AI inside and outside the classroom.",,,2024
1042,Applying STS to Engineering Education: A Comparative Study of STS Minors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2rtYKcMAAAAJ&citation_for_view=2rtYKcMAAAAJ:u-x6o8ySG0sC,"In recent years, the field of Science and Technology Studies (STS) has seen tremendous growth in universities across the United States. The majority of this growth is through the introduction of STS departments and programs into liberal arts divisions. However, a subset of these new STS programs are being integrated in engineering and other STEM-focused institutions, frequently in the form of STS minors. The purpose of this study is to expand on previous work by Neeley, Wiley, and Seabrook (2019), who in “In Search of Integration: Mapping Conceptual Efforts to Apply STS to Engineering Education,” argue that the perspectives and analytical frameworks STS offers are essential for helping engineering students critically understand the process of developing, executing, and implementing a successful major design experience, and for understanding the impact of technological innovation in a holistic sense. An STS minor has the additional advantage of providing students with a recognized credential in this skill set. Thus, in this paper, we ask further: how are STS minors being designed to provide this critical education as well as attract student attention and fulfill the mission of the school? This working paper considers the design, purpose, and execution of the STS minor in an engineering or other STEM-focused institution. The authors analyze materials such as enrollment numbers, course requirements, program descriptions, marketing materials, and integration with the school’s general curricula to identify patterns across STS minors in STEM schools. We are particularly interested in the skill sets that these minors offer engineering students …",,,2023
1043,AI Unleashed: Navigating Ethical Integration of Generative Tools in an Undergraduate Classroom,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2rtYKcMAAAAJ&citation_for_view=2rtYKcMAAAAJ:UeHWp8X0CEIC,"As generative AI tools increasingly permeate educational settings, the need for a critical examination of their integration in undergraduate classrooms becomes paramount. This paper establishes a general understanding of AI technologies and their implications for teaching and learning. Faculty are asked to explore the ethical considerations inherent in employing these technologies, challenging the notion of their inevitability. While AI presents transformative opportunities for enhancing learning, it also raises significant ethical dilemmas regarding equity, privacy, and academic integrity. Educators share the responsibility to teach about how innovations should reduce the risk of bias, including AI. At the same time, faculty often lack resources to develop skills for effectively discussing AI ethics with students, colleagues, and other communities. There is no nationwide consensus on how these tools should be used in higher education. Scholars like Ethan Mollick, José Antonio Bowen, and C. Edward Watson have published extensively on establishing a general understanding of AI tools, including preliminary guides for exercises that can be translated in classroom practices. While these works are informative and timely, they also rely on the assumption that AI adoption is inevitable. This paper aims to move beyond these preliminary discussions in order to introduce faculty to a new narrative about the inevitability of AI. Specifically, this paper aims to empower educators to become informed advocates for ethical AI practices, ultimately shaping a classroom environment that balances innovation with integrity. By rethinking the role of AI in higher education …",,,2025
1044,Choreographing Virtue: The Role of Situatedness and Layering in Building Moral Muscle Memory in Engineering Ethics Education,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2rtYKcMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2rtYKcMAAAAJ:IjCSPb-OGe4C,"This paper explores the contribution that a situated and competency-layering pedagogy can offer to enhance the effectiveness of Giving Voice to Values (GVV), a growing model for teaching ethical leadership in engineering, business, law, and other professional fields. The uptake of GVV as a framework for ethical leadership practice and education has had a growing influence in business school curricula, and more recently, in engineering ethics education. GVV is an innovative model that bridges ethical decision-making and ethical action by preparing learners to develop scripts and action plans for acting consistently with their values in ethically challenging scenarios. The approach moves away from discussing what the right action would be according to different ethical normative frameworks, and instead starts from the premise that most people are able to recognize the right course of action that is consistent with their values, and want to pursue it; however, they have difficulties acting accordingly. Central to this learning model is the application of a thought experiment framed as:“Assuming I know what I want to do to act on my values, how can I get it done?” The capacity to bridge the space between decision and action is strengthened by reflection about past experiences and each person’s specific style and personality.[Department Name] at [University Name] is currently applying the GVV model in its undergraduate engineering ethics courses. The developer of the GVV framework has stated that the model’s use of the notion of “moral muscle memory” draws in part from the pedagogical approach to layering the physical, emotional, and cognitive …",,,2024
1045,Incorporating Giving Voice to Values (GVV) into an Engineering Ethics Course,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2rtYKcMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2rtYKcMAAAAJ:zYLM7Y9cAGgC,"The Department of Engineering and Society instructors at the University of Virginia recently developed a new course on Engineering Ethics aimed at second-and third-year students. Unlike previous courses in the department, the mid-level course emphasizes micro-ethics and employs the Giving Voice to Values (GVV) framework. The emphasis on micro-ethics is timely and appropriate given the polarization and plurality of views and beliefs in our nation and world and the increasingly higher stakes of engineering practice. To help students understand how they can act on their personal ethics, the course also incorporates the GVV material, originally developed for application in business settings. The GVV modules in this course were adapted specifically for use in engineering education, in collaboration with the GVV founder and the Online Ethics Center (OEC) director and are now available through the OEC for anyone to use. This paper provides an overview of the GVV portion of the new course design and discusses initial impressions from piloting the course over three semesters.",,,2023
1046,Perspective on the future of silicon photonics and electronics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=0h-RyocAAAAJ&citation_for_view=0h-RyocAAAAJ:olpn-zPbct0C,,AIP Publishing LLC,,2021
1047,Photonic chip-based low-noise microwave oscillator,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=0h-RyocAAAAJ&citation_for_view=0h-RyocAAAAJ:LjlpjdlvIbIC,"Numerous modern technologies are reliant on the low-phase noise and exquisite timing stability of microwave signals. Substantial progress has been made in the field of microwave photonics, whereby low-noise microwave signals are generated by the down-conversion of ultrastable optical references using a frequency comb, –. Such systems, however, are constructed with bulk or fibre optics and are difficult to further reduce in size and power consumption. In this work we address this challenge by leveraging advances in integrated photonics to demonstrate low-noise microwave generation via two-point optical frequency division,. Narrow-linewidth self-injection-locked integrated lasers, are stabilized to a miniature Fabry–Pérot cavity, and the frequency gap between the lasers is divided with an efficient dark soliton frequency comb. The stabilized output of the microcomb is photodetected to produce a microwave …",Nature Publishing Group UK,,2024
1048,Integrated self-healing for mm-wave power amplifiers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=0h-RyocAAAAJ&citation_for_view=0h-RyocAAAAJ:u-x6o8ySG0sC,"Self-healing as a technique for improving performance and yield of millimeter-wave power amplifiers (PAs) against process variation and transistor mismatch, load impedance mismatch, and partial and total transistor failure is described and investigated. A 28-GHz PA is presented with three types of sensors, two types of actuators, data converters, and a digital algorithm block that are all integrated on a single chip to show the validity of the technique. Two algorithms are implemented to either maximize output power or to minimize dc power for a desired output power. Measurements from 20 chips show increased RF output power up to 3 dB or reduced dc power by 50% in backoff with a 50- load. Self-healing with up to 4-1 voltage standing-wave ratio load impedance mismatch is verified and linear operation under nonconstant envelope modulation is shown to improve with healing. Self-healing after laser cutter …",IEEE,,2013
1049,Interference Robust Detector-First Near-Zero Power Wake-Up Receiver,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=0h-RyocAAAAJ&citation_for_view=0h-RyocAAAAJ:vRqMK49ujn8C,"This paper presents the development of a wake-up receiver (WuRX) at nanowatt power levels for event-driven applications. This paper improves the state of the art, obtaining higher sensitivity than previous work in the 151.8- and 433-bands, low-power operation, and robustness to interference due to an integrated offset compensation algorithm operating without any external calibration. Simultaneous low-power operation and high sensitivity are achieved through a passive detector design based upon a terminal impedance boundary condition-based optimization of the detector dictated by the terminal impedances of the detector. This paper is implemented in a 130-nm CMOS process and obtains -76 dBm at the 151.8-MHz multi-use radio service (MURS) band and -71 dBm at the 433-MHz Industrial, Scientific and Medical (ISM) band with a total dc power draw of just 7.6 nW from 1.0- and 0.6-V supplies.",IEEE,,2019
1050,Low power receiver and related circuits,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=0h-RyocAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=0h-RyocAAAAJ:-_dYPAW6P2MC,"BACKGROUND Radio frequency (RF) wakeup receivers are used in a wide variety of applications to trigger operation of associated circuits and devices. Such applications include, for example, wireless sensor networks in which sensor nodes are normally powered down or in low power states to preserve power. Such circuits and devices are powered up in response to detection of an RF wakeup signal or code by the wakeup receiver. Because at least a portion of a wakeup receiver must always or frequently be on to “listen” for wakeup signals, it is important that the receiver consume very little power while having an appropriate level of sensitivity for detection of the wakeup signal. This is particularly true for sensor networks embedded in remote or inaccessible areas and for which the power level of the wakeup signal may be very low. Near-zero-power wakeup receivers can significantly increase the operational …",,,2025
1051,A Sub-μW Digital Temperature Compensation Architecture for Arbitrary Voltage and Current Reference Generation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=0h-RyocAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=0h-RyocAAAAJ:VLnqNzywnoUC,"Traditionally, both reference circuits and the components they supply are designed independently to be as immune to temperature change as practical, but this requires power and area overhead to achieve. These overheads can compound in complex systems or consume excessive portions of a low power budget. In contrast, we propose a sub-μwatt digital temperature compensation architecture that generates voltage and current references with a user-defined temperature response rather than a fixed, near-ideal response. This flexible approach allows a single programmable design to be reused easily to produce different profiles over temperature, reducing design time. It also can reduce the temperature non-linearity in the components it supports by providing an input temperature profile that effectively cancels that non-linear response to allow components to operate at their target spec and eliminate excess …",IEEE,,2025
1052,Additive Phase-Noise Reduction in Microwave Regenerative Dividers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=0h-RyocAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=0h-RyocAAAAJ:fEOibwPWpKIC,"A detailed investigation of a method to effectively reduce additive phase noise in regenerative frequency dividers is presented. The approach enhances the sensitivity of conventional regenerative dividers and addresses start-up challenges while preserving low-additive phase noise and low power consumption. As a proof of concept, an integrated low-additive phase-noise regenerative divider with an octave-spanning frequency range was designed and fabricated using a 250-nm InP heterojunction bipolar transistor (HBT) process. The impact of the classes of operation for both the amplifier and the buffer, along with the effect of the phase shifter, on the divider’s overall phase-noise performance was analyzed and measured. The regenerative divider achieved additive phase noise below −163 dBc/Hz from a 7-GHz carrier at 10-kHz offset with more than 12-dB fundamental rejection and greater than −10-dBm output …",IEEE,,2025
1053,Feature Selection: A Data Perspective,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uY6ek7sAAAAJ&citation_for_view=uY6ek7sAAAAJ:xGWFX6Gbr9MC,"Feature selection, as a data preprocessing strategy, has been proven to be effective and efficient in preparing data (especially high-dimensional data) for various data-mining and machine-learning problems. The objectives of feature selection include building simpler and more comprehensible models, improving data-mining performance, and preparing clean, understandable data. The recent proliferation of big data has presented some substantial challenges and opportunities to feature selection. In this survey, we provide a comprehensive and structured overview of recent advances in feature selection research. Motivated by current challenges and opportunities in the era of big data, we revisit feature selection research from a data perspective and review representative feature selection algorithms for conventional data, structured data, heterogeneous data and streaming data. Methodologically, to emphasize the …",ACM,,2018
1054,Deep Anomaly Detection on Attributed Networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uY6ek7sAAAAJ&citation_for_view=uY6ek7sAAAAJ:RXiHnyRawswC,"Attributed networks are ubiquitous and form a critical component of modern information infrastructure, where additional node attributes complement the raw network structure in knowledge discovery. Recently, detecting anomalous nodes on attributed networks has attracted an increasing amount of research attention, with broad applications in various high-impact domains, such as cybersecurity, finance, and healthcare. Most of the existing attempts, however, tackle the problem with shallow learning mechanisms by ego-network or community analysis, or through subspace selection. Undoubtedly, these models cannot fully address the computational challenges on attributed networks. For example, they often suffer from the network sparsity and data nonlinearity issues, and fail to capture the complex interactions between different information modalities, thus negatively impact the performance of anomaly detection …",,,2019
1055,Self-Supervised Multi-Channel Hypergraph Convolutional Network for Social Recommendation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uY6ek7sAAAAJ&citation_for_view=uY6ek7sAAAAJ:c1AJUTjuCtUC,"Social relations are often used to improve recommendation quality when user-item interaction data is sparse in recommender systems. Most existing social recommendation models exploit pairwise relations to mine potential user preferences. However, real-life interactions among users are very complex and user relations can be high-order. Hypergraph provides a natural way to model high-order relations, while its potentials for improving social recommendation are under-explored. In this paper, we fill this gap and propose a multi-channel hypergraph convolutional network to enhance social recommendation by leveraging high-order user relations. Technically, each channel in the network encodes a hypergraph that depicts a common high-order user relation pattern via hypergraph convolution. By aggregating the embeddings learned through multiple channels, we obtain comprehensive user representations to …",,,2021
1056,A Survey of Learning Causality with Data: Problems and Methods,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uY6ek7sAAAAJ&citation_for_view=uY6ek7sAAAAJ:E7VqQtBCVmcC,"This work considers the question of how convenient access to copious data impacts our ability to learn causal effects and relations. In what ways is learning causality in the era of big data different from—or the same as—the traditional one? To answer this question, this survey provides a comprehensive and structured review of both traditional and frontier methods in learning causality and relations along with the connections between causality and machine learning. This work points out on a case-by-case basis how big data facilitates, complicates, or motivates each approach.",,,2020
1057,Label Informed Attributed Network Embedding,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uY6ek7sAAAAJ&citation_for_view=uY6ek7sAAAAJ:rOcdG6UcVlcC,"Attributed network embedding aims to seek low-dimensional vector representations for nodes in a network, such that original network topological structure and node attribute proximity can be preserved in the vectors. These learned representations have been demonstrated to be helpful in many learning tasks such as network clustering and link prediction. While existing algorithms follow an unsupervised manner, nodes in many real-world attributed networks are often associated with abundant label information, which is potentially valuable in seeking more effective joint vector representations. In this paper, we investigate how labels can be modeled and incorporated to improve attributed network embedding. This is a challenging task since label information could be noisy and incomplete. In addition, labels are completely distinct with the geometrical structure and node attributes. The bewildering combination of …",ACM,,2017
1058,Graph Foundation Models: A Comprehensive Survey,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uY6ek7sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=uY6ek7sAAAAJ:TiIbgCYny7sC,"Graph-structured data pervades domains such as social networks, biological systems, knowledge graphs, and recommender systems. While foundation models have transformed natural language processing, vision, and multimodal learning through large-scale pretraining and generalization, extending these capabilities to graphs -- characterized by non-Euclidean structures and complex relational semantics -- poses unique challenges and opens new opportunities. To this end, Graph Foundation Models (GFMs) aim to bring scalable, general-purpose intelligence to structured data, enabling broad transfer across graph-centric tasks and domains. This survey provides a comprehensive overview of GFMs, unifying diverse efforts under a modular framework comprising three key components: backbone architectures, pretraining strategies, and adaptation mechanisms. We categorize GFMs by their generalization scope -- universal, task-specific, and domain-specific -- and review representative methods, key innovations, and theoretical insights within each category. Beyond methodology, we examine theoretical foundations including transferability and emergent capabilities, and highlight key challenges such as structural alignment, heterogeneity, scalability, and evaluation. Positioned at the intersection of graph learning and general-purpose AI, GFMs are poised to become foundational infrastructure for open-ended reasoning over structured data. This survey consolidates current progress and outlines future directions to guide research in this rapidly evolving field. Resources are available at https://github.com/Zehong-Wang/Awesome-Foundation …",,arXiv preprint arXiv:2505.15116,2025
1059,FedHERO: A Federated Learning Approach for Node Classification Task on Heterophilic Graphs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uY6ek7sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=uY6ek7sAAAAJ:j7XjBeKFbTsC,"Federated Graph Learning (FGL) empowers clients to collaboratively train Graph neural networks (GNNs) in a distributed manner while preserving data privacy. However, FGL methods usually require that the graph data owned by all clients is homophilic to ensure similar neighbor distribution patterns of nodes. Such an assumption ensures that the learned knowledge is consistent across the local models from all clients. Therefore, these local models can be properly aggregated as a global model without undermining the overall performance. Nevertheless, when the neighbor distribution patterns of nodes vary across different clients (e.g., when clients hold graphs with different levels of heterophily), their local models may gain different and even conflict knowledge from their node-level predictive tasks. Consequently, aggregating these local models usually leads to catastrophic performance deterioration on the global model. To address this challenge, we propose FedHERO, an FGL framework designed to harness and share insights from heterophilic graphs effectively. At the heart of FedHERO is a dual-channel GNN equipped with a structure learner, engineered to discern the structural knowledge encoded in the local graphs. With this specialized component, FedHERO enables the local model for each client to identify and learn patterns that are universally applicable across graphs with different patterns of node neighbor distributions. FedHERO not only enhances the performance of individual client models by leveraging both local and shared structural insights but also sets a new precedent in this field to effectively handle graph data with various …",,,2025
1060,Are We Merely Justifying Results ex Post Facto? Quantifying Explanatory Inversion in Post-Hoc Model Explanations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uY6ek7sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=uY6ek7sAAAAJ:j2GSQqY3pL0C,"Post-hoc explanation methods provide interpretation by attributing predictions to input features. Natural explanations are expected to interpret how the inputs lead to the predictions. Thus, a fundamental question arises: Do these explanations unintentionally reverse the natural relationship between inputs and outputs? Specifically, are the explanations rationalizing predictions from the output rather than reflecting the true decision process? To investigate such explanatory inversion, we propose Inversion Quantification (IQ), a framework that quantifies the degree to which explanations rely on outputs and deviate from faithful input-output relationships. Using the framework, we demonstrate on synthetic datasets that widely used methods such as LIME and SHAP are prone to such inversion, particularly in the presence of spurious correlations, across tabular, image, and text domains. Finally, we propose Reproduce-by-Poking (RBP), a simple and model-agnostic enhancement to post-hoc explanation methods that integrates forward perturbation checks. We further show that under the IQ framework, RBP theoretically guarantees the mitigation of explanatory inversion. Empirically, for example, on the synthesized data, RBP can reduce the inversion by 1.8% on average across iconic post-hoc explanation approaches and domains.",,,2025
1061,A Survey of Scaling in Large Language Model Reasoning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uY6ek7sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=uY6ek7sAAAAJ:-38epGy1wY0C,"The rapid advancements in large Language models (LLMs) have significantly enhanced their reasoning capabilities, driven by various strategies such as multi-agent collaboration. However, unlike the well-established performance improvements achieved through scaling data and model size, the scaling of reasoning in LLMs is more complex and can even negatively impact reasoning performance, introducing new challenges in model alignment and robustness. In this survey, we provide a comprehensive examination of scaling in LLM reasoning, categorizing it into multiple dimensions and analyzing how and to what extent different scaling strategies contribute to improving reasoning capabilities. We begin by exploring scaling in input size, which enables LLMs to process and utilize more extensive context for improved reasoning. Next, we analyze scaling in reasoning steps that improves multi-step inference and logical consistency. We then examine scaling in reasoning rounds, where iterative interactions refine reasoning outcomes. Furthermore, we discuss scaling in training-enabled reasoning, focusing on optimization through iterative model improvement. Finally, we review applications of scaling across domains and outline future directions for further advancing LLM reasoning. By synthesizing these diverse perspectives, this survey aims to provide insights into how scaling strategies fundamentally enhance the reasoning capabilities of LLMs and further guide the development of next-generation AI systems.",,,2025
1062,Text classification algorithms: A survey,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=h-Lr0bQAAAAJ&citation_for_view=h-Lr0bQAAAAJ:4fKUyHm3Qg0C,"In recent years, there has been an exponential growth in the number of complex documents and texts that require a deeper understanding of machine learning methods to be able to accurately classify texts in many applications. Many machine learning approaches have achieved surpassing results in natural language processing. The success of these learning algorithms relies on their capacity to understand complex models and non-linear relationships within data. However, finding suitable structures, architectures, and techniques for text classification is a challenge for researchers. In this paper, a brief overview of text classification algorithms is discussed. This overview covers different text feature extractions, dimensionality reduction methods, existing algorithms and techniques, and evaluations methods. Finally, the limitations of each technique and their application in real-world problems are discussed.",Multidisciplinary Digital Publishing Institute,Information,2019
1063,Hdltex: Hierarchical deep learning for text classification,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=h-Lr0bQAAAAJ&citation_for_view=h-Lr0bQAAAAJ:fPk4N6BV_jEC,"Increasingly large document collections require improved information processing methods for searching, retrieving, and organizing text. Central to these information processing methods is document classification, which has become an important application for supervised learning. Recently the performance of traditional supervised classifiers has degraded as the number of documents has increased. This is because along with growth in the number of documents has come an increase in the number of categories. This paper approaches this problem differently from current document classification methods that view the problem as multi-class classification. Instead we perform hierarchical classification using an approach we call Hierarchical Deep Learning for Text classification (HDLTex). HDLTex employs stacks of deep learning architectures to provide specialized understanding at each level of the document …",IEEE,,2017
1064,Rmdl: Random multimodel deep learning for classification,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=h-Lr0bQAAAAJ&citation_for_view=h-Lr0bQAAAAJ:b0M2c_1WBrUC,"The continually increasing number of complex datasets each year necessitates ever improving machine learning methods for robust and accurate categorization of these data. This paper introduces Random Multimodel Deep Learning (RMDL): a new ensemble, deep learning approach for classification. Deep learning models have achieved state-of-the-art results across many domains. RMDL solves the problem of finding the best deep learning structure and architecture while simultaneously improving robustness and accuracy through ensembles of deep learning architectures. RDML can accept as input a variety data to include text, video, images, and symbolic. This paper describes RMDL and shows test results for image and text data including MNIST, CIFAR-10, WOS, Reuters, IMDB, and 20newsgroup. These test results show that RDML produces consistently better performance than standard methods over a …",,,2018
1065,"Using mobile sensing to test clinical models of depression, social anxiety, state affect, and social isolation among college students",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=h-Lr0bQAAAAJ&citation_for_view=h-Lr0bQAAAAJ:NaGl4SEjCO4C,"Background Research in psychology demonstrates a strong link between state affect (moment-to-moment experiences of positive or negative emotionality) and trait affect (eg, relatively enduring depression and social anxiety symptoms), and a tendency to withdraw (eg, spending time at home). However, existing work is based almost exclusively on static, self-reported descriptions of emotions and behavior that limit generalizability. Despite adoption of increasingly sophisticated research designs and technology (eg, mobile sensing using a global positioning system [GPS]), little research has integrated these seemingly disparate forms of data to improve understanding of how emotional experiences in everyday life are associated with time spent at home, and whether this is influenced by depression or social anxiety symptoms. Objective We hypothesized that more time spent at home would be associated with more negative and less positive affect. Methods We recruited 72 undergraduate participants from a southeast university in the United States. We assessed depression and social anxiety symptoms using self-report instruments at baseline. An app (Sensus) installed on participants’ personal mobile phones repeatedly collected in situ self-reported state affect and GPS location data for up to 2 weeks. Time spent at home was a proxy for social isolation. Results We tested separate models examining the relations between state affect and time spent at home, with levels of depression and social anxiety as moderators. Models differed only in the temporal links examined. One model focused …",JMIR Publications,,2017
1066,Patient2vec: A personalized interpretable deep representation of the longitudinal electronic health record,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=h-Lr0bQAAAAJ&citation_for_view=h-Lr0bQAAAAJ:XiSMed-E-HIC,"The wide implementation of electronic health record (EHR) systems facilitates the collection of large-scale health data from real clinical settings. Despite the significant increase in adoption of EHR systems, these data remain largely unexplored, but present a rich data source for knowledge discovery from patient health histories in tasks, such as understanding disease correlations and predicting health outcomes. However, the heterogeneity, sparsity, noise, and bias in these data present many complex challenges. This complexity makes it difficult to translate potentially relevant information into machine learning algorithms. In this paper, we propose a computational framework, Patient2Vec, to learn an interpretable deep representation of longitudinal EHR data, which is personalized for each patient. To evaluate this approach, we apply it to the prediction of future hospitalizations using real EHR data and compare its …",IEEE,,2018
1067,WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=h-Lr0bQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=h-Lr0bQAAAAJ:mNrWkgRL2YcC,"Social anxiety is a common mental health condition linked to significant challenges in academic, social, and occupational functioning. A core feature is elevated momentary (state) anxiety in social situations, yet little prior work has measured or predicted fluctuations in this anxiety throughout the day. Capturing these intra-day dynamics is critical for designing real-time, personalized interventions such as Just-In-Time Adaptive Interventions (JITAIs). To address this gap, we conducted a study with socially anxious college students (N=91; 72 after exclusions) using our custom smartwatch-based system over an average of 9.03 days (SD = 2.95). Participants received seven ecological momentary assessments (EMAs) per day to report state anxiety. We developed a base model on over 10,000 days of external heart rate data, transferred its representations to our dataset, and fine-tuned it to generate probabilistic predictions. These were combined with trait-level measures in a meta-learner. Our pipeline achieved 60.4% balanced accuracy in state anxiety detection in our dataset. To evaluate generalizability, we applied the training approach to a separate hold-out set from the TILES-18 dataset-the same dataset used for pretraining. On 10,095 once-daily EMAs, our method achieved 59.1% balanced accuracy, outperforming prior work by at least 7%.",,,2025
1068,SocialPulse: An On-Smartwatch System for Detecting Real-World Social Interactions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=h-Lr0bQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=h-Lr0bQAAAAJ:dBIO0h50nwkC,"Social interactions are a fundamental part of daily life and play a critical role in well-being. As emerging technologies offer opportunities to unobtrusively monitor behavior, there is growing interest in using them to better understand social experiences. However, automatically detecting interactions, particularly via wearable devices, remains underexplored. Existing systems are often limited to controlled environments, constrained to in-person interactions, and rely on rigid assumptions such as the presence of two speakers within a fixed time window. These limitations reduce their generalizability to capture diverse real-world interactions. To address these challenges, we developed a real-time, on-watch system capable of detecting both in-person and virtual interactions. The system leverages transfer learning to detect foreground speech (FS) and infers interaction boundaries based upon FS and conversational cues like whispering. In a real-world evaluation involving 11 participants over a total of 38 days (Mean = 3.45 days, SD = 2.73), the system achieved an interaction detection accuracy of 73.18%. Follow-up with six participants indicated perfect recall for detecting interactions. These preliminary findings demonstrate the potential of our system to capture interactions in daily life, providing a foundation for applications such as personalized interventions targeting social anxiety.",,,2025
1069,Advances and Open Problems in Federated Learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DsR4PucAAAAJ&citation_for_view=DsR4PucAAAAJ:8cBNEdFwSQkC,"Federated learning (FL) is a machine learning setting where many clients (eg, mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (eg, service provider), while keeping the training data decentralized. FL embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in FL research, this monograph discusses recent advances and presents an extensive collection of open problems and challenges.",,,2019
1070,Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DsR4PucAAAAJ&citation_for_view=DsR4PucAAAAJ:PD-wXv1Sh1EC,"Although deep neural networks (DNNs) have achieved great success in many tasks, they can often be fooled by \emph{adversarial examples} that are generated by adding small but purposeful distortions to natural examples. Previous studies to defend against adversarial examples mostly focused on refining the DNN models, but have either shown limited success or required expensive computation. We propose a new strategy, \emph{feature squeezing}, that can be used to harden DNN models by detecting adversarial examples. Feature squeezing reduces the search space available to an adversary by coalescing samples that correspond to many different feature vectors in the original space into a single sample. By comparing a DNN model's prediction on the original input with that on squeezed inputs, feature squeezing detects adversarial examples with high accuracy and few false positives. This paper explores two feature squeezing methods: reducing the color bit depth of each pixel and spatial smoothing. These simple strategies are inexpensive and complementary to other defenses, and can be combined in a joint detection framework to achieve high detection rates against state-of-the-art attacks.",,,2018
1071,Localization for Mobile Sensor Networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DsR4PucAAAAJ&citation_for_view=DsR4PucAAAAJ:u5HHmVD_uO8C,"Many sensor network applications require location awareness, but it is often too expensive to include a GPS receiver in a sensor network node. Hence, localization schemes for sensor networks typically use a small number of seed nodes that know their location and protocols whereby other nodes estimate their location from the messages they receive. Several such localization techniques have been proposed, but none of them consider mobile nodes and seeds. Although mobility would appear to make localization more difficult, in this paper we introduce the sequential Monte Carlo Localization method and argue that it can exploit mobility to improve the accuracy and precision of localization. Our approach does not require additional hardware on the nodes and works even when the movement of seeds and nodes is uncontrollable. We analyze the properties of our technique and report experimental results from …",,,2004
1072,Faster Secure Two-Party Computation Using Garbled Circuits,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DsR4PucAAAAJ&citation_for_view=DsR4PucAAAAJ:IWHjjKOFINEC,"Secure two-party computation enables two parties to evaluate a function cooperatively without revealing to either party anything beyond the function’s output. The garbled-circuit technique, a generic approach to secure two-party computation for semi-honest participants, was developed by Yao in the 1980s, but has been viewed as being of limited practical significance due to its inefficiency. We demonstrate several techniques for improving the running time and memory requirements of the garbled-circuit technique, resulting in an implementation of generic secure two-party computation that is significantly faster than any previously reported while also scaling to arbitrarily large circuits. We validate our approach by demonstrating secure computation of circuits with over 10 9 gates at a rate of roughly 10 μs per garbled gate, and showing order-of-magnitude improvements over the best previous privacy-preserving protocols for computing Hamming distance, Levenshtein distance, Smith-Waterman genome alignment, and AES.",,,2011
1073,Using Directional Antennas to Prevent Wormhole Attacks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DsR4PucAAAAJ&citation_for_view=DsR4PucAAAAJ:2osOgNQ5qMEC,"Wormhole attacks enable an attacker with limited resources and no cryptographic material to wreak havoc on wireless networks. To date, no general defenses against wormhole attacks have been proposed. This paper presents an analysis of wormhole attacks and proposes a countermeasure using directional antennas. We present a cooperative protocol whereby nodes share directional information to prevent wormhole endpoints from masquerading as false neighbors. Our defense greatly diminishes the threat of wormhole attacks and requires no location information or clock synchronization.",,,2004
1074,Pitfalls in Evaluating Inference-time Methods for Improving LLM Reliability,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DsR4PucAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DsR4PucAAAAJ:rQKKVauEoioC,"Though Large Language Models (LLMs) have demonstrated remarkable capabilities, they are still prone to outputting falsehoods using seemingly persuasive language. Many recent works attempt to address this problem by using LLMs in a framework where a single seed prompt results in a series of interactions involving augmented prompts with an otherwise unchanged LLM, and the results are aggregated with a goal of producing a more reliable output. We consider the replicability and generalizability of evaluations of inference-time methods intended to improve the reliability of responses from a base LLMs. We survey how methods have been evaluated in the literature and find a great variety of benchmarks and models in use. Motivated by this, we conduct our own evaluation to evaluate the effectiveness of a few methods across a range of benchmarks and models. Our evaluation reveals that while these techniques show promise in improving reliability, there is still significant variability in performance across different domains and tasks, and methods that show substantial improvements on weaker base models often do not improve reliability for better base models.",,,2025
1075,Do Prevalent Bias Metrics Capture Allocational Harms from LLMs?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DsR4PucAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DsR4PucAAAAJ:wyCGhLAOp5UC,"Allocational harms occur when resources or opportunities are unfairly withheld from specific groups. Many proposed bias measures ignore the discrepancy between predictions, which are what the proposed methods consider, and decisions that are made as a result of those predictions. Our work examines the reliability of current bias metrics in assessing allocational harms arising from predictions of large language models (LLMs). We evaluate their predictive validity and utility for model selection across ten LLMs and two allocation tasks. Our results reveal that commonly-used bias metrics based on average performance gap and distribution distance fail to reliably capture group disparities in allocation outcomes. Our work highlights the need to account for how model predictions are used in decisions, in particular in contexts where they are influenced by how limited resources are allocated.",,,2025
1076,"Steering the CensorShip: Uncovering Representation Vectors for LLM ""Thought"" Control",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DsR4PucAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DsR4PucAAAAJ:Fx13dKtzC7kC,"Large language models (LLMs) have transformed the way we access information. These models are often tuned to refuse to comply with requests that are considered harmful and to produce responses that better align with the preferences of those who control the models. To understand how this ""censorship"" works. We use representation engineering techniques to study open-weights safety-tuned models. We present a method for finding a refusal--compliance vector that detects and controls the level of censorship in model outputs. We also analyze recent reasoning LLMs, distilled from DeepSeek-R1, and uncover an additional dimension of censorship through ""thought suppression"". We show a similar approach can be used to find a vector that suppresses the model's reasoning process, allowing us to remove censorship by applying the negative multiples of this vector. Our code is publicly available at: https://github.com/hannahxchen/llm-censorship-steering",,,2025
1077,Inferring Events from Time Series using Language Models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DsR4PucAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DsR4PucAAAAJ:52neCvzbxIwC,"Time series data measure how environments change over time and drive decision-making in critical domains like finance and healthcare. A common goal in analyzing time series data is to understand the underlying events that cause the observed variations. We conduct the first study of whether Large Language Models (LLMs) can infer events described with natural language from time series data. We evaluate 18 LLMs on a task to match event sequences with real-valued time series data using a new benchmark we develop using sports data. Several current LLMs demonstrate promising abilities, with OpenAI's o1 performing the best but with DS-R1-distill-Qwen-32B outperforming proprietary models such as GPT-4o. From insights derived from analyzing reasoning failures, we also find clear avenues to improve performance. By applying post-training optimizations, i.e., distillation and self-improvement, we significantly enhance the performance of the Qwen2.5 1.5B, achieving results second only to o1. All resources needed to reproduce our work are available: https://github.com/BennyTMT/GAMETime",,,2025
1078,Sensing and Steering Stereotypes: Extracting and Applying Gender Representation Vectors in LLMs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DsR4PucAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DsR4PucAAAAJ:H0nRGT7Dr7IC,"Large language models (LLMs) are known to perpetuate stereotypes and exhibit biases. Various strategies have been proposed to mitigate these biases, but most work studies biases in LLMs as a black-box problem without considering how concepts are represented within the model. We adapt techniques from representation engineering to study how the concept of ""gender"" is represented within LLMs. We introduce a new method that extracts concept representations via probability weighting without labeled data and efficiently selects a steering vector for measuring and manipulating the model's representation. We also present a projection-based method that enables precise steering of model predictions and demonstrate its effectiveness in mitigating gender bias in LLMs. Our code is available at: https://github.com/hannahxchen/gender-bias-steering",,,2025
1079,Widar3.0: Zero-Effort Cross-Domain Gesture Recognition with Wi-Fi,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fGNCS9oAAAAJ&citation_for_view=fGNCS9oAAAAJ:aqlVkmm33-oC,"With the development of signal processing technology, the ubiquitous Wi-Fi devices open an unprecedented opportunity to solve the challenging human gesture recognition problem by learning motion representations from wireless signals. Wi-Fi-based gesture recognition systems, although yield good performance on specific data domains, are still practically difficult to be used without explicit adaptation efforts to new domains. Various pioneering approaches have been proposed to resolve this contradiction but extra training efforts are still necessary for either data collection or model re-training when new data domains appear. To advance cross-domain recognition and achieve fully zero-effort recognition, we propose Widar3.0, a Wi-Fi-based zero-effort cross-domain gesture recognition system. The key insight of Widar3.0 is to derive and extract domain-independent features of human gestures at the lower signal …",IEEE,,2021
1080,Widar2.0: Passive human tracking with a single Wi-Fi link,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fGNCS9oAAAAJ&citation_for_view=fGNCS9oAAAAJ:eQOLeE2rZwMC,"This paper presents Widar2.0, the first WiFi-based system that enables passive human localization and tracking using a single link on commodity off-the-shelf devices. Previous works based on either specialized or commercial hardware all require multiple links, preventing their wide adoption in scenarios like homes where typically only one single AP is installed. The key insight underlying Widar2.0 to circumvent the use of multiple links is to leverage multi-dimensional signal parameters from one single link. To this end, we build a unified model accounting for Angle-of-Arrival, Time-of-Flight, and Doppler shifts together and devise an efficient algorithm for their joint estimation. We then design a pipeline to translate the erroneous raw parameters into precise locations, which first finds parameters corresponding to the reflections of interests, then refines range estimates, and ultimately outputs target locations. Our …",,,2018
1081,Widar: Decimeter-level passive tracking via velocity monitoring with commodity Wi-Fi,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fGNCS9oAAAAJ&citation_for_view=fGNCS9oAAAAJ:UeHWp8X0CEIC,"Various pioneering approaches have been proposed for Wi-Fi-based sensing, which usually employ learning-based techniques to seek appropriate statistical features, yet do not support precise tracking without prior training. Thus to advance passive sensing, the ability to track fine-grained human mobility information acts as a key enabler. In this paper, we propose Widar, a Wi-Fi-based tracking system that simultaneously estimates a human's moving velocity (both speed and direction) and location at a decimeter level. Instead of applying statistical learning techniques, Widar builds a theoretical model that geometrically quantifies the relationships between CSI dynamics and the user's location and velocity. On this basis, we propose novel techniques to identify frequency components related to human motion from noisy CSI readings and then derive a user's location in addition to velocity. We implement Widar on …",,,2017
1082,Enabling contactless detection of moving humans with dynamic speeds using CSI,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fGNCS9oAAAAJ&citation_for_view=fGNCS9oAAAAJ:Tyk-4Ss8FVUC,"Device-free passive detection is an emerging technology to detect whether there exist any moving entities in the areas of interest without attaching any device to them. It is an essential primitive for a broad range of applications including intrusion detection for safety precautions, patient monitoring in hospitals, child and elder care at home, and so forth. Despite the prevalent signal feature Received Signal Strength (RSS), most robust and reliable solutions resort to a finer-grained channel descriptor at the physical layer, e.g., the Channel State Information (CSI) in the 802.11n standard. Among a large body of emerging techniques, however, few of them have explored the full potential of CSI for human detection. Moreover, space diversity supported by nowadays popular multiantenna systems are not investigated to a comparable extent as frequency diversity. In this article, we propose a novel scheme for device-free …",ACM,,2018
1083,Inferring motion direction using commodity Wi-Fi for interactive exergames,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fGNCS9oAAAAJ&citation_for_view=fGNCS9oAAAAJ:qjMakFHDy7sC,"In-air interaction acts as a key enabler for ambient intelligence and augmented reality. As an increasing popular example, exergames, and the alike gesture recognition applications, have attracted extensive research in designing accurate, pervasive and low-cost user interfaces. Recent advances in wireless sensing show promise for a ubiquitous gesture-based interaction interface with Wi-Fi. In this work, we extract complete information of motion-induced Doppler shifts with only commodity Wi-Fi. The key insight is to harness antenna diversity to carefully eliminate random phase shifts while retaining relevant Doppler shifts. We further correlate Doppler shifts with motion directions, and propose a light-weight pipeline to detect, segment, and recognize motions without training. On this basis, we present WiDance, a Wi-Fi-based user interface, which we utilize to design and prototype a contactless dance-pad exergame …",,,2017
1084,Toward Spoofing-Resilient and Communication-Integrated MmWave Radar Sensing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fGNCS9oAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fGNCS9oAAAAJ:a0OBvERweLwC,"MmWave FMCW radars are integrated into many sensing systems for robust sensing. However, their sensing functions are vulnerable to spoofing attacks and interfered with by backscatter communications, both of which can cause sensor malfunction and system failure. Noticing that radar spoofing and communication share similar signal modulation mechanisms, in this paper, we present SCR, a new Spoofing-resilient and Communication-integrated Radar sensing scheme. SCR is based on the rigorous analysis of the radar sensing model that highlights the differences between modulated spoofing and communication signals and normal sensing signals reflected by natural objects. The key designs of SCR are a novel chirp configuration scheme and signal processing pipeline, which signify different patterns between modulated and normal signals in radar spectra, for reliable detection of spoofing and …",,,2025
1085,Radio Frequency Ray Tracing with Neural Object Representation for Enhanced RF Modeling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fGNCS9oAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fGNCS9oAAAAJ:D03iK_w7-QYC,"Radio frequency (RF) propagation modeling poses unique electromagnetic simulation challenges. While recent neural representations have shown success in visible spectrum rendering, the fundamentally different scales and physics of RF signals require novel modeling paradigms. In this paper, we introduce RFScape, a novel framework that bridges the gap between neural scene representation and RF propagation modeling. Our key insight is that complex RF-object interactions can be captured through object-centric neural representations while preserving the composability of traditional ray tracing. Unlike previous approaches that either rely on crude geometric approximations or require dense spatial sampling of entire scenes, RFScape learns per-object electromagnetic properties and enables flexible scene composition. Through extensive evaluation on real-world RF testbeds, we demonstrate that our approach achieves 13 dB improvement over conventional ray tracing and 5 dB over state-of-the-art neural baselines in modeling accuracy, while requiring only sparse training samples.",,,2025
1086,Rfcanvas: Modeling rf channel by fusing visual priors and few-shot rf measurements,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fGNCS9oAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fGNCS9oAAAAJ:u_35RYKgDlwC,"Accurate and responsive simulation of radio frequency (RF) signal propagation is crucial for designing wireless systems operating in dynamic environments. Conventional ray tracing approaches struggle to accurately model the intricate geometries and material properties of objects that impact propagation. Recently proposed neural scene representations can learn such intricacies from RF data, but they treat the entire scene as implicit neural networks, necessitating retraining with a massive amount of RF data upon any environmental changes. In this paper, we propose RFCanvas, which fuses visual priors and RF measurements to achieve high accuracy for realistic scenes and be responsive to environmental changes. To ensure compatibility between visual priors and RF measurements, we introduce RFCanvas scene representations that model shapes and materials of substantial objects with tensorial fields and …",,,2024
1087,Keystub: A passive rfid-based keypad interface using resonant stubs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fGNCS9oAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fGNCS9oAAAAJ:ns9cj8rnVeAC,"The proliferation of the Internet of Things is calling for new modalities that enable human interaction with smart objects. Recent research has explored RFID tags as passive sensors to detect finger touch. However, existing approaches either rely on custom-built RFID readers or are limited to pre-trained finger-swiping gestures. In this paper, we introduce KeyStub, which can discriminate multiple discrete keystrokes on an RFID tag. KeyStub interfaces with commodity RFID ICs with multiple microwave-band resonant stubs as keys. Each stub's geometry is designed to create a predefined impedance mismatch to the RFID IC upon a keystroke, which in turn translates into a known amplitude and phase shift, remotely detectable by an RFID reader. KeyStub combines two ICs' signals through a single common-mode antenna and performs differential detection to evade the need for calibration and ensure reliability in heavy …",ACM,,2024
1088,Neuroradar: A neuromorphic radar sensor for low-power iot systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fGNCS9oAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=fGNCS9oAAAAJ:YFjsv_pBGBYC,"Radar sensors have recently been explored in the industrial and consumer Internet of Things (IoT). However, such applications often require self-sustainable or untethered operations, which are at odds with the high power consumption of radar. This paper proposes NeuroRadar, a neuromorphic radar sensor, to achieve low-power wireless sensing. NeuroRadar jointly optimizes the analog hardware and the computation model, in order to mimic the highly efficient biological sensing and neural processing system. NeuroRadar features a highly simplified radar front end, which eliminates the power-hungry components in conventional radars. It directly ""encodes"" ambient motion into spiking signals, which can be processed using spiking neural networks running on energy-efficient neuromorphic computing platforms. We have prototyped NeuroRadar and evaluated its performance in two use cases: gesture sensing …",,,2023
1089,Insights into the biodegradation of weathered hydrocarbons in contaminated soils by bioaugmentation and nutrient stimulation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQoa2JMAAAAJ&citation_for_view=vQoa2JMAAAAJ:YOwf2qJgpHMC,"The potential for biotransformation of weathered hydrocarbon residues in soils collected from two commercial oil refinery sites (Soil A and B) was studied in microcosm experiments. Soil A has previously been subjected to on-site bioremediation and it was believed that no further degradation was possible while soil B has not been subjected to any treatment. A number of amendment strategies including bioaugmentation with hydrocarbon degrader, biostimulation with nutrients and soil grinding, were applied to the microcosms as putative biodegradation improvement strategies. The hydrocarbon concentrations in each amendment group were monitored throughout 112 days incubation. Microcosms treated with biostimulation (BS) and biostimulation/bioaugmentation (BS + BA) showed the most significant reductions in the aliphatic and aromatic hydrocarbon fractions. However, soil grinding was shown to reduce the …",Pergamon,,2016
1090,Enhanced biodegradation of phenol by a microbial consortium in a solid–liquid two phase partitioning bioreactor,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQoa2JMAAAAJ&citation_for_view=vQoa2JMAAAAJ:u5HHmVD_uO8C,"Two phase partitioning bioreactors (TPPBs) operate by partitioning toxic substrates to or from an aqueous, cell-containing phase by means of second immiscible phase. Uptake of toxic substrates by the second phase effectively reduces their concentration within the aqueous phase to sub-inhibitory levels, and transfer of molecules between the phases to maintain equilibrium results in the continual feeding of substrate based on the metabolic demand of the microorganisms. Conventionally, a single pure species of microorganism, and a pure organic solvent, have been used in TPPBs. The present work has demonstrated the benefits of using a mixed microbial population for the degradation of phenol in a TPPB that uses solid polymer beads (comprised of ethylene vinyl acetate, or EVA) as the second phase. Polymer modification via an increase in vinyl acetate concentration was also shown to increase phenol uptake …",Kluwer Academic Publishers,,2005
1091,Learning to organise risk management in organisations: what future for enterprise risk management?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQoa2JMAAAAJ&citation_for_view=vQoa2JMAAAAJ:LkGwnXOMwfcC,"Enterprise risk management (ERM) was originally developed to manage financial risks and was later transferred to other businesses, sectors and, crucially, government. ERM aims at a maximum of comprehensiveness suggesting the integration of all risks to an organisation’s objective in a portfolio to inform organisational strategy. However, the concept suffers from unknown interdependencies between risks, implementation strategies that lack empirical validation and ambivalences and uncertainties arising from their management. It is only weakly rooted in organisational theory. Drawing on knowledge generation, theory key aspects for the empirical study of risk management in organisations are identified. These address the commensuration of risks, the comprehensiveness of the risk portfolio and the communication of explicit and tacit knowledge enabling organisational learning processes in different institutional …",Routledge,,2014
1092,Management of petroleum hydrocarbon contaminated sites in Nigeria: Current challenges and future direction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQoa2JMAAAAJ&citation_for_view=vQoa2JMAAAAJ:4DMP91E08xMC,"Sites affected by petroleum hydrocarbons from oil exploitation activities have been identified as a major environmental and socio-economic problem in the Niger Delta region of Nigeria. The current Nigerian regulatory instruments to manage these contaminated sites are fragmented and the roles and responsibilities of government agencies, such as the Department for Petroleum Resources (DPR), and the National Oil Spill Detection and Response Agency (NOSDRA), are not well defined. This lack of coordination has led to ineffective land contamination policy and poor enforcement more generally. Appropriate, risk-based policy instruments are needed to improve regulatory capacity, and to enhance the regulator's ability to manage new and existing petroleum hydrocarbons contaminated sites. Lessons can be learned from countries like the United Kingdom (UK) and the United States America (USA) that have …",Pergamon,,2017
1093,Assessing bioavailability of complex chemical mixtures in contaminated soils: Progress made and research needs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQoa2JMAAAAJ&citation_for_view=vQoa2JMAAAAJ:L8Ckcad2t8MC,"Understanding the distribution, behaviour and interactions of complex chemical mixtures is key for providing the evidence necessary to make informed decisions and implement robust remediation strategies. Much of the current risk assessment frameworks applied to manage land contamination are based on total contaminant concentrations and the exposure assessments embedded within them do not explicitly address the partitioning and bioavailability of chemical mixtures. These oversights may contribute to an overestimation of both the eco-toxicological effects of the fractions and the mobility of contaminants. In turn, this may limit the efficacy of risk frameworks to inform targeted and proportionate remediation strategies. In this review we analyse the science surrounding bioavailability, its regulatory inclusion and the challenges of incorporating bioavailability in decision making process. While a number of …",Elsevier,Science of the Total Environment,2018
1094,Recovery of infauna macrobenthic invertebrates in oil-polluted tropical soft-bottom tidal flats: 7 years post spill,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQoa2JMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vQoa2JMAAAAJ:iH-uZ7U-co4C,"Coastal oil spills constitute significant threat to biotic energy distribution, and biodiversity integrity amongst others. This study monitored the recovery of low-intertidal, soft-bottom infauna macrobenthic invertebrates in Bodo Creek intermittently over a 7-year period post oil spill. Samples were taken twice a month (spring and neap low tides) for 6 months (September 2015–February 2016) at sites previously studied (pre-spill baseline studies, 3-year and 5-year post-spill studies) for the effects of oil pollution using the same sampling methods used during initial studies of the same area. Comparatively, the initial studies reported Polychaeta as the dominant class against the dominant Crustacea reported in this 7-year post-spill study, indicating a change in the community structure of the study area. Infauna macro-invertebrate communities recorded showed an improvement (that is, increased species richness and number …",Springer Berlin Heidelberg,,2019
1095,Linking bioavailability and toxicity changes of complex chemicals mixture to support decision making for remediation endpoint of contaminated soils,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQoa2JMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vQoa2JMAAAAJ:RHpTSmoSYBkC,"A six-month laboratory scale study was carried out to investigate the effect of biochar and compost amendments on complex chemical mixtures of tar, heavy metals and metalloids in two genuine contaminated soils. An integrated approach, where organic and inorganic contaminants bioavailability and distribution changes, along with a range of microbiological indicators and ecotoxicological bioassays, was used to provide multiple lines of evidence to support the risk characterisation and assess the remediation end-point. Both compost and biochar amendment (p = 0.005) as well as incubation time (p = 0.001) significantly affected the total and bioavailable concentrations of the total petroleum hydrocarbons (TPH) in the two soils. Specifically, TPH concentration decreased by 46% and 30% in Soil 1 and Soil 2 amended with compost. These decreases were accompanied by a reduction of 78% (Soil 1) and 6 …",Elsevier,,2019
1096,Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQoa2JMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vQoa2JMAAAAJ:4JMBOYKVnBMC,"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to …",Pergamon,,2019
1097,"Insights into mixed contaminants interactions and its implication for heavy metals and metalloids mobility, bioavailability and risk assessment",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQoa2JMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vQoa2JMAAAAJ:R3hNpaxXUhUC,"Mobility of heavy metals at contaminated sites is mainly influenced by the soil physicochemical properties and environmental conditions, therefore assessing heavy metals (HMs) and metalloids fractionation can provide insights into their potential risk and the mechanisms that regulate bioavailability. A 12-months mesocosms experiment was setup to investigate the effect of physicochemical factors (pH, moisture, and temperature) and weathering (time) on HMs and metalloids fractionation in three different multi-contaminated soil matrices (low, medium, and high contamination) collected from a soil treatment facility located in the United Kingdom, and two rural contaminated soil samples. The study demonstrates that even though Pb and Zn were found associated with the exchangeable fraction in the soil with the highest contamination (total average Pb 3400 mg/kg, and total average Zn 2100 mg/kg in Soil C), neither …",Elsevier,,2018
1098,Stakeholder engagement and the sustainable environmental management of oil-contaminated sites in Nigeria,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQoa2JMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vQoa2JMAAAAJ:e5wmG9Sq2KIC,"African nations are experiencing rapid economic growth and development, particularly within the energy sector; however, this growth has come at a cost to the environment and society. Nowhere have these impacts been felt more precisely than in the oil and gas-producing regions of Nigeria where years of neglect and mismanagement have resulted in vast areas of hydrocarbon-contaminated lands. In this chapter, we present a case study of the Niger Delta. We show how constructive stakeholder engagement can be used to integrate the values and perspectives of affected communities and how this information can be used to inform environmental regulation and sustainable development. Lessons learned are relevant to other countries seeking to develop their energy resources in a sustainable manner.",Springer International Publishing,,2018
1099,"Bewell: A smartphone application to monitor, model and promote wellbeing",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O0lONMkAAAAJ&citation_for_view=O0lONMkAAAAJ:qjMakFHDy7sC,"A key challenge for mobile health is to develop new technology that can assist individuals in maintaining a healthy lifestyle by keeping track of their everyday behaviors. Smartphones embedded with a wide variety of sensors are enabling a new generation of personal health applications that can actively monitor, model and promote wellbeing. Automated wellbeing tracking systems available so far have focused on physical fitness and sleep and often require external non-phone based sensors. In this work, we take a step towards a more comprehensive smartphone based system that can track activities that impact physical, social, and mental wellbeing namely, sleep, physical activity, and social interactions and provides intelligent feedback to promote better health. We present the design, implementation and evaluation of BeWell, an automated wellbeing app for the Android smartphones and demonstrate its feasibility in monitoring multi-dimensional wellbeing. By providing a more complete picture of health, BeWell has the potential to empower individuals to improve their overall wellbeing and identify any early signs of decline.",,,2011
1100,Toss'n'turn: smartphone as sleep and sleep quality detector,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O0lONMkAAAAJ&citation_for_view=O0lONMkAAAAJ:LkGwnXOMwfcC,"The rapid adoption of smartphones along with a growing habit for using these devices as alarm clocks presents an opportunity to use this device as a sleep detector. This adds value to UbiComp and personal informatics in terms of user context and new performance data to collect and visualize, and it benefits healthcare as sleep is correlated with many health issues. To assess this opportunity, we collected one month of phone sensor and sleep diary entries from 27 people who have a variety of sleep contexts. We used this data to construct models that detect sleep and wake states, daily sleep quality, and global sleep quality. Our system classifies sleep state with 93.06% accuracy, daily sleep quality with 83.97% accuracy, and overall sleep quality with 81.48% accuracy. Individual models performed better than generally trained models, where the individual models require 3 days of ground truth data and 3 weeks of …",,,2014
1101,"Bewell: Sensing sleep, physical activities and social interactions to promote wellbeing",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O0lONMkAAAAJ&citation_for_view=O0lONMkAAAAJ:WF5omc3nYNoC,"Smartphone sensing and persuasive feedback design is enabling a new generation of wellbeing apps capable of automatically monitoring multiple aspects of physical and mental health. In this article, we present BeWell+ the next generation of the BeWell smartphone wellbeing app, which monitors user behavior along three health dimensions, namely sleep, physical activity, and social interaction. BeWell promotes improved behavioral patterns via feedback rendered as an ambient display on the smartphone’s wallpaper. With BeWell+, we introduce new mechanisms to address key limitations of the original BeWell app; specifically, (1) community adaptive wellbeing feedback, which generalizes to diverse user communities (e.g., elderly, children) by promoting better behavior yet remains realistic to the user’s lifestyle; and, (2) wellbeing adaptive energy allocation, which prioritizes monitoring fidelity and feedback …",Springer US,,2014
1102,"Identifying behavioral phenotypes of loneliness and social isolation with passive sensing: statistical analysis, data mining and machine learning of smartphone and fitbit data",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O0lONMkAAAAJ&citation_for_view=O0lONMkAAAAJ:Wp0gIr-vW9MC,"Background: Feelings of loneliness are associated with poor physical and mental health. Detection of loneliness through passive sensing on personal devices can lead to the development of interventions aimed at decreasing rates of loneliness. Objective: The aim of this study was to explore the potential of using passive sensing to infer levels of loneliness and to identify the corresponding behavioral patterns. Methods: Data were collected from smartphones and Fitbits (Flex 2) of 160 college students over a semester. The participants completed the University of California, Los Angeles (UCLA) loneliness questionnaire at the beginning and end of the semester. For a classification purpose, the scores were categorized into high (questionnaire score> 40) and low (≤ 40) levels of loneliness. Daily features were extracted from both devices to capture activity and mobility, communication and phone usage, and sleep behaviors. The features were then averaged to generate semester-level features. We used 3 analytic methods:(1) statistical analysis to provide an overview of loneliness in college students,(2) data mining using the Apriori algorithm to extract behavior patterns associated with loneliness, and (3) machine learning classification to infer the level of loneliness and the change in levels of loneliness using an ensemble of gradient boosting and logistic regression algorithms with feature selection in a leave-one-student-out cross-validation manner. Results: The average loneliness score from the presurveys and postsurveys was above 43 (presurvey SD 9.4 and postsurvey SD 10.4), and the majority of participants fell into the high loneliness …","JMIR Publications Inc., Toronto, Canada",,2019
1103,Detecting depression and predicting its onset using longitudinal symptoms captured by passive sensing: a machine learning approach with robust feature selection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O0lONMkAAAAJ&citation_for_view=O0lONMkAAAAJ:mB3voiENLucC,"We present a machine learning approach that uses data from smartphones and fitness trackers of 138 college students to identify students that experienced depressive symptoms at the end of the semester and students whose depressive symptoms worsened over the semester. Our novel approach is a feature extraction technique that allows us to select meaningful features indicative of depressive symptoms from longitudinal data. It allows us to detect the presence of post-semester depressive symptoms with an accuracy of 85.7% and change in symptom severity with an accuracy of 85.4%. It also predicts these outcomes with an accuracy of >80%, 11–15 weeks before the end of the semester, allowing ample time for pre-emptive interventions. Our work has significant implications for the detection of health outcomes using longitudinal behavioral data and limited ground truth. By detecting change and predicting …",ACM,,2021
1104,4.3 Evaluation of MoodRing Passive Mood Monitoring Application on Improving Quality of Depression Management in Adolescents,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O0lONMkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=O0lONMkAAAAJ:P5F9QuxV20EC,"Objectives Despite guideline recommendations, more than two-thirds of adolescents identified with a depressive disorder in primary care do not receive symptom monitoring, and 19% do not receive symptom reassessment, increasing risks for untoward health outcomes. This pilot randomized controlled trial evaluated MoodRing, a mobile application incorporating data passively collected from the adolescent’s smartphone and providing visualization of symptom feedback, prompts for reflection, and suggested coping strategies on an adolescent app, parent app, and clinician dashboard. Methods We recruited adolescents aged 12-18 years with a prior depression diagnosis, and their parent, from clinical settings and online advertising. Adolescents were all required to provide passively collected smartphone data and complete weekly mood surveys. They were randomized 1: 1 to receive MoodRing or treatment as …",Elsevier,,2025
1105,Characterization and Feasibility of Wearable Spectroscopic Tracking of Nutrition Biomarkers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O0lONMkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=O0lONMkAAAAJ:nb7KW1ujOQ8C,"Disorders related to nutrition and metabolism remain a critical public health challenge globally, affecting a significant portion of the population. While traditional calorie tracking methods help monitor dietary intake, they do not capture how the body synthesizes and metabolizes nutrients, and are often inaccurate, cumbersome, and inconvenient. Wearable biosensing technologies present a promising avenue for more precise, noninvasive monitoring of nutritional intake, providing individuals with real-time feedback to improve their dietary habits. In this study, we explore the feasibility of using an off-the-shelf wearable device to track nutrients in the blood. Utilizing a multiwavelength optical sensor covering a range of wavelengths in the visible spectrum, we compare the device’s ability to measure spectral absorption profiles of various nutritional molecules relative to a spectrophotometer. Through advanced signal …",IEEE,,2025
1106,Predicting The Severity of Anxiety in Adolescents Through Passively Sensed Behaviors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O0lONMkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=O0lONMkAAAAJ:dshw04ExmUIC,"In this work, we investigate whether the severity of adolescents’ anxiety can be predicted using passively sensed behaviors. We recruited 55 adolescent participants with diagnosed anxiety to participate in a 24-week-long study. Participants completed a weekly questionnaire recording their anxiety level. Using Fitbits and participants’ mobile phones, we passively collected their physiology and behaviors. We find that adolescent anxiety can be predicted with a relatively low mean absolute error of 2.45 on a 22-point scale. Using SHAP values and feature importance, we determine that certain behaviors, particularly those related to phone usage, mobility, and activities, are particularly useful for predicting anxiety. Coincidentally, our study overlaps with the early stages of the COVID-19 pandemic. As such, we also explore how our participant’s anxiety and behaviors varied throughout government-mandated lockdowns …",IEEE,,2025
1107,SAINT: Attention-Based Modeling of Sub-Action Dependencies in Multi-Action Policies,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O0lONMkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=O0lONMkAAAAJ:b0M2c_1WBrUC,"The combinatorial structure of many real-world action spaces leads to exponential growth in the number of possible actions, limiting the effectiveness of conventional reinforcement learning algorithms. Recent approaches for combinatorial action spaces impose factorized or sequential structures over sub-actions, failing to capture complex joint behavior. We introduce the Sub-Action Interaction Network using Transformers (SAINT), a novel policy architecture that represents multi-component actions as unordered sets and models their dependencies via self-attention conditioned on the global state. SAINT is permutation-invariant, sample-efficient, and compatible with standard policy optimization algorithms. In 15 distinct combinatorial environments across three task domains, including environments with nearly 17 million joint actions, SAINT consistently outperforms strong baselines.",,,2025
1108,Student Receptiveness to Circadian-Aware AI-Driven Scheduling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O0lONMkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=O0lONMkAAAAJ:CHSYGLWDkRkC,"Circadian rhythm alignment plays a crucial role in our health and performance, yet most scheduling tools do not take it into account. College students, in particular, are affected by circadian misalignment due to their social and academic commitments. This paper investigates the desirability of an AIdriven scheduling application optimized for circadian rhythm alignment for students. Our initial interviews and observation of using GenAI tools with 16 undergraduate student participants indicated that while of them use AI daily, only utilize it for scheduling purposes. We further designed prototypes of an LLM-based scheduling application with varying levels of circadian awareness and evaluated their usefulness and desirability with 102 participants. Overwhelmed participants found the prototypes less helpful than those struggling with time management and exhaustion. However, our results indicate that students …",IEEE,,2025
1109,Photoacoustic image-guided delivery of plasmonic-nanoparticle-labeled mesenchymal stem cells to the spinal cord,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQnZTA0AAAAJ&citation_for_view=vQnZTA0AAAAJ:IjCSPb-OGe4C,"Regenerative therapies using stem cells have great potential for treating neurodegenerative diseases and traumatic injuries in the spinal cord. In spite of significant research efforts, many therapies fail at the clinical phase. As stem cell technologies advance toward clinical use, there is a need for a minimally invasive, safe, affordable, and real-time imaging technique that allows for the accurate and safe monitoring of stem cell delivery in the operating room. In this work, we present a combined ultrasound and photoacoustic imaging tool to provide image-guided needle placement and monitoring of nanoparticle-labeled stem cell delivery into the spinal cord. We successfully tagged stem cells using gold nanospheres and provided image-guided delivery of stem cells into the spinal cord in real-time, detecting as few as 1000 cells. Ultrasound and photoacoustic imaging was used to guide needle placement for direct stem …",American Chemical Society,,2018
1110,Development of a stem cell tracking platform for ophthalmic applications using ultrasound and photoacoustic imaging,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQnZTA0AAAAJ&citation_for_view=vQnZTA0AAAAJ:2osOgNQ5qMEC,"Glaucoma is the second leading cause of blindness in the world. Disease progression is associated with reduced cellularity in the trabecular meshwork (TM), a fluid drainage tissue in the anterior eye. A promising therapy seeks to deliver stem cells to the TM to regenerate the tissue and restore its function. However, like many stem cell-based regenerative therapies, preclinical development relies heavily on histology to evaluate outcomes. To expedite clinical translation, we are developing an ultrasound/photoacoustic (US/PA) imaging platform for longitudinal tracking of stem cells in the anterior eye. Methods Mesenchymal stem cells (MSCs) were labeled with gold nanospheres in vitro and injected through the cornea into the anterior chamber of ex vivo porcine eyes. Physiological pressure was imposed to mimic in vivo conditions. AuNS-labeled MSCs were injected through the cornea while single-wavelength US …",,,2019
1111,Improving stem cell delivery to the trabecular meshwork using magnetic nanoparticles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQnZTA0AAAAJ&citation_for_view=vQnZTA0AAAAJ:Y0pCki6q_DkC,"Glaucoma is a major cause of blindness and is frequently associated with elevated intraocular pressure. The trabecular meshwork (TM), the tissue that primarily regulates intraocular pressure, is known to have reduced cellularity in glaucoma. Thus, stem cells, if properly delivered to the TM, may offer a novel therapeutic option for intraocular pressure control in glaucoma patients. For this purpose, targeted delivery of stem cells to the TM is desired. Here, we used magnetic nanoparticles (Prussian blue nanocubes [PBNCs]) to label mesenchymal stem cells and to magnetically steer them to the TM following injection into the eye’s anterior chamber. PBNC-labeled stem cells showed increased delivery to the TM vs. unlabeled cells after only 15-minute exposure to a magnetic field. Further, PBNC-labeled mesenchymal stem cells could be delivered to the entire circumference of the TM, which was not possible without …",Nature Publishing Group UK,,2018
1112,Gold nanoparticles conjugated with DNA aptamer for photoacoustic detection of human matrix metalloproteinase-9,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQnZTA0AAAAJ&citation_for_view=vQnZTA0AAAAJ:Zph67rFs4hoC,"Matrix metalloproteinase-9 (MMP-9) plays major roles in extracellular matrix (ECM) remodeling and membrane protein cleavage, suggesting a high correlation with cancer cell invasion and tumor metastasis. Here, we present a contrast agent based on a DNA aptamer that can selectively target human MMP-9 in the tumor microenvironment (TME) with high affinity and sensitivity. Surface modification of plasmonic gold nanospheres with the MMP-9 aptamer and its complementary sequences allows the nanospheres to aggregate in the presence of human MMP-9 through DNA displacement and hybridization. Aggregation of gold nanospheres enhances the optical absorption in the first near-infrared window (NIR-I) due to the plasmon coupling effect, thereby allowing us to detect the aggregated gold nanospheres within the TME via ultrasound-guided photoacoustic (US/PA) imaging. Selective and sensitive detection of …",Elsevier,,2022
1113,Prussian blue nanocubes as a multimodal contrast agent for image-guided stem cell therapy of the spinal cord,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQnZTA0AAAAJ&citation_for_view=vQnZTA0AAAAJ:UebtZRa9Y70C,"Translation of stem cell therapies to treat injuries and diseases of the spinal cord is hindered by lack of real-time monitoring techniques to guide regenerative therapies intra- and postoperatively. Thus, we developed an ultrasound (US), photoacoustic (PA), and magnetic resonance (MR) imaging approach augmented with Prussian blue nanocubes (PBNCs) to guide stem cell injections intraoperatively and monitor stem cell therapies in the spinal cord postoperatively. Per the clinical procedure, a multi-level laminectomy was performed in rats ex vivo, and PBNC-labeled stem cells were injected directly into the spinal cord while US/PA images were acquired. US/PA/MR images were also acquired post-surgery. Several features of the imaging approach were demonstrated including detection of low stem cell concentrations, real-time needle guidance and feedback on stem cell delivery, and good agreement between …",Elsevier,,2020
1114,Ultrasound and photoacoustic imaging of cancer,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQnZTA0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vQnZTA0AAAAJ:R3hNpaxXUhUC,"In spite of amazing progress in development of new treatments, cancer continues to represent one of the most significant health challenges of our time. Due to the high variability of disease presentation and progression across patients, advanced functional, molecular, or theranostic imaging techniques are critically needed to better combat disease. The current chapter focuses on the unique role and advantages of ultrasound (US) and photoacoustic (PA) imaging of cancer to enable early detection, personalized therapy guidance, and monitoring. As a hybrid multimodal approach, US/PA imaging provides morphological and functional feedback by leveraging the combined benefits of optics and acoustics. Although both modalities are reviewed in the chapter, we focus on examples emphasizing the complementary benefits of each. We begin by summarizing key theoretical principles and fundamental US/PA imaging …",Academic Press,,2026
1115,Monitoring the immune/tumor microenvironment to improve cancer immunotherapy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQnZTA0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vQnZTA0AAAAJ:TQgYirikUcIC,"immune response in real-time, non-invasively, and longitudinally.5, 6 This allows us to map cell-cell interactions in situ, monitor therapeutic interventions based on the imaging feedback, and link these observations to patient outcomes. This special research topic includes 12 contributions (6 original research articles, 3 reviews, and 2 mini-reviews, and 1 opinion piece) that collectively illustrate the cutting-edge technologies for visualizing and quantifying the complex spatiotemporal dynamics of the immune-tumor microenvironment. These advanced imaging and diagnostic strategies offer profound insights into mechanisms of resistance, guide the optimization of current cancer immunotherapies, and inspire novel treatment strategies. A comprehensive review article by Racacho et al. frames the tumor/immune microenvironment (TIME) as a central determinant of cancer progression and therapeutic response, describing how cellular and molecular interactions drive immune activation or suppression and how modern immunotherapies aim to reprogram these processes. Moreover, it highlights emerging trends in imaging and artificial intelligence (AI) that enable precise visualization of immune dynamics, setting the stage for research advances in this collection. A complementary mini-review article by Purl et al. narrows in on adoptive cellular therapies for liver metastases, emphasizing how the hepatic niche restricts immune cell trafficking and persistence and how advanced imaging platforms, including PET and MRI, can be leveraged to track and optimize therapeutic cell delivery. Articles in this research topic also emphasize the significance of direct …",Frontiers,Frontiers in Immunology,2025
1116,Nanoengineered cytotoxic T cells for photoacoustic image-guided combinatorial cancer therapy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQnZTA0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vQnZTA0AAAAJ:HDshCWvjkbEC,"This study aims to demonstrate that surface engineering of cytotoxic T cells with drug-loaded nanoparticles enhances nanoparticle delivery to induce a more potent combinatorial chemotherapeutic and immunotherapeutic effect, as well as enabling spatial tracking through the use of non-invasive, real-time ultrasound-guided photoacoustic imaging. Ovalbumin (OVA)-targeting OT-1 T cells were functionalized with doxorubicin-loaded, mesoporous silica-coated gold nanorods. In vitro toxicity and synergistic effects were assessed using antigen-matched OVA-expressing melanoma cells, while in vivo studies evaluated therapeutic efficacy. Ultrasound-guided photoacoustic imaging was employed to confirm the targeted delivery of the nanoengineered cells. The integration of optically active, drug-loaded nanoparticles with T cells facilitates precise image-guided delivery and enhances nanoparticle accumulation within …",The Korean Society of Medical and Biological Engineering,,2025
1117,Acoustic loudness factor as an experimental parameter for benchmarking small molecule photoacoustic probes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQnZTA0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vQnZTA0AAAAJ:-f6ydRqryjwC,"Photoacoustic imaging (PAI) is an emerging biomedical imaging modality with promise as a point-of-care diagnostic. This imaging modality relies on optical excitation of an absorber followed by production of ultrasound through the photoacoustic effect, resulting in high spatial resolution with imaging depths in the centimeter range. Herein, we disclose the discovery of the first benchmarking parameter for small molecule dye performance in PAI, which we term the acoustic loudness factor (ALF). ALF can predict dye performance in PAI without the need for access to photoacoustic instrumentation and can be used to guide the systematic evaluation of design strategies to enhance photoacoustic signal. Lastly, we demonstrate that enhancements in ALF can be translated to in vivo PAI. Akin to the use of fluorescence brightness in fluorophore design and evaluation for fluorescence imaging, we anticipate that ALF will …",Nature Publishing Group UK,,2025
1118,Introducing the Stool Stomper: A Device Designed to Enable Accelerated and Standardized Stool Sample Preparation Using the Kato–Katz Technique,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vQnZTA0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vQnZTA0AAAAJ:hC7cP41nSMkC,"Soil-transmitted helminths (STHs) are parasitic worms that impact over 1.5 billion people globally. The Kato–Katz technique analyzes stool samples for STHs, allowing for individual diagnoses of STH infection and the estimation of community-level prevalence. One challenge that arises with the procedure is that lab technicians often struggle to prepare microscope slides of sufficient quality for analysis after one attempt. As a result, Kato–Katz procedures are repeated, wasting time and resources. To aid technicians during in-field slide preparation, we created the Stool Stomper. The Stool Stomper is a user-friendly, handheld mechanical device that applies constant, uniform pressure to stool samples to ensure standardized sample preparation onto microscope slides to improve egg counts. The Stool Stomper was assessed using artificial eggs during in-country testing in a lab setting in Dodoma, Tanzania, by lab technicians with various experience levels, from beginner to advanced. Compared to the traditional method, we found that the Stool Stomper reduced slide preparation time, reduced artificial egg counting time, and standardized artificial egg counts with more consistent and accurate readings. The current pilot study highlights the potential for future development and integration of the Stool Stomper device into the Kato–Katz technique to improve community-based STH treatment.",MDPI,,2025
1119,New modeling and experimental framework to characterize hindered and restricted water diffusion in brain white matter,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UnRdQPMAAAAJ&citation_for_view=UnRdQPMAAAAJ:u-x6o8ySG0sC,"To characterize anisotropic water diffusion in brain white matter, a theoretical framework is proposed that combines hindered and restricted models of water diffusion (CHARMED) and an experimental methodology that embodies features of diffusion tensor and q‐space MRI. This model contains a hindered extra‐axonal compartment, whose diffusion properties are characterized by an effective diffusion tensor, and an intra‐axonal compartment, whose diffusion properties are characterized by a restricted model of diffusion within cylinders. The hindered model primarily explains the Gaussian signal attenuation observed at low b values; the restricted non‐Gaussian model does so at high b. Both high and low b data obtained along different directions are required to estimate various microstructural parameters of the composite model, such as the nerve fiber orientation(s), the T2‐weighted extra‐ and intra‐axonal …","Wiley Subscription Services, Inc., A Wiley Company",,2004
1120,Comprehensive approach for correction of motion and distortion in diffusion‐weighted MRI,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UnRdQPMAAAAJ&citation_for_view=UnRdQPMAAAAJ:d1gkVwhDpl0C,"Patient motion and image distortion induced by eddy currents cause artifacts in maps of diffusion parameters computed from diffusion‐weighted (DW) images. A novel and comprehensive approach to correct for spatial misalignment of DW imaging (DWI) volumes acquired with different strengths and orientations of the diffusion sensitizing gradients is presented. This approach uses a mutual information‐based registration technique and a spatial transformation model containing parameters that correct for eddy current‐induced image distortion and rigid body motion in three dimensions. All parameters are optimized simultaneously for an accurate and fast solution to the registration problem. The images can also be registered to a normalized template with a single interpolation step without additional computational cost. Following registration, the signal amplitude of each DWI volume is corrected to account for size …","Wiley Subscription Services, Inc., A Wiley Company",,2004
1121,Optimal mass transport: Signal processing and machine-learning applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UnRdQPMAAAAJ&citation_for_view=UnRdQPMAAAAJ:SEKBqlyTJecC,"Transport-based techniques for signal and data analysis have recently received increased interest. Given their ability to provide accurate generative models for signal intensities and other data distributions, they have been used in a variety of applications, including content-based retrieval, cancer detection, image superresolution, and statistical machine learning, to name a few, and they have been shown to produce state-of-the-art results. Moreover, the geometric characteristics of transport-related metrics have inspired new kinds of algorithms for interpreting the meaning of data distributions. Here, we provide a practical overview of the mathematical underpinnings of mass transport-related methods, including numerical implementation, as well as a review, with demonstrations, of several applications. Software accompanying this article is available from [43].",IEEE,,2017
1122,The NIH MRI study of normal brain development,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UnRdQPMAAAAJ&citation_for_view=UnRdQPMAAAAJ:M3NEmzRMIkIC,"MRI is increasingly used to study normal and abnormal brain development, but we lack a clear understanding of “normal”. Previous studies have been limited by small samples, narrow age ranges and few behavioral measures. This multi-center project conducted epidemiologically based recruitment of a large, demographically balanced sample across a wide age range, using strict exclusion factors and comprehensive clinical/behavioral measures. A mixed cross-sectional and longitudinal design was used to create a MRI/clinical/behavioral database from approximately 500 children aged 7 days to 18 years to be shared with researchers and the clinical medicine community. Using a uniform acquisition protocol, data were collected at six Pediatric Study Centers and consolidated at a Data Coordinating Center. All data were transferred via a web-network into a MYSQL database that allowed (i) secure data transfer …",Academic Press,,2006
1123,The adaptive bases algorithm for intensity-based nonrigid image registration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UnRdQPMAAAAJ&citation_for_view=UnRdQPMAAAAJ:u5HHmVD_uO8C,"Nonrigid registration of medical images is important for a number of applications such as the creation of population averages, atlas-based segmentation, or geometric correction of functional magnetic resonance imaging (IMRI) images to name a few. In recent years, a number of methods have been proposed to solve this problem, one class of which involves maximizing a mutual information (Ml)-based objective function over a regular grid of splines. This approach has produced good results but its computational complexity is proportional to the compliance of the transformation required to register the smallest structures in the image. Here, we propose a method that permits the spatial adaptation of the transformation's compliance. This spatial adaptation allows us to reduce the number of degrees of freedom in the overall transformation, thus speeding up the process and improving its convergence properties. To …",IEEE,,2003
1124,Corrosion detection from IR thermal images in signed cumulative distribution transform domain,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UnRdQPMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=UnRdQPMAAAAJ:ve7iT2ZEuL4C,"This study introduces a novel approach to detect corrosive defects on metal substrates using infrared (IR) thermal images. Among numerous non-destructive techniques, infrared thermography (IRT) is notable for its effectiveness in identifying invisible surface and subsurface corrosion in materials. Existing methods for corrosion detection from IRT images lack the connection to the physical processes governing the emission of heat by defective areas. This paper proposes a transport-based mathematical model to describe the difference in heat-flow characteristics between the non-corroded and corroded material regions. A novel detection technique is then devised, utilizing the signed cumulative distribution transform (SCDT) and a subspace classifier to classify 1D thermal signals derived from IRT image sequences. Experiments demonstrate that the proposed approach is capable of detecting corrosive regions on …",Elsevier,,2025
1125,Linear optimal transport subspaces for point set classification,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UnRdQPMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=UnRdQPMAAAAJ:PcT55Ow6fAIC,"Learning from point sets is an essential component in many computer vision and machine learning applications. Native, unordered, and permutation-invariant set structure space is challenging to model, particularly for point set classification under spatial deformations. Here, we propose a framework for classifying point sets experiencing certain types of spatial deformations, with a particular emphasis on datasets featuring affine deformations. Our approach employs the linear optimal transport (LOT) transform to obtain a linear embedding of set-structured data. Utilizing the mathematical properties of the LOT transform, we demonstrate its capacity to accommodate variations in point sets by constructing a convex data space, effectively simplifying point set classification problems. Our method, which employs a nearest-subspace algorithm in the LOT space, demonstrates label efficiency, non-iterative behavior, and …",Springer US,,2025
1126,"System, method and computer readable medium for video-based facial weakness analysis for detecting neurological deficits",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UnRdQPMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=UnRdQPMAAAAJ:k6nH7jlkaTkC,"An automated and quantitative facial weakness screening framework that utilizes a Bi-LSTM network to model the temporal dynamics among the shape and appearance features. The technique is beneficial to assist the paramedics or other users to identify the facial weakness in the field or, more importantly, whenever expertise in neurology is not available either for emergency patient triage (eg, pre-hospital stroke care) or chronic disease management (eg, Bell's palsy rehabilitation screen), leading to increased coverage and earlier treatment. The technique provides visualizable and interpretable results to increase its transparency and interpretability. The technique provides for inexpensive solutions that can be used in areas underserved by non-neurologists to more readily identify neurological deficits such as facial weakness in the field or other environment.",,,2025
1127,Local sliced Wasserstein feature sets for illumination invariant face recognition,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UnRdQPMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=UnRdQPMAAAAJ:6ScxedgR18sC,"We present a new method for face recognition from digital images acquired under varying illumination conditions. The method is based on mathematical modeling of local gradient distributions using the Radon Cumulative Distribution Transform (R-CDT) (Kolouri et al., 2015). We demonstrate that lighting variations cause certain types of deformations of local image gradient distributions which, when expressed in R-CDT domain, can be modeled as a subspace. Face recognition is then performed using a nearest subspace method in R-CDT domain of local gradient distributions. Experimental results demonstrate the proposed method outperforms other alternatives in several face recognition tasks with challenging illumination conditions. Python code implementing the proposed method is publicly available, which is integrated as a part of the software package PyTransKit.",Pergamon,,2025
1128,An Efficient Transport-Based Dissimilarity Measure for Time Series Classification under Warping Distortions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UnRdQPMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=UnRdQPMAAAAJ:fc7zyzPI2QAC,"Time Series Classification (TSC) is an important problem with numerous applications in science and technology. Dissimilarity-based approaches, such as Dynamic Time Warping (DTW), are classical methods for distinguishing time series when time deformations are confounding information. In this paper, starting from a deformation-based model for signal classes we define a problem statement for time series classification problem. We show that, under theoretically ideal conditions, a continuous version of classic 1NN-DTW method can solve the stated problem, even when only one training sample is available. In addition, we propose an alternative dissimilarity measure based on Optimal Transport and show that it can also solve the aforementioned problem statement at a significantly reduced computational cost. Finally, we demonstrate the application of the newly proposed approach in simulated and real time series classification data, showing the efficacy of the method.",,,2025
1129,An iterative BP-CNN architecture for channel decoding,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=70LBhKcAAAAJ&citation_for_view=70LBhKcAAAAJ:g3aElNc5_aQC,"Inspired by the recent advances in deep learning, we propose a novel iterative belief propagation - convolutional neural network (BP-CNN) architecture for channel decoding under correlated noise. This architecture concatenates a trained CNN with a standard BP decoder. The standard BP decoder is used to estimate the coded bits, followed by a CNN to remove the estimation errors of the BP decoder and obtain a more accurate estimation of the channel noise. Iterating between BP and CNN will gradually improve the decoding SNR and, hence, result in better decoding performance. To train a well-behaved CNN model, we define a new loss function that involves not only the accuracy of the noise estimation but also the normality test for the estimation errors, i.e., to measure how likely the estimation errors follow a Gaussian distribution. The introduction of the normality test to the CNN training shapes the residual …",IEEE,,2018
1130,Towards optimal power control via ensembling deep neural networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=70LBhKcAAAAJ&citation_for_view=70LBhKcAAAAJ:HbR8gkJAVGIC,"A deep neural network (DNN) based power control method that aims at solving the non-convex optimization problem of maximizing the sum rate of a fading multi-user interference channel is proposed. Towards this end, we first present PCNet, which is a multi-layer fully connected neural network that is specifically designed for the power control problem. A key challenge in training a DNN for the power control problem is the lack of ground truth, i.e., the optimal power allocation is unknown. To address this issue, PCNet leverages the unsupervised learning strategy and directly maximizes the sum rate in the training phase. We then present PCNet+, which enhances the generalization capacity of PCNet by incorporating noise power as an input to the network. Observing that a single PCNet(+) does not universally outperform the existing solutions, we further propose ePCNet(+), a network ensemble with multiple PCNets …",IEEE,,2019
1131,Design and analysis of uplink and downlink communications for federated learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=70LBhKcAAAAJ&citation_for_view=70LBhKcAAAAJ:fFSKOagxvKUC,"Communication has been known to be one of the primary bottlenecks of federated learning (FL), and yet existing studies have not addressed the efficient communication design, particularly in wireless FL where both uplink and downlink communications have to be considered. In this paper, we focus on the design and analysis of physical layer quantization and transmission methods for wireless FL. We answer the question of what and how to communicate between clients and the parameter server and evaluate the impact of the various quantization and transmission options of the updated model on the learning performance. We provide new convergence analysis of the well-known FED AVG under non-i.i.d. dataset distributions, partial clients participation, and finite-precision quantization in uplink and downlink communications. These analyses reveal that, in order to achieve an O(1/T) convergence rate with …",IEEE,,2020
1132,Federated Multi-armed Bandits with Personalization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=70LBhKcAAAAJ&citation_for_view=70LBhKcAAAAJ:nZcligLrVowC,"A general framework of personalized federated multi-armed bandits (PF-MAB) is proposed, which is a new bandit paradigm analogous to the federated learning (FL) framework in supervised learning and enjoys the features of FL with personalization. Under the PF-MAB framework, a mixed bandit learning problem that flexibly balances generalization and personalization is studied. A lower bound analysis for the mixed model is presented. We then propose the Personalized Federated Upper Confidence Bound (PF-UCB) algorithm, where the exploration length is chosen carefully to achieve the desired balance of learning the local model and supplying global information for the mixed learning objective. Theoretical analysis proves that PF-UCB achieves an O (log (T)) regret regardless of the degree of personalization, and has a similar instance dependency as the lower bound. Experiments using both synthetic and real-world datasets corroborate the theoretical analysis and demonstrate the effectiveness of the proposed algorithm.",PMLR,,2021
1133,Collaborative service placement for edge computing in dense small cell networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=70LBhKcAAAAJ&citation_for_view=70LBhKcAAAAJ:DUooU5lO8OsC,"Mobile Edge Computing (MEC) pushes computing functionalities away from the centralized cloud to the proximity of data sources, thereby reducing service provision latency and saving backhaul network bandwidth. Although computation offloading for MEC systems has been extensively studied in the literature, service placement is an equally, if not more, important design topic of MEC, yet receives much less attention. Service placement refers to configuring the service platform and storing the related libraries/databases at the edge server, e.g., MEC-enabled Base Station (BS), which enables corresponding computation tasks to be executed. Due to the limited computing resource, the edge server can host only a small number of services and hence which services to host has to be judiciously decided to maximize the system performance. In this paper, we investigate collaborative service placement in MEC-enabled …",IEEE,,2019
1134,Edge intelligence through in-sensor and near-sensor computing for the artificial intelligence of things,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=70LBhKcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=70LBhKcAAAAJ:jE2MZjpN3IcC,"Artificial intelligence technology transforms traditional sensors from passive data collectors into active computing nodes, performing data processing at the edge. This paradigm shift toward in- and near-sensor computing mitigates inherent inefficiencies associated with data traversal between sensing, memory, and processing units. We introduce emerging device technologies, circuit architectures, algorithmic frameworks, and applications implementing artificial intelligence of things. Our perspective presents technical capabilities, implementation challenges, and strategic roadmaps for edge intelligence.",Nature Publishing Group UK,npj Unconventional Computing,2025
1135,The 11th Mining and Learning from Time Series (MILETS): From Classical Methods to LLMs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=70LBhKcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=70LBhKcAAAAJ:-7ulzOJl1JYC,"Time series data is now pervasive across domains such as healthcare, finance, entertainment, and transportation, driven by advances in sensing technologies that enable continuous data collection. The resulting increase in data volume and complexity poses significant challenges to traditional analysis methods, calling for the development of advanced, interdisciplinary approaches to temporal data mining. This workshop aims to: (1) identify key challenges in learning from time series data, including irregular sampling, spatiotemporal dependencies, and uncertainty quantification; (2) explore recent advances in algorithmic, statistical, theoretical, and systems-based solutions-ranging from classical methods to emerging techniques involving large language models (LLMs); and (3) foster collaboration by highlighting open problems and novel research directions in time series analysis. Bridging theory and practice, the …",,,2025
1136,Graph Prompting for Graph Learning Models: Recent Advances and Future Directions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=70LBhKcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=70LBhKcAAAAJ:AXkvAH5U_nMC,"Graph learning models have demonstrated great prowess in learning expressive representations from large-scale graph data in a wide variety of real-world scenarios. As a prevalent strategy for training powerful graph learning models, the ''pre-training, adaptation'' scheme first pre-trains graph learning models on unlabeled graph data in a self-supervised manner and then adapts them to specific downstream tasks. During the adaptation phase, graph prompting emerges as a promising approach that learns trainable prompts while keeping the pre-trained graph learning models unchanged. In this paper, we present a systematic review of recent advancements in graph prompting. First, we introduce representative graph pre-training methods that serve as the foundation step of graph prompting. Next, we review mainstream techniques in graph prompting and elaborate on how they design learnable prompts for graph …",,Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V. 2,2025
1137,Federated Split Learning with Improved Communication and Storage Efficiency,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=70LBhKcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=70LBhKcAAAAJ:KaMxkj08jr0C,"Federated learning (FL) is one of the popular distributed machine learning (ML) solutions but incurs significant communication and computation costs at edge devices. Federated split learning (FSL) can train sub-models in parallel and reduce the computational burden of edge devices by splitting the model architecture. However, it still requires a high communication overhead due to transmitting the smashed data and gradients between clients and the server in every global round. Furthermore, the server must maintain separate partial models for every client, leading to a significant storage requirement. To address these challenges, this paper proposes a novel communication and storage efficient federated split learning method, termed CSE-FSL, which utilizes an auxiliary network to locally update the weights of the clients while keeping a single model at the server, hence avoiding frequent transmissions of …",IEEE,,2025
1138,Chain-of-Thought Enhanced Shallow Transformers for Wireless Symbol Detection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=70LBhKcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=70LBhKcAAAAJ:jFemdcug13IC,"Transformers have shown potential in solving wireless communication problems, particularly via in-context learning (ICL), where models adapt to new tasks through prompts without requiring model updates. However, prior ICL-based Transformer models rely on deep architectures with many layers to achieve satisfactory performance, resulting in substantial storage and computational costs. In this work, we propose CHain Of thOught Symbol dEtection (CHOOSE), a CoT-enhanced shallow Transformer framework for wireless symbol detection. By introducing autoregressive latent reasoning steps within the hidden space, CHOOSE significantly improves the reasoning capacity of shallow models (1-2 layers) without increasing model depth. This design enables lightweight Transformers to achieve detection performance comparable to much deeper models, making them well-suited for deployment on resource-constrained mobile devices. Experimental results demonstrate that our approach outperforms conventional shallow Transformers and achieves performance comparable to that of deep Transformers, while maintaining storage and computational efficiency. This represents a promising direction for implementing Transformer-based algorithms in wireless receivers with limited computational resources.",,,2025
1139,Fetal outcome in motor-vehicle crashes: effects of crash characteristics and maternal restraint,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=y415HKMAAAAJ&citation_for_view=y415HKMAAAAJ:u-x6o8ySG0sC,"OBJECTIVE This project was undertaken to improve understanding of factors associated with adverse fetal outcomes of pregnant occupants involved in motor-vehicle crashes. STUDY DESIGN In-depth investigations of crashes involving 57 pregnant occupants were performed. Maternal and fetal injuries, restraint information, measures of external and internal vehicle damage, and details about the crash circumstances were collected. Crash severity was calculated using vehicle crush measurements. Chi-square analysis and logistic regression models were used to determine factors with a significant association with fetal outcome. RESULTS Fetal outcome is most strongly associated with crash severity (P < .001) and maternal injury (P = .002). Proper maternal belt-restraint use (with or without airbag deployment) is associated with acceptable fetal outcome (odds ratio = 4.5, P = .033). Approximately half of fetal losses …",Mosby,,2008
1140,National survey of emergency department alcohol screening and intervention practices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=y415HKMAAAAJ&citation_for_view=y415HKMAAAAJ:YOwf2qJgpHMC,"STUDY OBJECTIVE We describe current alcohol screening and brief intervention practices in emergency departments (EDs) at Level I and Level II trauma centers and characterize ED directors' attitudes and perceived barriers associated with these practices among injured patients in the ED. METHODS ED directors at Level I and Level II trauma centers were surveyed about current alcohol screening and intervention practices in the ED, as well as knowledge, attitudes, and perceived barriers to these practices. RESULTS Nearly half (46.0%) of ED directors surveyed responded. The majority (64.5%) reported using a serum alcohol level to routinely screen for unhealthy alcohol use; only 23.6% routinely use standardized instruments. Sixty-five percent of ED directors support screening and 70% support intervention among injured ED patients. Only 15% reported having formal screening and intervention policies in …",Mosby,,2010
1141,Increased depth of subcutaneous fat is protective against abdominal injuries in motor vehicle collisions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=y415HKMAAAAJ&citation_for_view=y415HKMAAAAJ:9ZlFYXVOiuMC,"The objective of this study was to determine the effect of differences in subcutaneous fat depth on adult injury patterns in motor vehicle collisions. Sixty-seven consecutive adult crash subjects aged 19–65 who received computed tomography of their chest, abdomen and pelvis as part of their medical evaluation and who consented to inclusion in the Crash Injury Research Engineering Network (CIREN) study were included. Subcutaneous fat was measured just lateral to the rectus abdominus muscle in a transverse section taken through the subject at the level of L4. Women had significantly greater subcutaneous fat depth than men. Increased subcutaneous fat depth was associated with significantly decreased injury severity to the abdominal region of females. A similar trend was noted in males although it did not reach statistical significance. Our findings suggest that increased subcutaneous fat may be protective …",,,2003
1142,Biomechanics of the human brain during dynamic rotation of the head,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=y415HKMAAAAJ&citation_for_view=y415HKMAAAAJ:D_sINldO8mEC,"Traumatic brain injuries (TBI) are a substantial societal burden. The development of better technologies and systems to prevent and/or mitigate the severity of brain injury requires an improved understanding of the mechanisms of brain injury, and more specifically, how head impact exposure relates to brain deformation. Biomechanical investigations have used computational models to identify these relations, but more experimental brain deformation data are needed to validate these models and support their conclusions. The objective of this study was to generate a dataset describing in situ human brain motion under rotational loading at impact conditions considered injurious. Six head-neck human post-mortem specimens, unembalmed and never frozen, were instrumented with 24 sonomicrometry crystals embedded throughout the parenchyma that can directly measure dynamic brain motion. Dynamic brain …","Mary Ann Liebert, Inc., publishers",,2020
1143,Gender differences in hip anatomy: possible implications for injury tolerance in frontal collisions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=y415HKMAAAAJ&citation_for_view=y415HKMAAAAJ:qjMakFHDy7sC,"Male occupants in frontal motor vehicle collisions have reduced tolerance for hip fractures than females in similar crashes. We studied 92 adult pelvic CT scans and found significant gender differences in bony pelvic geometry, including acetabular socket depth and femoral head width. Significant differences were also noted in the presentation angle of the acetabular socket to frontal loading. The observed differences provide biomechanical insight into why hip injury tolerance may differ with gender. These findings have implications for the future design of vehicle countermeasures as well as finite element models capable of more accurately predicting body tolerances to injury.",,,2004
1144,Peripheral Vasopressor Use in Early Sepsis-Induced Hypotension,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=y415HKMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=y415HKMAAAAJ:5qfkUJPXOUwC,"Importance Evidence supporting the safety of infusing vasopressors through peripheral intravenous catheters (peripheral vasopressors) is largely derived from single-center studies, limiting generalizability. Objective To evaluate factors associated with vasopressor route selection and assess safety and clinical outcomes of peripheral vasopressor administration in early sepsis resuscitation. Design, Setting, and Participants This prospective cohort study is a secondary analysis of the Crystalloid Liberal vs Early Vasopressors in Sepsis (CLOVERS) trial conducted in 60 US hospitals from March 2018 to February 2022. Patients in CLOVERS who received vasopressors within 24 hours of enrollment and did not have central venous access at enrollment were included. Data were analyzed from January 2023 to June 2025. Exposure Route of vasopressor initiation (central or peripheral). Main Outcomes and Measures The …",American Medical Association,,2025
1145,Human Cervical Intervertebral Disc Pressure Response During Non-Injurious Quasistatic Motion: A Feasibility Study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=y415HKMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=y415HKMAAAAJ:XoXfffV-tXoC,"Featured Application This study presents a novel approach to measuring cervical spine intradiscal pressure using a minimally invasive sensor in a whole-body post-mortem human subject (PMHS, i.e., cadaver). The timing, rate, and magnitude of disc loading provided by this sensor are highly significant to gaining insight into cervical spine mechanics during head/neck motion. Abstract The human neck is highly vulnerable in motor vehicle crashes, and cervical spine response data are essential to improve injury prediction tools (e.g., crash test dummies, human body models). This feasibility study aimed to implement the use of pressure sensors in whole-body post-mortem human subject (PMHS) cervical spine intervertebral discs (IVDs) to confirm the feasibility and repeatability of cervical IVD pressure response to biomechanic research. Two fresh frozen whole-body PMHSs were instrumented with miniature pressure sensors (Model 060S, Precision Measurement Company, Ann Arbor, MI, USA) at three cervical IVD levels (C3/C4, C5/C6, and C7/T1) using minimally invasive surgical insertion techniques. Each PMHS underwent three quasistatic motion test trials, and each trial included multiple head/neck motions (i.e., gentle traction, flexion/extension, lateral bending, axial rotation, and forced tension/compression). Results showed marked pressure differences between both the cervical level assessed and the motion undertaken as well as successful intra-subject repeatability between the three motion trials. This study demonstrates that changes in cervical IVD pressure are associated with motion events …",MDPI,,2025
1146,Acetaminophen for prevention and treatment of organ dysfunction in critically ill patients with sepsis: the ASTER randomized clinical trial,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=y415HKMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=y415HKMAAAAJ:86PQX7AUzd4C,"Importance Acetaminophen (paracetamol) has many pharmacological effects that might be beneficial in sepsis, including inhibition of cell-free hemoglobin-induced oxidation of lipids and other substrates. Objective To determine whether acetaminophen increases days alive and free of organ dysfunction in sepsis compared with placebo. Design, Setting, and Participants Phase 2b randomized, double-blind, clinical trial conducted from October 2021 to April 2023 with 90-day follow-up. Adults with sepsis and respiratory or circulatory organ dysfunction were enrolled in the emergency department or intensive care unit of 40 US academic hospitals within 36 hours of presentation. Intervention Patients were randomized to 1 g of acetaminophen intravenously every 6 hours or placebo for 5 days. Main Outcome and Measures The primary end point was days alive and free of organ support (mechanical ventilation, vasopressors …",American Medical Association,,2024
1147,Mass Gathering Medicine: A Guide to the Medical Management of Large Events,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=y415HKMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=y415HKMAAAAJ:ILKRHgRFtOwC,"Mass medical deployments to large events, such as music festivals or sporting events, are increasing in number, size, and complexity. This textbook provides guidance and direction for rational, effective, and practical medical management of mass gathering events for medical leaders. This is the first authoritative text on mass event medicine, filling a much-needed gap in a large and important area of the specialty. An international group of contributors introduce the specialty and cover topics such as general deployment, staffing, equipment, and resources, moving on to more complex issues such as the business aspect of mass gathering medicine and the legal implications. There are also practical chapters on specific types of events and adverse events such as terrorism, severe weather, and civil disobedience. An invaluable text for all healthcare professionals planning for and attending mass events, particularly EMS professionals, large event planners and administrators, and law enforcement and security personnel.",Cambridge University Press,,2024
1148,Using formal verification to evaluate human-automation interaction: A review,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6c19RG8AAAAJ&citation_for_view=6c19RG8AAAAJ:4TOpqqG69KYC,"Failures in complex systems controlled by human operators can be difficult to anticipate because of unexpected interactions between the elements that compose the system, including human-automation interaction (HAI). HAI analyses would benefit from techniques that support investigating the possible combinations of system conditions and HAIs that might result in failures. Formal verification is a powerful technique used to mathematically prove that an appropriately scaled model of a system does or does not exhibit desirable properties. This paper discusses how formal verification has been used to evaluate HAI. It has been used to evaluate human-automation interfaces for usability properties and to find potential mode confusion. It has also been used to evaluate system safety properties in light of formally modeled task analytic human behavior. While capable of providing insights into problems associated with …",IEEE,"IEEE Transactions on Systems, Man, and Cybernetics: Systems",2013
1149,A systematic approach to model checking human–automation interaction using task analytic models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6c19RG8AAAAJ&citation_for_view=6c19RG8AAAAJ:UeHWp8X0CEIC,"Formal methods are typically used in the analysis of complex system components that can be described as “automated” (digital circuits, devices, protocols, and software). Human-automation interaction has been linked to system failure, where problems stem from human operators interacting with an automated system via its controls and information displays. As part of the process of designing and analyzing human-automation interaction, human factors engineers use task analytic models to capture the descriptive and normative human operator behavior. In order to support the integration of task analyses into the formal verification of larger system models, we have developed the enhanced operator function model (EOFM) as an Extensible Markup Language-based, platform- and analysis-independent language for describing task analytic models. We present the formal syntax and semantics of the EOFM and an …",IEEE,,2011
1150,Generating phenotypical erroneous human behavior to evaluate human–automation interaction using model checking,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6c19RG8AAAAJ&citation_for_view=6c19RG8AAAAJ:MXK_kJrjxJIC,"Breakdowns in complex systems often occur as a result of system elements interacting in unanticipated ways. In systems with human operators, human–automation interaction associated with both normative and erroneous human behavior can contribute to such failures. Model-driven design and analysis techniques provide engineers with formal methods tools and techniques capable of evaluating how human behavior can contribute to system failures. This paper presents a novel method for automatically generating task analytic models encompassing both normative and erroneous human behavior from normative task models. The generated erroneous behavior is capable of replicating Hollnagel's zero-order phenotypes of erroneous action for omissions, jumps, repetitions, and intrusions. Multiple phenotypical acts can occur in sequence, thus allowing for the generation of higher order phenotypes. The task …",Academic Press,,2012
1151,Formally verifying human–automation interaction as part of a system model: limitations and tradeoffs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6c19RG8AAAAJ&citation_for_view=6c19RG8AAAAJ:u5HHmVD_uO8C,"Both the human factors engineering (HFE) and formal methods communities are concerned with improving the design of safety-critical systems. This work discusses a modeling effort that leveraged methods from both fields to perform formal verification of human–automation interaction with a programmable device. This effort utilizes a system architecture composed of independent models of the human mission, human task behavior, human-device interface, device automation, and operational environment. The goals of this architecture were to allow HFE practitioners to perform formal verifications of realistic systems that depend on human–automation interaction in a reasonable amount of time using representative models, intuitive modeling constructs, and decoupled models of system components that could be easily changed to support multiple analyses. This framework was instantiated using a patient controlled …",Springer-Verlag,,2010
1152,The mathematical meaninglessness of the NASA task load index: A level of measurement analysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6c19RG8AAAAJ&citation_for_view=6c19RG8AAAAJ:l7t_Zn2s7bgC,"Human mental workload can profoundly impact human performance and is thus an important consideration in the design and operation of many systems. The standard method for assessing human mental workload is the NASA Task Load Index (NASA-TLX). This involves a human operator subjectively rating a task based on six dimensions. These dimensions are combined into a single workload score using one of two methods: scaling and summing the dimensions (where scales are derived from a paired comparisons procedure) or averaging dimensions together. Despite its widespread use, the level of measurement of NASA-TLX's dimensions and its computed workload score has not been investigated. Additionally, nobody has researched whether NASA-TLX's two approaches for computing overall workload are mathematically meaningful with respect to the constituent dimensions' levels of measurement. This …",IEEE,,2023
1153,Integrating an intuitive tactical navigation solution to enable situational awareness for people with visual disabilities,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6c19RG8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6c19RG8AAAAJ:HE397vMXCloC,"This research designed a wearable vibrotactile display for providing intuitive orientation and communication cues to aid in navigation for the visually disabled. The device’s signals were designed to communicate the three levels of situation awareness (SA; perceive, comprehend, and project) intuitively, as if one was being guided by a partner’s hand. We evaluated the effectiveness of this device in a human subject experiment with fully blind participants. Participants were tested in an open 15 ft x 15 ft space with no objects for reference. Performance with the vibrotactile display was compared against participants’ normal methods of navigation based on performance measures (navigation, accuracy, and time). Subjective measures of mental workload, situation awareness, and usability were collected; as were surveys designed to understand how participants’ categorized tactor signals into SA levels. Results showed …",Elsevier,,2025
1154,Examining Dual-Task Interference Effects of Visual and Auditory Perceptual Load in Virtual Reality,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6c19RG8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6c19RG8AAAAJ:_B80troHkn4C,"Immersive environments often require users to perform tasks that vary in sensory modality and processing demands. Dual-task interference arises when such tasks are performed concurrently, often leading to performance declines and safety risks in applied settings. Yet, it remains unclear how perceptual load and task type jointly shape such interference in virtual reality (VR). To address this gap, we examined intramodal and crossmodal effects of visual and auditory load on dual-task interference in a VR dual-task paradigm. Participants performed a continuous visual tracking task while concurrently completing auditory detection tasks of two types: spatial and object-based. Results showed that perceptual load and task type differentially influenced intramodal interference, with stronger effects in the auditory detection task. Contrary to predictions, no crossmodal interference was observed, suggesting a degree of …",Academic Press,,2025
1155,Validation of a Formal Method for Human Error Rate Prediction With Negative Transfer,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6c19RG8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6c19RG8AAAAJ:eMMeJKvmdy0C,"Human error is often associated with system failures. The complexity of human-automation interaction can make it difficult to anticipate what errors can occur and how they contribute to failures. Previous research has shown that task analytic behavior modeling with the enhanced operator function model and the cognitive reliability analysis method (CREAM) can be combined with statistical model checking to make predictions about human error rates, their stochastic impact on system failures, and the effect of negative transfer of design changes on these predictions. These efforts were successful, but the validation studies used artificial examples with limited data. Predictions also slightly overestimated error rates. This article addresses these deficiencies by conducting a validation study based on the prescription order entry interface of the OpenEMR electronic medical record. As part of this, we explored how …",IEEE,,2025
1156,Towards a Signal Detection Based Measure for Assessing Information Quality of Explainable Recommender Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6c19RG8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6c19RG8AAAAJ:AXPGKjj_ei8C,"There is growing interest in explainable recommender systems that provide recommendations along with explanations for the reasoning behind them. When evaluating recommender systems, most studies focus on overall recommendation performance. Only a few assess the quality of the explanations. Explanation quality is often evaluated through user studies that subjectively gather users' opinions on representative explanatory factors that shape end-users' perspective towards the results, not about the explanation contents itself. We aim to fill this gap by developing an objective metric to evaluate Veracity: the information quality of explanations. Specifically, we decompose Veracity into two dimensions: Fidelity and Attunement. Fidelity refers to whether the explanation includes accurate information about the recommended item. Attunement evaluates whether the explanation reflects the target user's preferences. By applying signal detection theory, we first determine decision outcomes for each dimension and then combine them to calculate a sensitivity, which serves as the final Veracity value. To assess the effectiveness of the proposed metric, we set up four cases with varying levels of information quality to validate whether our metric can accurately capture differences in quality. The results provided meaningful insights into the effectiveness of our proposed metric.",,,2025
1157,A Trust-Aware Reinforcement Learning Approach to Enhance Human-Agent Teaming: An Overcooked-AI Study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6c19RG8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6c19RG8AAAAJ:mvPsJ3kp5DgC,"This study integrates a previously developed trust prediction model into a reinforcement learning framework to enhance human-agent collaboration. The ensemble trust prediction model, consisting of long short-term memory and neural network architectures, analyzes gameplay trajectories to predict dynamic trust levels in real-time. We embed this model within the Overcooked-AI environment, modifying the agent's reward strategy to account for trust dynamics. Our integration employs shaped and sparse rewards as well as a bonus point mechanism. Rewards are adjusted based on fluctuations in the predicted trust score to promote trust-building actions and discourage those that erode trust. The bonus point mechanism was intended to incentivize the maintenance of trust above a specified threshold. This novel approach was designed to ensure that the RL agent prioritized trust and cooperation within its decision …",IEEE,,2025
1158,Polypeptide organic radical batteries,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NEflOBIAAAAJ&citation_for_view=NEflOBIAAAAJ:7PzlFSSx8tAC,"In only a few decades, lithium-ion batteries have revolutionized technologies, enabling the proliferation of portable devices and electric vehicles, with substantial benefits for society. However, the rapid growth in technology has highlighted the ethical and environmental challenges of mining lithium, cobalt and other mineral ore resources, and the issues associated with the safe usage and non-hazardous disposal of batteries. Only a small fraction of lithium-ion batteries are recycled, further exacerbating global material supply of strategic elements, –. A potential alternative is to use organic-based redox-active materials, – to develop rechargeable batteries that originate from ethically sourced, sustainable materials and enable on-demand deconstruction and reconstruction. Making such batteries is challenging because the active materials must be stable during operation but degradable at end of life. Further, the …",Nature Publishing Group UK,,2021
1159,"Biomaterials via peptide assembly: Design, characterization, and application in tissue engineering",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NEflOBIAAAAJ&citation_for_view=NEflOBIAAAAJ:qUcmZB5y_30C,"A core challenge in biomaterials, with both fundamental significance and technological relevance, concerns the rational design of bioactive microenvironments. Designed properly, peptides can undergo supramolecular assembly into dynamic, physical hydrogels that mimic the mechanical, topological, and biochemical features of native tissue microenvironments. The relatively facile, inexpensive, and automatable preparation of peptides, coupled with low batch-to-batch variability, motivates the expanded use of assembling peptide hydrogels for biomedical applications. Integral to realizing dynamic peptide assemblies as functional biomaterials for tissue engineering is an understanding of the molecular and macroscopic features that govern assembly, morphology, and biological interactions. In this review, we first discuss the design of assembling peptides, including primary structure (sequence), secondary structure …",Elsevier,Acta biomaterialia,2022
1160,The effect of comb architecture on complex coacervation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NEflOBIAAAAJ&citation_for_view=NEflOBIAAAAJ:d1gkVwhDpl0C,"Complex coacervation is a widely utilized technique for effecting phase separation, though predictive understanding of molecular-level details remains underdeveloped. Here, we couple coarse-grained Monte Carlo simulations with experimental efforts using a polypeptide-based model system to investigate how a comb-like architecture affects complex coacervation and coacervate stability. Specifically, the phase separation behavior of linear polycation-linear polyanion pairs was compared to that of comb polycation-linear polyanion and comb polycation-comb polyanion pairs. The comb architecture was found to mitigate cooperative interactions between oppositely charged polymers, as no discernible phase separation was observed for comb-comb pairs and complex coacervation of linear-linear pairs yielded stable coacervates at higher salt concentration than linear-comb pairs. This behavior was attributed to …",Royal Society of Chemistry,,2017
1161,"Crystallization-driven assembly of fully degradable, natural product-based poly (l-lactide)-block-poly (α-d-glucose carbonate) s in aqueous solution",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NEflOBIAAAAJ&citation_for_view=NEflOBIAAAAJ:WF5omc3nYNoC,"Crystallization-driven self assembly (CDSA) was achieved with fully degradable amphiphilic block polymers derived from three natural products, l-lactide, l-cysteine and d-glucose, to afford spherical and cylindrical nanostructures. A series of functional l-cysteine-modified diblock copolymers, poly(l-lactide)-block-poly(α-d-glucose carbonate)s (PLLA-b-PDGC-cys), was synthesized by organocatalyzed sequential ring-opening polymerization (ROP) of l-lactide and an alkyne-substituted bicyclic α-d-glucose carbonate, followed by UV-initiated thiol-yne “click” reaction with l-cysteine to render the PDGC block hydrophilic. Incubation of the resulting amphiphilic diblock copolymers in water at 65 °C for 30 h, followed by cooling to room temperature yielded spherical, cylindrical and 2D platelet-like bundled cylinder micellar nanostructures, depending on the PLLA weight percentage in the block copolymer, as revealed by …",Elsevier,,2017
1162,Molecular engineering of antimicrobial peptide (AMP)–polymer conjugates,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NEflOBIAAAAJ&citation_for_view=NEflOBIAAAAJ:L8Ckcad2t8MC,"As antimicrobial resistance becomes an increasing threat, bringing significant economic and health burdens, innovative antimicrobial treatments are urgently needed. While antimicrobial peptides (AMPs) are promising therapeutics, exhibiting high activity against resistant bacterial strains, limited stability and toxicity to mammalian cells has hindered clinical development. Attaching AMPs to polymers provides opportunities to present AMPs in a way that maximizes bacterial killing while enhancing compatibility with mammalian cells, stability, and solubility. Conjugation of an AMP to a linear hydrophilic polymer yields the desired improvements in stability, mammalian cell compatibility, and solubility, yet often markedly reduces bactericidal effects. Non-linear polymer architectures and supramolecular assemblies that accommodate multiple AMPs per polymer chain afford AMP–polymer conjugates that strike a superior …",Royal Society of Chemistry,Biomaterials science,2021
1163,Programming Peptide Assembly for Advanced Biomaterials: Organic Processing Conditions and Stereocomplexation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NEflOBIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=NEflOBIAAAAJ:u_35RYKgDlwC,,AIChE,,2025
1164,Repressed ang 1-7 in covid-19 is inversely associated with inflammation and coagulation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NEflOBIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=NEflOBIAAAAJ:pqnbT2bcN3wC,"(201301); A61K 45/06 (2013 01)(57) ABSTRACT Provided are methods for treating subjects with coronavirus infections. The methods include providing a subject infected with a coronavirus resulting in a prothrombotic condition in addition to being infected by a coronavirus, and administering to the subject an angiotensin (1-7) peptide or an analog or derivative thereof, a Mas Receptor (MasR) agonist, or any combination thereof. The subject may be suffering from COVID-19 disease, including but not limited to a thrombotic complication, an adverse pregnancy outcome, and/or a complication resulting from an underlying prothrombotic state. Also provided are compositions that include Ang (1-7) peptides, analogs, and/or derivatives thereof that are associated with degradable and/or nondegradable polymers having electrostatic interactions therewith, hydrophobic interaction therewith, hydrogen bonding interactions …",,,2025
1165,Presenting Antimicrobial Peptides on Poly (ethylene glycol): Star-Shaped vs Comb-Like Architectures,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NEflOBIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=NEflOBIAAAAJ:M05iB0D1s5AC,"Conjugating antimicrobial peptides (AMPs) to nonlinear polymers is a promising strategy to overcome the translational challenges of AMPs toward treating infections caused by antibiotic-resistant bacteria. Nonlinear polymers, and therefore conjugates, can be prepared with various architectures (e.g., star-shaped, comb-like, hyperbranched, etc.), however, the effects of polymer architecture on antimicrobial performance and related properties, like size and morphology in solution and secondary structure, are not yet well-understood. Here, we compare conjugates of the human chemokine-derived AMP stapled P9 with poly(ethylene glycol) (PEG) prepared in two of the major nonlinear architectures: star-shaped and comb-like. At comparable molecular weights and compositions (peptide wt %), comb-like conjugates afford increased helicity, solubility, antimicrobial activity, and proteolytic stability compared to star …",American Chemical Society,,2025
1166,Orally Delivered Milk-Derived Nanovesicles Loaded with Connexin 43 Peptides for Targeted Cardiac Ischemia-Reperfusion Therapy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=NEflOBIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=NEflOBIAAAAJ:ldfaerwXgEUC,"Extracellular vesicles have emerged as promising nanocarriers for targeted drug delivery, but their therapeutic potential is limited by challenges related to administration route, loading, targeted delivery and production at scale. Here, we report an innovative approach for targeted delivery of therapeutic peptides to injured tissues using milk-derived small extracellular vesicles (mEVs) as an abundant, safe, orally administrable nanoplatform. We demonstrate that a sub-population of mEVs naturally contain Connexin 43 (Cx43) and its Carboxyl-Terminal (CT) polypeptides, which have been shown to play crucial roles in wound healing and tissue repair. Leveraging this intrinsic property, we developed an esterification method to efficiently and uniformly load mEVs with enhanced levels of an exogenous Cx43 CT peptide (αCT11 - RPRPDDLEI), as assessed by flow cytometry-based vesicle quantification and mass spectrometry. These engineered mEVs exhibited remarkable injury targeting capabilities, with > 30-fold increases in uptake by injured cells compared to non-wounded cells in vitro and preferential accumulation in wounded tissues in vivo. Notably, αCT11-loaded mEVs orally administered after myocardial infarction reduced infarct size by >60% and preserved heart function in a mouse model of ischemia-reperfusion injury. This study represents a significant advance in nanomedicine, demonstrating the utilization of naturally occurring milk-derived extracellular vesicles as an oral delivery system for therapeutic peptides, achieving unprecedented targeting efficiency and efficacy in the treatment of myocardial ischemia-reperfusion injury.",Cold Spring Harbor Laboratory,,2025
1167,Multi-scale modeling of ionic electrospray emission,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z3xMOP0AAAAJ&citation_for_view=z3xMOP0AAAAJ:KlAtU1dfN6UC,"The physics of ionic electrospray propulsion spans multiple length scales. This paper combines a molecular dynamics model, a particle–particle model, and a particle-in-cell model to investigate the physics of ionic electrospray propulsion over 9 orders of magnitude in length scale. The combined models are applied to simulate beam emission for an ionic electrospray propulsion system with porous emitter tips and 1-ethyl-3-methylimidazolium tetrafluoroborate ionic liquid propellant from the emission site to the downstream plume. Additionally, the impact of multiple emission sites from a single emitter tip is analyzed with regard to extractor grid interception and overall beam neutralization for bipolar thruster pairs. Results show that beams consisting of species of different masses (ie, monomer and dimer species) are affected by particle–particle forces during acceleration and should not be treated as a superposition of …",AIP Publishing LLC,,2022
1168,Grid-based Vlasov simulation of collisionless plasma expansion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z3xMOP0AAAAJ&citation_for_view=z3xMOP0AAAAJ:MXK_kJrjxJIC,"Grid-based Vlasov simulations are carried out to re-evaluate the one-dimensional collisionless plasma expansion into vacuum. The grid-based method eliminates the inherent statistical noise in particle-based methods and allows us to extend the solution beyond the self-similar expansion region and resolve small electron timescale wave perturbations. It is shown that the expansion generates both an ion-acoustic rarefaction wave mode and an electron Langmuir wave mode that propagate into the unperturbed plasma upstream. The assumption used in the classical expansion solution that the electrons are an isothermal fluid is accurate within a quasi-neutral, self-similar expansion region but fails in both the upstream and downstream of that region due to electron timescale perturbations.",AIP Publishing LLC,,2021
1169,Simulations of Pure Ionic Electrospray Thruster Plume Neutralization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z3xMOP0AAAAJ&citation_for_view=z3xMOP0AAAAJ:roLk4NBRz8UC,Fully kinetic Particle-in-Cell simulations are carried out to study the neutralization process of pure ionic electrospray thruster bi-polar operation. We find that beam neutralization is achieved mainly through ion bouncing inside a potential well established between the beam front and the exit along the beam direction. The alternating accelerations of the positive and negative ions also create an oscillation pattern in the beam.,,,2020
1170,Grid-Based Kinetic Simulations of Collisionless Plasma Expansion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z3xMOP0AAAAJ&citation_for_view=z3xMOP0AAAAJ:UebtZRa9Y70C,"Previous fully kinetic PIC simulations showed that the electrons in the plasma plume emitted from electric propulsion thrusters are non-equilibrium and the electron temperature is anisotropic. To further study the electron kinetic properties in plasma expansion and to reduce the interference from numerical noise in particle simulations, this study presents a grid-based Vlasov method model. This model is benchmarked against particlein-cell simulations and analytical solutions on semi-infinite collisionless plasma expansion and finite-size collisionless plasma expansion. It is shown that the Vlasov model captures the same anisotropic kinetic characteristics observed in previous full PIC simulation results and eliminates the interference from the typical numerical noise in a PIC model.",,,2019
1171,Development of a Parallel Multi-dimensional Grid-based Vlasov Solver for Plasma Plume Simulation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z3xMOP0AAAAJ&citation_for_view=z3xMOP0AAAAJ:5nxA0vEk-isC,"View Video Presentation: https://doi.org/10.2514/6.2021-3413.vid A parallel multi-dimensional grid-based Vlasov solver named Vlasolver is introduced in this paper. The simulation model and algorithm is introduced in detail. Both numerical implementations and parallelization strategies are described. Two-stream instability, linear and non-linear Landau damping problems are used to verify the code correctness. It is shown that the results agree well with the linear theory. Parallelization efficiency is tested by using two-stream instability cases with the same set-up but a different processesnumber. It is found the Vlasolver can remain a good efficiency. Collisionless plasma plume expansion is considered and results agree well with the self-similar solutions to the semi-infinite expansion problems. The iso-contour lines of density show a smooth pattern in the low-density region and this suggests the grid-based method …",,,2021
1172,Vlasov simulations of electric propulsion beam,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z3xMOP0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=z3xMOP0AAAAJ:dhFuZR0502QC,"A grid-based Vlasov simulation model is developed to simulate the two-dimensional unmagnetized electric propulsion (EP) plasma beam emission process. Comparing to the standard fully kinetic Particle-in-Cell simulation, the grid-based Vlasov simulation method eliminates the interference of particle noise and is capable of resolving higher-order velocity moment, such as electron heat flux, accurately. Vlasov simulations are carried out to investigate the effects of microscopic electron kinetics on macroscopic electron thermodynamics in EP beam. We find that the electron velocity distribution function (eVDF) exhibits a near-Maxwellian shape but with a depleted negative velocity tail in the beam direction and a'top-hat'shape in the transverse direction. Macroscopically, the electrons confined within the quasi-neutral beam core region has a near constant temperature along the beam direction but follow a near …",IOP Publishing,,2024
1173,Quantifying PIC Noise Effects on Particle Velocity Moments: Comparisons of PIC and Vlasov Simulations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z3xMOP0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=z3xMOP0AAAAJ:QIV2ME_5wuYC,"It is well understood that Particle-in-Cell (PIC) simulation results are affected by the inherent statistical noise of the macro-particles. While the statistical noise level of PIC method in general scales inversely with the square root of the number of particles per cell, its exact effect on the different orders of particle velocity moments obtained from simulation is less clear. This paper investigates the statistical noise effects on particle velocity moments in fully kinetic PIC simulations through comparisons of PIC and grid-based Vlasov simulations. The grid-based Vlasov method eliminates the statistical noise in PIC. We present correlated PIC and Vlasov simulations of plasma expansion and several representative instability problems, with a focus on the electron kinetics and thermodynamic in the processes. We derive the scaling of PIC statistical noise in density, velocity, temperature, and heat flux. We discuss the limitations of …",,,2024
1174,Impact of Initial Non-Maxwellian Electron Velocity Distribution Function on Electric Propulsion Beam Expansion: Grid-Based Vlasov Simulations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z3xMOP0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=z3xMOP0AAAAJ:qxL8FJ1GzNcC,"This study investigates the impact of initial non-Maxwellian electron velocity distribution functions (eVDFs) on beam expansion in electric propulsion devices, using grid-based Vlasov simulations. The study primarily focuses on understanding the influence of augmented high-energy electrons which are represented by the Kappa distribution in this work on ion acceleration and electron thermodynamics during the beam expansion process. The Kappa distribution function is used to mimic the augmented high-energy electrons in this study. A near-constant acceleration ratio for different degrees of enhanced high-energy electrons at different time moments is found in this study. An anomalous electron temperature enhancement is found in the beam expansion process when starting with an initial Kappa velocity distribution. Furthermore, the electron heat flux characteristics appear similar for both initial Maxwellian and …",,,2024
1175,Rigorously conservative charge and current deposition in 3D cylindrical PIC,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z3xMOP0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=z3xMOP0AAAAJ:YOwf2qJgpHMC,"A charge and current deposition method is presented for electromagnetic particle-in-cell simulations in 3D cylindrical coordinates using Yee’s grid. The method is a direct extension of Villasenor and Buneman’s current deposition method from Cartesian to 3D cylindrical coordinates, through computing the volumes swept by cylindrical sector charges over the current density surfaces. Along with Verboncoeur’s correct volume terms for cylindrical coordinates, the method satisfies the continuity equation rigorously and eliminates edge errors.",Springer International Publishing,,2023
1176,Electron Scale Physics in Plasma Expansion: Grid-based Vlasov Simulations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z3xMOP0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=z3xMOP0AAAAJ:Wp0gIr-vW9MC,"Plasma expansion is a fundamental plasma dynamics problem and has various applications such as spacecraft plasma wake formation and electric propulsion plume expansion. Previous studies of plasma expansion have mostly focused on the ion time scale whereas the electrons were commonly treated as an equilibrium charge-neutralizing fluid. However, recent studies have shown that the electrons during plasma expansion are non-equilibrium and highly anisotropic and that the massless fluid assumption for electrons breaks down in the outer expansion region. Recently, Cui and Wang also showed that the electron Langmuir wave is excited during one-dimensional plasma expansion which propagates ahead of the ion rarefaction wave into the unperturbed plasma. In this work, a parallel multi-dimensional grid-based Vlasov-Poisson system solver recently developed at USC, Vlasolver, is used to study the …",IEEE,,2023
1177,Synthesis of human-in-the-loop control protocols for autonomous systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HiyMQzEAAAAJ&citation_for_view=HiyMQzEAAAAJ:W7OEmFMy1HYC,"We propose an approach to synthesize control protocols for autonomous systems that account for uncertainties and imperfections in interactions with human operators. As an illustrative example, we consider a scenario involving road network surveillance by an unmanned aerial vehicle (UAV) that is controlled remotely by a human operator but also has a certain degree of autonomy. Depending on the type (i.e., probabilistic and/or nondeterministic) of knowledge about the uncertainties and imperfections in the human–automation interactions, we use abstractions based on Markov decision processes and augment these models to stochastic two-player games. Our approach enables the synthesis of operator-dependent optimal mission plans for the UAV, highlighting the effects of operator characteristics (e.g., workload, proficiency, and fatigue) on UAV mission performance. It can also provide informative feedback (e …",IEEE,,2016
1178,Safe multi-agent reinforcement learning via shielding,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HiyMQzEAAAAJ&citation_for_view=HiyMQzEAAAAJ:NaGl4SEjCO4C,"Multi-agent reinforcement learning (MARL) has been increasingly used in a wide range of safety-critical applications, which require guaranteed safety (e.g., no unsafe states are ever visited) during the learning process.Unfortunately, current MARL methods do not have safety guarantees. Therefore, we present two shielding approaches for safe MARL. In centralized shielding, we synthesize a single shield to monitor all agents' joint actions and correct any unsafe action if necessary. In factored shielding, we synthesize multiple shields based on a factorization of the joint state space observed by all agents; the set of shields monitors agents concurrently and each shield is only responsible for a subset of agents at each step.Experimental results show that both approaches can guarantee the safety of agents during learning without compromising the quality of learned policies; moreover, factored shielding is more scalable in the number of agents than centralized shielding.",,,2021
1179,Deeptake: Prediction of driver takeover behavior using multimodal data,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HiyMQzEAAAAJ&citation_for_view=HiyMQzEAAAAJ:bEWYMUwI8FkC,"Automated vehicles promise a future where drivers can engage in non-driving tasks without hands on the steering wheels for a prolonged period. Nevertheless, automated vehicles may still need to occasionally hand the control back to drivers due to technology limitations and legal requirements. While some systems determine the need for driver takeover using driver context and road condition to initiate a takeover request, studies show that the driver may not react to it. We present DeepTake, a novel deep neural network-based framework that predicts multiple aspects of takeover behavior to ensure that the driver is able to safely take over the control when engaged in non-driving tasks. Using features from vehicle data, driver biometrics, and subjective measurements, DeepTake predicts the driver’s intention, time, and quality of takeover. We evaluate DeepTake performance using multiple evaluation metrics …",,,2021
1180,Medirl: Predicting the visual attention of drivers via maximum entropy deep inverse reinforcement learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HiyMQzEAAAAJ&citation_for_view=HiyMQzEAAAAJ:blknAaTinKkC,"Inspired by human visual attention, we propose a novel inverse reinforcement learning formulation using Maximum Entropy Deep Inverse Reinforcement Learning (MEDIRL) for predicting the visual attention of drivers in accident-prone situations. MEDIRL predicts fixation locations that lead to maximal rewards by learning a task-sensitive reward function from eye fixation patterns recorded from attentive drivers. Additionally, we introduce EyeCar, a new driver attention dataset in accident-prone situations. We conduct comprehensive experiments to evaluate our proposed model on three common benchmarks:(DR (eye) VE, BDD-A, DADA-2000), and our EyeCar dataset. Results indicate that MEDIRL outperforms existing models for predicting attention and achieves state-of-the-art performance. We present extensive ablation studies to provide more insights into different features of our proposed model.",,,2021
1181,Controller synthesis for autonomous systems interacting with human operators,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HiyMQzEAAAAJ&citation_for_view=HiyMQzEAAAAJ:2osOgNQ5qMEC,"We propose an approach to synthesize control protocols for autonomous systems that account for uncertainties and imperfections in interactions with human operators. As an illustrative example, we consider a scenario involving road network surveillance by an unmanned aerial vehicle (UAV) that is controlled remotely by a human operator but also has a certain degree of autonomy. Depending on the type (i.e., probabilistic and/or nondeterministic) of knowledge about the uncertainties and imperfections in the operator-autonomy interactions, we use abstractions based on Markov decision processes and augment these models to stochastic two-player games. Our approach enables the synthesis of operator-dependent optimal mission plans for the UAV, highlighting the effects of operator characteristics (e.g., workload, proficiency, and fatigue) on UAV mission performance; it can also provide informative feedback (e …",,,2015
1182,Robust Permissive Controller Synthesis for Interval MDPs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HiyMQzEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=HiyMQzEAAAAJ:08ZZubdj9fEC,"We address the problem of robust permissive controller synthesis for robots operating under uncertain dynamics, modeled as Interval Markov Decision Processes (IMDPs). IMDPs generalize standard MDPs by allowing transition probabilities to vary within intervals, capturing epistemic uncertainty from sensing noise, actuation imprecision, and coarse system abstractions-common in robotics. Traditional controller synthesis typically yields a single deterministic strategy, limiting adaptability. In contrast, permissive controllers (multi-strategies) allow multiple actions per state, enabling runtime flexibility and resilience. However, prior work on permissive controller synthesis generally assumes exact transition probabilities, which is unrealistic in many robotic applications. We present the first framework for robust permissive controller synthesis on IMDPs, guaranteeing that all strategies compliant with the synthesized multi-strategy satisfy reachability or reward-based specifications under all admissible transitions. We formulate the problem as mixed-integer linear programs (MILPs) and propose two encodings: a baseline vertex-enumeration method and a scalable duality-based method that avoids explicit enumeration. Experiments on four benchmark domains show that both methods synthesize robust, maximally permissive controllers and scale to large IMDPs with up to hundreds of thousands of states.",,,2025
1183,IrrMap: A Large-Scale Comprehensive Dataset for Irrigation Method Mapping,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HiyMQzEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=HiyMQzEAAAAJ:p2g8aNsByqUC,"We introduce IrrMap, the first large-scale dataset (1.1 million patches) for irrigation method mapping across regions. IrrMap consists of multi-resolution satellite imagery from LandSat and Sentinel, along with key auxiliary data such as crop type, land use, and vegetation indices. The dataset spans 1,668,899 farms and 11,443,492 acres across multiple western U.S. states from 2013 to 2023, providing a rich and diverse foundation for irrigation analysis and ensuring geospatial alignment and quality control. The dataset is ML-ready, with standardized 224×224 GeoTIFF patches, the multiple input modalities, carefully chosen train-test-split data, and accompanying dataloaders for seamless deep learning model training and benchmarking in irrigation mapping. The dataset is also accompanied by a complete pipeline for dataset generation, enabling researchers to extend IrrMap to new regions for irrigation data collection …",,,2025
1184,Runtime Safety through Adaptive Shielding: From Hidden Parameter Inference to Provable Guarantees,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HiyMQzEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=HiyMQzEAAAAJ:K3LRdlH-MEoC,"Variations in hidden parameters, such as a robot's mass distribution or friction, pose safety risks during execution. We develop a runtime shielding mechanism for reinforcement learning, building on the formalism of constrained hidden-parameter Markov decision processes. Function encoders enable real-time inference of hidden parameters from observations, allowing the shield and the underlying policy to adapt online. The shield constrains the action space by forecasting future safety risks (such as obstacle proximity) and accounts for uncertainty via conformal prediction. We prove that the proposed mechanism satisfies probabilistic safety guarantees and yields optimal policies among the set of safety-compliant policies. Experiments across diverse environments with varying hidden parameters show that our method significantly reduces safety violations and achieves strong out-of-distribution generalization, while incurring minimal runtime overhead.",,,2025
1185,Counterfactual Explanations for Continuous Action Reinforcement Learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HiyMQzEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=HiyMQzEAAAAJ:u9iWguZQMMsC,"Reinforcement Learning (RL) has shown great promise in domains like healthcare and robotics but often struggles with adoption due to its lack of interpretability. Counterfactual explanations, which address ""what if"" scenarios, provide a promising avenue for understanding RL decisions but remain underexplored for continuous action spaces. We propose a novel approach for generating counterfactual explanations in continuous action RL by computing alternative action sequences that improve outcomes while minimizing deviations from the original sequence. Our approach leverages a distance metric for continuous actions and accounts for constraints such as adhering to predefined policies in specific states. Evaluations in two RL domains, Diabetes Control and Lunar Lander, demonstrate the effectiveness, efficiency, and generalization of our approach, enabling more interpretable and trustworthy RL applications.",,,2025
1186,"ChatGPT: Applications, opportunities, and threats",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rby-obUAAAAJ&citation_for_view=rby-obUAAAAJ:Y0pCki6q_DkC,"Developed by OpenAI, ChatGPT (Conditional Generative Pre-trained Transformer) is an artificial intelligence technology that is fine-tuned using supervised machine learning and reinforcement learning techniques, allowing a computer to generate natural language conversation fully autonomously. ChatGPT is built on the transformer architecture and trained on millions of conversations from various sources. The system combines the power of pre-trained deep learning models with a programmability layer to provide a strong base for generating natural language conversations. In this study, after reviewing the existing literature, we examine the applications, opportunities, and threats of ChatGPT in 10 main domains, providing detailed examples for the business and industry as well as education. We also conducted an experimental study, checking the effectiveness and comparing the performances of GPT-3.5 and …",IEEE,,2023
1187,Profit-oriented partial disassembly line design: dealing with hazardous parts and task processing times uncertainty,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rby-obUAAAAJ&citation_for_view=rby-obUAAAAJ:u5HHmVD_uO8C,"This paper addresses the problem of profit-oriented disassembly line design and balancing considering partial disassembly, presence of hazardous parts and uncertainty of task processing times. Few papers have studied the stochastic disassembly line balancing problem and existing approaches have focused on heuristic and metaheuristic methods. Most existing work has concentrated on complete disassembly where task times are assumed to be normal random variables and where AND/OR graphs are not considered. The objective of this paper is the design of a serial line that obtains the maximum revenue and then balances the workload under uncertainty. The processing time of a disassembly task is assumed to be a random variable with any known probability distribution. An AND/OR graph is used to model the precedence relationships among tasks. Stochastic programming models and exact-based …",Taylor & Francis,,2018
1188,Disassembly line balancing under high variety of end of life states using a joint precedence graph approach,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rby-obUAAAAJ&citation_for_view=rby-obUAAAAJ:d1gkVwhDpl0C,"Disassembly is an important aspect of end of life product treatment, as well as having products disassembled in an efficient and responsible manner. Disassembly line balancing is a technique that enables a product to be disassembled as efficiently and economically viable as possible; however, considering all possible end of life (EOL) states of a product makes disassembly line balancing very difficult. The EOL state and the possibility of multiple recovery options of a product can alter both disassembly tasks and task times for the disassembly of the EOL product. This paper shows how generating a joint precedence graph based on the different EOL states of a product is beneficial to achieving an optimal line balance where traditional line balancing approaches are used. We use a simple example of a pen from the literature to show how a joint disassembly precedence graph is created and a laptop example for joint …",Elsevier,,2015
1189,Disassembly liaison graphs inspired by word clouds,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rby-obUAAAAJ&citation_for_view=rby-obUAAAAJ:qjMakFHDy7sC,"Liaison or connection graphs depict physical mates between components in a graphical representation but do not incorporate any precedence relations or order of assembly or disassembly of components. For the context of disassembly, we developed a method to graphically show not only the physical mates between components but also the disassembly precedence relations amongst all the components. The transformation of a liaison graph into a weighted liaison graph (WLG) is inspired by the generation of word clouds from the visual design domain where component nodes are weighted and colored to depict disassembly precedence relations. A WLG allows users to quickly comprehend the order of disassembly and component embeddedness.",Elsevier,,2013
1190,"Social choice rules, fallback bargaining, and related games in common resource conflicts",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rby-obUAAAAJ&citation_for_view=rby-obUAAAAJ:IjCSPb-OGe4C,"Due to the lack of resources, individuals, groups, or countries are more involved in common resource conflicts. This paper uses the Graph Model for Conflict Resolution methodology to model a conflict based on the Nash solution concept, General Meta-Rationality, Symmetric Meta-Rationality, Sequential Stability, Limited h Move Stability, and Non-Myopic Stability definitions and then sieve the socially optimal outcomes from the results of the graph model. We propose to add a new analytical stage as a sequential next step to the equilibria in the Graph Model for Conflict Resolution and utilize social choice voting rules such as the Borda score, the Plurality rule, the Median voting rule, Copeland’s method, Simpson’s rule, and Fallback bargaining. We also apply a new approach called Related games, where we show how the Leading game impacts the Consequential game’s outcome and equilibria. To demonstrate the …",Elsevier,,2021
1191,Refining a Novel AI Restaurant Recommender Application: A Systems Approach to Increasing User Engagement and Retention,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rby-obUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rby-obUAAAAJ:MXK_kJrjxJIC,"Deciding which restaurant to eat at often poses an inconvenience for many individuals. The decision-making process is riddled with a variety of factors such as personal preferences, social dynamics, and an overwhelming number of options. Our study addresses this issue by partnering with a startup, dinemait, that utilizes an artificial intelligence (AI) recommendation model to provide curated restaurant suggestions to its mobile application users. The goal of this work is centered around improving dinemait’s application to retain and grow its active user base. Our team used a systems-based approach to increase user engagement by: (1) evaluating the existing application, and (2) improving outreach features and techniques. After an internal review of the application, a study was conducted to gain user-centric data to further assess it. It consisted of focus group discussions and surveys to gain insight into necessary …",IEEE,2025 Systems and Information Engineering Design Symposium (SIEDS),2025
1192,Check-In Check-Up: Analyzing and Improving Pre-Appointment Engagement in a Primary Care Clinic at UVA Health System,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rby-obUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rby-obUAAAAJ:8k81kl-MbHgC,"The UVA Health System utilizes a cloud-based electronic medical record (EMR) platform, featuring a secure patient portal that helps patients manage their health. This portal empowers users by enabling them to complete key health tasks, such as communicating with their care team, accessing health records, and coordinating appointments. This project focuses on increasing pre-appointment engagement through the patient portal to enhance the patient experience at a primary care clinic (PCC) within UVA Health.Patients can be assigned multiple types of pre-appointment tasks via the portal. One task, referred to as eCheck-In, is available to all patients prior to their appointment. This allows patients to complete necessary paperwork before their appointments, which streamlines visits. However, eCheck-Ins were completed for only 35.3% of patient encounters in 2024 at the PCC. To gather insights into this issue, an …",IEEE,,2025
1193,Redesign of the University of Virginia’s Emergency Department Waiting Room Layout to Optimize Patient Flow and Increase Satisfaction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rby-obUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rby-obUAAAAJ:5nxA0vEk-isC,"Increasing demands on emergency departments (EDs) due to rising patient volumes and operational inefficiencies necessitate innovative solutions to enhance patient flow and satisfaction. Data from UVA Health reveals substantial ED crowding, with a 12% increase in ED visits between 2022 and 2023, and a 25% increase from 2021 to 2023. To address these challenges, a simulated redesign of the waiting room at the University of Virginia (UVA) ED was completed to improve space utilization and streamline patient movement. Current designs, characterized by repeated patient returns to the waiting area, create congestion and hinder the perception of progress in care. This redesign aims to expand available space and create “progression areas” where patients can be effectively managed post-triage, reducing returns to the main lobby and thereby minimizing congestion. Utilizing FlexSim HC simulation software, both the current …",IEEE,,2025
1194,A novel approach for multi-objective truck scheduling problems in a cross-docking center,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rby-obUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rby-obUAAAAJ:hqOjcs7Dif8C,"Cross-docking implementation pursues different goals, including integrating transportation, shorter delivery time, and cost reduction. In this paper, we proposed an operational approach to schedule the trucks in a cross-docking system considering the breakdown probability of the trucks, capacity constraint, and earliness penalty under a just-in-time approach. The proposed objective functions, to be minimized, represent the total completion time and the outbound trucks’ earliness and tardiness. As our problem is an NP-hard, we used genetic algorithm functions with a non-dominated sorting procedure, and particle swarm optimization algorithm to reach near-optimal solutions and compared these two algorithms using test problems with four different indexes; (1) quality (2) mean ideal distance, (3) diversity, and (4) the number of Pareto solutions. We performed sensitivity analyses to show the sensitivity of breakdown …",Springer India,,2024
1195,Expanding VIAble Employment for Adults with Autism: A Systems Approach to Increase Nonprofit Sales,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rby-obUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rby-obUAAAAJ:Se3iqnhoufwC,"Across industries, people with disabilities face barriers obtaining and maintaining employment. Our project addresses this issue through a partnership with VIAble Ventures, a microbusiness run by the VIA Centers for Neurodevelopment. VIAble Ventures sells spa products like candles and bath salts, all of which are made by artisans with autism. The program provides on-site job training and a source of income for adults with intellectual and developmental disorders. The goal of this work was centered on increasing VIAble Venture sales to expand employment opportunities for autistic adults in the local Charlottesville area. Currently, sales depend heavily on availability and seasonality of in-person sales and limited online sales. Our team used a systems approach to increase online sales on VIAble Venture’s website by: (1) analyzing past transactions, and (2) redesigning the website. Using data analytics, we …",IEEE,,2024
1196,Automobile injury trends in the contemporary fleet: Belted occupants in frontal collisions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyM1HJAAAAAJ&citation_for_view=JyM1HJAAAAAJ:l7t_Zn2s7bgC,"Objective: As vehicle safety technologies and evaluation procedures advance, it is pertinent to periodically evaluate injury trends to identify continuing and emerging priorities for intervention. This study examined detailed injury distributions and injury risk trends in belted occupants in frontal automobile collisions (10 o’clock to 2 o’clock) using NASS-CDS (1998–2015). Methods: Injury distributions were examined by occupant age and vehicle model year (stratified at pre- and post-2009). Logistic regression models were developed to examine the effects of various factors on injury risk (by body region), controlling for delta-V, sex, age, height, body mass index (BMI), vehicle model year (again stratified at 2009). Results: Among other observations, these analyses indicate that newer model year vehicles (model year [MY] 2009 and later) carry less risk of Abbreviated Injury Scale (AIS) 2+ and AIS 3+ injury compared to …",Taylor & Francis,,2019
1197,Human surrogates for injury biomechanics research,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyM1HJAAAAAJ&citation_for_view=JyM1HJAAAAAJ:V3AGJWp-ZtQC,"This article reviews the attributes of the human surrogates most commonly used in injury biomechanics research. In particular, the merits of human cadavers, human volunteers, animals, dummies, and computational models are assessed relative to their ability to characterize the living human response and injury in an impact environment. Although data obtained from these surrogates have enabled biomechanical engineers and designers to develop effective injury countermeasures for occupants and pedestrians involved in crashes, the magnitude of the traffic safety problem necessitates expanded efforts in research and development. This article makes the case that while there are limitations and challenges associated with any particular surrogate, each provides a critical and necessary component in the continued quest to reduce crash‐related injuries and fatalities. Clin. Anat. 24:362–371, 2011. © 2011 Wiley …","Wiley Subscription Services, Inc., A Wiley Company",Clinical anatomy,2011
1198,Accidental injury: biomechanics and prevention,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyM1HJAAAAAJ&citation_for_view=JyM1HJAAAAAJ:fQNAKQ3IYiAC,"This book provides a state-of-the-art look at the applied biomechanics of accidental injury and prevention. The editors, Drs. Narayan Yoganandan, Alan M. Nahum and John W. Melvin are recognized international leaders and researchers in injury biomechanics, prevention and trauma medicine. They have assembled renowned researchers as authors for 29 chapters to cover individual aspects of human injury assessment and prevention. This third edition is thoroughly revised and expanded with new chapters in different fields. Topics covered address automotive, aviation, military and other environments. Field data collection; injury coding/scaling; injury epidemiology; mechanisms of injury; human tolerance to injury; simulations using experimental, complex computational models (finite element modeling) and statistical processes; anthropomorphic test device design, development and validation for crashworthiness applications in topics cited above; and current regulations are covered. Risk functions and injury criteria for various body regions are included. Adult and pediatric populations are addressed. The exhaustive list of references in many areas along with the latest developments is valuable to all those involved or intend to pursue this important topic on human injury biomechanics and prevention. The expanded edition will interest a variety of scholars and professionals including physicians, biomedical researchers in many disciplines, basic scientists, attorneys and jurists involved in accidental injury cases and governmental bodies. It is hoped that this book will foster multidisciplinary collaborations by medical and engineering researchers …",Springer,,2014
1199,Predicting rib fracture risk with whole-body finite element models: development and preliminary evaluation of a probabilistic analytical framework,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyM1HJAAAAAJ&citation_for_view=JyM1HJAAAAAJ:YsMSGLbcyi4C,"This study sought to develop a strain-based probabilistic method to predict rib fracture risk with whole-body finite element (FE) models, and to describe a method to combine the results with collision exposure information to predict injury risk and potential intervention effectiveness in the field. An age-adjusted ultimate strain distribution was used to estimate local rib fracture probabilities within an FE model. These local probabilities were combined to predict injury risk and severity within the whole ribcage. The ultimate strain distribution was developed from a literature dataset of 133 tests. Frontal collision simulations were performed with the THUMS (Total HUman Model for Safety) model with four levels of delta-V and two restraints: a standard 3-point belt and a progressive 3.5–7 kN force-limited, pretensioned (FL+PT) belt. The results of three simulations (29 km/h standard, 48 km/h standard, and 48 km/h FL+PT) were …",,,2012
1200,A Novel Method for Quantifying Human In Situ Whole Brain Deformation under Rotational Loading Using Sonomicrometry,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyM1HJAAAAAJ&citation_for_view=JyM1HJAAAAAJ:CHSYGLWDkRkC,"Traumatic brain injuries (TBI) are one of the least understood injuries to the body. Finite element (FE) models of the brain have been crucial for understanding concussion and for developing injury mitigation systems; however, the experimental brain deformation data currently used to validate these models are limited. The objective of this study was to develop a methodology for the investigation of in situ three-dimensional brain deformation during pure rotational loading of the head, using sonomicrometry. Sonomicrometry uses ultrasonic pulses to measure the dynamic distances between piezoelectric crystals implanted in any sound-transmitting media. A human cadaveric head-neck specimen was acquired 14 h postmortem and was instrumented with an array of 32 small sonomicrometry crystals embedded in the head: 24 crystals were implanted in the brain, and 8 were fixed to the inner skull. A dynamic rotation …","Mary Ann Liebert, Inc.",,2018
1201,Disc Injury and Spine Loads in Low-to-Moderate-Severity Frontal Impacts: R. Kent and J. Forman,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyM1HJAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=JyM1HJAAAAAJ:L7CI7m0gUJcC,"Purpose Determine the cervical and lumbar spine forces and moments generated in belted occupants in frontal impacts up to 40-km/h change in velocity () and assess their potential to cause spinal disc injury. Methods Loads experienced by anthropomorphic test devices, human volunteers, and human cadavers were measured in 282 impact tests. Functions were developed to describe the expected loads as functions of for small females, mid-size males, and large males. Loads were contextualized by comparison to injury assessment reference values, manual lifting standards, the compressive loads that have caused spinal disc injuries in vitro, and the compressive spinal loads that occur in other situations. Results The functions confirm that the spinal loads are well below any established injury assessment reference value. Compressive loads are within the range of loads voluntarily tolerated during daily activities …",Springer International Publishing,,2025
1202,"Assessing seatbelt use among pregnant drivers in Australia: correct seatbelt positioning, discomfort, knowledge and information sources",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyM1HJAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=JyM1HJAAAAAJ:BUYA1_V_uYcC,"Background: Correct seatbelt use during pregnancy is critical for ensuring maternal and fetal safety during a motor vehicle crash. This study aimed to investigate seatbelt use among pregnant vehicle drivers in Australia, focusing on correct seatbelt positioning and the potential influence of comfort and the receipt of seatbelt information. Method: An online survey was completed by 1,491 participants (M = 33.2 years, SD = 4.1, Range = 18.0 – 50.0 years). Results: While nearly all participants (99.1%) reported ‘always’ wearing their seatbelt while driving a vehicle, only 41.4% met the correct seatbelt positioning criteria, defined as positioning the lap belt under the belly and low over the upper thighs and the shoulder belt between the breasts. Despite increased discomfort with seatbelt use as pregnancy advanced, discomfort was not significantly associated with correct seatbelt positioning. Additionally, while most …",Pergamon,,2025
1203,Evaluation of THOR-50M-RS under reclined seating conditions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyM1HJAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=JyM1HJAAAAAJ:vbGhcppDl1QC,"Objective Testing was conducted to evaluate the performance of the THOR-50M for Reclined Seating (THOR-50M-RS) with modifications to allow for a more realistic posture and impact response under reclined seating conditions. Results were compared to tests conducted with PMHS under the same conditions. Methods Nine frontal sled tests were conducted using the THOR-50M-RS in a controlled response seat with the seatback angle set to 45 degrees. Three tests were conducted under each of three conditions: (1) nominal 32 km/h delta V, 4.5 kN seatbelt load limiter (LL), knee bolster condition 1 (180 mm spacing); (2) nominal 50 km/h delta V, 2.7 kN LL, knee bolster condition 1; and (3) nominal 50 km/h delta V, 2.7 kN LL, knee bolster condition 2 (100 mm spacing). The ATD was positioned using a seating procedure based on data from volunteers in reclined seats. THOR-50M-RS instrumentation …",Taylor & Francis,,2025
1204,"Seatbelt use trends by pregnancy status and state in the United States, 2011–2024",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyM1HJAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=JyM1HJAAAAAJ:ML0RJ9NH7IQC,"Objectives Seatbelts decrease injuries and fatalities in motor vehicle collisions. Most seatbelt use studies are performed at a national or international scale, yet many lack data granularity to evaluate trends in population subgroups that might have differing belt use behaviors, such as pregnant females. Using data from the Center of Disease Control and Prevention Behavioral Risk Factor Surveillance System (BRFSS), this study aims to evaluate geographic differences in habitual seatbelt use and trends over time across respondent factors, focusing on pregnant females. Methods Weighted responses of “always wearing seatbelt” in the 2011–2024 BRFSS were aggregated by state, year, age group, sex, and pregnancy status and analyzed using a Bayesian zero-one-inflated beta regression. State seatbelt enforcement was coded as primary or secondary and added into the model. Results There were 1,149,325 total …",Taylor & Francis,,2025
1205,Pulmonary injury risk assessment for short-duration blasts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=THpvWA0AAAAJ&citation_for_view=THpvWA0AAAAJ:2osOgNQ5qMEC,"Background: Blast injuries are becoming more common in modern war and terrorist action. This increasing threat underscores the importance of understanding and evaluating blast effects. Methods: For this study, data on more than 2,550 large animal experiments were collected from more than 50 experimental studies on blast. From this dataset, over 1,100 large animal experiments were selected with positive phase overpressure durations of 30 milliseconds or less. A two variable nonlinear logistic regression was performed on the experimental data for threshold injury and lethality in terms of pressure and duration. The effects of mass, pressure, and duration scaling were all evaluated. Results: New injury risk assessment curves were analyzed for both incident and reflected pressure conditions. Position dependent injury risk curves were also analyzed and were found to be unnecessary, at least for prone and side on …",LWW,,2008
1206,Pressure-induced mechanical stress in the carotid artery bifurcation: a possible correlation to atherosclerosis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=THpvWA0AAAAJ&citation_for_view=THpvWA0AAAAJ:9yKSN-GCB0IC,"A possible correlation between regions of high intramural wall stress and the development of atherosclerotic lesions in the carotid artery bifurcation is investigated. The bifurcation geometry is determined through in vivo studies, as well as the analysis of cadaver specimens. Having compiled accurate geometric data, two representative finite element models were created in order to determine the areas of localized stress concentrations that occur in the bifurcation. The artery is assumed isotropic and is mechanically loaded with an incremental pressure of 40 mmHg. A highly localized stress concentration of approximately 9 to 14 times the proximal circumferential wall stress occurs at the point of bifurcation. A lower stress concentration of approximately 3 to 4 times the proximal cirumferential stress occurs over a large area of the sinus bulb. Acknowledging that these two regions of the carotid bifurcation are highly …",Elsevier,,1995
1207,Experimental investigation of cavitation as a possible damage mechanism in blast-induced traumatic brain injury in post-mortem human subject heads,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=THpvWA0AAAAJ&citation_for_view=THpvWA0AAAAJ:OU6Ihb5iCvQC,"The potential of blast-induced traumatic brain injury from the mechanism of localized cavitation of the cerebrospinal fluid (CSF) is investigated. While the mechanism and criteria for non-impact blast-induced traumatic brain injury is still unknown, this study demonstrates that local cavitation in the CSF layer of the cranial volume could contribute to these injuries. The cranial contents of three post-mortem human subject (PMHS) heads were replaced with both a normal saline solution and a ballistic gel mixture with a simulated CSF layer. Each were instrumented with multiple pressure transducers and placed inside identical shock tubes at two different research facilities. Sensor data indicates that cavitation may have occurred in the PMHS models at pressure levels below those for a 50% risk of blast lung injury. This study points to skull flexion, the result of the shock wave on the front of the skull leading to a negative …","Mary Ann Liebert, Inc.",,2017
1208,Survival risk assessment for primary blast exposures to the head,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=THpvWA0AAAAJ&citation_for_view=THpvWA0AAAAJ:IjCSPb-OGe4C,"Many soldiers returning from the current conflicts in Iraq and Afghanistan have had at least one exposure to an explosive event and a significant number have symptoms consistent with traumatic brain injury. Although blast injury risk functions have been determined and validated for pulmonary injury, there is little information on the blast levels necessary to cause blast brain injury. Anesthetized male New Zealand White rabbits were exposed to varying levels of shock tube blast exposure focused on the head, while their thoraces were protected. The specimens were euthanized and evaluated when the blast resulted in respiratory arrest that was non-responsive to resuscitation or at 4 h post-exposure. Injury was evaluated by gross examination and histological evaluation. The fatality data from brain injury were then analyzed using Fisher's exact test to determine a brain fatality risk function. Greater blast intensity was …","Mary Ann Liebert, Inc.",,2011
1209,Use of a Porcine Cadaver Model as a Human Surrogate for Behind Armor Blunt Trauma,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=THpvWA0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=THpvWA0AAAAJ:eMMeJKvmdy0C,"Current body armor design evaluation is based on legacy backface deformation criteria for protection despite limited medical basis. This uniform protection approach, which does not account for anatomical and physiological variability within the torso, may result in heavy armors that limit Warfighter mobility. To optimize armor design, anatomical and physiological regional injury tolerances must be assessed through live animal experimentation. Prior to this, the animal and human must first be compared to determine the animal model's viability as a surrogate for thoracoabdominal behind armor blunt trauma (BABT) response. Here, 74 BABT impacts were conducted using ten midsized male postmortem human subjects (PMHS) and ten 40-kg porcine cadavers in matched testing conditions over the lungs, liver, and sternum. Injury risk functions were generated from experimental data and compared across …",American Society of Mechanical Engineers,,2025
1210,Back Muscle Activity During One Hour of Vertical Vibration Simulating a Helicopter Flight,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=THpvWA0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=THpvWA0AAAAJ:_B80troHkn4C,"Purpose Back pain is detected at high rates in helicopter aircrew members, leading in some cases to flying incapacitations. The cause of this pain remains unclear in this population. The goal of this research is to better understand how muscles respond over time (1 h) in a seat that vertically vibrates simulating a helicopter flight. Methods Surface electromyography (EMG) data at six locations (middle trapezius, erector spinae, longissimus, iliocostalis lumborum, and multifidus) was collected in 14 subjects during 1 h of vertical whole-body vibration (0.2 g at 4 Hz). To simulate a helicopter flight, a rigid seat with the dimensions of an H-60 helicopter was used, including pedals and hand controls of a flight simulator, HGU-56/P helmets and a 5-point harness. The EMG readings were collected at 0, 15, 30, 45, and 60 min during the vibrational exposure. Results Low muscle activity was seen in all the tracked muscles with …",Springer International Publishing,,2025
1211,A Systematic Literature Review of Impact Systems for Developing Generalized Medical Injury Criteria for Behind Armor Blunt Trauma,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=THpvWA0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=THpvWA0AAAAJ:tkaPQYYpVKoC,"Introduction The focus of previous reviews on behind armor blunt trauma (BABT) as applied to the thoraco-abdominal region has been the rationale for the clay deformation-based standard of 44 mm and injuries from field and laboratory studies. The objective of this study was to conduct a systematic literature review of BABT studies with a focus on impact systems used to deliver high-rate compressive loads to the thorax and development of injury criteria in the form of risk curves for enhanced medical injury criteria. Materials and Methods The widely used PubMed database was accessed to identify articles for a systematic literature review ranging from its inception until November 15, 2024. The detailed review focused on articles covering thoraco-abdominal injuries using biological and other models, impact delivery systems, presence of body armor, and development of injury …",Oxford University Press,Military Medicine,2025
1212,Matched-pair hybrid test paradigm for behind armor blunt trauma using an experimental animal model,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=THpvWA0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=THpvWA0AAAAJ:AXPGKjj_ei8C,"Background The current behind armor blunt trauma (BABT) injury criterion uses a single penetration limit of 44 mm in Roma Plastilina clay and is not specific to thoracoabdominal regions. However, different regions in the human body have different injury tolerances. This manuscript presents a matched-pair hybrid test paradigm with different experimental models and candidate metrics to develop regional human injury criteria. Methods Live and cadaver swine were used as matched pair experimental models. An impactor simulating backface deformation profiles produced by body armor from military-relevant ballistics was used to deliver BABT loading to liver and lung regions in cadaver and live swine. Impact loading was characterized using peak accelerations and energy. For live swine, physiological parameters were monitored for 6 hours, animals were euthanized, and a detailed necropsy was done to identify …",BMJ Publishing Group Ltd,,2024
1213,Development of a biofidelic computational model of human pelvis for predicting biomechanical responses and pelvic fractures,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=THpvWA0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=THpvWA0AAAAJ:Mojj43d5GZwC,"Background and objective The pelvis, a crucial structure for human locomotion, is susceptible to injuries resulting in significant morbidity and disability. This study aims to introduce and validate a biofidelic computational pelvis model, enhancing our understanding of pelvis injury mechanisms under lateral loading conditions. Methods The Finite Element (FE) pelvic model, representing a mid-sized male, was developed with variable cortical thickness in pelvis bones. Material properties were determined through a synthesis of existing constitutive models, parametric studies, and multiple validations. Comprehensive validation included various tests, such as load-displacement assessments of sacroiliac joints, quasi-static and dynamic lateral compression on the acetabulum, dynamic side impacts on the acetabulum and iliac wing using defleshed pelvis, and lateral impacts by a rigid plate on the full body's pelvis region …",Pergamon,,2024
1214,Stein variational message passing for continuous graphical models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PyK6cB0AAAAJ&citation_for_view=PyK6cB0AAAAJ:u5HHmVD_uO8C,"We propose a novel distributed inference algorithm for continuous graphical models, by extending Stein variational gradient descent (SVGD) to leverage the Markov dependency structure of the distribution of interest. Our approach combines SVGD with a set of structured local kernel functions defined on the Markov blanket of each node, which alleviates the curse of high dimensionality and simultaneously yields a distributed algorithm for decentralized inference tasks. We justify our method with theoretical analysis and show that the use of local kernels can be viewed as a new type of localized approximation that matches the target distribution on the conditional distributions of each node over its Markov blanket. Our empirical results show that our method outperforms a variety of baselines including standard MCMC and particle message passing methods.",,,2018
1215,SIMPLE: A Gradient Estimator for k-Subset Sampling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PyK6cB0AAAAJ&citation_for_view=PyK6cB0AAAAJ:5nxA0vEk-isC,,,,2023
1216,Efficient Search-Based Weighted Model Integration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PyK6cB0AAAAJ&citation_for_view=PyK6cB0AAAAJ:d1gkVwhDpl0C,"Weighted model integration (WMI) extends Weighted model counting (WMC) to the integration of functions over mixed discrete-continuous domains. It has shown tremendous promise for solving inference problems in graphical models and probabilistic programming. Yet, state-of-the-art tools for WMI are limited in terms of performance and ignore the independence structure that is crucial to improving efficiency. To address this limitation, we propose an efficient model integration algorithm for theories with tree primal graphs. We exploit the sparse graph structure by using search to performing integration. Our algorithm greatly improves the computational efficiency on such problems and exploits context-specific independence between variables. Experimental results show dramatic speedups compared to existing WMI solvers on problems with tree-shaped dependencies.",,,2019
1217,Probabilistically Rewired Message-Passing Neural Networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PyK6cB0AAAAJ&citation_for_view=PyK6cB0AAAAJ:aqlVkmm33-oC,"Message-passing graph neural networks (MPNNs) emerged as powerful tools for processing graph-structured input. However, they operate on a fixed input graph structure, ignoring potential noise and missing information. Furthermore, their local aggregation mechanism can lead to problems such as over-squashing and limited expressive power in capturing relevant graph structures. Existing solutions to these challenges have primarily relied on heuristic methods, often disregarding the underlying data distribution. Hence, devising principled approaches for learning to infer graph structures relevant to the given prediction task remains an open challenge. In this work, leveraging recent progress in exact and differentiable -subset sampling, we devise probabilistically rewired MPNNs (PR-MPNNs), which learn to add relevant edges while omitting less beneficial ones. For the first time, our theoretical analysis explores how PR-MPNNs enhance expressive power, and we identify precise conditions under which they outperform purely randomized approaches. Empirically, we demonstrate that our approach effectively mitigates issues like over-squashing and under-reaching. In addition, on established real-world datasets, our method exhibits competitive or superior predictive performance compared to traditional MPNN models and recent graph transformer architectures.",,,2024
1218,Scaling up Hybrid Probabilistic Inference with Logical and Arithmetic Constraints via Message Passing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PyK6cB0AAAAJ&citation_for_view=PyK6cB0AAAAJ:W7OEmFMy1HYC,"Weighted model integration (WMI) is an appealing framework for probabilistic inference: it allows for expressing the complex dependencies in real-world problems, where variables are both continuous and discrete, via the language of Satisfiability Modulo Theories (SMT), as well as to compute probabilistic queries with complex logical and arithmetic constraints. Yet, existing WMI solvers are not ready to scale to these problems. They either ignore the intrinsic dependency structure of the problem entirely, or they are limited to overly restrictive structures. To narrow this gap, we derive a factorized WMI computation enabling us to devise a scalable WMI solver based on message passing, called MP-WMI. Namely, MP-WMI is the first WMI solver that can (i) perform exact inference on the full class of tree-structured WMI problems, and (ii) perform inter-query amortization, eg, to compute all marginal densities simultaneously. Experimental results show that our solver dramatically outperforms the existingWMI solvers on a large set of benchmarks.",,,2020
1219,Deep generative models with hard linear equality constraints,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PyK6cB0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=PyK6cB0AAAAJ:4DMP91E08xMC,"While deep generative models~(DGMs) have demonstrated remarkable success in capturing complex data distributions, they consistently fail to learn constraints that encode domain knowledge and thus require constraint integration. Existing solutions to this challenge have primarily relied on heuristic methods and often ignore the underlying data distribution, harming the generative performance. In this work, we propose a probabilistically sound approach for enforcing the hard constraints into DGMs to generate constraint-compliant and realistic data. This is achieved by our proposed gradient estimators that allow the constrained distribution, the data distribution conditioned on constraints, to be differentiably learned. We carry out extensive experiments with various DGM model architectures over five image datasets and three scientific applications in which domain knowledge is governed by linear equality constraints. We validate that the standard DGMs almost surely generate data violating the constraints. Among all the constraint integration strategies, ours not only guarantees the satisfaction of constraints in generation but also archives superior generative performance than the other methods across every benchmark.",,,2025
1220,Neurosymbolic Learning and Reasoning for Trustworthy AI,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PyK6cB0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=PyK6cB0AAAAJ:4TOpqqG69KYC,"Along with the ubiquitous applications of Artificial Intelligence (AI), the quest for developing trustworthy AI models intensifies. Deep neural networks, while powerful in learning, fall short in reasoning with domain knowledge and offering robustness guarantees. Neurosymbolic AI bridges this gap by melding the learning capabilities of neural networks and reasoning techniques from symbolic AI, thus building models that behave as intended. This dissertation demonstrates my work that addresses the two fundamental challenges in neurosymbolic AI: 1) enabling differentiable learning of deep neural networks under symbolic constraints and 2) performing scalable and reliable probabilistic reasoning over expressive symbolic constraints. It presents how these neurosymbolic approaches achieve trustworthiness through explainability, uncertainty quantification, and domain-knowledge incorporation. These contributions …",,,2024
1221,A unified approach to count-based weakly supervised learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PyK6cB0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=PyK6cB0AAAAJ:Zph67rFs4hoC,"High-quality labels are often very scarce, whereas unlabeled data with inferred weak labels occurs more naturally. In many cases, these weak labels dictate the frequency of each respective class over a set of instances. In this paper, we develop a unified approach to learning from such weakly-labeled data, which we call* count-based weakly-supervised learning*. At the heart of our approach is the ability to compute the probability of exactly out of outputs being set to true. This computation is differentiable, exact, and efficient. Building upon the previous computation, we derive a* count loss* penalizing the model for deviations in its distribution from an arithmetic constraint defined over label counts.",,,2023
1222,Collapsed inference for bayesian deep learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PyK6cB0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=PyK6cB0AAAAJ:KlAtU1dfN6UC,"Bayesian neural networks (BNNs) provide a formalism to quantify and calibrate uncertainty in deep learning. Current inference approaches for BNNs often resort to few-sample estimation for scalability, which can harm predictive performance, while its alternatives tend to be computationally prohibitively expensive. We tackle this challenge by revealing a previously unseen connection between inference on BNNs and volume computation problems. With this observation, we introduce a novel collapsed inference scheme that performs Bayesian model averaging using collapsed samples. It improves over a Monte-Carlo sample by limiting sampling to a subset of the network weights while pairing it with some closed-form conditional distribution over the rest. A collapsed sample represents uncountably many models drawn from the approximate posterior and thus yields higher sample efficiency. Further, we show that the marginalization of a collapsed sample can be solved analytically and efficiently despite the non-linearity of neural networks by leveraging existing volume computation solvers. Our proposed use of collapsed samples achieves a balance between scalability and accuracy. On various regression and classification tasks, our collapsed Bayesian deep learning approach demonstrates significant improvements over existing methods and sets a new state of the art in terms of uncertainty estimation as well as predictive performance.",,,2023
1223,Federated learning enables big data for rare cancer boundary detection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dr2krBsAAAAJ&citation_for_view=dr2krBsAAAAJ:XiVPGOgt02cC,"Although machine learning (ML) has shown promise across disciplines, out-of-sample generalizability is concerning. This is currently addressed by sharing multi-site data, but such centralization is challenging/infeasible to scale due to various limitations. Federated ML (FL) provides an alternative paradigm for accurate and generalizable ML, by only sharing numerical model updates. Here we present the largest FL study to-date, involving data from 71 sites across 6 continents, to generate an automatic tumor boundary detector for the rare disease of glioblastoma, reporting the largest such dataset in the literature (n = 6, 314). We demonstrate a 33% delineation improvement for the surgically targetable tumor, and 23% for the complete tumor extent, over a publicly trained model. We anticipate our study to: 1) enable more healthcare studies informed by large diverse data, ensuring meaningful results for rare …",Nature Publishing Group UK,,2022
1224,Modeling and forecasting short-term power load with copula model and deep belief network,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dr2krBsAAAAJ&citation_for_view=dr2krBsAAAAJ:f2IySw72cVMC,"Load forecasting is critical for effective scheduling and operation of power systems, which are becoming increasingly complex and uncertain, especially with the penetration of distributed power. This paper proposes a data-driven deep learning framework to forecast the short-term power load. First, the load data is processed by Box-Cox transformation. The tail-dependence of the power load on electricity price and temperature is then investigated by fitting the parametric Copula models and computing the threshold of peak load. Next, a deep belief network is built to forecast the hourly load of the power system. One-year grid load data collected from urban areas in both Texas and Arkansas, in the United States, is utilized in the case studies on short-term load forecasting (day-ahead and week-ahead) is conducted for four seasons independently. The proposed framework is compared with classical neural networks …",IEEE,,2019
1225,Parametric human body shape modeling framework for human-centered product design,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dr2krBsAAAAJ&citation_for_view=dr2krBsAAAAJ:u5HHmVD_uO8C,"The objective of this study is the development of a novel parametric human body shape modeling framework for integration into various product design applications. Our modeling framework is comprised of three phases of database construction, statistical analysis, and model generation. During the database construction phase, a 3D whole body scan data of 250 subjects are obtained, and their data structures are processed so as to be suitable for statistical analysis. Using those preprocessed scan data, the characteristics of the human body shape variation and their correlations with several items of body sizes are investigated in the statistical analysis phase. The correlations obtained from such analysis allow us to develop an interactive modeling interface, which takes the body sizes as inputs and returns a corresponding body shape model as an output. Using this interface, we develop a parametric human body …",Elsevier,,2012
1226,Deep learning for synthetic microstructure generation in a materials-by-design framework for heterogeneous energetic materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dr2krBsAAAAJ&citation_for_view=dr2krBsAAAAJ:OU6Ihb5iCvQC,"The sensitivity of heterogeneous energetic (HE) materials (propellants, explosives, and pyrotechnics) is critically dependent on their microstructure. Initiation of chemical reactions occurs at hot spots due to energy localization at sites of porosities and other defects. Emerging multi-scale predictive models of HE response to loads account for the physics at the meso-scale, i.e. at the scale of statistically representative clusters of particles and other features in the microstructure. Meso-scale physics is infused in machine-learned closure models informed by resolved meso-scale simulations. Since microstructures are stochastic, ensembles of meso-scale simulations are required to quantify hot spot ignition and growth and to develop models for microstructure-dependent energy deposition rates. We propose utilizing generative adversarial networks (GAN) to spawn ensembles of synthetic heterogeneous energetic material …",Nature Publishing Group UK,,2020
1227,Deep segmentation networks predict survival of non-small cell lung cancer,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dr2krBsAAAAJ&citation_for_view=dr2krBsAAAAJ:dshw04ExmUIC,"Non-small-cell lung cancer (NSCLC) represents approximately 80–85% of lung cancer diagnoses and is the leading cause of cancer-related death worldwide. Recent studies indicate that image-based radiomics features from positron emission tomography/computed tomography (PET/CT) images have predictive power for NSCLC outcomes. To this end, easily calculated functional features such as the maximum and the mean of standard uptake value (SUV) and total lesion glycolysis (TLG) are most commonly used for NSCLC prognostication, but their prognostic value remains controversial. Meanwhile, convolutional neural networks (CNN) are rapidly emerging as a new method for cancer image analysis, with significantly enhanced predictive power compared to hand-crafted radiomics features. Here we show that CNNs trained to perform the tumor segmentation task, with no other information than physician …",Nature Publishing Group UK,,2019
1228,A physics-aware deep learning model for shear band formation around collapsing pores in shocked reactive materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dr2krBsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dr2krBsAAAAJ:epqYDVWIO7EC,"Modeling shock-to-detonation phenomena in energetic materials (EMs) requires capturing complex physical processes such as strong shocks, rapid changes in microstructural morphology, and nonlinear dynamics of chemical reaction fronts. These processes participate in energy localization at hotspots, which initiate chemical energy release leading to detonation. This study addresses the formation of hotspots in crystalline EMs subjected to weak-to-moderate shock loading, which, despite its critical relevance to the safe storage and handling of EMs, remains underexplored compared to the well-studied strong shock conditions. To overcome the computational challenges associated with direct numerical simulations, we advance the Physics-Aware Recurrent Convolutional Neural Network (PARCv2), which has been shown to be capable of predicting strong shock responses in EMs. We improved the architecture of …",AIP Publishing,,2025
1229,Towards a Physics Foundation Model,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dr2krBsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dr2krBsAAAAJ:EkHepimYqZsC,"Foundation models have revolutionized natural language processing through a ``train once, deploy anywhere'' paradigm, where a single pre-trained model adapts to countless downstream tasks without retraining. Access to a Physics Foundation Model (PFM) would be transformative -- democratizing access to high-fidelity simulations, accelerating scientific discovery, and eliminating the need for specialized solver development. Yet current physics-aware machine learning approaches remain fundamentally limited to single, narrow domains and require retraining for each new system. We present the General Physics Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that demonstrates foundation model capabilities are achievable for physics. Our key insight is that transformers can learn to infer governing dynamics from context, enabling a single model to simulate fluid-solid interactions, shock waves, thermal convection, and multi-phase dynamics without being told the underlying equations. GPhyT achieves three critical breakthroughs: (1) superior performance across multiple physics domains, outperforming specialized architectures by up to 29x, (2) zero-shot generalization to entirely unseen physical systems through in-context learning, and (3) stable long-term predictions through 50-timestep rollouts. By establishing that a single model can learn generalizable physical principles from data alone, this work opens the path toward a universal PFM that could transform computational science and engineering.",,,2025
1230,Reduced Order Modeling of Energetic Materials Using Physics-Aware Recurrent Convolutional Neural Networks in a Latent Space (LatentPARC),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dr2krBsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dr2krBsAAAAJ:ipzZ9siozwsC,"Physics-aware deep learning (PADL) has gained popularity for use in complex spatiotemporal dynamics (field evolution) simulations, such as those that arise frequently in computational modeling of energetic materials (EM). Here, we show that the challenge PADL methods face while learning complex field evolution problems can be simplified and accelerated by decoupling it into two tasks: learning complex geometric features in evolving fields and modeling dynamics over these features in a lower dimensional feature space. To accomplish this, we build upon our previous work on physics-aware recurrent convolutions (PARC). PARC embeds knowledge of underlying physics into its neural network architecture for more robust and accurate prediction of evolving physical fields. PARC was shown to effectively learn complex nonlinear features such as the formation of hotspots and coupled shock fronts in various initiation scenarios of EMs, as a function of microstructures, serving effectively as a microstructure-aware burn model. In this work, we further accelerate PARC and reduce its computational cost by projecting the original dynamics onto a lower-dimensional invariant manifold, or 'latent space.' The projected latent representation encodes the complex geometry of evolving fields (e.g. temperature and pressure) in a set of data-driven features. The reduced dimension of this latent space allows us to learn the dynamics during the initiation of EM with a lighter and more efficient model. We observe a significant decrease in training and inference time while maintaining results comparable to PARC at inference. This work takes steps towards …",,,2025
1231,Towards fair decentralized benchmarking of healthcare AI algorithms with the Federated Tumor Segmentation (FeTS) challenge,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dr2krBsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dr2krBsAAAAJ:0KyAp5RtaNEC,"Computational competitions are the standard for benchmarking medical image analysis algorithms, but they typically use small curated test datasets acquired at a few centers, leaving a gap to the reality of diverse multicentric patient data. To this end, the Federated Tumor Segmentation (FeTS) Challenge represents the paradigm for real-world algorithmic performance evaluation. The FeTS challenge is a competition to benchmark (i) federated learning aggregation algorithms and (ii) state-of-the-art segmentation algorithms, across multiple international sites. Weight aggregation and client selection techniques were compared using a multicentric brain tumor dataset in realistic federated learning simulations, yielding benefits for adaptive weight aggregation, and efficiency gains through client sampling. Quantitative performance evaluation of state-of-the-art segmentation algorithms on data distributed internationally …",Nature Publishing Group UK,,2025
1232,Latent Representation Learning of Multi-scale Thermophysics: Application to Dynamics in Shocked Porous Energetic Material,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dr2krBsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dr2krBsAAAAJ:nrtMV_XWKgEC,"Coupling of physics across length and time scales plays an important role in the response of microstructured materials to external loads. In a multi-scale framework, unresolved (subgrid) meso-scale dynamics is upscaled to the homogenized (macro-scale) representation of the heterogeneous material through closure models. Deep learning models trained using meso-scale simulation data are now a popular route to assimilate such closure laws. However, meso-scale simulations are computationally taxing, posing practical challenges in training deep learning-based surrogate models from scratch. In this work, we investigate an alternative meta-learning approach motivated by the idea of tokenization in natural language processing. We show that one can learn a reduced representation of the micro-scale physics to accelerate the meso-scale learning process by tokenizing the meso-scale evolution of the physical fields involved in an archetypal, albeit complex, reactive dynamics problem, \textit{viz.}, shock-induced energy localization in a porous energetic material. A probabilistic latent representation of \textit{micro}-scale dynamics is learned as building blocks for \textit{meso}-scale dynamics. The \textit{meso-}scale latent dynamics model learns the correlation between neighboring building blocks by training over a small dataset of meso-scale simulations. We compare the performance of our model with a physics-aware recurrent convolutional neural network (PARC) trained only on the full meso-scale dataset. We demonstrate that our model can outperform PARC with scarce meso-scale data. The proposed approach accelerates the development …",,,2025
1233,Validating design methods and research: the validation square,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XNS-78IAAAAJ&citation_for_view=XNS-78IAAAAJ:u-x6o8ySG0sC,"Validation of engineering research is typically anchored in the scientific inquiry tradition that is based primarily on logical induction and / or deduction. Since much engineering research is based on mathematical modeling, this kind of validation has worked — and still works — very well. There are, however, other areas of engineering research that rely on subjective statements as well as mathematical modeling, which makes this type of validation problematic. One such area is that of design methods within the field of engineering design. In this paper, we explore the question of how one validates design research in general, and design methods in particular. Being anchored in the scientific inquiry tradition, research validation is strongly tied to a fundamental problem addressed in epistemology, namely, what is scientific knowledge and how is new knowledge confirmed? Thus, we first look to epistemology …",American Society of Mechanical Engineers,,2000
1234,Applying Ecological Input‐Output Flow Analysis to Material Flows in Industrial Systems: Part I: Tracing Flows,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XNS-78IAAAAJ&citation_for_view=XNS-78IAAAAJ:u5HHmVD_uO8C,"Input‐output mathematics, which allows a modeler to fully consider direct and indirect relationships among conserved flows in a system, has a long history in economics with prominent use dating to Leontief in the 1930s. Nearly all previous industrial applications of input‐output analysis have been grounded in the monetary flows of an economy. Here however, because of the central nature of physical flows in the environmental impact of industry, we consider physical flows to be a fundamental component of an industrial economy. Hence, we propose an input‐output based approach for modeling physical flows in industry independent of their monetary implications. In this first part of a two‐part article, a framework for using input‐output mathematics to model material and energy flows is constructed from a foundation laid by previous research in nutrient and energy cycling in natural ecosystems. The mathematics of …",MIT Press,,2004
1235,The validation square: how does one verify and validate a design method,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XNS-78IAAAAJ&citation_for_view=XNS-78IAAAAJ:UeHWp8X0CEIC,"Validation 5 of engineering research has traditionally been anchored in the tradition of scientific inquiry. This demands formal, rigorous and quantitative validation, which is based primarily on logical induction and/or deduction. Since much engineering research is based on mathematical modeling, this kind of validation has worked–and still works–very well. There are, however, other areas of engineering research that rely on subjective statements as well as mathematical modeling, which makes formal, rigorous and quantitative validation problematic. One such area","ASME Press, New York",,2006
1236,Assessing engineering design process knowledge,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XNS-78IAAAAJ&citation_for_view=XNS-78IAAAAJ:qjMakFHDy7sC,"Rigorously assessing students' design process knowledge is essential for understanding how to best create learning environments to facilitate the development of such knowledge. Such assessment is also quite difficult and hence there is a lack of assessment tools capable of measuring design process knowledge of every student in a large college. Faculty from both the Colleges of Engineering and Education at the University of Arizona are developing such a tool. The approach being developed aims at assessing if students can explain and analyze an engineering design process by having them critique a proposed process. Two versions have been developed so as to provide a pre-and post-test. An analytic scoring rubric is used to assess the design knowledge embodied by the student responses. Results from the 2003±4 academic year indicate that one of the two tests has sufficient validity and that the scoring rubric is too detailed for the nature of the tests. Hence, in the second phase of this work, a new test will replace the invalid one and a simpler rubric will be implemented.",TEMPUS PUBLICATIONS,,2007
1237,Applying ecological input‐output flow analysis to material flows in industrial systems: part II: flow metrics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XNS-78IAAAAJ&citation_for_view=XNS-78IAAAAJ:d1gkVwhDpl0C,"This article, continuing with the themes of the companion article, expounds the capabilities of input‐output techniques as applied to material flows in industrial systems. Material flows are the primary focus because of their role in directly linking natural and industrial systems and thereby being fundamental components of environmental issues in industrial economies. The specific topic in this article concerns several material flow metrics used to characterize system behavior that are derived from the ecological development of input‐output techniques; most notable of these metrics are several measures of material cycling and a measure of the number of processes visited by material while in a system. These metrics are shown to be useful in analyzing the state of material flow systems. Further‐more, the metrics are shown to be a central link in connecting input‐output flow analysis to synthesis (i.e., the process of using …",MIT Press,,2004
1238,Using design timelines for tracking and reflection on design processes: Emerging insights,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XNS-78IAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XNS-78IAAAAJ:0N-VGjzr574C,"This paper focuses on better understanding the student experience of tracking and reflecting on design timelines during team-based engineering design projects. While it is clear that doing design is necessary to learn how to design, evidence has shown that the act of doing alone is not sufficient to promote design learning. Layering reflection on top of doing has shown promising results in learning generally-with a challenge for design learning being how to create authentic opportunities for students to reflect deeply and regularly on their design process. In this paper, we explore how the act of self-tracking activities to create visual representations of one's design process provides such authentic opportunities for students across different class years in group projects of different lengths. In particular, we examine the student experience of self-tracking their design activities by analyzing their responses to a survey completed at the conclusion of their projects. The majority of the data points to promising results, showing self-tracking helped students develop metacognitive awareness without viewing reflection as a detraction from their design work.",,2025 ASEE Annual Conference & Exposition,2025
1239,A Decision-Driven Methodology for Business Intelligence Dashboards in Start-Ups,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XNS-78IAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XNS-78IAAAAJ:ruyezt5ZtCIC,"Many businesses rely on data-driven metrics to inform critical decisions and drive success. Data reporting is a common way to facilitate these decisions so businesses may effectively achieve their mission. However, ‘data’ can present a significant obstacle for companies if not appropriately presentable for stakeholders while maintaining accuracy and reliability. The work herein describes the design of dashboard systems that effectively display important metrics based on user and enterprise needs for a startup. Through utilizing user design principles and identifying business needs, we applied the following discovery methodology: understanding and familiarizing ourselves with enterprise data, conducting discovery interviews with stakeholders, and distilling interviews into key business decision needs. From here, we determined system objectives for each decision and metrics for each objective. This methodology …",IEEE,,2025
1240,Impacts of a Short-Term International Engineering and Business Consulting Practicum,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XNS-78IAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XNS-78IAAAAJ:foquWX3nUaYC,"Increase in short-term programs is one of the biggest shifts in study abroad over the past twenty years. With prior research in this area showing many positive but also mixed impacts, skepticism persists about the ability of short-term study abroad to change students’ views on cultural differences. The aim of this study is to characterize if and how students’ views on cultural differences in the context of international client work change after a practicum-based faculty-led short-term study abroad program in Argentina. Twenty-four students who participated in the program responded to short-answer questions before and after the program. These responses were open-coded, and themes were identified. Results show that, before the program, students largely identified surface-level cultural differences from an ethnocentric perspective. After the program, students were more ethnorelative as evidenced by their discussing the deeper cultural context and values of Argentina and their willingness to adapt.",,,2024
1241,A Systems Methodology for Informed Solar Energy Decision-Making,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XNS-78IAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XNS-78IAAAAJ:SpbeaW3--B0C,"Solar technology for buildings has flourished in recent years. The technology is becoming more popular in both the residential and commercial sectors. The process of purchasing solar is often complicated by different proposals from companies that cannot be directly compared. Changing government incentives, multiple financial models, the 25 year panel lifecycle, quickly changing technologies, structural limitations and diverse stakeholder motives make comparing proposals difficult. Presented through a case study of a non-profit in Charlottesville, Virginia, we propose a systems methodology for navigating this complicated landscape. This methodology involves working with stakeholders in the project to establish main objectives, identify current limitations, determine key decisions, and interpret metrics to measure success of a commercial solar project. These objectives, limitations, and decisions are used with …",IEEE,,2024
1242,A model for integrating engineering design into science teacher education,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XNS-78IAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XNS-78IAAAAJ:e_rmSamDkqQC,"The Framework for K-12 Science Education and the Next Generation Science Standards require teachers to integrate engineering design into K-12 science teaching. However, many teachers have no formal preparation in engineering design and how to integrate it into science instruction. Furthermore, few models exist for preparing teachers in engineering design and how to integrate it into science teaching. Therefore, in this paper, we describe the model we have used for the past 8 years to prepare eighty-one (81) secondary pre-service science teachers in engineering design and how to integrate it into science instruction. We have also provided the outcomes and suggestions for implementing this model in science teacher education programs. We believe the model is transferable to other institutions and school districts that are involved in preparing teachers in engineering design integrated science teaching.",Springer Netherlands,,2024
1243,"Thermal conductivity and thermal boundary resistance of atomic layer deposited high-k dielectric aluminum oxide, hafnium oxide, and titanium oxide thin films on silicon",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-MALwVsAAAAJ&citation_for_view=-MALwVsAAAAJ:u5HHmVD_uO8C,"The need for increased control of layer thickness and uniformity as device dimensions shrink has spurred increased use of atomic layer deposition (ALD) for thin film growth. The ability to deposit high dielectric constant (high-k) films via ALD has allowed for their widespread use in a swath of optical, optoelectronic, and electronic devices, including integration into CMOS compatible platforms. As the thickness of these dielectric layers is reduced, the interfacial thermal resistance can dictate the overall thermal resistance of the material stack compared to the resistance due to the finite dielectric layer thickness. Time domain thermoreflectance is used to interrogate both the thermal conductivity and the thermal boundary resistance of aluminum oxide, hafnium oxide, and titanium oxide films on silicon. We calculate a representative design map of effective thermal resistances, including those of the dielectric layers and …",AIP Publishing,,2018
1244,Phonon scattering effects from point and extended defects on thermal conductivity studied via ion irradiation of crystals with self-impurities,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-MALwVsAAAAJ&citation_for_view=-MALwVsAAAAJ:qjMakFHDy7sC,"Fundamental theories predict that reductions in thermal conductivity from point and extended defects can arise due to phonon scattering with localized strain fields. To experimentally determine how these strain fields impact phonon scattering mechanisms, we employ ion irradiation as a controlled means of introducing strain and assorted defects into the lattice. In particular, we observe the reduction in thermal conductivity of intrinsic natural silicon after self-irradiation with two different silicon isotopes, and . Irradiating with an isotope with a nearly identical atomic mass as the majority of the host lattice produces a damage profile lacking mass impurities and allows us to assess the role of phonon scattering with local strain fields on the thermal conductivity. Our results demonstrate that point defects will decrease the thermal conductivity more so than spatially extended defect structures assuming the same …",American Physical Society,,2018
1245,"Orders of magnitude reduction in the thermal conductivity of polycrystalline diamond through carbon, nitrogen, and oxygen ion implantation",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-MALwVsAAAAJ&citation_for_view=-MALwVsAAAAJ:Tyk-4Ss8FVUC,"Despite the exceptional thermal and mechanical functionalities of diamond, its superlative properties are highly subject to the presence of point defects, dislocations, and interfaces. In this study, polycrystalline diamond is ion implanted with C 3+, N 3+, and O 3+ ions at an energy of 16.5 MeV, producing an amorphous layer at the projected range and a damaged crystalline region between the surface and amorphous layer. Using time-domain thermoreflectance in combination with thermal penetration depth calculations based upon the multilayer heat diffusion equation, it is determined that reductions in the thermal conductivity can span nearly two orders of magnitude while still maintaining a polycrystalline structure within the regions thermally probed. Dynamical diffraction simulations of high-resolution x-ray diffraction measurements demonstrate the formation of a strained layer localized at the end of range, with …",Pergamon,,2020
1246,Thermal resistance and heat capacity in hafnium zirconium oxide (Hf1–xZrxO2) dielectrics and ferroelectric thin films,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-MALwVsAAAAJ&citation_for_view=-MALwVsAAAAJ:UeHWp8X0CEIC,"We report on the thermal resistances of thin films (20 nm) of hafnium zirconium oxide (Hf 1–x Zr x O 2) with compositions ranging from 0≤ x≤ 1. Measurements were made via time-domain thermoreflectance and analyzed to determine the effective thermal resistance of the films in addition to their associated thermal boundary resistances. We find effective thermal resistances ranging from 28.79 to 24.72 m 2 K GW− 1 for amorphous films, which decreased to 15.81 m 2 K GW− 1 upon crystallization. Furthermore, we analyze the heat capacity for two compositions, x= 0.5 and x= 0.7, of Hf 1–x Zr x O 2 and find them to be 2.18±0.56 and 2.64±0.53 MJ m− 3 K− 1, respectively.",AIP Publishing,,2018
1247,"Interface and layer periodicity effects on the thermal conductivity of copper-based nanomultilayers with tungsten, tantalum, and tantalum nitride diffusion barriers",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-MALwVsAAAAJ&citation_for_view=-MALwVsAAAAJ:ufrVoPGSRksC,"Nanomultilayers are complex architectures of materials stacked in sequence with layer thicknesses in the nanometer range. Their application in microelectronics is challenged by their thermal stability, conductivity, and interface reactivity, which can compromise their performance and usability. By using different materials as thermal barriers and by changing their thickness, it is possible to manipulate interfacial effects on thermal transport. In this work, we report on the thermal conductivity of Cu/W, Cu/Ta, and Cu/TaN sputter deposited nanomultilayers with different thicknesses. The resistive interfacial effects are rationalized and discussed also in relation to the structural transformation into a nano-composite upon high-temperature annealing.",AIP Publishing,,2020
1248,Ruddlesden-Popper chalcogenides push the limit of mechanical stiffness and glass-like thermal conductivity in single crystals,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-MALwVsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=-MALwVsAAAAJ:r0BpntZqJG4C,"Insulating materials featuring ultralow thermal conductivity for diverse applications also require robust mechanical properties. Conventional thinking, however, which correlates strong bonding with high atomic-vibration-mediated heat conduction, led to diverse weakly bonded materials that feature ultralow thermal conductivity and low elastic moduli. One must, therefore, search for strongly-bonded single crystals in which heat transport is impeded by other means. Here, we report intrinsic, glass-like, ultralow thermal conductivity and ultrahigh elastic-modulus/thermal-conductivity ratio in single-crystalline Ruddlesden-Popper Ban+1ZrnS3n+1, n = 2, 3, which are derivatives of BaZrS3. Their key features are strong anharmonicity and intra-unit-cell rock-salt blocks. The latter produce strongly bonded intrinsic superlattices, impeding heat conduction by broadband reduction of phonon velocities and mean free paths and …",Nature Publishing Group UK,,2025
1249,"Limitations and Advances in Optical Thermal Transport Measurements: Extremes in Properties, Length Scales, and Temperature",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-MALwVsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=-MALwVsAAAAJ:iH-uZ7U-co4C,"Conductive and radiative thermal transport play a critical role in the design, development, and performance of a wide array of technologies and applications. In this review, we focus on the challenges associated with nano- and microscale thermal measurements and the strategies developed thus far to overcome them. For measurements below ∼1,000°C, numerous thermoreflectance techniques are already in wide use; however, uncertainty and measurement error may limit the measurement of samples in certain regimes. These regimes include materials of high thermal conductivity (≳2,000 W/m·K), thin films (≲100 nm), or interfaces located well below the sample surface. A rigorous treatment of uncertainty and error is thus required for measuring these samples and for the development of future metrology tools. At higher temperatures, pyrometry techniques are being developed; however, several physical and …",Annual Reviews,Annual Review of Materials Research,2025
1250,Picking the Right TMD is the Key to Controlling Heat In a Phase Change Superlattice,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-MALwVsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=-MALwVsAAAAJ:bEWYMUwI8FkC,"Conclusions Both VTe2 and ZrTe2 make promising candidates for use in PCM superlattices due to their high crystalline quality, thermal stability and consistently low thermal conductivity contrast. On top of this, ZrTe2 and its superlattice demonstrate a low thermal conductivity, even at high temperatures, making it a prime candidate for further investigations.",,,2025
1251,Suspended silicon nitride platforms for thermal sensing applications in the limit of minimized membrane thickness,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-MALwVsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=-MALwVsAAAAJ:j3f4tGmQtD8C,"Silicon nitride has long been employed in the microfabrication of thermal sensors due to its favorable material properties and the ease with which it facilitates surface micromachining. While a variety of studies have utilized thin silicon nitride membranes for high sensitivity thermal measurements, limited reports exist on the physical characteristics of membranes and platforms in a thickness limit much less than 100 nm. Herein, we report on the development of low-stress, suspended silicon nitride platform devices that enable thermal characterization of membranes ranging from 120 nm to less than 10 nm in thickness, providing thermal conductivities as low as 1.1 W m−1 K−1 near room temperature. Applications of these platforms may enable appreciable enhancement in the performance of devices reliant upon environmental thermal isolation including bolometers, calorimeters, and gas sensors, among others. [2024 …",IEEE,,2024
1252,Cost-related medication non-adherence among US adults with diabetes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z4lOaroAAAAJ&citation_for_view=z4lOaroAAAAJ:ZHo1McVdvXMC,"Aims To examine factors that affect cost-related medication non-adherence (CRN), defined as taking medication less than as prescribed because of cost, among adults with diabetes and to determine their relative contribution in explaining CRN. Methods Behavioral Risk Factor Surveillance System data for 2013–2014 were used to identify individuals with diabetes and their CRN. We modeled CRN as a function of financial factors, regimen complexity, and other contextual factors including diabetes care, lifestyle, and health factors. Dominance analysis was performed to rank these factors by relative importance. Results CRN among US adults with diabetes was 16.5%. Respondents with annual income< $50,000 and without health insurance were more likely to report CRN, compared to those with income≥ $50,000 and those with insurance, respectively. Insulin users had 1.24 times higher risk of CRN compared to …",Elsevier,,2018
1253,Evaluating the costs of nurse burnout-attributed turnover: a Markov modeling approach,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z4lOaroAAAAJ&citation_for_view=z4lOaroAAAAJ:8AbLer7MMksC,Objective Burnout is a public health crisis that impacts 1 in 3 registered nurses in the United States and the safe provision of patient care. This study sought to understand the cost of nurse burnout-attributed turnover using hypothetical hospital scenarios. Methods A cost-consequence analysis with a Markov model structure was used to assess nurse burnout-attributed turnover costs under the following scenarios:(1) a hospital with “status quo” nurse burnout prevalence and (2) a hospital with a “burnout reduction program” and decreased nurse burnout prevalence. The model evaluated turnover costs from a hospital payer perspective and modeled a cohort of nurses who were new to a hospital. The outcome measures were defined as years in burnout among the nurse cohort and years retained/employed in the hospital. Data inputs derived from the health services literature base. Results The expected model results …,LWW,,2022
1254,A scoping review of racial/ethnic disparities in sleep,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z4lOaroAAAAJ&citation_for_view=z4lOaroAAAAJ:l7t_Zn2s7bgC,"Background Despite remarkable achievements in ensuring health equity, racial/ethnic disparities in sleep still persist and are emerging as a major area of concern. Accumulating evidence has not yet been well characterized from a broad perspective. We conducted a scoping review of studies on sleep disparities by race/ethnicity to summarize characteristics of existing studies and identify evidence gaps. Methods We searched PubMed, CINAHL, PsycINFO, and Web of Science databases for studies of racial/ethnic disparities in sleep. Studies that met inclusion criteria were retrieved and organized in a data charting form by study design, sleep measuring methods, sleep features, and racial/ethnic comparisons. Results One hundred sixteen studies were included in this review. Most studies focused on disparities between Whites and Blacks. Disproportionately fewer studies examined disparities for Hispanic, Asian, and …",Elsevier,Sleep Medicine,2021
1255,Second-line agents for glycemic control for type 2 diabetes: are newer agents better?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z4lOaroAAAAJ&citation_for_view=z4lOaroAAAAJ:YsMSGLbcyi4C,"OBJECTIVE While metformin is generally accepted as the first-line agent in treatment of type 2 diabetes, there are insufficient evidence and extensive debate about the best second-line agent. We aimed to assess the benefits and harms of four commonly used antihyperglycemia treatment regimens considering clinical effectiveness, quality of life, and cost. RESEARCH DESIGN AND METHODS We developed and validated a new population-based glycemic control Markov model that simulates natural variation in HbA 1c progression. The model was calibrated using a US data set of privately insured individuals diagnosed with type 2 diabetes. We compared treatment intensification of metformin monotherapy with sulfonylurea, dipeptidyl peptidase-4 inhibitor, glucagon-like peptide-1 receptor agonist, or insulin. Outcome measures included life-years (LYs), quality-adjusted life-years (QALYs), mean time to insulin …",American Diabetes Association,,2014
1256,ID: 4340773 ELECTROCARDIOGRAPHY FROM DEEPER SLEEP BETTER PREDICTS ATRIAL FIBRILLATION RISK,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z4lOaroAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=z4lOaroAAAAJ:PR6Y55bgFSsC,"Background ECG-based artificial intelligence (ECG-AI) can detect atrial fibrillation (AF) even during normal sinus rhythm. Sleep is associated with modulations of the sympathetic and parasympathetic control of cardiac dynamics, which can be reflected in the ECG. Whether sleep ECG would yield comparable predictions to awake ECG has not been studied. Objective To develop a single lead sleep ECG-based-AI model to predict the risk of incident AF from single lead sleep ECG. Methods We used the Sleep Heart Health Study (SHHS) data through the National Sleep Research Resource. We included participants without known AF at the time of sleep study. Incident AF was adjudicated by the parent cohorts mainly through annual resting 12 lead ECGs and hospital discharge diagnoses at any time between the baseline sleep study and the final follow-up date for AF ascertainment of June 30, 2006. We developed an …",Elsevier,,2025
1257,Positional obstructive sleep apnea and cardiovascular outcomes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z4lOaroAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=z4lOaroAAAAJ:N5tVd3kTz84C,Background A tendency to obstruct the upper airway is markedly increased in supine sleep. Positional obstructive sleep apnea (OSA) (POSA) occurs predominantly in the supine position. The implication of POSA in terms of future cardiovascular (CV) risk is unknown. We hypothesized that patients with POSA have decreased future CV risks compared to OSA patients without POSA (non-POSA). Methods This single-center study included patients who underwent clinically indicated polysomnography. POSA was defined as an apnea-hypopnea index (AHI) ≥ 5 events/hour and supine AHI at least twice as high as non-supine AHI (nsAHI). Exclusive POSA (ePOSA) includes the additional requirement that the nsAHI normalizes to an AHI of < 5/hour. A Cox proportional hazard model was used to assess the future risk of new CV events in patients with POSA compared to non-POSA (reference group). Results There were 3 …,Springer International Publishing,,2025
1258,Ends in Multiple Sclerosis Mortality by Race and Ethnicity in the United States: Analysis of the CDC WONDER Database,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z4lOaroAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=z4lOaroAAAAJ:hkOj_22Ku90C,,SAGE PUBLICATIONS LTD,,2025
1259,1112 Association of High-Risk OSA with Incident Atrial Fibrillation: The Multi-Ethnic Study of Atherosclerosis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z4lOaroAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=z4lOaroAAAAJ:VL0QpB8kHFEC,"Introduction Obstructive sleep apnea (OSA) is associated with atrial fibrillation (AF), a significant cause of morbidity and mortality. However, this association varies by population characteristics and definitions of OSA and AF. This study examined whether “High-Risk” OSA, characterized by elevated OSA-related hypoxic burden (HB) or heart rate response (ΔHR), is linked to increased AF incidence. Methods The analysis used data from the Multi-Ethnic Study of Atherosclerosis (MESA), including polysomnography (2010-2013), and ascertainment of AF through 2018 (median follow-up time of 6.8 years). OSA-related HB was quantified as the cumulative area under the desaturation curve and ΔHR was defined as the increase in heart rate upon event termination. High-Risk OSA was defined by the presence of an apnea-hypopnea index (AHI) ≥15 events/h) with either a high ΔHR …",Oxford University Press,,2025
1260,Disparities in Antidiabetic Medication Discontinuation Between Non-Hispanic White and Black Beneficiaries in Medicare Across Diabetes Belt and Surrounding Area,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z4lOaroAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=z4lOaroAAAAJ:ye4kPcJQO24C,"Objective To assess racial and geographic disparities in antidiabetic medication discontinuation among Medicare beneficiaries with type 2 diabetes (T2D) in or around Diabetes Belt (DB) areas, with a specific focus on differences between non-Hispanic (NH) white and NH Black individuals. Study Design A retrospective cohort analysis was conducted on Medicare beneficiaries who initiated metformin and used antidiabetic medications during 2011–2015, including metformin, sulfonylureas, insulin, DPP-4 inhibitors, GLP-1 receptor agonists, SGLT2 inhibitors, and thiazolidinediones. Medication discontinuation was defined as a gap of 90 days or more without any antidiabetic medications. Methods Multivariable Cox regression was used to examine the influence of racial and geographic factors on medication discontinuation, controlling for demographic, socioeconomic, and contextual factors. The interaction between …",Springer International Publishing,,2025
1261,Design & analysis of fault tolerant digital systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vMTL9koAAAAJ&citation_for_view=vMTL9koAAAAJ:-f6ydRqryjwC,"While significant results are available which allow estimation of reliability measure for systems with permanent faults, no generally applicable results are available for intermittent (transient) faults. Methods are presented here which allow...","Addison-Wesley Longman Publishing Co., Inc.",,1988
1262,Methods for secure enrollment of personal identity credentials into electronic devices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vMTL9koAAAAJ&citation_for_view=vMTL9koAAAAJ:UxriW0iASnsC,"(57) ABSTRACT A method and system for securely enrolling personal identity credentials into personal identification devices. The system of the invention comprises the manufacturer of the device and an enrollment authority. The manufacturer is responsible for recording serial numbers or another unique identifier for each device that it produces, along with a self-generated public key for each device. The enrollment authority is recognized by the manufacturer or another Suitable institution as capable of validating an individual before enrolling him into the device. The enrollment authority maintains and operates the appro priate equipment for enrollment, and provides its approval of the enrollment. The methods described herein discuss post manufacturing, enrollment, backup, and recovery processes for the device.",,,2012
1263,Fault-tolerant microprocessor-based systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vMTL9koAAAAJ&citation_for_view=vMTL9koAAAAJ:tzM49s52ZIMC,How do computers go wrong and what can we do about it? This tutorial outlines the causes of faults and the basic techniques for dealing with them.,IEEE,,1984
1264,The Codesign of Embedded Systems: A Unified Hardware/Software Representation: A Unified Hardware/Software Representation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vMTL9koAAAAJ&citation_for_view=vMTL9koAAAAJ:tS2w5q8j5-wC,"Current practice dictates the separation of the hardware and software development paths early in the design cycle. These paths remain independent with very little interaction occurring between them until system integration. In particular, hardware is often specified without fully appreciating the computational requirements of the software. Also, software development does not influence hardware development and does not track changes made during the hardware design phase. Thus, the ability to explore hardware/software tradeoffs is restricted, such as the movement of functionality from the software domain to the hardware domain (and vice-versa) or the modification of the hardware/software interface. As a result, problems that are encountered during system integration may require modification of the software and/or hardware, resulting in potentially significant cost increases and schedule overruns. To address the problems described above, a cooperative design approach, one that utilizes a unified view of hardware and software, is described. This approach is called hardware/software codesign. The Codesign of Embedded Systems develops several fundamental hardware/software codesign concepts and a methodology that supports them. A unified representation, referred to as a decomposition graph, is presented which can be used to describe hardware or software using either functional abstractions or data abstractions. Using a unified representation based on functional abstractions, an abstract hardware/software model has been implemented in a common simulation environment called ADEPT (Advanced Design Environment Prototyping …",Springer Science & Business Media,,2012
1265,Example application of D_RAMP for Safety Analysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vMTL9koAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vMTL9koAAAAJ:ZuybSZzF8UAC,"This paper summarizes the D_RAMP safety analysis methodology and demon-strates a typical application to a system. The safety is quantified in terms of the Mean Time Between hazardous Event (MTBHE). The summarized safety anal-ysis shown the necessary conditions to prove the MTBHE> 1x10^ years. 1.0 Introduction The Union Switch & Signal has been developing a tool to be used for the verifi-cation and validation, concurrent with the design of Real Time Computing Sys-tems (RTCSs). This toolkit is called D_RAMP (Design for Reliability, Availability, Maintainability, Performance and Safety). D_RAMP plays a cen-tral role in the V&V methodology and constitutes a novel approach to accessing and quantifying the",WIT Press,,2024
1266,Reliability theory and practice for unmanned aerial vehicles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vMTL9koAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vMTL9koAAAAJ:TIZ-Mc8IlK0C,"Due to rapid advancements on the Internet of Things (IoT), unmanned aerial vehicles (UAVs), also known as drones, are transforming numerous military and civil application areas. UAVs aim to enhance the production efficiency, ensure safety, and reduce risk, particularly protecting the human workforce in the case of harsh and dangerous environments. Due to the mission-critical, business-critical, or safety-critical nature of the UAV applications, it is pivotal that UAVs perform reliably to deliver the required service during the intended mission time. Therefore, reliability is one of the essential requirements for designing and operating UAVs. This article presents a critical review of UAV reliability literature in both theoretical and practical research, pinpointing failure causes and reliability challenges of UAV systems, classifying and reflecting on the reliability modeling, analysis, and design methods for UAV systems and …",IEEE,IEEE Internet of Things Journal,2022
1267,Men are worse allies than they think,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vMTL9koAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vMTL9koAAAAJ:WZBGuue-350C,"We define gender allyship as the purposeful collaboration of dominant group members (men) with women to actively promote gender equality and equity in their personal lives and in the workplace through supportive and collaborative relationships, acts of sponsorship, and public advocacy in order to drive systemic change.(For a full breakdown of the allyship continuum, see the table below.) This definition emphasizes the interpersonal aspect of developing awareness and motivation, public action to create accountability and transparency, and systemic change that is long-lasting and sustainable.",,,2022
1268,Object-Oriented Modeling of Hardware for Embedded Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vMTL9koAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vMTL9koAAAAJ:_xSYboBqXhAC,"In this chapter, the application of object-oriented techniques to the modeling and design of hardware for embedded systems is presented. The use of these techniques is an example of cross fertilization from the software domain to the hardware domain. This work brings together several ideas common to both hardware and software, such as state, information hiding, specialization, reuse, families of components, and virtual machines. The potential advantages of object-oriented techniques when applied to hardware design are discussed and illustrated on several examples using C++, which supports user-defined data types and inheritance. It is shown that data decomposition, a decomposition technique based on abstract data types, can be applied recursively to hardware components, supporting complexity management and refinement. A representation that captures this decomposition technique, referred to as the …",Springer US,,2022
1269,"Methods, systems and apparatuses for secure transactions",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vMTL9koAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vMTL9koAAAAJ:f2IySw72cVMC,"The invention is directed towards methods, systems and apparatuses, see FIG. 1,(100) for providing secure and private interactions. The invention provides capability for verifying the identity of a party initiating an electronic interaction with another party through data input module (140) which is verified by the identity verification module (150), which further includes a self-destruct mechanism (153). Embodiments of the invention include secure meth ods for conducting transactions and for limiting the transfer and distribution of personal data to only those data that are absolutely necessary for the completion of the transactions.",,,2019
1270,Mechanisms of mechanotransduction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xQ8zbXMAAAAJ&citation_for_view=xQ8zbXMAAAAJ:u5HHmVD_uO8C,"Essentially all organisms from bacteria to humans are mechanosensitive. Physical forces regulate a large array of physiological processes, and dysregulation of mechanical responses contributes to major human diseases. A survey of both specialized and widely expressed mechanosensitive systems suggests that physical forces provide a general means of altering protein conformation to generate signals. Specialized systems differ mainly in having acquired efficient mechanisms for transferring forces to the mechanotransducers.",Elsevier,Developmental cell,2006
1271,Rapid displacement of vimentin intermediate filaments in living endothelial cells exposed to flow,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xQ8zbXMAAAAJ&citation_for_view=xQ8zbXMAAAAJ:u-x6o8ySG0sC,"—Hemodynamic shear stress at the endothelial cell surface induces acute and chronic intracellular responses that regulate vessel wall biology. The cytoskeleton is implicated by acting both as a direct connector to local surface deformation and as a distribution network for mechanical forces throughout the cell; however, direct observation and measurement of its position during flow have only recently become possible. In this study, we directly demonstrate rapid deformation of the intermediate filament (IF) network in living endothelial cells subjected to changes in hemodynamic shear stress. Time-lapse optical sectioning and deconvolution microscopy were performed within the first 3 minutes after the introduction of flow (shear stress, 12 dyn/cm2). Spatial and temporal dynamics of green fluorescent protein–vimentin IFs in confluent endothelial cells were analyzed. The imposition of shear stress significantly …",Lippincott Williams & Wilkins,,2000
1272,Analysis of SM22α-deficient mice reveals unanticipated insights into smooth muscle cell differentiation and function,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xQ8zbXMAAAAJ&citation_for_view=xQ8zbXMAAAAJ:d1gkVwhDpl0C,"SM22α is a 22-kDa smooth muscle cell (SMC) lineage-restricted protein that physically associates with cytoskeletal actin filament bundles in contractile SMCs. To examine the function of SM22α, gene targeting was used to generate SM22α-deficient (SM22−/−LacZ) mice. The gene targeting strategy employed resulted in insertion of the bacterial lacZ reporter gene at the SM22α initiation codon, permitting precise analysis of the temporal and spatial pattern of SM22α transcriptional activation in the developing mouse. Northern and Western blot analyses confirmed that the gene targeting strategy resulted in a null mutation. Histological analysis of SM22+/−LacZ embryos revealed detectable β-galactosidase activity in the unturned embryonic day 8.0 embryo in the layer of cells surrounding the paired dorsal aortae concomitant with its expression in the primitive heart tube, cephalic mesenchyme, and yolk sac vasculature …",Taylor & Francis,,2001
1273,The cytoskeleton under external fluid mechanical forces: hemodynamic forces acting on the endothelium,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xQ8zbXMAAAAJ&citation_for_view=xQ8zbXMAAAAJ:qjMakFHDy7sC,"The endothelium, a single layer of cells that lines all blood vessels, is the focus of intense interest in biomechanics because it is the principal recipient of hemodynamic shear stress. In arteries, shear stress has been demonstrated to regulate both acute vasoregulation and chronic adaptive vessel remodeling and is strongly implicated in the localization of atherosclerotic lesions. Thus, endothelial biomechanics and the associated mechanotransduction of shear stress are of great importance in vascular physiology and pathology. Here we discuss the important role of the cytoskeleton in a decentralization model of endothelial mechanotransduction. In particular, recent studies of four-dimensional cytoskeletal motion in living cells under external fluid mechanical forces are summarized together with new data on the spatial distribution of cytoskeletal strain. These quantitative studies strongly support the decentralized …",Kluwer Academic Publishers-Plenum Publishers,Annals of biomedical engineering,2002
1274,Spatiotemporal analysis of flow-induced intermediate filament displacement in living endothelial cells,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xQ8zbXMAAAAJ&citation_for_view=xQ8zbXMAAAAJ:2osOgNQ5qMEC,"The distribution of hemodynamic shear stress throughout the arterial tree is transduced by the endothelium into local cellular responses that regulate vasoactivity, vessel wall remodeling, and atherogenesis. Although the exact mechanisms of mechanotransduction remain unknown, the endothelial cytoskeleton has been implicated in transmitting extracellular force to cytoplasmic sites of signal generation via connections to the lumenal, intercellular, and basal surfaces. Direct observation of intermediate filament (IF) displacement in cells expressing green fluorescent protein-vimentin has suggested that cytoskeletal mechanics are rapidly altered by the onset of fluid shear stress. Here, restored images from time-lapse optical sectioning fluorescence microscopy were analyzed as a four-dimensional intensity distribution function that represented IF positions. A displacement index, related to the product moment …",Elsevier,,2001
1275,Creating Inclusive Environments to Support Learning and Professional Development in Biomedical Engineering Education,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xQ8zbXMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xQ8zbXMAAAAJ:l7t_Zn2s7bgC,"At the Fifth Biomedical Engineering (BME) Education Summit in 2024, the BME education professional community discussed diversity, equity, and inclusion (DEI) in a series of workshops. The goals were to identify professional competencies related to DEI that support students after graduation, to outline strategies for including DEI principles in teaching and learning, and to describe efforts in BME departments that support an equitable and inclusive educational environment. Using a backward design approach, workshop leaders guided participants as they outlined desirable outcomes, assessment strategies, and inclusive activities to support DEI efforts. Based on the feedback from participants, pharmaceutical industry representatives, and supporting literature, we propose an “Engineering for All” framework in BME education with strategies for lowering systemic barriers and creating an equitable and inclusive …",Springer International Publishing,,2025
1276,WIP: A Peer-Taught Course to Lower Barriers to Undergraduate Research Experiences,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xQ8zbXMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xQ8zbXMAAAAJ:vRqMK49ujn8C,"This Work in Progress paper reports a novel course titled “Starting an Undergraduate Research Experience (SURE): Intro to Research” which synergistically combines course design, peer-led instruction, and specifications grading to reduce barriers to entry into undergraduate research and increase students’ sense of belonging. Undergraduate research is a high-impact experiential learning opportunity; however, students often face high barriers to entry, including lack of confidence, uncertainty about how to start, limited guidance, and feelings of inadequacy. These challenges are especially pronounced for first-year students, first-generation students, and members of underrepresented groups. To address this problem, we designed a one-credit course focused on professional development primarily for first-year engineering students. The four course learning objectives were:(1) to recognize what undergraduate research is, how undergraduate research works, and identify the value of undergraduate research;(2) to gain a deeper understanding of lab environments and identify personal goals for a research experience;(3) to seek out research opportunities and effectively communicate skills and goals; and (4) to be able to find and analyze scientific writing applicable to a topic and become familiar with research deliverables. Activities designed to support these objectives incorporated active learning opportunities such as undergraduate research panels, lab tours, a contact letter writing workshop, and mock interviews. The course was taught by a peer instructor. Learning objectives were assessed using specifications grading, which is an inclusive …",,,2025
1277,Correction: Lowering Barriers to Entry in Undergraduate Research Through Student-Led Virtual Workshops,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xQ8zbXMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xQ8zbXMAAAAJ:WbkHhVStYXYC,"Correction: Lowering Barriers to Entry in Undergraduate Research Through Student-Led Virtual Workshops Page 1 Vol.:(0123456789) Biomedical Engineering Education https://doi.org/10.1007/s43683-024-00164-4 CORRECTION Correction: Lowering Barriers to Entry in Undergraduate Research Through Student‑Led Virtual Workshops Connor Amelung1,2 · Brian P. Helmke1 © The Author(s) 2024 Correction to: Biomedical Engineering Education https://doi.org/10.1007/s43683-024-00157-3 The Conflict of Interest statement for this paper is incomplete. Information that Brian Helmke (author) is Deputy Editorin-Chief of Biomedical Engineering Education is missing. The correct conflict of interest should read: The authors have no relevant financial or non-financial interests to disclose. Brian Helmke (author) is Deputy Editor-in-Chief of Biomedical Engineering Education. Open Access This article is licensed under a …",Springer International Publishing,,2025
1278,Lowering Barriers to Entry in Undergraduate Research Through Student-Led Virtual Workshops,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xQ8zbXMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xQ8zbXMAAAAJ:uWQEDVKXjbEC,"Undergraduate research is a high-impact learning experience, but undergraduate students interested in research often face high barriers to entry, such as limited guidance, confusing application processes, and feelings of not belonging. These barriers are especially prohibitive to first-year students, first-generation students, and members of underrepresented groups, and COVID-19 exacerbated the difficulty of undergraduates joining research by reducing opportunities to gain meaningful research experiences. To address these challenges, we designed a novel extracurricular education program named Starting an Undergraduate Research Experience (SURE) in the fall 2020 with the goal of lowering barriers to entry for engineering students to gain research experiences. Over 150 students enrolled in the workshop series throughout both semesters and were put into small groups led by research-experienced …",Springer International Publishing,,2025
1279,Transmission with energy harvesting nodes in fading wireless channels: Optimal policies,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AbFi7JAAAAAJ&citation_for_view=AbFi7JAAAAAJ:-f6ydRqryjwC,"Wireless systems comprised of rechargeable nodes have a significantly prolonged lifetime and are sustainable. A distinct characteristic of these systems is the fact that the nodes can harvest energy throughout the duration in which communication takes place. As such, transmission policies of the nodes need to adapt to these harvested energy arrivals. In this paper, we consider optimization of point-to-point data transmission with an energy harvesting transmitter which has a limited battery capacity, communicating in a wireless fading channel. We consider two objectives: maximizing the throughput by a deadline, and minimizing the transmission completion time of the communication session. We optimize these objectives by controlling the time sequence of transmit powers subject to energy storage capacity and causality constraints. We, first, study optimal offline policies. We introduce a directional water-filling …",IEEE,,2011
1280,Optimal packet scheduling in an energy harvesting communication system,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AbFi7JAAAAAJ&citation_for_view=AbFi7JAAAAAJ:bEWYMUwI8FkC,"We consider the optimal packet scheduling problem in a single-user energy harvesting wireless communication system. In this system, both the data packets and the harvested energy are modeled to arrive at the source node randomly. Our goal is to adaptively change the transmission rate according to the traffic load and available energy, such that the time by which all packets are delivered is minimized. Under a deterministic system setting, we assume that the energy harvesting times and harvested energy amounts are known before the transmission starts. For the data traffic arrivals, we consider two different scenarios. In the first scenario, we assume that all bits have arrived and are ready at the transmitter before the transmission starts. In the second scenario, we consider the case where packets arrive during the transmissions, with known arrival times and sizes. We develop optimal off-line scheduling policies …",IEEE,,2011
1281,Optimal status update for age of information minimization with an energy harvesting source,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AbFi7JAAAAAJ&citation_for_view=AbFi7JAAAAAJ:zYLM7Y9cAGgC,"In this paper, we consider a scenario where an energy harvesting sensor continuously monitors a system and sends time-stamped status updates to a destination. The destination keeps track of the system status through the received updates. We use the metric Age of Information (AoI), the time that has elapsed since the last received update was generated, to measure the “freshness” of the status information available at the destination. Our objective is to design optimal online status update policies to minimize the long-term average AoI, subject to the energy causality constraint at the sensor. We consider three scenarios, i.e., the battery size is infinite, finite, and one unit only, respectively. For the infinite battery scenario, we adopt a besteffort uniform status update policy and show that it minimizes the long-term average AoI. For the finite battery scenario, we adopt an energy-aware adaptive status update policy, and …",IEEE,,2017
1282,Broadcasting with an energy harvesting rechargeable transmitter,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AbFi7JAAAAAJ&citation_for_view=AbFi7JAAAAAJ:IjCSPb-OGe4C,"In this paper, we investigate the transmission completion time minimization problem in an additive white Gaussian noise (AWGN) broadcast channel, where the transmitter is able to harvest energy from the nature, using a rechargeable battery. The harvested energy is modeled to arrive at the transmitter during the course of transmissions. The transmitter has a fixed number of packets to be delivered to each receiver. The objective is to minimize the time by which all of the packets are delivered to their respective destinations. To this end, we optimize the transmit powers and transmission rates in a deterministic setting. We first analyze the structural properties of the optimal transmission policy in a two-user broadcast channel via the dual problem of maximizing the departure region by a fixed time T. We prove that the optimal total transmit power sequence has the same structure as the optimal single-user transmit power …",IEEE,,2011
1283,Energy cooperation in energy harvesting communications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AbFi7JAAAAAJ&citation_for_view=AbFi7JAAAAAJ:u-x6o8ySG0sC,"In energy harvesting communications, users transmit messages using energy harvested from nature during the course of communication. With an optimum transmit policy, the performance of the system depends only on the energy arrival profiles. In this paper, we introduce the concept of energy cooperation, where a user wirelessly transmits a portion of its energy to another energy harvesting user. This enables shaping and optimization of the energy arrivals at the energy-receiving node, and improves the overall system performance, despite the loss incurred in energy transfer. We consider several basic multi-user network structures with energy harvesting and wireless energy transfer capabilities: relay channel, two-way channel and multiple access channel. We determine energy management policies that maximize the system throughput within a given duration using a Lagrangian formulation and the resulting KKT …",IEEE,,2013
1284,Robust Offline Reinforcement Learning for Non-Markovian Decision Processes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AbFi7JAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=AbFi7JAAAAAJ:geHnlv5EZngC,"Distributionally robust offline reinforcement learning (RL) aims to find a policy that performs the best under the worst environment within an uncertainty set using an offline dataset collected from a nominal model. While recent advances in robust RL focus on Markov decision processes (MDPs), robust non-Markovian RL is limited to planning problem where the transitions in the uncertainty set are known. In this paper, we study the learning problem of robust offline non-Markovian RL. Specifically, when the nominal model admits a low-rank structure, we propose a new algorithm, featuring a novel dataset distillation and a lower confidence bound (LCB) design for robust values under different types of the uncertainty set. We also derive new dual forms for these robust values in non-Markovian RL, making our algorithm more amenable to practical implementation. By further introducing a novel type-I concentrability coefficient …",IEEE,,2025
1285,Decision feedback in-context symbol detection over block-fading channels,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AbFi7JAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=AbFi7JAAAAAJ:8AbLer7MMksC,"Pre-trained Transformers, through in-context learning (ICL), have demonstrated exceptional capabilities to adapt to new tasks using example prompts without model update. Transformer-based wireless receivers, where prompts consist of the pilot data in the form of transmitted and received signal pairs, have shown high estimation accuracy when pilot data are abundant. However, pilot information is often costly and limited in practice. In this work, we propose the DEcision Feedback INContExt Detection (DEFINED) solution as a new wireless receiver design, which bypasses channel estimation and directly performs symbol detection using the (sometimes extremely) limited pilot data. The key innovation in DEFINED is the proposed decision feedback mechanism in ICL, where we sequentially incorporate the detected symbols into the prompts to improve the detections for subsequent symbols. Extensive experiments …",IEEE,,2025
1286,Augmenting Online RL with Offline Data is All You Need: A Unified Hybrid RL Algorithm Design and Analysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AbFi7JAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=AbFi7JAAAAAJ:D_sINldO8mEC,"This paper investigates a hybrid learning framework for reinforcement learning (RL) in which the agent can leverage both an offline dataset and online interactions to learn the optimal policy. We present a unified algorithm and analysis and show that augmenting confidence-based online RL algorithms with the offline dataset outperforms any pure online or offline algorithm alone and achieves state-of-the-art results under two learning metrics, i.e., sub-optimality gap and online learning regret. Specifically, we show that our algorithm achieves a sub-optimality gap , where is a new concentrability coefficient, and are the numbers of offline and online samples, respectively. For regret minimization, we show that it achieves a constant speed-up compared to pure online learning, where is the concentrability coefficient over all sub-optimal policies. Our results also reveal an interesting separation on the desired coverage properties of the offline dataset for sub-optimality gap minimization and regret minimization. We further validate our theoretical findings in several experiments in special RL models such as linear contextual bandits and Markov decision processes (MDPs).",,,2025
1287,How Transformers Learn Regular Language Recognition: A Theoretical Study on Training Dynamics and Implicit Bias,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AbFi7JAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=AbFi7JAAAAAJ:VOx2b1Wkg3QC,"Language recognition tasks are fundamental in natural language processing (NLP) and have been widely used to benchmark the performance of large language models (LLMs). These tasks also play a crucial role in explaining the working mechanisms of transformers. In this work, we focus on two representative tasks in the category of regular language recognition, known as `even pairs' and `parity check', the aim of which is to determine whether the occurrences of certain subsequences in a given sequence are even. Our goal is to explore how a one-layer transformer, consisting of an attention layer followed by a linear layer, learns to solve these tasks by theoretically analyzing its training dynamics under gradient descent. While even pairs can be solved directly by a one-layer transformer, parity check need to be solved by integrating Chain-of-Thought (CoT), either into the inference stage of a transformer well-trained for the even pairs task, or into the training of a one-layer transformer. For both problems, our analysis shows that the joint training of attention and linear layers exhibits two distinct phases. In the first phase, the attention layer grows rapidly, mapping data sequences into separable vectors. In the second phase, the attention layer becomes stable, while the linear layer grows logarithmically and approaches in direction to a max-margin hyperplane that correctly separates the attention layer outputs into positive and negative samples, and the loss decreases at a rate of . Our experiments validate those theoretical results.",,,2025
1288,Entropy and heat transfer analysis using Cattaneo-Christov heat flux model for a boundary layer flow of Casson nanofluid,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k5hsbOEAAAAJ&citation_for_view=k5hsbOEAAAAJ:IWHjjKOFINEC,"A numerical investigation of Casson nanofluid flow, heat transfer and entropy generation over a horizontal porous stretching surface is carried out in the present research. The simplified flow model includes the effect of Lorentz forces, Cattaneo-Christov heat flux, thermal radiation and non-uniform stretching of porous surface. Similarity technique is employed to reduce the governing nonlinear partial differential equations to a set of nonlinear ordinary differential equations. The resulting set is then solved using finite difference numerical scheme to approximate the solutions for the velocity, temperature and the entropy profiles. Furthermore, the skin friction factor and the heat exchange rate at the boundary have been computed and explored graphically. The numerical computations are carried for Cu-H 2 O and TiO 2-H 2 O nanofluids. The significant findings of the study are the negative impact of Lorentz forces on the …",Elsevier,,2018
1289,"Mathematical model for thermal solar collectors by using magnetohydrodynamic maxwell nanofluid with slip conditions, thermal radiation and variable thermal conductivity",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k5hsbOEAAAAJ&citation_for_view=k5hsbOEAAAAJ:ZeXyd9-uunAC,"Solar energy is the cleanest, renewable and most abundant source of energy available on earth. The main use of solar energy is to heat and cool buildings, heat water and to generate electricity. There are two types of solar energy collection system, the photovoltaic systems and the solar thermal collectors. The efficiency of any solar thermal system depend on the thermophysical properties of the operating fluids and the geometry/length of the system in which fluid is flowing. In the present research a simplified mathematical model for the solar thermal collectors is considered in the form of non-uniform unsteady stretching surface. The flow is induced by a non-uniform stretching of the porous sheet and the uniform magnetic field is applied in the transverse direction to the flow. The non-Newtonian Maxwell fluid model is utilized for the working fluid along with slip boundary conditions. Moreover the high temperature …",Elsevier,,2017
1290,Non-Newtonian flow-induced deformation from pressurized cavities in absorbing porous tissues,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k5hsbOEAAAAJ&citation_for_view=k5hsbOEAAAAJ:qUcmZB5y_30C,We investigate the behavior of a spherical cavity in a soft biological tissue modeled as a deformable porous material during an injection of non-Newtonian fluid that follows a power law model. Fluid flows into the neighboring tissue due to high cavity pressure where it is absorbed by capillaries and lymphatics at a rate proportional to the local pressure. Power law fluid pressure and displacement of a solid in the tissue are computed as function of radial distance and time. Numerical solutions indicate that shear thickening fluids exhibit less fluid pressure and induce small solid deformation as compared to shear thinning fluids. Absorption in the biological tissue increases as a consequence of flow-induced deformation for power law fluids. In most cases non-Newtonian results are compared with the viscous fluid case to magnify the differences.,Taylor & Francis,,2017
1291,Joule and Viscous Dissipation Effects on MHD Boundary Layer Flow over a Stretching Sheet with Variable Thickness,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k5hsbOEAAAAJ&citation_for_view=k5hsbOEAAAAJ:TQgYirikUcIC,"This paper is aimed to investigate the influence of Joule and viscous dissipation effects on boundary layer flow over a stretching sheet with variable thickness and surface temperature. The said flow is subjected to space dependent magnetic field applied normal to the sheet. Mathematical modeling is done under boundary layer approximations. The governing partial differential equations are transformed into ordinary differential equations via appropriate similarity transformations. The resulting set of nonlinear equations is solved numerically using shooting method. MATLAB software is used to obtain numerical results. The impact of various physical parameters, such as power index, magnetic parameter, on velocity and temperature profiles is analyzed. Also, their effects on skin friction coefficient and Nusselt number are presented and discussed.",,,2022
1292,Infiltration of MHD liquid into a deformable porous material,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k5hsbOEAAAAJ&citation_for_view=k5hsbOEAAAAJ:hFOr9nPyWt4C,"We analyze the capillary rise dynamics for magnetohydrodynamics (MHD) fluid flow through deformable porous material in the presence of gravity effects. The modeling is performed using mixture theory approach and mathematical manipulation yields a nonlinear free boundary problem. Due to the capillary rise action, the pressure gradient in the liquid generates a stress gradient that results in the deformation of porous substrate. The capillary rise process for MHD fluid slows down as compared to Newtonian fluid case. Numerical solutions are obtained using a method of lines approach. The graphical results are presented for important physical parameters, and comparison is presented with Newtonian fluid case.",Elsevier,,2018
1293,A MATHEMATICAL MODEL OF NON-NEWTONIAN FLUID FLOW THROUGH A POROELASTIC CYLINDER WITH MOVING BOUNDARIES,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k5hsbOEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=k5hsbOEAAAAJ:e5wmG9Sq2KIC,"This paper investigates the radial flow of a non-Newtonian fluid through a poroelastic cylinder with moving boundaries. Some applications of the present work include fluid flow through arteries, pressurization of boreholes, extraction of oil from earth, and filtration processes. A general (ie, planar, cylindrical, and spherical) one-dimensional nonlinear diffusion equation for dilatation is derived for a power-law fluid, and a relation for the solid displacement is given. Geometrically, two different cases of a poroelastic cylinder, ie, constrained and unconstrained, are considered and corresponding nonclassical time-dependent integral boundary conditions are presented. The governing nonlinear moving boundary value problem is first nondimensionalized by choosing suitable dimensionless quantities and then transformed to a fixed domain by employing a transformation. The closed form equilibrium solutions for dilatation …",Begel House Inc.,,2025
1294,Effect of inertia on viscous fluid in a wall-driven corner flow with leakage,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k5hsbOEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=k5hsbOEAAAAJ:HDshCWvjkbEC,"A study of the inertial flow of a viscous fluid near the corner of two intersecting walls with leakage is presented. The flow is primarily generated when one of the walls is moved parallel to itself, but a mass source or sink due to leakage at the apex of the corner can also effect it. The non-linear partial differential equations that arise due to inertial forces are solved analytically, and an approximate solution is obtained by applying a recursive approach. Furthermore, the expressions for stream functions, velocity fields, pressure fields, and the tangential and normal stresses upto second approximation have been obtained. Finally, the effect of inertial forces on the stresses, velocity components and streamlines is discussed with the help of graphs.",Natural Sciences Publishing Corporation,,2019
1295,Dendritic cell activation and T cell priming with adjuvant-and antigen-loaded oxidation-sensitive polymersomes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wkqsNacAAAAJ&citation_for_view=wkqsNacAAAAJ:Y0pCki6q_DkC,"While current subunit vaccines successfully induce humoral immune responses, a need exists for vaccine strategies to elicit strong cell-mediated immunity to address diseases such as cancer and chronic viral infection. Polymersomes are stable vesicles composed of self-assembling block copolymers with tunable degradation properties allowing delivery of both hydrophilic (within vesicle interior) or hydrophobic (within vesicle membrane) payload molecules. Here we apply oxidation-sensitive nanoscale polymersomes for both antigen and adjuvant delivery to dendritic cell (DC) endosomes. Calcein-loaded polymersomes were observed to release their payload initially in multiple DC endosomal compartments and subsequently within the cytosol. With either the Toll-like receptor agonists gardiquimod or R848 as payloads within the polymersomes, release resulted in DC activation, as indicated by induction of …",Elsevier,,2012
1296,Toll-like receptor 8 agonist nanoparticles mimic immunomodulating effects of the live BCG vaccine and enhance neonatal innate and adaptive immune responses,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wkqsNacAAAAJ&citation_for_view=wkqsNacAAAAJ:TQgYirikUcIC,"Background Newborns display distinct immune responses, leaving them vulnerable to infections and impairing immunization. Targeting newborn dendritic cells (DCs), which integrate vaccine signals into adaptive immune responses, might enable development of age-specific vaccine formulations to overcome suboptimal immunization. Objective Small-molecule imidazoquinoline Toll-like receptor (TLR) 8 agonists robustly activate newborn DCs but can result in reactogenicity when delivered in soluble form. We used rational engineering and age- and species-specific modeling to construct and characterize polymer nanocarriers encapsulating a TLR8 agonist, allowing direct intracellular release after selective uptake by DCs. Methods Chemically similar but morphologically distinct nanocarriers comprised of amphiphilic block copolymers were engineered for targeted uptake by murine DCs in vivo, and a range of TLR8 …",Mosby,,2017
1297,Tunable T cell immunity towards a protein antigen using polymersomes vs. solid-core nanoparticles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wkqsNacAAAAJ&citation_for_view=wkqsNacAAAAJ:0EnyYjriUFMC,"Using poly(propylene sulfide) (PPS) and poly(ethylene glycol) (PEG) as components of a nanocarrier platform, we sought to compare immune responses induced by PPS-bl-PEG polymersomes (PSs; watery-core structures, with antigen incorporated within the PSs) and PEG-stabilized PPS nanoparticles (NPs; solid-core structures, with antigen conjugated upon the NP surface). We have previously shown strong CD8+ T cell responses to antigen conjugated to NPs via a disulfide link, and here we investigated the extent to which antigen incorporated within oxidatively-sensitive PSs could induce CD4+ or CD8+ T cell responses. C57BL/6 mice were subcutaneously immunized with free ovalbumin (OVA) as a model antigen, or equivalent doses of OVA-loaded into PSs, conjugated onto NPs, or given as a mixture of the two. Free CpG was used as an adjuvant. Antigen-loaded PSs induced enhanced frequencies of …",Elsevier,,2013
1298,Tailoring nanostructure morphology for enhanced targeting of dendritic cells in atherosclerosis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wkqsNacAAAAJ&citation_for_view=wkqsNacAAAAJ:mB3voiENLucC,"Atherosclerosis, a leading cause of heart disease, results from chronic vascular inflammation that is driven by diverse immune cell populations. Nanomaterials may function as powerful platforms for diagnostic imaging and controlled delivery of therapeutics to inflammatory cells in atherosclerosis, but efficacy is limited by nonspecific uptake by cells of the mononuclear phagocytes system (MPS). MPS cells located in the liver, spleen, blood, lymph nodes, and kidney remove from circulation the vast majority of intravenously administered nanomaterials regardless of surface functionalization or conjugation of targeting ligands. Here, we report that nanostructure morphology alone can be engineered for selective uptake by dendritic cells (DCs), which are critical mediators of atherosclerotic inflammation. Employing near-infrared fluorescence imaging and flow cytometry as a multimodal approach, we compared organ and …",American Chemical Society,,2016
1299,Facile assembly and loading of theranostic polymersomes via multi-impingement flash nanoprecipitation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wkqsNacAAAAJ&citation_for_view=wkqsNacAAAAJ:e5wmG9Sq2KIC,"Flash nanoprecipitation (FNP) has proven to be a powerful tool for the rapid and scalable assembly of solid-core nanoparticles from block copolymers. The process can be performed using a simple confined impingement jets mixer and provides an efficient and reproducible method of loading micelles with hydrophobic drugs. To date, FNP has not been applied for the fabrication of complex or vesicular nanoarchitectures capable of encapsulating hydrophilic molecules or bioactive protein therapeutics. Here, we present FNP as a single customizable method for the assembly of bicontinuous nanospheres, filomicelles and vesicular, multilamellar and tubular polymersomes from poly(ethylene glycol)-bl-poly(propylene sulfide) block copolymers. Multiple impingements of polymersomes assembled via FNP were shown to decrease vesicle diameter and polydispersity, allowing gram-scale fabrication of monodisperse …",Elsevier,,2017
1300,Linking autophagy to endothelial cell immunogenicity in transplant-associated ischemia-reperfusion injury,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wkqsNacAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wkqsNacAAAAJ:fEOibwPWpKIC,"Background Cold storage (CS) and ischemia-reperfusion injury (IRI) are inevitable consequences of heart transplantation (HTx), primarily affecting the microvascular endothelial cells (ECs) of donor hearts. The nutrient deprivation and oxidative stresses sustained by ECs during CS and IRI activate and trigger alloimmune recognition. ECs adapt to these conditions by utilizing autophagy to maintain cellular homeostasis. Whether autophagy plays a role in EC activation and immunogenicity during CS and IRI in HTx remains unknown. Methods Autophagy in murine microvascular cardiac endothelial cells (MCEC) was modulated by genetic (knockout of the autophagy-related gene 5 (Atg5) by CRISPR/Cas9 technology) or pharmacological (rapamycin to induce autophagy and chloroquine to inhibit autophagy) approaches or by nanocarriers encapsulating rapamycin. MCECs were subjected to a previously established …",Elsevier,,2025
1301,Facile Assembly of Soft Nanoarchitectures and Co-Loading of Hydrophilic and Hydrophobic Molecules via Flash Nanoprecipitation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wkqsNacAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wkqsNacAAAAJ:j8SEvjWlNXcC,"Described herein are flash nanoprecipitation methods capable of encapsulating hydrophobic molecules, hydrophilic molecules, bioactive protein therapeutics, or other target molecules in amphiphilic copolymer nanocarriers.",,,2025
1302,Filomicelle-Embedded Composite Hydrogels for Localized Gelation within the Anterior Chamber of the Eye,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wkqsNacAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wkqsNacAAAAJ:-_dYPAW6P2MC,"Nanocarriers hold transformative potential for treating anterior segment eye diseases, yet corneal epithelium impermeability necessitates intraocular injection. Given the discomfort and infection risk, an injectable hydrogel-based depot offers a promising strategy for sustained nanocarrier delivery in intraocular therapy. However, because the aqueous humor is a large, fluid-filled environment, achieving spatially confined gelation remains a key challenge as injected materials rapidly diffuse. Herein, we present a composite hydrogel (C-gel) that enables localized in situ gelation and sustained nanocarrier release within the anterior chamber. This is achieved using poly(ethylene glycol)-b-poly(propylene sulfide) (PEG-b-PPS) filomicelles (FMs), whose filamentous structure confines crosslinking reactions spatially, promoting efficient gel formation. As a result, 90% of the injected polymer is retained within the crosslinked hydrogel matrix. Embedded FMs then undergo oxidation-induced cylinder-to-sphere transitions, facilitating gradual release of micellar nanocarriers. The rheological properties, gelation timing, and microstructure of the C-gel are adjustable, allowing precise control of nanocarrier release dynamics. In vivo evaluation in mice confirmed excellent biocompatibility without inducing intraocular pressure elevation, ocular toxicity, or immune cell infiltration. Sustained release of nanocarriers was observed for over a month under conditions mimicking that of the anterior chamber of the eye, underscoring the potential of C-gels for long-term drug delivery in anterior segment eye diseases therapy.",Cold Spring Harbor Laboratory,,2025
1303,A biomimetic multi-component subunit vaccine via ratiometric loading of hierarchical hydrogels,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wkqsNacAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wkqsNacAAAAJ:dTyEYWd-f8wC,"The development of subunit vaccines that mimic the molecular complexity of attenuated vaccines has been limited by the difficulty of intracellular co-delivery of multiple chemically diverse payloads at controllable concentrations. We report on hierarchical hydrogel depots employing simple poly(propylene sulfone) homopolymers to enable ratiometric loading of a protein antigen and four physicochemically distinct adjuvants in a hierarchical manner. The optimized vaccine consisted of immunostimulants either adsorbed to or encapsulated within nanogels, which were capable of noncovalent anchoring to subcutaneous tissues. In female BALB/c and C57BL/6 mice, these 5-component nanogel vaccines demonstrated enhanced humoral and cell-mediated immune responses compared to formulations with standard single adjuvant and antigen pairing. The use of a single simple homopolymer capable of rapid and stable …",Nature Publishing Group UK,,2025
1304,New tools for genetic targeting of the Schlemm's canal endothelium,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wkqsNacAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wkqsNacAAAAJ:evX43VCCuoAC,"Purpose: Schlemm’s canal (SC) carries the majority of aqueous humor outflow and is a key mediator of IOP. Understanding genes and pathways regulating SC endothelial cells is crucial to the next generation of glaucoma therapies. Tamoxifen-inducible Cre-loxP systems (Cre-ERT2) are a critical tool for these studies, allowing cell-type specific gene deletion and generation of new glaucoma models. However, they depend on tissue-specific promotors to drive Cre expression and no ideal Cre mouse lines exist for specific SC targeting. We have developed a novel nanocarrier to deliver the active tamoxifen metabolite 4-OH-tamoxifen to the SC endothelium. This system provides highly efficient, SC-specific deletion, and eliminates systemic phenotypes when using nonspecific Cre mouse strains Methods: We have reported that poly (ethylene glycol)-b-poly (propylene sulfide) nanocarriers with a VEGF-C derived …",The Association for Research in Vision and Ophthalmology,,2025
1305,Supporting controlled experimentation with testing techniques: An infrastructure and its potential impact,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swPW5FYAAAAJ&citation_for_view=swPW5FYAAAAJ:u-x6o8ySG0sC,"Where the creation, understanding, and assessment of software testing and regression testing techniques are concerned, controlled experimentation is an indispensable research methodology. Obtaining the infrastructure necessary to support such experimentation, however, is difficult and expensive. As a result, progress in experimentation with testing techniques has been slow, and empirical data on the costs and effectiveness of techniques remains relatively scarce. To help address this problem, we have been designing and constructing infrastructure to support controlled experimentation with testing and regression testing techniques. This paper reports on the challenges faced by researchers experimenting with testing techniques, including those that inform the design of our infrastructure. The paper then describes the infrastructure that we are creating in response to these challenges, and that we are now …",Kluwer Academic Publishers,,2005
1306,Test case prioritization: A family of empirical studies,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swPW5FYAAAAJ&citation_for_view=swPW5FYAAAAJ:u5HHmVD_uO8C,"To reduce the cost of regression testing, software testers may prioritize their test cases so that those which are more important, by some measure, are run earlier in the regression testing process. One potential goal of such prioritization is to increase a test suite's rate of fault detection. Previous work reported results of studies that showed that prioritization techniques can significantly improve rate of fault detection. Those studies, however, raised several additional questions: 1) Can prioritization techniques be effective when targeted at specific modified versions; 2) what trade-offs exist between fine granularity and coarse granularity prioritization techniques; 3) can the incorporation of measures of fault proneness into prioritization techniques improve their effectiveness? To address these questions, we have performed several new studies in which we empirically compared prioritization techniques using both controlled …",IEEE,,2002
1307,Prioritizing test cases for regression testing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swPW5FYAAAAJ&citation_for_view=swPW5FYAAAAJ:d1gkVwhDpl0C,"Test case prioritization techniques schedule test cases in an order that increases their effectiveness in meeting some performance goal. One performance goal, rate of fault detection, is a measure of how quickly faults are detected within the testing process; an improved rate of fault detection can provide faster feedback on the system under test, and let software engineers begin locating and correcting faults earlier than might otherwise be possible. In previous work, we reported the results of studies that showed that prioritization techniques can significantly improve rate of fault detection. Those studies, however, raised several additional questions: (1) can prioritization techniques be effective when aimed at specific modified versions; (2) what tradeoffs exist between fine granularity and coarse granularity prioritization techniques; (3) can the incorporation of measures of fault proneness into prioritization techniques …",,,2000
1308,Incorporating varying test costs and fault severities into test case prioritization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swPW5FYAAAAJ&citation_for_view=swPW5FYAAAAJ:qjMakFHDy7sC,"Test case prioritization techniques schedule test cases for regression testing in an order that increases their ability to meet some performance goal. One performance goal, rate of fault detection, measures how quickly faults are detected within the testing process. In previous work (S. Elbaum et al., 2000; G. Rothermel et al., 1999), we provided a metric, APFD, for measuring rate of fault detection, and techniques for prioritizing test cases to improve APFD, and reported the results of experiments using those techniques. This metric and these techniques, however, applied only in cases in which test costs and fault severity are uniform. We present a new metric for assessing the rate of fault detection of prioritized test cases that incorporates varying test case and fault costs. We present the results of a case study illustrating the application of the metric. This study raises several practical questions that might arise in applying …",IEEE,,2001
1309,Techniques for improving regression testing in continuous integration development environments,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swPW5FYAAAAJ&citation_for_view=swPW5FYAAAAJ:t7zJ5fGR-2UC,"In continuous integration development environments, software engineers frequently integrate new or changed code with the mainline codebase. This can reduce the amount of code rework that is needed as systems evolve and speed up development time. While continuous integration processes traditionally require that extensive testing be performed following the actual submission of code to the codebase, it is also important to ensure that enough testing is performed prior to code submission to avoid breaking builds and delaying the fast feedback that makes continuous integration desirable. In this work, we present algorithms that make continuous integration processes more cost-effective. In an initial pre-submit phase of testing, developers specify modules to be tested, and we use regression test selection techniques to select a subset of the test suites for those modules that render that phase more cost-effective …",,,2014
1310,T4PC: Training Deep Neural Networks for Property Conformance,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swPW5FYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=swPW5FYAAAAJ:PaBasH6fAo0C,"The increasing integration of Deep Neural Networks (DNNs) into safety critical systems, such as Autonomous Vehicles (AVs), where failures can lead to significant consequences, has fostered the development of many Verification and Validation (V&V) techniques. However, these techniques are applied mainly after the DNN training process is complete. This delayed application of V&V techniques means that property violations found require restarting the expensive training process, and that V&V techniques struggle in pursuit of checking increasingly large and sophisticated DNNs. To address this issue, we propose T4PC, a framework to increase property conformance during DNN training. Increasing property conformance is achieved by enriching: 1) the data preparation phase to account for properties’ pre and postcondition satisfaction, and 2) the training phase to account for the property satisfaction by …",IEEE,,2025
1311,Steering the Future: A Catalog of Failures in Deep Learning-Enabled Robotic Navigation Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swPW5FYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=swPW5FYAAAAJ:MpfHP-DdYjUC,"Failure catalogs have proven to be key instruments driving the evolution and assessment of program analysis techniques. However, such infrastructure does not support the development of techniques for the large number of emerging robotic systems. Developing such a catalog is costly and challenging because it requires access to the full physical system and the presentation of a diverse set of failures. We have started to tackle this challenge, building Defects4DeepNav, a growing catalog of over 100 failures from a commercial open source robot operating in the real world navigated by a learned component, with a diverse set of failures arising from 30 navigation components and growing. This paper introduces Defects4DeepNav, including a diverse set of failures, full sensor data for failing and non-failing behavior, tools to analyze the data, and illustrations of its potential use cases and extensions.",,,2025
1312,10 Years Later: Revisiting How Developers Search for Code,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swPW5FYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=swPW5FYAAAAJ:cK4Rrx0J3m0C,"Code search is an integral part of a developer’s workflow. In 2015, researchers published a paper reflecting on the code search practices at Google of 27 developers who used the internal Code Search tool. That paper had first-hand accounts for why those developers were using code search and highlighted how often and in what situations developers were searching for code. In the past decade, much has changed in the landscape of developer support. New languages have emerged, artificial intelligence (AI) for code generation has gained traction, auto-complete in the IDE has gotten better, Q&A forums have increased in popularity, and code repositories are larger than ever. It is worth considering whether those observations from almost a decade ago have stood the test of time. In this work, inspired by the prior survey about the Code Search tool, we run a series of three surveys with 1,945 total responses and …",ACM,,2025
1313,Scene Flow Specifications: Encoding and Monitoring Rich Temporal Safety Properties of Autonomous Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swPW5FYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=swPW5FYAAAAJ:kVjdVfd2voEC,"To ensure the safety of autonomous systems, it is imperative for them to abide by their safety properties. The specification of such safety properties is challenging because of the gap between the input sensor space (e.g., pixels, point clouds) and the semantic space over which safety properties are specified (e.g. people, vehicles, road). Recent work utilized scene graphs to overcome portions of that gap, enabling the specification and synthesis of monitors targeting many safe driving properties for autonomous vehicles. However, scene graphs are not rich enough to express the many driving properties that include temporal elements (i.e., when two vehicles enter an intersection at the same time, the vehicle on the left shall yield...), fundamentally limiting the types of specifications that can be monitored. In this work, we characterize the expressiveness required to specify a large body of driving properties, identify …",ACM,,2025
1314,Monitoring safety properties for autonomous driving systems with vision-language models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swPW5FYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=swPW5FYAAAAJ:LdasjJ6CEcoC,"With the increased adoption of autonomous vehicles comes the need to ensure they reliably follow safe driving properties. Formally specifying and monitoring such properties is challenging because of the semantic mismatch between the high-level properties (e.g., assertions on spatial relationships between the ego vehicle and other entities in a road scene) and the sensed inputs of the vehicles (e.g., raw pixels). For this reason, existing monitoring methods are applicable in limited simulation settings where the ground-truth spatial relationships are available. To bridge this gap we investigate the use of Vision-Language Models (VLMs) for extracting spatial relationships from real images of driving scenes. Towards this goal, we automated the process to extract triplets of the form <subject, relation, ego> from real image datasets such as nuScenes, Waymo, and KITTI, to create DriST, a dataset of road-scene images …",IEEE,,2025
1315,A community-driven global reconstruction of human metabolism,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bPsB_RIAAAAJ&citation_for_view=bPsB_RIAAAAJ:3s1wT3WcHBgC,"Multiple models of human metabolism have been reconstructed, but each represents only a subset of our knowledge. Here we describe Recon 2, a community-driven, consensus 'metabolic reconstruction', which is the most comprehensive representation of human metabolism that is applicable to computational modeling. Compared with its predecessors, the reconstruction has improved topological and functional features, including ∼2× more reactions and ∼1.7× more unique metabolites. Using Recon 2 we predicted changes in metabolite biomarkers for 49 inborn errors of metabolism with 77% accuracy when compared to experimental data. Mapping metabolomic data and drug information onto Recon 2 demonstrates its potential for integrating and analyzing diverse data types. Using protein expression data, we automatically generated a compendium of 65 cell type–specific models, providing a basis for manual …",Nature Publishing Group US,,2013
1316,Applications of genome‐scale metabolic reconstructions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bPsB_RIAAAAJ&citation_for_view=bPsB_RIAAAAJ:UeHWp8X0CEIC,"The availability and utility of genome‐scale metabolic reconstructions have exploded since the first genome‐scale reconstruction was published a decade ago. Reconstructions have now been built for a wide variety of organisms, and have been used toward five major ends: (1) contextualization of high‐throughput data, (2) guidance of metabolic engineering, (3) directing hypothesis‐driven discovery, (4) interrogation of multi‐species relationships, and (5) network property discovery. In this review, we examine the many uses and future directions of genome‐scale metabolic reconstructions, and we highlight trends and opportunities in the field that will make the greatest impact on many fields of biology.","John Wiley & Sons, Ltd",Molecular systems biology,2009
1317,Reconstruction of cellular signalling networks and analysis of their properties,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bPsB_RIAAAAJ&citation_for_view=bPsB_RIAAAAJ:u5HHmVD_uO8C,"The study of cellular signalling over the past 20 years and the advent of high-throughput technologies are enabling the reconstruction of large-scale signalling networks. After careful reconstruction of signalling networks, their properties must be described within an integrative framework that accounts for the complexity of the cellular signalling network and that is amenable to quantitative modelling.",Nature Publishing Group UK,Nature reviews Molecular cell biology,2005
1318,Genome-scale microbial in silico models: the constraints-based approach,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bPsB_RIAAAAJ&citation_for_view=bPsB_RIAAAAJ:d1gkVwhDpl0C,"Genome sequencing and annotation has enabled the reconstruction of genome-scale metabolic networks. The phenotypic functions that these networks allow for can be defined and studied using constraints-based models and in silico simulation. Several useful predictions have been obtained from such in silico models, including substrate preference, consequences of gene deletions, optimal growth patterns, outcomes of adaptive evolution and shifts in expression profiles. The success rate of these predictions is typically in the order of 70–90% depending on the organism studied and the type of prediction being made. These results are useful as a basis for iterative model building and for several practical applications.",Elsevier,Trends in biotechnology,2003
1319,MEMOTE for standardized genome-scale metabolic model testing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bPsB_RIAAAAJ&citation_for_view=bPsB_RIAAAAJ:3xcwCnWquLEC,"To the Editor—Reconstructing metabolic reaction networks enables the development of testable hypotheses of an organism’s metabolism under different conditions 1. State-of-the-art genome-scale metabolic models (GEMs) can include thousands of metabolites and reactions that are assigned to subcellular locations. Gene–protein–reaction (GPR) rules and annotations using database information can add metainformation to GEMs. GEMs with metadata can be built using standard reconstruction protocols 2, and guidelines have been put in place for tracking provenance and enabling interoperability, but a standardized means of quality control for GEMs is lacking 3. Here we report a community effort to develop a test suite named MEMOTE (for metabolic model tests) to assess GEM quality. Incompatible description formats and missing annotations 4 limit GEM reuse. Moreover, numerical errors 5 and omission of …",Nature Publishing Group US,,2020
1320,Reframing the role of the objective function in its proper context for metabolic network modeling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bPsB_RIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bPsB_RIAAAAJ:eRtW2U1rV1UC,"The ""objective function"" is a core concept in metabolic network modeling. Its use has enabled the analysis of large data to drive deeper understanding of cellular metabolism. This commentary reframes how the objective function is discussed to enhance its value and clarify misunderstandings in metabolic network modeling.",Elsevier,,2025
1321,Genome-scale metabolic network reconstruction analysis identifies bacterial vaginosis-associated metabolic interactions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bPsB_RIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bPsB_RIAAAAJ:_sH1KHQ1xKcC,"Bacterial vaginosis (BV) is the most prevalent vaginal condition among reproductive-age women presenting with vaginal complaints. Despite its significant impact on women’s health, limited knowledge exists regarding the microbial community composition and metabolic interactions associated with BV. In this study, we analyze metagenomic data obtained from human vaginal swabs to generate in silico predictions of BV-associated bacterial metabolic interactions via genome-scale metabolic network reconstructions (GENREs). While most efforts to characterize symptomatic BV (and thus guide therapeutic intervention by identifying responders and non-responders to treatment) are based on genomic profiling, our in silico simulations reveal functional metabolic relatedness between species as quite distinct from genetic relatedness. We grow several of the most common co-occurring bacteria (Prevotella amnii …",Nature Publishing Group UK,,2025
1322,"Methods, systems and compositions for the prediction and prevention of parenteral nutrition associated cholestasis using fecal biomarkers",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=bPsB_RIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=bPsB_RIAAAAJ:IEPzPICaOQQC,"Provided are biomarkers for parenteral nutrition associated cholestasis (PNAC) in subjects, especially infants receiving parenteral nutrition (PN). Using such biomarkers provide methods of diagnosing and/or assessing risk of PNAC in a subject, including screening a sample from a subject believed to be at risk for PNAC for one or more biomarkers of PNAC. The biomarkers can include one or more fecal metabolites. Such biomarkers and associated methods provide neonatal intensive care unit clinicians with an additional tool for early identification of PNAC risk. Early identification of high-risk infants would enable clinicians to confidently optimize caloric nutrition with PN for infants at low risk of developing PNAC and enable proactive mitigation with alterations to the administered PN.",,,2025
1323,Comparison of parametric and nonparametric models for traffic flow forecasting,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9uFvl5wAAAAJ&citation_for_view=9uFvl5wAAAAJ:u5HHmVD_uO8C,"Single point short-term traffic flow forecasting will play a key role in supporting demand forecasts needed by operational network models. Seasonal autoregressive integrated moving average (ARIMA), a classic parametric modeling approach to time series, and nonparametric regression models have been proposed as well suited for application to single point short-term traffic flow forecasting. Past research has shown seasonal ARIMA models to deliver results that are statistically superior to basic implementations of nonparametric regression. However, the advantages associated with a data-driven nonparametric forecasting approach motivate further investigation of refined nonparametric forecasting methods. Following this motivation, this research effort seeks to examine the theoretical foundation of nonparametric regression and to answer the question of whether nonparametric regression based on heuristically …",Pergamon,,2002
1324,Traffic flow forecasting: comparison of modeling approaches,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9uFvl5wAAAAJ&citation_for_view=9uFvl5wAAAAJ:u-x6o8ySG0sC,"The capability to forecast traffic volume in an operational setting has been identified as a critical need for intelligent transportation systems (ITS). In particular, traffic volume forecasts will support proactive, dynamic traffic control. However, previous attempts to develop traffic volume forecasting models have met with limited success. This research effort focused on developing traffic volume forecasting models for two sites on Northern Virginia's Capital Beltway. Four models were developed and tested for the freeway traffic flow forecasting problem, which is defined as estimating traffic flow 15 min into the future. They were the historical average, time-series, neural network, and nonparametric regression models. The nonparametric regression model significantly outperformed the other models. A Wilcoxon signed-rank test revealed that the nonparametric regression model experienced significantly lower errors than the …",American Society of Civil Engineers,,1997
1325,Short-Term Traffic Flow Prediction: Neural Network Approach,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9uFvl5wAAAAJ&citation_for_view=9uFvl5wAAAAJ:YFjsv_pBGBYC,,Transportation Research Board of the National Acad,,1994
1326,Traffic signal control with connected vehicles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9uFvl5wAAAAJ&citation_for_view=9uFvl5wAAAAJ:W5xh706n7nkC,"The operation of traffic signals is currently limited by the data available from traditional point sensors. Point detectors can provide only limited vehicle information at a fixed location. The most advanced adaptive control strategies are often not implemented in the field because of their operational complexity and high-resolution detection requirements. However, a new initiative known as connected vehicles allows the wireless transmission of the positions, headings, and speeds of vehicles for use by the traffic controller. A new traffic control algorithm, the predictive microscopic simulation algorithm, which uses these new, more robust data, was developed. The decentralized, fully adaptive traffic control algorithm uses a rolling-horizon strategy in which the phasing is chosen to optimize an objective function over a 15-s period in the future. The objective function uses either delay only or a combination of delay, stops, and …",SAGE Publications,,2013
1327,Divine war in the Old Testament and in the ancient Near East,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9uFvl5wAAAAJ&citation_for_view=9uFvl5wAAAAJ:L7CI7m0gUJcC,"The series Beihefte zur Zeitschrift fr die alttestamentliche Wissenschaft (BZAW) covers all areas of research into the Old Testament, focusing on the Hebrew Bible, its early and later forms in Ancient Judaism, as well as its branching into many neighboring cultures of the Ancient Near East and the Greco-Roman world.",Walter de Gruyter,,1989
1328,0844 Dermal fibroblast-derived thrombospondin 2 orchestrates extracellular matrix organization and influences wound healing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9uFvl5wAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9uFvl5wAAAAJ:lvd772isFD0C,"Background Diabetic and leprosy foot-ulcers remain major contributors to morbidity, disability and amputation, imposing a heavy economic burden on healthcare systems. Diabetic-ulcers affect 15-25% of patients globally, while Nepal continues to grapple with endemic leprosy, reporting annual prevalence of 11.8 per 100,000 in 2023, with 6% of cases presenting severe deformities and ulcers. Neuropathic-ulcers associated with leprosy are particularly resistant to conventional therapies. Platelet-Rich Plasma, abundant in growthfactors has shown promise in enhancing wound-healing. Methods A study was conducted with chronic foot ulcers (16 diabetic, 16 leprosy-related two groups). PRP therapy and conventional treatment. Wound healing was assessed using the Bates-Jensen Wound Assessment Tool, dermoscopy and vascular USG before and after treatment. Laboratory parameters included CRP, ESR, HbA1c …",Elsevier,,2025
1329,Evaluating current and future pedestrian mid-block crossing safety treatments using virtual reality simulation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9uFvl5wAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9uFvl5wAAAAJ:6ZxmRoH8BuwC,"Virtual reality (VR) simulation offers a proactive, cost effective, immersive, and low risk platform for studying pedestrian safety. Within immersive virtual environments (IVEs), existing and alternative design conditions and intelligent transportation systems (ITS) technologies can be directly compared, prior to real-world implementation, to assess the impacts alternatives may have on pedestrian safety, perception, and behavior. Environmental factors can be controlled within IVEs so that test trials are replicable and directly comparable. Coupled with stated preference feedback, participants’ observed preferences and behavior provide a comprehensive understanding of the impacts of proposed design alternatives. This research presents a case study of pedestrian behavior with three different mid-block crossing safety treatments modeled within a one-to-one scale IVE replication of a real-world location in Charlottesville …",Pergamon,,2024
1330,Immersive collaboration of remote participants via media displays,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9uFvl5wAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9uFvl5wAAAAJ:ODE9OILHJdcC,"An immersive digital experience for video conferencing simulates common presence of a virtual participant in a local environment. Such simulation may include (i) using a transparent media display having a portion of its pixels projecting the virtual participant's body image while keeping at least a portion of the background transparent (eg, to visible light),(ii) disposing sensor (s)(eg, camera) behind the transparent media display at the gaze of the participant, and/or (iii) using added virtual overlays (eg, of plants, memorabilia, and/or furniture) to the virtual image (eg, that are consistent with the local environment), eg, to provide a sense of depth ranging from the overlays to the virtual participant projection and to the background showing through the transparent media display.",,,2024
1331,Cyberattack monitoring architectures for resilient operation of connected and automated vehicles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9uFvl5wAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9uFvl5wAAAAJ:yFnVuubrUp4C,"The deployment of connected and automated vehicles (CAVs) may enhance operations and safety with little human feedback. Automation requires the use of communication and smart devices, thus introducing potential access points for adversaries. This paper develops a prototype real-time monitoring system for a vehicle to infrastructure (V2I) based CAV system that generates cyberattack data for CAV operations under realistic traffic conditions. The monitoring system detects any deviations from the normal operation of CAVs using a long-short term memory (LSTM) neural network proposed by the authors and reverts the system back to a safe state of operation using a set of countermeasures. The proposed algorithm was also compared to convolutional neural network (CNN) and other classical algorithms. The monitoring system detected three different emulated cyberattacks with high accuracy. The LSTM showed …",IEEE,,2024
1332,Display construct for media projection and wireless charging,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=9uFvl5wAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=9uFvl5wAAAAJ:QYdC8u9Cj1oC,"2023-05-25 Assigned to VIEW, INC. reassignment VIEW, INC. ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS). Assignors: SARIN, AMIT, MUSTAFA, AHMED, GHANTIWALA, NAYANA VASANT, YOUNG, ANTHONY, ANTES, TODD DANIEL, CHAN, CHEE YUNG, KAILASAM, Sridhar Karthik, MARTINSON, Robert Michael, NGUYEN, VINH N., Sheffield, Matthew Burton, TRIKHA, NITESH",,,2024
1333,Research Progress on Memristor: From Synapses to Computing Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_JIESQ8AAAAJ&citation_for_view=_JIESQ8AAAAJ:Y0pCki6q_DkC,"As the limits of transistor technology are approached, feature size in integrated circuit transistors has been reduced very near to the minimum physically-realizable channel length, and it has become increasingly difficult to meet expectations outlined by Moore’s law. As one of the most promising devices to replace transistors, memristors have many excellent properties that can be leveraged to develop new types of neural and non-von Neumann computing systems, which are expected to revolutionize information-processing technology. This survey provides a comparative overview of research progress on memristors. Different memristor synaptic devices are classified according to stimulation patterns and the working mechanisms of these various synaptic devices are analyzed in detail. Crossbar-based memristors have demonstrated advantages in physically executing vector-matrix multiplication and enabling highly …",IEEE,,2022
1334,ReTransformer: ReRAM-based Processing-in-Memory Architecture for Transformer Acceleration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_JIESQ8AAAAJ&citation_for_view=_JIESQ8AAAAJ:9yKSN-GCB0IC,"Transformer has emerged as a popular deep neural network (DNN) model for Neural Language Processing (NLP) applications and demonstrated excellent performance in neural machine translation, entity recognition, etc. However, its scaled dot-product attention mechanism in auto-regressive decoder brings a performance bottleneck during inference. Transformer is also computationally and memory intensive and demands for a hardware acceleration solution. Although researchers have successfully applied ReRAM-based Processing-in-Memory (PIM) to accelerate convolutional neural networks (CNNs) and recurrent neural networks (RNNs), the unique computation process of the scaled dot-product attention in Transformer makes it difficult to directly apply these designs. Besides, how to handle intermediate results in Matrix-matrix Multiplication (MatMul) and how to design a pipeline at a finer granularity of …",,,2020
1335,Harnessing Optoelectronic Noises in a Photonic Generative Network,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_JIESQ8AAAAJ&citation_for_view=_JIESQ8AAAAJ:WF5omc3nYNoC,"Integrated optoelectronics is emerging as a promising platform of neural network accelerator, which affords efficient in-memory computing and high bandwidth interconnectivity. The inherent optoelectronic noises, however, make the photonic systems error-prone in practice. It is thus imperative to devise strategies to mitigate and, if possible, harness noises in photonic computing systems. Here, we demonstrate a photonic generative network as a part of a generative adversarial network (GAN). This network is implemented with a photonic core consisting of an array of programable phase-change memory cells to perform four-element vector-vector dot multiplication. The GAN can generate a handwritten number (“7”) in experiments and full 10 digits in simulation. We realize an optical random number generator, apply noise-aware training by injecting additional noise, and demonstrate the network’s resilience to …",American Association for the Advancement of Science,,2022
1336,Multi-Objective Optimization of ReRAM Crossbars for Robust DNN Inferencing under Stochastic Noise,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_JIESQ8AAAAJ&citation_for_view=_JIESQ8AAAAJ:qjMakFHDy7sC,"Resistive random-access memory (ReRAM) is a promising technology for designing hardware accelerators for deep neural network (DNN) inferencing. However, stochastic noise in ReRAM crossbars can degrade the DNN inferencing accuracy. We propose the design and optimization of a high-performance, area-and energy-efficient ReRAM-based hardware accelerator to achieve robust DNN inferencing in the presence of stochastic noise. We make two key technical contributions. First, we propose a stochastic-noise-aware training method, referred to as ReSNA, to improve the accuracy of DNN inferencing on ReRAM crossbars with stochastic noise. Second, we propose an information-theoretic algorithm, referred to as CF-MESMO, to identify the Pareto set of solutions to trade-off multiple objectives, including inferencing accuracy, area overhead, execution time, and energy consumption. The main challenge in …",IEEE,,2021
1337,Memory Is All You Need: An Overview of Compute-in-Memory Architectures for Accelerating Large Language Model Inference,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_JIESQ8AAAAJ&citation_for_view=_JIESQ8AAAAJ:KlAtU1dfN6UC,"Large language models (LLMs) have recently transformed natural language processing, enabling machines to generate human-like text and engage in meaningful conversations. This development necessitates speed, efficiency, and accessibility in LLM inference as the computational and memory requirements of these systems grow exponentially. Meanwhile, advancements in computing and memory capabilities are lagging behind, exacerbated by the discontinuation of Moore's law. With LLMs exceeding the capacity of single GPUs, they require complex, expert-level configurations for parallel processing. Memory accesses become significantly more expensive than computation, posing a challenge for efficient scaling, known as the memory wall. Here, compute-in-memory (CIM) technologies offer a promising solution for accelerating AI inference by directly performing analog computations in memory, potentially reducing latency and power consumption. By closely integrating memory and compute elements, CIM eliminates the von Neumann bottleneck, reducing data movement and improving energy efficiency. This survey paper provides an overview and analysis of transformer-based models, reviewing various CIM architectures and exploring how they can address the imminent challenges of modern AI computing systems. We discuss transformer-related operators and their hardware acceleration schemes and highlight challenges, trends, and insights in corresponding CIM designs.",,arXiv preprint arXiv:2406.08413,2024
1338,Norm-Q: Effective Compression Method for Hidden Markov Models in Neuro-Symbolic Applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_JIESQ8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_JIESQ8AAAAJ:hC7cP41nSMkC,"Hidden Markov models (HMM) are commonly used in generation tasks and have demonstrated strong capabilities in neuro-symbolic applications for the Markov property. These applications leverage the strengths of neural networks and symbolic reasoning to create robust and interpretable AI systems. However, they may inherit and amplify the shortcomings of both approaches. Both components require dense computation and data transfer, and their communication further hinders performance. This paper proposes Norm-Q, a normalized linear quantization approach for compressing probabilistic symbolic models, such as HMMs. We reduce the bit width of the data with minimal impact, thereby alleviating memory and bandwidth stress and enabling deployment on potential custom hardware. Our method introduces a normalized quantization-aware expectation maximization process for probabilistic model training. The experimental results show that Norm-Q achieves a higher compression rate with reasonable score loss compared to traditional quantization methods. In the case of the constrained generation task of large language models, we successfully quantize an HMM of 4096 hidden states to 8 bits without loss and, at most, 3 bits with acceptable loss. Notably, the Norm-Q method can achieve a compression rate of 99% for the weights of the HMM. The code is open source at https://github.com/superstarghy/Norm-Q.",,,2025
1339,Titanus: Enabling KV Cache Pruning and Quantization On-the-Fly for LLM Acceleration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_JIESQ8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_JIESQ8AAAAJ:9ZlFYXVOiuMC,"Large language models (LLMs) have gained great success in various domains. Existing systems cache Key and Value within the attention block to avoid redundant computations. However, the size of key-value cache (KV cache) is unpredictable and can even be tens of times larger than the weights in the long context length scenario. In this work, we propose Titanus, a software-hardware co-design to efficiently compress the KV cache on-the-fly. We first propose the cascade pruning-quantization (CPQ) method to reduce the KV cache movement. The hierarchical quantization extension strategy is introduced to tackle the non-independent per-channel quantization issue. To further reduce KV cache movement, we transfer only the non-zero KV cache between the accelerator and off-chip memory. Moreover, we customize a two-stage design space exploration framework for the CPQ method. A novel pipeline and parallelism dataflow is designed to reduce the first token generation time. Experiments show that Titanus achieves 159.9x (49.6x) and 34.8x (29.2x) energy efficiency (throughput) compared to Nvidia A100 GPU and FlightLLM respectively. The code for Titanus is available at https://github.com/peilin-chen/Titanus-for-LLM-acceleration.",,,2025
1340,AutoRAC: Automated Processing-in-Memory Accelerator Design for Recommender Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_JIESQ8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_JIESQ8AAAAJ:dhFuZR0502QC,"The performance bottleneck of deep-learning-based recommender systems resides in their backbone Deep Neural Networks. By integrating Processing-In-Memory (PIM) architectures, researchers can reduce data movement and enhance energy efficiency, paving the way for next-generation recommender models. Nevertheless, achieving performance and efficiency gains is challenging due to the complexity of the PIM design space and the intricate mapping of operators. In this paper, we demonstrate that automated PIM design is feasible even within the most demanding recommender model design space, spanning over 1054 possible architectures. We propose AutoRAC, which formulates the co-optimization of recommender models and PIM design as a combinatorial search over mixed-precision interaction operations, and parameterizes the search with a one-shot supernet encompassing all mixed-precision …",,,2025
1341,Neuromorphic Computing in the Era of Large Models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_JIESQ8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_JIESQ8AAAAJ:qxL8FJ1GzNcC,"The rapid advancement of deep learning and the emergence of large-scale neural models, such as bidirectional encoder representations from transformers (BERT), generative pre-trained transformer (GPT), and large language model Meta AI (LLaMa), have brought significant computational and energy challenges. Neuromorphic computing presents a biologically inspired approach to addressing these issues, leveraging event-driven processing and in-memory computation for enhanced energy efficiency. This survey explores the intersection of neuromorphic computing and large-scale deep learning models, focusing on neuromorphic models, learning methods, and hardware. We highlight transferable techniques from deep learning to neuromorphic computing and examine the memory-related scalability limitations of current neuromorphic systems. Furthermore, we identify potential directions to enable …",Southwest University,,2025
1342,Optimizing and Exploring System Performance in Compact Processing-in-Memory-based Chips,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_JIESQ8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_JIESQ8AAAAJ:M3ejUd6NZC8C,"Processing-in-memory (PIM) is a promising computing paradigm to tackle the ""memory wall"" challenge. However, PIM system-level benefits over traditional von Neumann architecture can be reduced when the memory array cannot fully store all the neural network (NN) weights. The NN size is increasing while the PIM design size cannot scale up accordingly due to area constraints. Therefore, this work targets the system performance optimization and exploration for compact PIM designs. We first analyze the impact of data movement on compact designs. Then, we propose a novel pipeline method that maximizes the reuse of NN weights to improve the throughput and energy efficiency of inference in compact chips. To further boost throughput, we introduce a scheduling algorithm to mitigate the pipeline bubble problem. Moreover, we investigate the trade-off between the network size and system performance for a compact PIM chip. Experimental results show that the proposed algorithm achieves 2.35x and 0.5% improvement in throughput and energy efficiency, respectively. Compared to the area-unlimited design, our compact chip achieves approximately 56.5% of the throughput and 58.6% of the energy efficiency while using only one-third of the chip area, along with 1.3x improvement in area efficiency. Our compact design also outperforms the modern GPU with 4.56x higher throughput and 157x better energy efficiency. Besides, our compact design uses less than 20% of the system energy for data movement as batch size scales up.",,,2025
1343,A Deeper Look at Experience Replay,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pn7fj4IAAAAJ&citation_for_view=Pn7fj4IAAAAJ:u5HHmVD_uO8C,"Recently experience replay is widely used in various deep reinforcement learning (RL) algorithms, in this paper we rethink the utility of experience replay. It introduces a new hyper-parameter, the memory buffer size, which needs carefully tuning. However unfortunately the importance of this new hyper-parameter has been underestimated in the community for a long time. In this paper we did a systematic empirical study of experience replay under various function representations. We showcase that a large replay buffer can significantly hurt the performance. Moreover, we propose a simple O(1) method to remedy the negative influence of a large replay buffer. We showcase its utility in both simple grid world and challenging domains like Atari games.",,,2017
1344,GradientDICE: Rethinking Generalized Offline Estimation of Stationary Values,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pn7fj4IAAAAJ&citation_for_view=Pn7fj4IAAAAJ:8k81kl-MbHgC,"We present GradientDICE for estimating the density ratio between the state distribution of the target policy and the sampling distribution in off-policy reinforcement learning. GradientDICE fixes several problems of GenDICE (Zhang et al., 2020), the current state-of-the-art for estimating such density ratios. Namely, the optimization problem in GenDICE is not a convex-concave saddle-point problem once nonlinearity in optimization variable parameterization is introduced to ensure positivity, so primal-dual algorithms are not guaranteed to find the desired solution. However, such nonlinearity is essential to ensure the consistency of GenDICE even with a tabular representation. This is a fundamental contradiction, resulting from GenDICE’s original formulation of the optimization problem. In GradientDICE, we optimize a different objective from GenDICE by using the Perron-Frobenius theorem and eliminating GenDICE’s use of divergence, such that nonlinearity in parameterization is not necessary for GradientDICE, which is provably convergent under linear function approximation.",,,2020
1345,Distributional Reinforcement Learning for Efficient Exploration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pn7fj4IAAAAJ&citation_for_view=Pn7fj4IAAAAJ:YsMSGLbcyi4C,"In distributional reinforcement learning (RL), the estimated distribution of value functions model both the parametric and intrinsic uncertainties. We propose a novel and efficient exploration method for deep RL that has two components. The first is a decaying schedule to suppress the intrinsic uncertainty. The second is an exploration bonus calculated from the upper quantiles of the learned distribution. In Atari 2600 games, our method achieves 483% average gain across 49 games in cumulative rewards over QR-DQN. We also compared our algorithm with QR-DQN in a challenging 3D driving simulator (CARLA). Results show that our algorithm achieves nearoptimal safety rewards twice faster than QRDQN.",,,2019
1346,DAC: The Double Actor-Critic Architecture for Learning Options,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pn7fj4IAAAAJ&citation_for_view=Pn7fj4IAAAAJ:Y0pCki6q_DkC,"We reformulate the option framework as two parallel augmented MDPs. Under this novel formulation, all policy optimization algorithms can be used off the shelf to learn intra-option policies, option termination conditions, and a master policy over options. We apply an actor-critic algorithm on each augmented MDP, yielding the Double Actor-Critic (DAC) architecture. Furthermore, we show that, when state-value functions are used as critics, one critic can be expressed in terms of the other, and hence only one critic is necessary. We conduct an empirical study on challenging robot simulation tasks. In a transfer learning setting, DAC outperforms both its hierarchy-free counterpart and previous gradient-based option learning algorithms.",,,2019
1347,"mlpack 3: a fast, flexible machine learning library",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pn7fj4IAAAAJ&citation_for_view=Pn7fj4IAAAAJ:d1gkVwhDpl0C,"In the past several years, the field of machine learning has seen an explosion of interest and excitement, with hundreds or thousands of algorithms developed for different tasks every year. But a primary problem faced by the field is the ability to scale to larger and larger data—since it is known that training on larger datasets typically produces better results (Halevy, Norvig, and Pereira 2009). Therefore, the development of new algorithms for the continued growth of the field depends largely on the existence of good tooling and libraries that enable researchers and practitioners to quickly prototype and develop solutions (Sonnenburg et al. 2007). Simultaneously, useful libraries must also be efficient and well-implemented. This has motivated our development of mlpack. mlpack is a flexible and fast machine learning library written in C++ that has bindings that allow use from the command-line and from Python, with support for other languages in active development. mlpack has been developed actively for over 10 years (Curtin et al. 2011, Curtin, Cline, et al.(2013)), with over 100 contributors from around the world, and is a frequent mentoring organization in the Google Summer of Code program (https://summerofcode. withgoogle. com). If used in C++, the library allows flexibility with no speed penalty through policy-based design and template metaprogramming (Alexandrescu 2001); but bindings are available to other languages, which allow easy use of the fast mlpack codebase. For fast linear algebra, mlpack is built on the Armadillo C++ matrix library (Sanderson and Curtin 2016), which in turn can use an optimized BLAS implementation such as …",,,2018
1348,Extensions of Robbins-Siegmund Theorem with Applications in Reinforcement Learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pn7fj4IAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Pn7fj4IAAAAJ:BqipwSGYUEgC,"The Robbins-Siegmund theorem establishes the convergence of stochastic processes that are almost supermartingales and is foundational for analyzing a wide range of stochastic iterative algorithms in stochastic approximation and reinforcement learning (RL). However, its original form has a significant limitation as it requires the zero-order term to be summable. In many important RL applications, this summable condition, however, cannot be met. This limitation motivates us to extend the Robbins-Siegmund theorem for almost supermartingales where the zero-order term is not summable but only square summable. Particularly, we introduce a novel and mild assumption on the increments of the stochastic processes. This together with the square summable condition enables an almost sure convergence to a bounded set. Additionally, we further provide almost sure convergence rates, high probability concentration bounds, and convergence rates. We then apply the new results in stochastic approximation and RL. Notably, we obtain the first almost sure convergence rate, the first high probability concentration bound, and the first convergence rate for -learning with linear function approximation.",,,2025
1349,Finite Sample Analysis of Linear Temporal Difference Learning with Arbitrary Features,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pn7fj4IAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Pn7fj4IAAAAJ:blknAaTinKkC,"Linear TD() is one of the most fundamental reinforcement learning algorithms for policy evaluation. Previously, convergence rates are typically established under the assumption of linearly independent features, which does not hold in many practical scenarios. This paper instead establishes the first convergence rates for linear TD() operating under arbitrary features, without making any algorithmic modification or additional assumptions. Our results apply to both the discounted and average-reward settings. To address the potential non-uniqueness of solutions resulting from arbitrary features, we develop a novel stochastic approximation result featuring convergence rates to the solution set instead of a single point.",,,2025
1350,Changing the resilience paradigm,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qVfffxkAAAAJ&citation_for_view=qVfffxkAAAAJ:iH-uZ7U-co4C,"Resilience management goes beyond risk management to address the complexities of large integrated systems and the uncertainty of future threats, especially those associated with climate change.",Nature Publishing Group UK,,2014
1351,Inoperability input-output model for interdependent infrastructure sectors. I: Theory and methodology,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qVfffxkAAAAJ&citation_for_view=qVfffxkAAAAJ:WF5omc3nYNoC,"The paper discusses the theory and methodology supporting the development of the inoperability input-output model (IIM). The IIM is based on Leontief’s input-output model, which characterizes interdependencies among sectors in the economy and analyzes initial disruptions to a set of sectors and the resulting ripple effects. An advantage of building on Leontief’s model is that it is supported by publications of the Bureau of Economic Analysis. Independent computer runs of the IIM can represent the entire nation or sectors within particular U.S. regions. A dynamic extension of the IIM analyzes different temporal frames of recovery and characterizes the required sector adjustments for achieving new production levels. The IIM can systemically prioritize and manage the sectors deemed to be economically critical and also identify those sectors whose continued operability is critical during recovery. A companion paper …",American Society of Civil Engineers,,2005
1352,"Risk filtering, ranking, and management framework using hierarchical holographic modeling",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qVfffxkAAAAJ&citation_for_view=qVfffxkAAAAJ:MLfJN-KU85MC,"This paper contributes a methodological framework to identify, prioritize, assess, and manage risk scenarios of a large‐scale system. Qualitative screening of scenarios and classes of scenarios is appropriate initially, while quantitative assessments may be applied once the set of all scenarios (hundreds) has been prioritized in several phases. The eight‐phase methodology is described in detail and is applied to operations other than war. The eight phases are as follows: Phase I, Scenario Identification—A hierarchical holographic model (HHM) is developed to describe the system's ``as planned'' or ``success'' scenario. Phase II, Scenario Filtering—The risk scenarios identified in Phase I are filtered according to the responsibilities and interests of the current system user. Phase III, Bi‐Criteria Filtering and Ranking. Phase IV, Multi‐Criteria Evaluation. Phase V, Quantitative Ranking—We continue to filter and rank …","Blackwell Publishing, Inc",,2002
1353,Inoperability input-output model for interdependent infrastructure sectors. II: Case studies,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qVfffxkAAAAJ&citation_for_view=qVfffxkAAAAJ:LI9QrySNdTsC,"The paper discusses case studies of the inoperability input-output model (IIM) for modeling impacts of willful attacks on interdependent sectors. The IIM is a model for assessing sector vulnerabilities using the inoperability and economic loss impact metrics. The case studies focus on high-altitude electromagnetic pulse (HEMP) attack scenarios. HEMP is an intense electromagnetic blast induced from high-elevation nuclear explosions, potentially causing damage to electronic and electrical systems. Parametric and uncertainty analyses are conducted for assessing (1) intensity of initial disruptions, (2) sector recovery characteristics, (3) economic loss reduction policies for critical sectors, and (4) regional scope of an attack. Sectors susceptible to a HEMP attack have been identified, including electric power, electronic equipment, and workforce. Trade-off analyses are performed to analyze the efficacy of resource …",American Society of Civil Engineers,,2005
1354,Risk of extreme events under nonstationary conditions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qVfffxkAAAAJ&citation_for_view=qVfffxkAAAAJ:FAceZFleit8C,"The concept of the return period is widely used in the analysis of the risk of extreme events and in engineering design. For example, a levee can be designed to protect against the 100‐year flood, the flood which on average occurs once in 100 years. Use of the return period typically assumes that the probability of occurrence of an extreme event in the current or any future year is the same. However, there is evidence that potential climate change may affect the probabilities of some extreme events such as floods and droughts. In turn, this would affect the level of protection provided by the current infrastructure. For an engineering project, the risk of an extreme event in a future year could greatly exceed the average annual risk over the design life of the project. An equivalent definition of the return period under stationary conditions is the expected waiting time before failure. This paper examines how this definition can …",Blackwell Publishing Ltd,,1998
1355,Enterprise Risk Management of Electronics and Computing Device Supply Chains,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qVfffxkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qVfffxkAAAAJ:-7ulzOJl1JYC,"Tracking and managing enterprise risks across product, service, and system lifecycles is critical for engineering managers, as components must be secure, reliable, and meet various functional and nonfunctional requirements. The global supplies and demands for electronics and computing devices are dynamic influenced by a complexity of factors. Various sources of risk can disrupt the quality, quantity, and distribution of electronics, precipitating business losses and involving costly remediation. Counterfeiting of devices and certifications creates particular challenges for the supply chains. A risk management process involves several activities, from identification of potential hazards, to quantification of risk, prioritization of vulnerabilities, and design and integration of risk countermeasures. This chapter describes principles and methods of operations research and systems engineering that support risk management …",CRC Press,,2026
1356,Management of Electronics and Computing Device Supply Chains,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qVfffxkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qVfffxkAAAAJ:1Ye0OR6EYb4C,"The life cycle of a semiconductor is complex, with sophisticated procedures and numerous constituent inputs to produce a single chip. For example, it is estimated to take over 700 steps to produce a semiconductor (Whalen, 2021). In terms of resources, a 2-gram chip requires approximately 1.6 kg of fossil fuels, 72 g of chemicals, and 32 kg of water to produce. Around 630 times the mass of input materials go into making a chip as compared to the mass of the final output (Graham, 2002). Managing the associated supply chain is similarly complex, with subsystem experts/-operators/owners specializing in different value-adding processes, from design, fabrication, assembly, packaging, testing, and integration into products (Varas et al., 2021). The market for semiconductors after their production involves several interests and partners, such as networks of distributors and brokers (DiMase et al., 2016). Managing the complexities inherent in the industry thus necessitates a perspective of the system of systems across multiple time horizons. The discipline of systems engineering offers principles and set of tools by which to manage large and complex product development efforts. According to INCOSE (2006),“Systems Engineering is an interdisciplinary approach and means to enable the realization of successful systems. It focuses on defining customer needs and required functionality early in the development cycle, documenting requirements, and then proceeding with design synthesis and system validation while considering the complete problem. Systems Engineering considers both the business and the technical needs of all customers with the goal …",CRC Press,,2025
1357,Supply Chains of Computer and Electronics Hardware with Resilience to Counterfeiting and Other Disruptions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qVfffxkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qVfffxkAAAAJ:6_hjMsCP8ZoC,"This chapter addresses the vulnerabilities of supply chains, with a particular focus on those involving electronic hardware embedded in modern cyber-physical systems. It begins by identifying key factors that enable resilience and explains the roles of various actors within the supply chain. The chapter discusses metrics for characterizing cyber resilience and provides a comprehensive review of research on emerging topics related to supply chain resilience. It emphasizes the importance of understanding and mitigating risks associated with supply chain disruptions related to operating conditions and environments, material shortages, counterfeit components, and other stressors. By incorporating a resilience-based perspective, the chapter highlights the need for strategies that go beyond traditional risk assessment to ensure the robustness and adaptability of supply chains. Future research directions include the …",Springer Nature Switzerland,Cyber Resilience: Applied Perspectives,2025
1358,Can AI help authors prepare better risk science manuscripts?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qVfffxkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qVfffxkAAAAJ:SjuI4pbJlxcC,"Scientists, publishers, and journal editors are wondering how, whether, and to what extent artificial intelligence (AI) tools might soon help to advance the rigor, efficiency, and value of scientific peer review. Will AI provide timely, useful feedback that helps authors improve their manuscripts while avoiding the biases and inconsistencies of human reviewers? Or might it instead generate low‐quality verbiage, add noise and errors, reinforce flawed reasoning, and erode trust in the review process? This perspective reports on evaluations of two experimental AI systems: (i) a “Screener” available at http://screener.riskanalysis.cloud/ that gives authors feedback on whether a draft paper (or abstract, proposal, etc.) appears to be a fit for the journal Risk Analysis, based on the guidance to authors provided by the journal (https://www.sra.org/journal/what‐makes‐a‐good‐risk‐analysis‐article/); and (ii) a more ambitious …",,Risk analysis,2025
1359,Systems Analysis and Negotiation of Strategic Partnerships in the Supply of Biofuels to Commercial Aviation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qVfffxkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qVfffxkAAAAJ:6bLC7aUMtPcC,"Industrial supplies of energy and fuels need coordinated efforts of stakeholders to address complex challenges related to resources, finances, infrastructure, regulations, innovations, behaviors, etc. Advanced aviation biofuels, in particular, involve negotiations and tradeoffs among subsystem owners and operators, regulators, government agencies, and transportation providers. This paper utilizes a case study on biofuel distribution to Dulles International Airport to address three primary components of a systems engineering-based supply chain analysis: (i) stakeholder mapping, (ii) scenario evaluations, and (iii) resilience analysis. This paper builds upon the power-interest matrix to develop an Engagement, Financing, and Time Horizon Analysis (EFHA) matrix to support systems engineering and stakeholder negotiations for energy and fuel supply chains. EFHA identifies several key problem dimensions …",IEEE,,2025
1360,Improving viability of stem cells during syringe needle flow through the design of hydrogel cell carriers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwykGVgAAAAJ&citation_for_view=BwykGVgAAAAJ:u5HHmVD_uO8C,"Cell transplantation is a promising therapy for a myriad of debilitating diseases; however, current delivery protocols using direct injection result in poor cell viability. We demonstrate that during the actual cell injection process, mechanical membrane disruption results in significant acute loss of viability at clinically relevant injection rates. As a strategy to protect cells from these damaging forces, we hypothesize that cell encapsulation within hydrogels of specific mechanical properties will significantly improve viability. We use a controlled in vitro model of cell injection to demonstrate success of this acute protection strategy for a wide range of cell types including human umbilical vein endothelial cells (HUVEC), human adipose stem cells, rat mesenchymal stem cells, and mouse neural progenitor cells. Specifically, alginate hydrogels with plateau storage moduli (G′) ranging from 0.33 to 58.1 Pa were studied. A …","Mary Ann Liebert, Inc.",,2012
1361,Maintenance of neural progenitor cell stemness in 3D hydrogels requires matrix remodelling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwykGVgAAAAJ&citation_for_view=BwykGVgAAAAJ:qxL8FJ1GzNcC,"Neural progenitor cell (NPC) culture within three-dimensional (3D) hydrogels is an attractive strategy for expanding a therapeutically relevant number of stem cells. However, relatively little is known about how 3D material properties such as stiffness and degradability affect the maintenance of NPC stemness in the absence of differentiation factors. Over a physiologically relevant range of stiffness from ∼0.5 to 50 kPa, stemness maintenance did not correlate with initial hydrogel stiffness. In contrast, hydrogel degradation was both correlated with, and necessary for, maintenance of NPC stemness. This requirement for degradation was independent of cytoskeletal tension generation and presentation of engineered adhesive ligands, instead relying on matrix remodelling to facilitate cadherin-mediated cell–cell contact and promote β-catenin signalling. In two additional hydrogel systems, permitting NPC-mediated …",Nature Publishing Group UK,,2017
1362,"Stimuli-responsive, pentapeptide, nanofiber hydrogel for tissue engineering",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwykGVgAAAAJ&citation_for_view=BwykGVgAAAAJ:-f6ydRqryjwC,"Short peptides are uniquely versatile building blocks for self-assembly. Supramolecular peptide assemblies can be used to construct functional hydrogel biomaterials—an attractive approach for neural tissue engineering. Here, we report a new class of short, five-residue peptides that form hydrogels with nanofiber structures. Using rheology and spectroscopy, we describe how sequence variations, pH, and peptide concentration alter the mechanical properties of our pentapeptide hydrogels. We find that this class of seven unmodified peptides forms robust hydrogels from 0.2–20 kPa at low weight percent (less than 3 wt %) in cell culture media and undergoes shear-thinning and rapid self-healing. The peptides self-assemble into long fibrils with sequence-dependent fibrillar morphologies. These fibrils exhibit a unique twisted ribbon shape, as visualized by transmission electron microscopy (TEM) and Cryo-EM …",American Chemical Society,,2019
1363,Defining and designing polymers and hydrogels for neural tissue engineering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwykGVgAAAAJ&citation_for_view=BwykGVgAAAAJ:qjMakFHDy7sC,"The use of biomaterials, such as hydrogels, as neural cell delivery devices is becoming more common in areas of research such as stroke, traumatic brain injury, and spinal cord injury. When reviewing the available research there is some ambiguity in the type of materials used and results are often at odds. This review aims to provide the neuroscience community who may not be familiar with fundamental concepts of hydrogel construction, with basic information that would pertain to neural tissue applications, and to describe the use of hydrogels as cell and drug delivery devices. We will illustrate some of the many tunable properties of hydrogels and the importance of these properties in obtaining reliable and consistent results. It is our hope that this review promotes creative ideas for ways that hydrogels could be adapted and employed for the treatment of a broad range of neurological disorders.",Elsevier,Neuroscience research,2012
1364,Design of three-dimensional engineered protein hydrogels for tailored control of neurite growth,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwykGVgAAAAJ&citation_for_view=BwykGVgAAAAJ:zYLM7Y9cAGgC,"The design of bioactive materials allows tailored studies probing cell–biomaterial interactions, however, relatively few studies have examined the effects of ligand density and material stiffness on neurite growth in three-dimensions. Elastin-like proteins (ELPs) have been designed with modular bioactive and structural regions to enable the systematic characterization of design parameters within three-dimensional (3-D) materials. To promote neurite out-growth and better understand the effects of common biomaterial design parameters on neuronal cultures we here focused on the cell-adhesive ligand density and hydrogel stiffness as design variables for ELP hydrogels. With the inherent design freedom of engineered proteins these 3-D ELP hydrogels enabled decoupled investigations into the effects of biomechanics and biochemistry on neurite out-growth from dorsal root ganglia. Increasing the cell-adhesive RGD …",Elsevier,,2013
1365,In Vitro Tissue Models of Neural Cell Development Towards Myelination and Remyelination,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwykGVgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BwykGVgAAAAJ:4OULZ7Gr8RgC,,AIChE,,2025
1366,High-rate mechano-stimulation alters proliferation-and maturation-related signaling of oligodendrocyte precursor cells in a 3D hydrogel,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwykGVgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BwykGVgAAAAJ:u_35RYKgDlwC,"Traumatic brain injury (TBI) leads to neuroinflammation and is associated with chronic neurodegeneration. Many TBI studies aim to understand further the mechanism by which cells in the brain respond to the mechanical forces associated with TBI. In particular, mild TBI is the most common level of injury among TBI patients, and the reactivity of glial cells is a key mechanism in understanding mild TBI. However, there is a lack of studies focusing on oligodendrocyte precursor cells (OPCs). OPCs respond to the injury by migration, proliferation, and differentiation into oligodendrocytes (OL) to assist in post-injury repair. Given their ability to proliferate and differentiate, OPCs are a promising therapeutic target for OL regeneration. Despite their important role in maintaining normal neuronal functions, the response of OPCs to mechanical insult remains poorly understood. Thus, this study aims to elucidate the cellular …",,,2025
1367,Guiding oligodendrocyte progenitor cell maturation using electrospun fiber cues in a 3D hyaluronic acid hydrogel culture system,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwykGVgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BwykGVgAAAAJ:pqnbT2bcN3wC,"The current lack of therapeutic approaches to demyelinating disorders and injuries stems from a lack of knowledge surrounding the underlying mechanisms of myelination. This knowledge gap motivates the development of effective models to study the role of environmental cues in oligodendrocyte progenitor cell (OPC) maturation. Such models should focus on determining, which factors influence OPCs to proliferate and differentiate into mature myelinating oligodendrocytes (OLs). Here, we introduce a hyaluronic acid (HA) hydrogel system composed of cross-linked HA containing encapsulated HA fibers with swollen diameters similar to mature axons (2.7 ± 0.2 μm). We tuned hydrogel storage moduli to simulate native brain tissue (200–2000 Pa) and studied the effects of fiber presence on OPC proliferation, metabolic activity, protein deposition, and morphological changes in gels of intermediate storage modulus …",American Chemical Society,,2024
1368,Effects of cell-adhesive ligand presentation on pentapeptide supramolecular assembly and gelation: Simulations and Experiments,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BwykGVgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BwykGVgAAAAJ:70eg2SAEIzsC,"The extracellular matrix (ECM) is a complex, hierarchical material containing structural and bioactive components. This complexity makes decoupling the effects of biomechanical properties and cell-matrix interactions difficult, especially when studying cellular processes in a 3D environment. Matrix mechanics and cell adhesion are both known regulators of specific cellular processes such as stem cell proliferation and differentiation. However, more information is required about how such variables impact various neural lineages that could, upon transplantation, therapeutically improve neural function after a central nervous system injury or disease. Rapidly Assembling Pentapeptides for Injectable Delivery (RAPID) hydrogels are one biomaterial approach to meet these goals, consisting of a family of peptide sequences that assemble into physical hydrogels in physiological media. In this study, we studied our …",S. Karger AG,,2023
1369,Electrochemical techniques in corrosion science and engineering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eRFnqYwAAAAJ&citation_for_view=eRFnqYwAAAAJ:u5HHmVD_uO8C,"This book describes the origin, use, and limitations of electrochemical phase diagrams, testing schemes for active, passive, and localized corrosion, the development and electrochemical characterization of passivity, and methods in process alteration, failure prediction, and materials selection. It offers useful guidelines for assessing the efficac",CRC Press,,2002
1370,"Accurate electrochemical measurement of magnesium corrosion rates; a combined impedance, mass-loss and hydrogen collection study",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eRFnqYwAAAAJ&citation_for_view=eRFnqYwAAAAJ:WAzi4Gm8nLoC,"Experiments were conducted to enable the simultaneous measurement of electrochemical impedance and collection of hydrogen gas during the corrosion of pure magnesium in NaCl solutions. These results were then assessed along with the attendant specimen mass loss, providing three unique measures of magnesium corrosion for the same specimen. It was determined that analysis of impedance data, while accounting for a physically justified inductive response at low frequencies, enabled the determination of the polarization resistance, RP at the zero frequency limit. The determination of RP, as evaluated herein from electrochemical testing, provided excellent correlation to the mass loss and volume of hydrogen collected. This finding is elaborated in a broader discussion that critically addresses previous studies which have utilized the impedance behavior of magnesium and which claim electrochemical tests …",Pergamon,,2014
1371,Corrosion tests and standards: application and interpretation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eRFnqYwAAAAJ&citation_for_view=eRFnqYwAAAAJ:0aBXIfxlw9sC,"CORROSION CONTINUES to be a problem of worldwide importance. The second edition of this manual has been prepared and published to address this form of degradation. Corrosion is often neglected, but it seriously impacts our economy, jeopardizes human health and safety, and impedes technological progress. The most important fac-tors in addressing corrosion and its control are:(1) recognizing and understanding the mechanisms,(2) developing solutions to the problems, and (3) implementing those solutions. Corrosion tests and standards are very significant in addressing each of these factors. Therefore, this manual includes guidelines for recognizing types of corrosion as well as fundamentals of testing and provides the tools required for mak-ing calculations, interpretations, and correlations. It serves as a source book of procedures, equipment, and standards used in testing. The editor and section editors have coordinated the revision and update of this book so that most recent technologies are included in each section. In most cases, the original authors of chapters have made the revisions. In some cases, new authors needed to be chosen, or the editors performed that task. Users of the manual will find that it is an invaluable and instructive tool, as well as a source book on how to con-duct corrosion tests, interpret results, and use standards. The second edition of the manual is the result of a massive effort of planning, writ-ing, reviewing, editing, production, and marketing. It would not have been possible without the outstanding efforts of the ASTM staff and the valuable and competent work of the editors and over 400 experts in the field …",ASTM international,,2005
1372,Corrosion of magnesium alloys: the role of alloying,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eRFnqYwAAAAJ&citation_for_view=eRFnqYwAAAAJ:eGYfIraVYiQC,"The demand for light-weighting in transport and consumer electronics has seen rapid growth in the commercial usage of magnesium (Mg). The major use of Mg is now in cast Mg products, as opposed to the use of Mg as an alloying element in other alloy systems and there is an emerging market of wrought Mg products and biomedical Mg components – such that the past two decades have seen a significant number of new Mg-alloys reported. None-the-less, the corrosion of Mg alloys continues to be a challenge facing engineers seeking weight reductions by deployment of Mg. Herein, authors review the influence of alloying on the corrosion of Mg-alloys, with particular emphasis on the underlying electrochemical kinetics that dictate the ultimate corrosion rate. Such a review focusing on the chemistry–corrosion link, both in depth and in a holistic approach, is lacking. As such the authors do not describe aspects such …",SAGE Publications,International Materials Reviews,2015
1373,Electrochemical impedance: analysis and interpretation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eRFnqYwAAAAJ&citation_for_view=eRFnqYwAAAAJ:2osOgNQ5qMEC,"The collection of twenty-seven papers published has been grouped into six major categories: corrosion process characterization and modeling, applications of Kramers-Kronig transformations for evaluating the validity of data, corrosion and its inhibition by either corrosion products of specially added inhibitors, corrosion of aluminum and aluminum alloys, corrosion of steel in soils and concrete, and evaluation of coatings on metal substrates.",ASTM International,,1993
1374,Evaluating Cold-Rolling and Irradiation Effects on Corrosion Resistance of Ni-Cr Alloys in Molten Flinak Salt,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eRFnqYwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=eRFnqYwAAAAJ:CB6W3GmKGOEC,,ECS,,2025
1375,The Effect of Temperature on the Dealloying Behavior of Binary Ni-20Cr Alloy in Molten Flinak,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eRFnqYwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=eRFnqYwAAAAJ:5UUbrqTvKfUC,,ECS,,2025
1376,Investigating the Role of Alloying a Third Element on the Aqueous Passivation of Fe-Co-Ni-Cr-Al Compositionally Complex Alloys and Conventional Ternary Alloys …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eRFnqYwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=eRFnqYwAAAAJ:ve7iT2ZEuL4C,,ECS,,2025
1377,Passivity and Pitting of Single-phase FeCoNi-Cr-Al Compositionally Complex alloys: An Al-Cr Third Element Effect in Sulfuric Acid containing Chloride,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eRFnqYwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=eRFnqYwAAAAJ:GDem9OnCwu8C,"The synergistic effects of Al on Cr(III) passivation in a family of single phase FCC (FeCoNi)100-x-yCrxAly (at.%) compositionally complex alloys (CCAs), where x = (10, 13, 16) and y = (0, 3, 6, 9) were investigated for both passivation and resistance to chloride induced local breakdown of the passive film. Homogenized solid solution alloys containing Cr and small amounts of Al achieved excellent passivation compared to Cr containing CCAs alone by enriching both Cr and some Al on the surface in chloride containing sulfuric acid solutions. For example, an alloy containing 10 at.% Cr and 9 at.% Al demonstrated better repassivation as well as resistance to chloride induced pitting corrosion compared to CCA containing just 10 at.% Cr. Further, compared to 304 L stainless steel containing 20 at.% Cr, CCA containing 16 at.% Cr and 3 at.% Al attained better resistance in 1 M NaCl + 0.1 M H2SO4(aq.) solution. Two …",Pergamon,,2025
1378,Revisiting the Influence of Sn in Cu-Al Alloys: A Third Element Effect Enabling Stainless Steel Type Corrosion Behavior,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=eRFnqYwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=eRFnqYwAAAAJ:eJjLl3UG7CkC,"The influence of Sn alloying additions on the aqueous passivation behavior of Cu-Al alloys was revisited and found to function as a new third element effect in acidified 0.1 M Na2SO4 solution. The role of each element during the process of aqueous passivation was investigated using electrochemical and surface-sensitive ex-situ and in-operando spectroscopic techniques. The connection between passivation and the atomic arrangements of atoms in the solid-solution was supported by first principles’ based cluster expansion calculations and Monte Carlo simulations probing the chemical short-range order in the Cu-Al-Sn system. High purity Sn, like high purity Cu, did not passivate in the test environment, whereas high purity Al formed a passive film with a stable passive current density of 0.01 mA·cm−2. Cu-xAl-Sn solid-solution alloys where x > 18 at.%, containing less than 3 at.% Sn additions exhibited lower …",,,2025
1379,Urban freeway traffic flow prediction: application of seasonal autoregressive integrated moving average and exponential smoothing models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SSPvo1IAAAAJ&citation_for_view=SSPvo1IAAAAJ:qjMakFHDy7sC,"The application of seasonal time series models to the single-interval traffic flow forecasting problem for urban freeways is addressed. Seasonal time series approaches have not been used in previous forecasting research. However, time series of traffic flow data are characterized by definite periodic cycles. Seasonal autoregressive integrated moving average (ARIMA) and Winters exponential smoothing models were developed and tested on data sets belonging to two sites: Telegraph Road and the Woodrow Wilson Bridge on the inner and outer loops of the Capital Beltway in northern Virginia. Data were 15-min flow rates and were the same as used in prior forecasting research by B. Smith. Direct comparisons with the Smith report findings were made and it was found that ARIMA (2, 0, 1)(0, 1, 1)96 and ARIMA (1, 0, 1)(0, 1, 1)96 were the best-fit models for the Telegraph Road and Wilson Bridge sites, respectively …",SAGE Publications,,1998
1380,Automatic crime prediction using events extracted from twitter posts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SSPvo1IAAAAJ&citation_for_view=SSPvo1IAAAAJ:3fE2CSJIrl8C,"Prior work on criminal incident prediction has relied primarily on the historical crime record and various geospatial and demographic information sources. Although promising, these models do not take into account the rich and rapidly expanding social media context that surrounds incidents of interest. This paper presents a preliminary investigation of Twitter-based criminal incident prediction. Our approach is based on the automatic semantic analysis and understanding of natural language Twitter posts, combined with dimensionality reduction via latent Dirichlet allocation and prediction via linear modeling. We tested our model on the task of predicting future hit-and-run crimes. Evaluation results indicate that the model comfortably outperforms a baseline model that predicts hit-and-run incidents uniformly across all days.",Springer Berlin Heidelberg,,2012
1381,Health-status monitoring through analysis of behavioral patterns,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SSPvo1IAAAAJ&citation_for_view=SSPvo1IAAAAJ:u-x6o8ySG0sC,"With the rapid growth of the elderly population, there is a need to support the ability of elders to maintain an independent and healthy lifestyle in their homes rather than through more expensive and isolated care facilities. One approach to accomplish these objectives employs the concepts of ambient intelligence to remotely monitor an elder's activities and condition. The SmartHouse project uses a system of basic sensors to monitor a person's in-home activity; a prototype of the system is being tested within a subject's home. We examined whether the system could be used to detect behavioral patterns and report the results in this paper. Mixture models were used to develop a probabilistic model of behavioral patterns. The results of the mixture-model analysis were then evaluated by using a log of events kept by the occupant.",IEEE,,2005
1382,Quantifying the relative importance of survival threats to a long-lived reptile using expert elicitation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SSPvo1IAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=SSPvo1IAAAAJ:-EqDysdaREAC,"Long-term survival of a conservation-reliant species requires understanding the impact of threats on population growth rate and the management actions that can help mitigate these threats. We used a threat assessment with expert-elicited estimates to determine the relative effect of each stage-specific threat on the population growth rate of the wood turtle Glyptemys insculpta. In addition, we offered potential management actions that could mitigate these threats and examined the relative cost and benefit of each. The experts responded that predators had the largest effect on hatchling and juvenile survival and that road mortality had the largest effect on adult survival. The population growth rate of the simulated turtle population increased the most when predators were removed from the system, though the population trajectory remained negative. Finally, we found that predator control had the lowest cost: benefit …",,,2025
1383,Examining Vision Language Models through Multi-dimensional Experiments with Vision and Text Features,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SSPvo1IAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=SSPvo1IAAAAJ:ib87rSy7x5MC,"Recent research on Vision Language Models (VLMs) suggests that they rely on inherent biases learned during training to respond to questions about visual properties of an image. These biases are exacerbated when VLMs are asked highly specific questions that require focusing on specific areas of the image. For example, a VLM tasked with counting stars on a modified American flag (e.g., with more than 50 stars) will often disregard the visual evidence and fail to answer accurately. We build upon this research and develop a multi-dimensional examination framework to systematically determine which characteristics of the input data, including both the image and the accompanying prompt, lead to such differences in performance. Using open-source VLMs, we further examine how attention values fluctuate with varying input parameters (e.g., image size, number of objects in the image, background color, prompt specificity). This research aims to learn how the behavior of vision language models changes and to explore methods for characterizing such changes. Our results suggest, among other things, that even minor modifications in image characteristics and prompt specificity can lead to large changes in how a VLM formulates its answer and, subsequently, its overall performance.",,,2025
1384,MisstepMath: A Diverse Student Mistake Dataset for AI in Mathematics Teacher Training,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SSPvo1IAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=SSPvo1IAAAAJ:JOhajB-2wfwC,"Effective teacher training requires exposure to a wide array of student behaviors and learning challenges. This paper introduces MisstepMath (MisstepMath Dataset: https://huggingface.co/datasets/LLMEducation/MisstepMath), a novel semi-synthetic dataset comprising 12,000 categorized student mistakes paired with instructional teacher responses. Designed to enhance AI-driven teacher training, MisstepMath spans mathematics topics and sub-topics from Kindergarten through Grade 8, systematically categorizing errors into conceptual misunderstandings, procedural mistakes, learning disabilities, and language-related difficulties. Developed in three phases—expert brainstorming and categorization, AI-assisted data generation, and expert review and refinement—MisstepMath ensures diverse and contextually rich student simulations. This approach combines human expertise with AI generation to improve …",Springer Nature Switzerland,,2025
1385,A Bayesian Survival Analysis on Long COVID and Non-Long COVID Patients: A Cohort Study Using National COVID Cohort Collaborative (N3C) Data,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SSPvo1IAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=SSPvo1IAAAAJ:jmwITWCuk8IC,"Since the outbreak of the COVID-19 pandemic in 2020, numerous studies have focused on the long-term effects of COVID infection. On 1 October 2021, the Centers for Disease Control (CDC) implemented a new code in the International Classification of Diseases, Tenth Revision, Clinical Modification (ICD-10-CM) for reporting ‘Post COVID-19 condition, unspecified (U09.9)’. This change indicated that the CDC recognized Long COVID as a real illness with associated chronic conditions. The National COVID Cohort Collaborative (N3C) provides researchers with abundant electronic health record (EHR) data by harmonizing EHR data across more than 80 different clinical organizations in the United States. This paper describes the creation of a COVID-positive N3C cohort balanced by the presence or absence of Long COVID (U09.9) and evaluates whether or not documented Long COVID (U09.9) is associated with decreased survival length.",MDPI,,2025
1386,Predictive Modeling and Machine Learning Insights into Multi-Drug Resistant Tuberculosis Treatment Outcomes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SSPvo1IAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=SSPvo1IAAAAJ:GKX6TSFDq9oC,"Tuberculosis (TB) remains a major global health burden, particularly in resource-prevented settings. Predictive models may improve patient outcomes by identifying individuals at higher risk of treatment failure, but many existing models are trained on data from high-income countries and may not generalize well to low- and middle-income contexts. In this study, we analyzed two datasets: a longitudinal, multi-site cohort, termed the International Collaborations in Infectious Disease Research (ICIDR), with data from Tanzania, Bangladesh, and Siberia and a cross-sectional dataset from Kibong’oto Infectious Disease Hospital (KIDH) in Tanzania. We applied logistic regression, random forest, and XGBoost models to predict outcomes in multidrug-resistant TB (MDR-TB). For the KIDH dataset, patients were stratified by treatment regimen (bedaquiline, short-term injectable, and long-term injectable) to capture regimen …",IEEE,,2025
1387,PdSe2: Pentagonal Two-Dimensional Layers with High Air Stability for Electronics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MIMAxEUAAAAJ&citation_for_view=MIMAxEUAAAAJ:p__nRnzSRKYC,"Most studied two-dimensional (2D) materials exhibit isotropic behavior due to high lattice symmetry; however, lower-symmetry 2D materials such as phosphorene and other elemental 2D materials exhibit very interesting anisotropic properties. In this work, we report the atomic structure, electronic properties, and vibrational modes of few-layered PdSe2 exfoliated from bulk crystals, a pentagonal 2D layered noble transition metal dichalcogenide with a puckered morphology that is air-stable. Micro-absorption optical spectroscopy and first-principles calculations reveal a wide band gap variation in this material from 0 (bulk) to 1.3 eV (monolayer). The Raman-active vibrational modes of PdSe2 were identified using polarized Raman spectroscopy, and a strong interlayer interaction was revealed from large, thickness-dependent Raman peak shifts, agreeing with first-principles Raman simulations. Field-effect transistors …",American Chemical Society,,2017
1388,Advances and future prospects of spin-transfer torque random access memory,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MIMAxEUAAAAJ&citation_for_view=MIMAxEUAAAAJ:roLk4NBRz8UC,"Spin-transfer torque random access memory (STT-RAM) is a potentially revolutionary universal memory technology that combines the capacity and cost benefits of DRAM, the fast read and write performance of SRAM, the non-volatility of Flash, and essentially unlimited endurance. In order to realize a small cell size, high speed and achieve a fully functional STT-RAM chip, the MgO-barrier magnetic tunnel junctions (MTJ) used as the core storage and readout element must meet a set of performance requirements on switching current density, voltage, magneto-resistance ratio (MR), resistance-area product (RA), thermal stability factor (¿) , switching current distribution, read resistance distribution and reliability. In this paper, we report the progress of our work on device design, material improvement, wafer processing, integration with CMOS, and testing for a demonstration STT-RAM test chip, and projections based on …",IEEE,IEEE Transactions on Magnetics,2010
1389,Unified description of molecular conduction: From molecules to metallic wires,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MIMAxEUAAAAJ&citation_for_view=MIMAxEUAAAAJ:u5HHmVD_uO8C,"We describe a rigorous and yet computationally simple way of calculating conductance properties of molecular conductors, using self-energy matrices to partition the overall structure into a molecular device and contacts. The standard methods of quantum chemistry are combined self-consistently with a nonequilibrium Green’s function formalism to describe transport in an open system under bias. We employ our method to demonstrate the transition between two limiting cases of molecular conduction: metallic conduction in a gold nanowire and resonant conduction in a phenyl dithiol molecule.",American Physical Society,,2001
1390,Computational investigation of half-Heusler compounds for spintronics applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MIMAxEUAAAAJ&citation_for_view=MIMAxEUAAAAJ:-_dYPAW6P2MC,"We present first-principles density functional calculations of the electronic structure, magnetism, and structural stability of 378 XYZ half-Heusler compounds (with Cr, Mn, Fe, Co, Ni, Ru, Rh; Ti, V, Cr, Mn, Fe, Ni; Al, Ga, In, Si, Ge, Sn, P, As, Sb). We find that a “Slater-Pauling gap” in the density of states (i.e., a gap or pseudogap after nine states in the three atom primitive cell) in at least one spin channel is a common feature in half-Heusler compounds. We find that the presence of such a gap at the Fermi energy in one or both spin channels contributes significantly to the stability of a half-Heusler compound. We calculate the formation energy of each compound and systematically investigate its stability against all other phases in the open quantum materials database (OQMD). We represent the thermodynamic phase stability of each compound as its distance from the convex hull of stable phases in the respective …",American Physical Society,,2017
1391,Electron optics with pn junctions in ballistic graphene,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MIMAxEUAAAAJ&citation_for_view=MIMAxEUAAAAJ:z_wVstp3MssC,"Electrons transmitted across a ballistic semiconductor junction are expected to undergo refraction, analogous to light rays across an optical boundary. In graphene, the linear dispersion and zero-gap band structure admit highly transparent p-n junctions by simple electrostatic gating. Here, we employ transverse magnetic focusing to probe the propagation of carriers across an electrostatically defined graphene junction. We find agreement with the predicted Snell’s law for electrons, including the observation of both positive and negative refraction. Resonant transmission across the p-n junction provides a direct measurement of the angle-dependent transmission coefficient. Comparing experimental data with simulations reveals the crucial role played by the effective junction width, providing guidance for future device design. Our results pave the way for realizing electron optics based on graphene p-n junctions.",American Association for the Advancement of Science,,2016
1392,Economic mpc with an online reference trajectory for battery scheduling considering demand charge management,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MIMAxEUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MIMAxEUAAAAJ:wLxue7F8ec0C,"Monthly demand charges form a significant portion of the electric bill for microgrids with variable renewable energy generation. A battery energy storage system (BESS) is commonly used to manage these demand charges. Economic model predictive control (EMPC) with a reference trajectory can be used to dispatch the BESS to optimize the microgrid operating cost. Since demand charges are incurred monthly, EMPC requires a fullmonth reference trajectory for asymptotic stability guarantees that result in optimal operating costs. However, a full-month reference trajectory is unrealistic from a renewable generation forecast perspective. Therefore, to construct a practical EMPC with a reference trajectory, an EMPC formulation considering both non-coincident demand and on-peak demand charges is designed in this work for 24 to 48 h prediction horizons. The corresponding reference trajectory is computed at each …",IEEE,,2025
1393,Economic Model Predictive Control with a Non-Fixed Reference Trajectory for Optimal Microgrid Dispatch,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MIMAxEUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MIMAxEUAAAAJ:jlhcAiayVhoC,"Economic Model Predictive Control (EMPC), instead of stabilizing a reference trajectory/state in the objective function like a Tracking MPC, optimizes the economic performance over the prediction horizon, making it attractive for economical microgrid (MG) dispatch. However, the demand charge component in the monthly electricity cost, make it difficult to be encapsulated in additive stage costs, and can make solutions violate the principle of optimality if naively introduced in the objective function. Moreover, previous EMPC based works mostly rely on a-priori knowledge of an optimal economic steady state or optimal periodic trajectory for performance guarantees, which are not useful or possibly don't exist respectively, for real-time economical MG dispatch where load/generation forecasts are known only 24-48 h in advance. This paper, first, proposes an EMPC formulation for a generic deterministic discrete non-linear time varying system with hard state and input constraints, without any a-priori requirements of an optimal economic steady state or optimal periodic trajectory. It is proved that under mild assumptions on terminal cost and region, the asymptotic average economic cost of the proposed method is no worse than the asymptotic average economic cost of any other non-fixed arbitrary reference trajectory which is known only until the current time-step. The EMPC framework is then leveraged for optimal MG dispatch by showing that the problem can be reformulated to satisfy the assumptions required for the asymptotic performance guarantee. Realistic simulations at the Port of San Diego MG demonstrated that the proposed method can also …",,,2025
1394,Degradation Aware Optimal Allocation of Battery Energy Storage System for Unbalanced Active Distribution Network,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MIMAxEUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MIMAxEUAAAAJ:M0leSnx2MbUC,"As the power system is transforming towards a decentralized system through integration of distributed energy resources (DERs), optimal planning & operation of the battery energy storage system (BESS) is becoming very crucial for efficient operation of the active distribution network (ADN). Previous research considers balanced ADN and mostly the cycle aging of BESS. Since most ADNs are unbalanced and calendar aging significantly impacts BESS lifespan, incorporating it properly into planning is essential. This article proposes a BESS integration approach considering battery cycle life, calendar life and unbalanced conditions of ADN. A mixed integer linear programming problem is formulated to minimize the investment, operation and maintenance cost and degradation cost, while supporting the operation of the unbalanced ADN. The proposed approach is tested with an IEEE 37 bus unbalanced network. The …",IEEE,,2025
1395,Demonstration of alloy scattering in quaternary Sb-based Avalanche Photodiodes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MIMAxEUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=MIMAxEUAAAAJ:1r-w4gtu6w8C,"This paper presents a physics-based approach to calculate the alloy scattering rate in Sb-based quaternary alloys. Considering the screened Coulomb interactions and electronic band non-parabolicity in III-V semiconductors, our method advances Monte Carlo simulations, enabling precise modeling and improved design of APDs for enhanced performance.",Optica Publishing Group,,2025
1396,A periciliary brush promotes the lung health by separating the mucus layer from airway epithelia,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rxHv2FQAAAAJ&citation_for_view=rxHv2FQAAAAJ:zYLM7Y9cAGgC,"Mucus clearance is the primary defense mechanism that protects airways from inhaled infectious and toxic agents. In the current gel-on-liquid mucus clearance model, a mucus gel is propelled on top of a “watery” periciliary layer surrounding the cilia. However, this model fails to explain the formation of a distinct mucus layer in health or why mucus clearance fails in disease. We propose a gel-on-brush model in which the periciliary layer is occupied by membrane-spanning mucins and mucopolysaccharides densely tethered to the airway surface. This brush prevents mucus penetration into the periciliary space and causes mucus to form a distinct layer. The relative osmotic moduli of the mucus and periciliary brush layers explain both the stability of mucus clearance in health and its failure in airway disease.",American Association for the Advancement of Science,,2012
1397,Tough self-healing elastomers by molecular enforced integration of covalent and reversible networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rxHv2FQAAAAJ&citation_for_view=rxHv2FQAAAAJ:r0BpntZqJG4C,"Self‐healing polymers crosslinked by solely reversible bonds are intrinsically weaker than common covalently crosslinked networks. Introducing covalent crosslinks into a reversible network would improve mechanical strength. It is challenging, however, to apply this concept to “dry” elastomers, largely because reversible crosslinks such as hydrogen bonds are often polar motifs, whereas covalent crosslinks are nonpolar motifs. These two types of bonds are intrinsically immiscible without cosolvents. Here, we design and fabricate a hybrid polymer network by crosslinking randomly branched polymers carrying motifs that can form both reversible hydrogen bonds and permanent covalent crosslinks. The randomly branched polymer links such two types of bonds and forces them to mix on the molecular level without cosolvents. This enables a hybrid “dry” elastomer that is very tough with fracture energy 13500 Jm−2 …",,,2017
1398,Mobility of Nonsticky Nanoparticles in Polymer Liquids,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rxHv2FQAAAAJ&citation_for_view=rxHv2FQAAAAJ:u-x6o8ySG0sC,"We use scaling theory to derive the time dependence of the mean-square displacement ⟨Δr2⟩ of a probe nanoparticle of size d experiencing thermal motion in polymer solutions and melts. Particles with size smaller than solution correlation length ξ undergo ordinary diffusion (⟨Δr2(t)⟩ ∼ t) with diffusion coefficient similar to that in pure solvent. The motion of particles of intermediate size (ξ < d < a), where a is the tube diameter for entangled polymer liquids, is subdiffusive (⟨Δr2(t)⟩ ∼ t1/2) at short time scales since their motion is affected by subsections of polymer chains. At long time scales the motion of these particles is diffusive, and their diffusion coefficient is determined by the effective viscosity of a polymer liquid with chains of size comparable to the particle diameter d. The motion of particles larger than the tube diameter a at time scales shorter than the relaxation time τe of an entanglement strand is similar to …",American Chemical Society,,2011
1399,Self-healing of unentangled polymer networks with reversible bonds,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rxHv2FQAAAAJ&citation_for_view=rxHv2FQAAAAJ:ufrVoPGSRksC,"Self-healing polymeric materials are systems that after damage can revert to their original state with full or partial recovery of mechanical strength. Using scaling theory we study a simple model of autonomic self-healing of unentangled polymer networks. In this model one of the two end monomers of each polymer chain is fixed in space mimicking dangling chains attachment to a polymer network, while the sticky monomer at the other end of each chain can form pairwise reversible bond with the sticky end of another chain. We study the reaction kinetics of reversible bonds in this simple model and analyze the different stages in the self-repair process. The formation of bridges and the recovery of the material strength across the fractured interface during the healing period occur appreciably faster after shorter waiting time, during which the fractured surfaces are kept apart. We observe the slowest formation of bridges …",American Chemical Society,,2013
1400,Cystic fibrosis airway secretions exhibit mucin hyperconcentration and increased osmotic pressure,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rxHv2FQAAAAJ&citation_for_view=rxHv2FQAAAAJ:LkGwnXOMwfcC,"The pathogenesis of mucoinfective lung disease in cystic fibrosis (CF) patients likely involves poor mucus clearance. A recent model of mucus clearance predicts that mucus flow depends on the relative mucin concentration of the mucus layer compared with that of the periciliary layer; however, mucin concentrations have been difficult to measure in CF secretions. Here, we have shown that the concentration of mucin in CF sputum is low when measured by immunologically based techniques, and mass spectrometric analyses of CF mucins revealed mucin cleavage at antibody recognition sites. Using physical size exclusion chromatography/differential refractometry (SEC/dRI) techniques, we determined that mucin concentrations in CF secretions were higher than those in normal secretions. Measurements of partial osmotic pressures revealed that the partial osmotic pressure of CF sputum and the retained mucus in …",American Society for Clinical Investigation,,2014
1401,Hybrid 3D Printing of Anisotropic Bottlebrush Polymer Nanocomposites,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rxHv2FQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rxHv2FQAAAAJ:B3FOqHPlNUQC,,AIChE,,2025
1402,Method and system for all-aqueous printing of viscoelastic droplets,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rxHv2FQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rxHv2FQAAAAJ:4fKUyHm3Qg0C,This document describes printing viscoelastic material in an aqueous medium. Such printing can involve positioning a print nozzle at specified coordinates in the medium and triggering deposition of the viscoelastic material to form a viscoelastic droplet. The deposition can be established by delivering a specified flow velocity of the viscoelastic material through an aperture in the print nozzle. The print nozzle can be detached from the droplet and a receiving material by translating the nozzle relative to the droplet according to a specified acceleration. The droplet can remain captive on or within the receiving material upon detachment from the nozzle.,,,2025
1403,Molecular Structure of Foldable Bottlebrush Polymers in Melts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rxHv2FQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rxHv2FQAAAAJ:vRqMK49ujn8C,"A bottlebrush polymer consists of a long linear backbone densely grafted with many relatively short side chains. A widely accepted view is that strong steric repulsion among the highly overlapped side chains prestrains the bottlebrush backbone, resulting in low polymer extensibility. However, we recently discovered that in the melt of bottlebrush polymers with highly incompatible side chains and backbone, the backbone collapses to reduce interfacial free energy, regardless of the strong steric repulsion among side chains. Despite this discovery, the molecular structure of these so-called “foldable” bottlebrush polymers and their assemblies remains poorly understood. Here, we present the deterministic relationships among molecular architecture, mesoscopic conformation, and macroscopic properties of foldable bottlebrush polymers. A combination of scaling theory and experiments reveals that as the side chain …",American Chemical Society,,2025
1404,A gel coated air-liquid-interface culture system with tunable substrate stiffness matching healthy and diseased lung tissues,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rxHv2FQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rxHv2FQAAAAJ:tOudhMTPpwUC,The present disclosure is directed an air-liquid-interface culture apparatus including a porous support and a polyacrylamide hydrogel layer. The porous support includes a polymer plate having a plurality of pores and a support surface. The polyacrylamide hydrogel layer is deposited onto the support surface of the porous support. The polyacrylamide hydrogel layer includes a polyacrylamide hydrogel having mechanical properties that mimic the extracellular matrix for epithelial cells in the human airway. An air-liquid-interface cell culture system disclosed herein may include the air-liquid-interface culture apparatus disclosed herein with one or more cells deposited on the polyacrylamide hydrogel layer.,,,2025
1405,Immersive virtual environments versus physical built environments: A benchmarking study for building design and user-built environment explorations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VTdMErEAAAAJ&citation_for_view=VTdMErEAAAAJ:NhqRSupF_l8C,"In order for a project to be satisfactory to end-users and completed with high quality, the architecture, engineering, and construction (AEC) industry heavily relies on digital modeling, simulation and visual communication. In the past two decades, the AEC community has examined different approaches, including virtual and augmented reality, to improve communication, visualization, and coordination among different project participants; yet these approaches are slowly being adopted by the industry. Such technological advancements have the potential to improve and revolutionize the current approaches in design (e.g., by involving end-user feedback to ensure higher performing building operations and end-user satisfaction), in construction (e.g., by improving safety through virtual training), and in operations (e.g., by visualizing real-time sensor data to improve diagnostics). The authors' research vision builds upon …",Elsevier,,2015
1406,Vision-based action recognition of earthmoving equipment using spatio-temporal features and support vector machine classifiers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VTdMErEAAAAJ&citation_for_view=VTdMErEAAAAJ:qjMakFHDy7sC,"Video recordings of earthmoving construction operations provide understandable data that can be used for benchmarking and analyzing their performance. These recordings further support project managers to take corrective actions on performance deviations and in turn improve operational efficiency. Despite these benefits, manual stopwatch studies of previously recorded videos can be labor-intensive, may suffer from biases of the observers, and are impractical after substantial period of observations. This paper presents a new computer vision based algorithm for recognizing single actions of earthmoving construction equipment. This is particularly a challenging task as equipment can be partially occluded in site video streams and usually come in wide variety of sizes and appearances. The scale and pose of the equipment actions can also significantly vary based on the camera configurations. In the proposed …",Elsevier,,2013
1407,"Trend analysis on adoption of virtual and augmented reality in the architecture, engineering, and construction industry",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VTdMErEAAAAJ&citation_for_view=VTdMErEAAAAJ:sSrBHYA8nusC,"With advances in Building Information Modeling (BIM), Virtual Reality (VR) and Augmented Reality (AR) technologies have many potential applications in the Architecture, Engineering, and Construction (AEC) industry. However, the AEC industry, relative to other industries, has been slow in adopting AR/VR technologies, partly due to lack of feasibility studies examining the actual cost of implementation versus an increase in profit. The main objectives of this paper are to understand the industry trends in adopting AR/VR technologies and identifying gaps within the industry. The identified gaps can lead to opportunities for developing new tools and finding new use cases. To achieve these goals, two rounds of a survey at two different time periods (a year apart) were conducted. Responses from 158 industry experts and researchers were analyzed to assess the current state, growth, and saving opportunities for AR/VR technologies for the AEC industry. The findings demonstrate that older generations are significantly more confident about the future of AR/VR technologies and they see more benefits in AR/VR utilization. Furthermore, the research results indicate that Residential and commercial sectors have adopted these tools the most, compared to other sectors and institutional and transportation sectors had the highest growth from 2017 to 2018. Industry experts anticipated a solid growth in the use of AR/VR technologies in 5 to 10 years, with the highest expectations towards healthcare. Ultimately, the findings show a significant increase in AR/VR utilization in the AEC industry from 2017 to 2018.",MDPI,,2020
1408,Towards user centered building design: Identifying end-user lighting preferences via immersive virtual environments,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VTdMErEAAAAJ&citation_for_view=VTdMErEAAAAJ:XiSMed-E-HIC,"In this paper, a systematic approach is presented to (1) collect end-user lighting-related behavior by using immersive virtual environments (IVEs) as an experimental tool, (2) integrate the collected data with building performance simulation (BPS) tools in order to translate behavioral information into quantitative measures (i.e., preferred lux level), and (3) incorporate user preference data for evaluating design alternatives with the objective of meeting end-user lighting preferences while reducing the building lighting-related energy consumption. To evaluate the applicability of this approach, 89 participants' lighting preferences, performance (reading speed and comprehension), personality traits, and environmental views were collected in IVEs. BPS tools were used to translate participants' lighting preferences into quantitative lux distributions, which were then used to evaluate alternative designs and make user …",Elsevier,,2017
1409,What drives our behaviors in buildings? A review on occupant interactions with building systems from the lens of behavioral theories,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VTdMErEAAAAJ&citation_for_view=VTdMErEAAAAJ:5Ul4iDaHHb8C,"Occupant behavior has a significant impact on building systems’ operations and efficiency. As a result, several innovative approaches have been introduced to quantify the dynamics of occupants within indoor environments, such as interactions with different building systems and the impact of various feedback and interventions to reduce the building energy consumption. To achieve this, researchers have highlighted the importance of reducing energy consumption without impacting occupant comfort. As a result, there is an increasing body of research evaluating how different theories of behavior across a variety of disciplines can explain occupant interactions with building systems. Future progress in this area calls for an in-depth understanding of behavioral theories in explaining occupant interactions with different building systems. In this paper, we have used a structured literature review approach to investigate …",Pergamon,Building and Environment,2020
1410,"Adoption of virtual and augmented reality in the architecture, engineering, construction, and facilities management (AEC-FM): mixed method analysis of trends, gaps, and solutions",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VTdMErEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=VTdMErEAAAAJ:j8SEvjWlNXcC,"The Architecture, Engineering, Construction, and Facilities Management (AEC-FM) industry is undergoing a transformative phase with the integration of Augmented Reality (AR) and Virtual Reality (VR) technologies. This study investigates adoption trends, challenges, and future potential of AR/VR technologies within the AEC-FM using a mixed-methods approach, including surveys of over 200 industry experts (2018, 2020, and 2023) and thematic analysis of qualitative interviews. Findings reveal initial optimism in 2018 due to technological advancements, followed by tempered expectations as limitations, costs, and implementation challenges became apparent. While adoption has been led by commercial and institutional sectors, recent growth in the industrial sector reflects AR/VR’s value in large-scale, complex projects. Furthermore, perceptions about AR/VR’s future are consistent across age and gender. The study also highlights the industry’s growing preference for outsourcing AR/VR-related tasks and the shift toward cost-effective solutions like Virtual Design and Construction (VDC) technologies reducing the need for internal AR/VR expertise.",Frontiers Media SA,,2025
1411,Wcdt: World-centric diffusion transformer for traffic scene generation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VTdMErEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=VTdMErEAAAAJ:uLbwQdceFCQC,"In this paper, we introduce a novel approach for autonomous driving trajectory generation by harnessing the complementary strengths of diffusion probabilistic models (a.k.a., diffusion models) and transformers. Our proposed framework, termed the “World-centric Diffusion Transformer” (WcDT), optimizes the entire trajectory generation process, from feature extraction to model inference. To enhance the scene diversity and stochasticity, the historical trajectory data is first preprocessed into “Agent Move Statement” and encoded into latent space using Denoising Diffusion Probabilistic Models (DDPM) enhanced with Diffusion with Transformer (DiT) blocks. Then, the latent features, historical trajectories, HD map features, and historical traffic signal information are fused with various transformer-based encoders that is used to enhance the interaction of agents with other elements in the traffic scene. The encoded traffic …",IEEE,,2025
1412,Real-Time Roadway Obstacle Detection for Electric Scooters Using Deep Learning and Multi-Sensor Fusion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VTdMErEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=VTdMErEAAAAJ:tzM49s52ZIMC,"The increasing adoption of electric scooters (e-scooters) in urban areas has coincided with a rise in traffic accidents and injuries, largely due to their small wheels, lack of suspension, and sensitivity to uneven surfaces. While deep learning-based object detection has been widely used to improve automobile safety, its application for e-scooter obstacle detection remains unexplored. This study introduces a novel ground obstacle detection system for e-scooters, integrating an RGB camera, and a depth camera to enhance real-time road hazard detection. Additionally, the Inertial Measurement Unit (IMU) measures linear vertical acceleration to identify surface vibrations, guiding the selection of six obstacle categories: tree branches, manhole covers, potholes, pine cones, non-directional cracks, and truncated domes. All sensors, including the RGB camera, depth camera, and IMU, are integrated within the Intel RealSense Camera D435i. A deep learning model powered by YOLO detects road hazards and utilizes depth data to estimate obstacle proximity. Evaluated on the seven hours of naturalistic riding dataset, the system achieves a high mean average precision (mAP) of 0.827 and demonstrates excellent real-time performance. This approach provides an effective solution to enhance e-scooter safety through advanced computer vision and data fusion. The dataset is accessible at https://zenodo.org/records/14583718, and the project code is hosted on https://github.com/Zeyang-Zheng/Real-Time-Roadway-Obstacle-Detection-for-Electric-Scooters.",,,2025
1413,Tifl: A tier-based federated learning system,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TMGwBH0AAAAJ&citation_for_view=TMGwBH0AAAAJ:JQOojiI6XY0C,"Federated Learning (FL) enables learning a shared model acrossmany clients without violating the privacy requirements. One of the key attributes in FL is the heterogeneity that exists in both resource and data due to the differences in computation and communication capacity, as well as the quantity and content of data among different clients. We conduct a case study to show that heterogeneity in resource and data has a significant impact on training time and model accuracy in conventional FL systems. To this end, we propose TiFL, a Tier-based Federated Learning System, which divides clients into tiers based on their training performance and selects clients from the same tier in each training round to mitigate the straggler problem caused by heterogeneity in resource anddata quantity. To further tame the heterogeneity caused by non-IID (Independent and Identical Distribution) data and resources, TiFL employs …",,,2020
1414,FedAT: A High-Performance and Communication-Efficient Federated Learning System with Asynchronous Tiers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TMGwBH0AAAAJ&citation_for_view=TMGwBH0AAAAJ:35r97b3x0nAC,"Federated learning (FL) involves training a model over massive distributed devices, while keeping the training data localized and private. This form of collaborative learning exposes new tradeoffs among model convergence speed, model accuracy, balance across clients, and communication cost, with new challenges including: (1) straggler problem---where clients lag due to data or (computing and network) resource heterogeneity, and (2) communication bottleneck---where a large number of clients communicate their local updates to a central server and bottleneck the server. Many existing FL methods focus on optimizing along only one single dimension of the tradeoff space. Existing solutions use asynchronous model updating or tiering-based, synchronous mechanisms to tackle the straggler problem. However, asynchronous methods can easily create a communication bottleneck, while tiering may introduce …",,,2021
1415,FaaSNet: Scalable and Fast Provisioning of Custom Serverless Container Runtimes at Alibaba Cloud Function Compute,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TMGwBH0AAAAJ&citation_for_view=TMGwBH0AAAAJ:7T2F9Uy0os0C,"Serverless computing, or Function-as-a-Service (FaaS), enables a new way of building and scaling applications by allowing users to deploy fine-grained functions while providing fully-managed resource provisioning and auto-scaling. Custom FaaS container support is gaining traction as it enables better control over OSes, versioning, and tooling for modernizing FaaS applications. However, providing rapid container provisioning introduces non-trivial challenges for FaaS providers, since container provisioning is costly, and real-world FaaS workloads exhibit highly dynamic patterns.",https://www.usenix.org/conference/atc21/presentation/wang-ao,,2021
1416,Wukong: A scalable and locality-enhanced framework for serverless parallel computing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TMGwBH0AAAAJ&citation_for_view=TMGwBH0AAAAJ:kzcrU_BdoSEC,"Executing complex, burst-parallel, directed acyclic graph (DAG) jobs poses a major challenge for serverless execution frameworks, which will need to rapidly scale and schedule tasks at high throughput, while minimizing data movement across tasks. We demonstrate that, for serverless parallel computations, decentralized scheduling enables scheduling to be distributed across Lambda executors that can schedule tasks in parallel, and brings multiple benefits, including enhanced data locality, reduced network I/Os, automatic resource elasticity, and improved cost effectiveness. We describe the implementation and deployment of our new serverless parallel framework, called Wukong, on AWS Lambda. We show that Wukong achieves near-ideal scalability, executes parallel computation jobs up to 68.17X faster, reduces network I/O by multiple orders of magnitude, and achieves 92.96% tenant-side cost savings …",,,2020
1417,Beyond efficiency: A systematic survey of resource-efficient large language models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TMGwBH0AAAAJ&citation_for_view=TMGwBH0AAAAJ:vDijr-p_gm4C,"The burgeoning field of Large Language Models (LLMs), exemplified by sophisticated models like OpenAI's ChatGPT, represents a significant advancement in artificial intelligence. These models, however, bring forth substantial challenges in the high consumption of computational, memory, energy, and financial resources, especially in environments with limited resource capabilities. This survey aims to systematically address these challenges by reviewing a broad spectrum of techniques designed to enhance the resource efficiency of LLMs. We categorize methods based on their optimization focus: computational, memory, energy, financial, and network resources and their applicability across various stages of an LLM's lifecycle, including architecture design, pretraining, finetuning, and system design. Additionally, the survey introduces a nuanced categorization of resource efficiency techniques by their specific resource types, which uncovers the intricate relationships and mappings between various resources and corresponding optimization techniques. A standardized set of evaluation metrics and datasets is also presented to facilitate consistent and fair comparisons across different models and techniques. By offering a comprehensive overview of the current sota and identifying open research avenues, this survey serves as a foundational reference for researchers and practitioners, aiding them in developing more sustainable and efficient LLMs in a rapidly evolving landscape.",,,2024
1418,Efficient and Workload-Aware LLM Serving via Runtime Layer Swapping and KV Cache Resizing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TMGwBH0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TMGwBH0AAAAJ:LI9QrySNdTsC,"Efficiently serving large language models (LLMs) under dynamic and bursty workloads remains a key challenge for real-world deployment. Existing serving frameworks and static model compression techniques fail to adapt to workload fluctuations, leading to either service-level objective (SLO) violations under full-precision serving or persistent accuracy degradation with static quantization. We present MorphServe, a dynamic, workload-aware LLM serving framework based on morphological adaptation. MorphServe introduces two asynchronous, token-level runtime mechanisms: quantized layer swapping, which selectively replaces less impactful layers with quantized alternatives during high-load periods, and pressure-aware KV cache resizing, which dynamically adjusts KV cache capacity in response to memory pressure. These mechanisms enable state-preserving transitions with minimum runtime overhead and are fully compatible with modern scheduling and attention techniques. Extensive experiments on Vicuna and Llama family models with real-world workloads demonstrate that MorphServe reduces average SLO violations by 92.45 percent and improves the P95 TTFT latency by 2.2x-3.9x compared to full-precision serving, without compromising generation quality. These results establish MorphServe as a practical and elastic solution for LLM deployment in dynamic environments.",,,2025
1419,ZenFlow: Enabling Stall-Free Offloading Training via Asynchronous Updates,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TMGwBH0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TMGwBH0AAAAJ:k8Z6L05lTy4C,"Fine-tuning large language models (LLMs) often exceeds GPU memory limits, prompting systems to offload model states to CPU memory. However, existing offloaded training frameworks like ZeRO-Offload treat all parameters equally and update the full model on the CPU, causing severe GPU stalls, where fast, expensive GPUs sit idle waiting for slow CPU updates and limited-bandwidth PCIe transfers. We present ZenFlow, a new offloading framework that prioritizes important parameters and decouples updates between GPU and CPU. ZenFlow performs in-place updates of important gradients on GPU, while asynchronously offloading and accumulating less important ones on CPU, fully overlapping CPU work with GPU computation. To scale across GPUs, ZenFlow introduces a lightweight gradient selection method that exploits a novel spatial and temporal locality property of important gradients, avoiding costly global synchronization. ZenFlow achieves up to 5x end-to-end speedup, 2x lower PCIe traffic, and reduces GPU stalls by over 85 percent, all while preserving accuracy.",,,2025
1420,Towards Efficient LLM Storage Reduction via Tensor Deduplication and Delta Compression,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TMGwBH0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TMGwBH0AAAAJ:MLfJN-KU85MC,"Modern model hubs, such as Hugging Face, store tens of petabytes of LLMs, with fine-tuned variants vastly outnumbering base models and dominating storage consumption. Existing storage reduction techniques -- such as deduplication and compression -- are either LLM oblivious or not compatible with each other, limiting data reduction effectiveness. Our large-scale characterization study across all publicly available Hugging Face LLM repositories reveals several key insights: (1) fine-tuned models within the same family exhibit highly structured, sparse parameter differences suitable for delta compression; (2) bitwise similarity enables LLM family clustering; and (3) tensor-level deduplication offers strong synergy with model aware compressors. Building on these insights, we present BitX, an effective, fast, lossless delta compression algorithm that compresses XORed redundancy between fine-tuned and base LLMs. We build zLLM, a model storage reduction pipeline that unifies tensor-level deduplication and lossless BitX compression. By synergizing deduplication and compression around LLM family clustering, zLLM reduces model storage consumption by 49.5 percent, over 20 percent more than state-of-the-art deduplication and compression designs.",,,2025
1421,Centralization in the Decentralized Web: Challenges and Opportunities in IPFS Data Management,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TMGwBH0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TMGwBH0AAAAJ:TIZ-Mc8IlK0C,"The InterPlanetary File System (IPFS) is a pioneering effort for Web 3.0, well-known for its decentralized infrastructure. However, some recent studies have shown that IPFS exhibits a high degree of centralization and has integrated centralized components for improved performance. While this change contradicts the core decentralized ethos of IPFS and introduces risks of hurting the data replication level and thus availability, it also opens some opportunities for better data management and cost savings through deduplication. To explore these challenges and opportunities, we start by collecting an extensive dataset of IPFS internal traffic spanning the last three years with 20+ billion messages. By analyzing this long-term trace, we obtain a more complete and accurate view of how the status of centralization evolves over an extended period. In particular, our study reveals that (1) IPFS shows a low replication level …",,,2025
1422,NotebookOS: A Replicated Notebook Platform for Interactive Training with On-Demand GPUs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TMGwBH0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TMGwBH0AAAAJ:tuHXwOkdijsC,"Interactive notebook programming is universal in modern ML and AI workflows, with interactive deep learning training (IDLT) emerging as a dominant use case. To ensure responsiveness, platforms like Jupyter and Colab reserve GPUs for long-running notebook sessions, despite their intermittent and sporadic GPU usage, leading to extremely low GPU utilization and prohibitively high costs. In this paper, we introduce NotebookOS, a GPU-efficient notebook platform tailored for the unique requirements of IDLT. NotebookOS employs replicated notebook kernels with Raft-synchronized replicas distributed across GPU servers. To optimize GPU utilization, NotebookOS oversubscribes server resources, leveraging high inter-arrival times in IDLT workloads, and allocates GPUs only during active cell execution. It also supports replica migration and automatic cluster scaling under high load. Altogether, this design enables interactive training with minimal delay. In evaluation on production workloads, NotebookOS saved over 1,187 GPU hours in 17.5 hours of real-world IDLT, while significantly improving interactivity.",,,2025
1423,Prioritization of regression tests using singular value decomposition with empirical change records,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_2vphAIAAAAJ&citation_for_view=_2vphAIAAAAJ:u-x6o8ySG0sC,"During development and testing, changes made to a system to repair a detected fault can often inject a new fault into the code base. These injected faults may not be in the same files that were just changed, since the effects of a change in the code base can have ramifications in other parts of the system. We propose a methodology for determining the effect of a change and then prioritizing regression test cases by gathering software change records and analyzing them through singular value decomposition. This methodology generates clusters of files that historically tend to change together. Combining these clusters with test case information yields a matrix that can be multiplied by a vector representing a new system modification to create a prioritized list of test cases. We performed a post hoc case study using this technique with three minor releases of a software product at IBM. We found that our methodology …",IEEE,,2007
1424,Empirical software change impact analysis using singular value decomposition,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_2vphAIAAAAJ&citation_for_view=_2vphAIAAAAJ:u5HHmVD_uO8C,"Verification and validation techniques often generate various forms of software development artifacts. Change records created from verification and validation efforts show how files in the system tend to change together in response to fixes for identified faults and failures. We propose a methodology for determining the impact of a new system modification by analyzing software change records through singular value decomposition. This methodology generates clusters of files that historically tend to change together to address faults and failures found in the code base. We performed a post hoc case study using this technique on five open source software systems. We determined that our technique was effective in identifying impacted files in a system from an introduced change when the developers tended to make small, targeted updates to the source system regularly. We further compared our technique against two …",IEEE,,2008
1425,A service learning practicum capstone,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_2vphAIAAAAJ&citation_for_view=_2vphAIAAAAJ:4DMP91E08xMC,"We present the design and execution of a Service Learning Practicum (SLP) course sequence intended to be year-long capstone for computer science seniors. Students are teamed into groups of six, and develop software for local nonprofit organizations. In addition to the structure of the course, we describe the challenges faced (legal, organizational, etc.), student perceptions via survey results, and provide a number of suggestions for other institutions who are looking to create a similar course sequence. At the end of the cap- stone experience, the customers are provided with working software that meet their current needs.",,,2014
1426,A (updated) review of empiricism at the sigcse technical symposium,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_2vphAIAAAAJ&citation_for_view=_2vphAIAAAAJ:QIV2ME_5wuYC,"The computer science education (CSEd) research community consists of a large group of passionate CS educators who often contribute to other disciplines of CS research. There has been a trend in other disciplines toward more rigorous and empirical evaluation of various hypotheses. Prior investigations of the then-current state of CSEd research showed a distinct lack of rigor in the top research publication venues, with most papers falling in the general category of experience reports. In this paper, we present our examination of the two most recent proceedings of the SIGCSE Technical Symposium, providing a snapshot of the current state of empiricism at the largest CSEd venue. Our goal to categorize the current state of empiricism in the SIGCSE Technical Symposium and identify where the community might benefit from increased empiricism when conducting CSEd research. We found an increase in empirical …",,Proceedings of the 47th ACM Technical Symposium on Computing Science Education,2016
1427,Addressing Challenges in Teaching-Track Faculty Promotion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_2vphAIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_2vphAIAAAAJ:J_g5lzvAfSwC,"Interest in teaching-track faculty positions has been steadily increasing as enrollments in computer science degree programs continue to trend upward. While departments have welcomed these new teaching-track faculty members, senior faculty, department chairs, and university committees often struggle with how to best evaluate these faculty members during the promotion process. In our experience, some universities try to use a ""watered-down"" version of the tenure-track promotion standards with the intent of uniformity. Other universities have created whole new processes, which may be better at capturing the differences in teaching-track positions, but also can create a ""second-class citizen"" status for the teaching-track faculty members. For this panel, we will bring together teaching-track and tenured faculty who have been active in promotion committees, have written letters of support for teaching-track faculty …",,,2025
1428,Teaching track faculty in computer science,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_2vphAIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_2vphAIAAAAJ:HDshCWvjkbEC,"Many computer science departments have chosen to hire faculty to teach in teaching-track positions that parallel the standard tenure-track position, providing the possibility of promotion, longer-term contracts, and higher pay for excellence in teaching and service. This birds-of-a-feather is designed to gather educators, both experienced and new to teaching track positions, who are currently in such a position to share their experiences as members of the faculty of their departments and schools, and to provide opportunities for schools considering such positions to gather information. This year, we plan on discussing challenges we face in continuing- / post-COVID-19 classrooms, and lessons-learned from over a year of pandemic teaching. We will also celebrate our teaching and career successes from the past two years of teaching.",,,2022
1429,Engineering a complete curriculum overhaul,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_2vphAIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_2vphAIAAAAJ:JV2RwH3_ST0C,"We present an eight-year curriculum redesign effort impacting al-most every course in our computer science department. Having not made a major update to our curriculum in two decades, complications began to arise from significant increases in enrollment and instituting multiple degrees in computing in the same department. Starting from a desire to adjust a few courses, we systematically collected a broad set of requirements and blue-sky ideas from many stakeholders, resulting in an unsatisfiable set of content, ordering, and course boundary constraints. After multiple rounds of conversation with our stakeholders in and out of the department, we evolved and relaxed several of our constraints, allowing us to develop a compromise plan for seven new courses and a new prerequisite system. We then piloted five of the new courses and collected feedback on results, iterating on these courses each semester for two …",,,2022
1430,Training computing educators to become computing education researchers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_2vphAIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_2vphAIAAAAJ:M3NEmzRMIkIC,"The computing education community endeavors to consistently move forward, improving the educational experience of our students. As new innovations in computing education practice are learned and shared, however, these papers may not exhibit the desired qualities that move simple experience reports to true Scholarship of Teaching and Learning (SoTL). We report on our six years of experience in running professional development for computing educators in empirical research methods for social and behavioral studies in the classroom. Our goal is to have a direct impact on instructors who are in the beginning stages of transitioning their educational innovations from anecdotal to empirical results that can be replicated by instructors at other institutions. To achieve this, we created a year-long mentoring experience, beginning with a multi-day workshop on empirical research methods during the summer …",,,2022
1431,A systematic literature review of empiricism and norms of reporting in computing education research literature,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_2vphAIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=_2vphAIAAAAJ:k_IJM867U9cC,"Context. Computing Education Research (CER) is critical to help the computing education community and policy makers support the increasing population of students who need to learn computing skills for future careers. For a community to systematically advance knowledge about a topic, the members must be able to understand published work thoroughly enough to perform replications, conduct meta-analyses, and build theories. There is a need to understand whether published research allows the CER community to systematically advance knowledge and build theories. Objectives. The goal of this study is to characterize the reporting of empiricism in Computing Education Research literature by identifying whether publications include content necessary for researchers to perform replications, meta-analyses, and theory building. We answer three research questions related to this goal: (RQ1) What percentage of …",ACM,ACM Transactions on Computing Education (TOCE),2021
1432,Nanomaterial-based electrochemical sensing of neurological drugs and neurotransmitters,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iS12HRMAAAAJ&citation_for_view=iS12HRMAAAAJ:beqBT5984LEC,"Nanomaterial-modified detection systems represent a chief driver towards the adoption of electrochemical methods, since nanomaterials enable functional tunability, ability to self-assemble, and novel electrical, optical and catalytic properties that emerge at this scale. This results in tremendous gains in terms of sensitivity, selectivity and versatility. We review the electrochemical methods and mechanisms that may be applied to the detection of neurological drugs. We focus on understanding how specific nano-sized modifiers may be applied to influence the electron transfer event to result in gains in sensitivity, selectivity and versatility of the detection system. This critical review is structured on the basis of the Anatomical Therapeutic Chemical (ATC) Classification System, specifically ATC Code N (neurotransmitters). Specific sections are dedicated to the widely used electrodes based on the carbon materials …",Springer Vienna,Microchimica Acta,2015
1433,Real-time electrochemical monitoring of adenosine triphosphate in the picomolar to micromolar range using graphene-modified electrodes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iS12HRMAAAAJ&citation_for_view=iS12HRMAAAAJ:vV6vV6tmYwMC,"We report on a competitive electrochemical detection system that is free of wash steps and enables the real-time monitoring of adenosine triphosphate (ATP) in a quantitative manner over a five-log concentration range. The system utilizes a recognition surface based on ATP aptamer (ATPA) capture probes prebound to electroactive flavin adenine dinucleotide (FAD) molecules, and a signaling surface utilizing graphene (Gr) and gold nanoparticle (AuNP) modified carbon paste electrode (Gr–AuNP–CPE) that is optimized to enhance electron-transfer kinetics and signal sensitivity. Binding of ATP to ATPA at the recognition surface causes the release of an equivalent concentration of FAD that can be quantitatively monitored in real time at the signaling surface, thereby enabling a wide linear working range (1.14 × 10–10 to 3.0 × 10–5 M), a low detection limit (2.01 × 10–11 M using graphene and AuNP modified glassy …",American Chemical Society,,2013
1434,Photoelectrochemical Stability of Electrodeposited Cu2O Films,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iS12HRMAAAAJ&citation_for_view=iS12HRMAAAAJ:hqOjcs7Dif8C,"We report on the photoelectrochemical stability of electrodeposited films of cuprous oxide (Cu2O) in aqueous solutions. p-type Cu2O was electrodeposited from an alkaline lactate solution onto Au substrates with a (111) preferred orientation. The as-deposited films exhibit a strong (111) orientation and a columnar morphology, terminating at the surface with pyramidal features. Stability of the photoelectrochemical response was studied via repeated cycling polarization and by monitoring the photocurrent within a voltage window where only the CuO/Cu2O transformation would occur. The Cu2O film morphology changes from a dense structure to a more stable network of elongated leaf-like crystals. We attributed this behavior to the energy differences among the various crystallographic facets of Cu2O, with the {111} facets being the most stable. Photocurrent evolution over time was explained in terms of an initial …",American Chemical Society,,2010
1435,Electrokinetic preconcentration and detection of neuropeptides at patterned graphene-modified electrodes in a nanochannel,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iS12HRMAAAAJ&citation_for_view=iS12HRMAAAAJ:djft3U1LymYC,"Neuropeptides are vital to the transmission and modulation of neurological signals, with Neuropeptide Y (NPY) and Orexin A (OXA) offering diagnostic information on stress, depression, and neurotrauma. NPY is an especially significant biomarker, since it can be noninvasively collected from sweat, but its detection has been limited by poor sensitivity, long assay times, and the inability to scale-down sample volumes. Herein, we apply electrokinetic preconcentration of the neuropeptide onto patterned graphene-modified electrodes in a nanochannel by frequency-selective dielectrophoresis for 10 s or by electrochemical adsorptive accumulation for 300 s, to enable the electrochemical detection of NPY and OXA at picomolar levels from subnanoliter samples, with sufficient signal sensitivity to avoid interferences from high levels of dopamine and ascorbic acid within biological matrices. Given the high sensitivity of the …",American Chemical Society,,2014
1436,Single-cell microfluidic impedance cytometry: From raw signals to cell phenotypes using data analytics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iS12HRMAAAAJ&citation_for_view=iS12HRMAAAAJ:WTSGYGHz1bkC,"The biophysical analysis of single-cells by microfluidic impedance cytometry is emerging as a label-free and high-throughput means to stratify the heterogeneity of cellular systems based on their electrophysiology. Emerging applications range from fundamental life-science and drug assessment research to point-of-care diagnostics and precision medicine. Recently, novel chip designs and data analytic strategies are laying the foundation for multiparametric cell characterization and subpopulation distinction, which are essential to understand biological function, follow disease progression and monitor cell behaviour in microsystems. In this tutorial review, we present a comparative survey of the approaches to elucidate cellular and subcellular features from impedance cytometry data, covering the related subjects of device design, data analytics (i.e., signal processing, dielectric modelling, population clustering), and …",Royal Society of Chemistry,Lab on a Chip,2021
1437,Detecting apoptotic bodies by impedance cytometry as an indicator of drug sensitivity,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iS12HRMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iS12HRMAAAAJ:IwGqIHSOC8kC,"A microfluidic system can be used to quantify apoptotic bodies (ABs) with single-cell sensitivity, providing real-time information regarding the presence, and properties of ABs. Different subpopulations of ABs can thus be distinguished from one another to quantify cellular dis-assembly and drug sensitivity of the cancer cells under test. Impedance measurement can be performed by flowing secreted bodies at a substantially single-particle sensitivity. A plurality of electrical impedance magnitude and phase parameters of the biological sample can be measured within the flow cell structure, corresponding to a specified range of frequencies to help determine a biological characteristic of the cancer cells.",,,2025
1438,Multiparametric single-cell biophysical cytometry under tunable viscoelastic extensional flows for classification of T-cell lymphomas on their nuclear phenotypes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iS12HRMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iS12HRMAAAAJ:9UF2BbDYXHIC,"Cutaneous T-cell lymphoma cells expand in the skin microenvironment but are eliminated by therapies that act in the blood, highlighting the need to enhance cell migration from skin to blood by modulating their biomechanics to improve the efficacy of therapies. Herein, single-cell biophysical cytometry under tunable viscoelastic extensional flows to modulate the geometry for cell deformation is utilized to correlate nuclear phenotypes (size, shape, lamin protein expression and telomere organization) of clonally related lymphoma cells from the blood (Mac-1) and skin (Mac-2A and Mac-2B) to their deformability characteristics. Through coupling single-cell metrics from impedance, deformability and recovery dynamics, we infer that Mac-2A cells from the skin with larger nuclear sizes and diverse nuclear shapes exhibit lower deformability than Mac-1 cells from blood. On the other hand, through lowering nuclear lamin A …",Elsevier,,2025
1439,Controlled Nanoconfinement in a Microfluidic Modular Bead Array Device via Elastomeric Diaphragm Collapse for Enhancing Biomolecular Binding Kinetics (Small 34/2025),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iS12HRMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iS12HRMAAAAJ:6e4D8M0GhXMC,"In article number 2412474, Chia-Fu Chou, Nathan S. Swami, and co-workers presented a modular platform for controlled nanoconfinement over a large area using an elastomeric diaphragm integrated with strain sensors and microfabricated posts (≈ 500 nm) to enhance biomolecular binding by alternating between confinement and bulk transport for rapid DNA immobilization and screening aptamers on their binding affinities to target molecules.",,,2025
1440,Modified cells as multimodal standards for cytometry and separation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iS12HRMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iS12HRMAAAAJ:fHS53ZCY-AEC,"Inline classification of a biological specimen including mammalian cells can include generating an alternating current (AC) electrical stimulus to an electrode structure. The electrode structure can be electrically coupled with a flow cell. A response, elicited by the electrical stimulus, can be received when a model specimen class traverses the flow cell. Using the received response, a corresponding impedance parameter value can be determined, the value indicative of a specified biophysical characteristic corresponding to the model specimen class. The first impedance parameter can be translated to a value corresponding to the specified biophysical characteristic.",,,2025
1441,On-Chip Integration of Impedance Cytometry for Inline Optimization of Dielectrophoretic Separations on Multiple Cellular Biophysical Metrics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iS12HRMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iS12HRMAAAAJ:cUMtEw7vMgQC,"Microfluidic cell separation by dielectrophoresis, based on biophysical and electrical physiology metrics, is often optimized using on-chip fluorescence microscopy or off-chip flow cytometry of the separated fractions. However, these techniques require fluorescent reporters or stained samples that operate as end point assays, preventing the separated cell fractions from being utilized for longitudinal or transplantation studies. Single-cell impedance cytometry has a small footprint for facile integration toward label-free quantification of the separated fractions based on cell size, viability, and biophysical metrics. However, this is limited by low impedance signal-to-noise ratios in the low-conductivity media optimal for dielectrophoretic separation and by irreversible dielectrophoretic cell capture on impedance acquisition electrodes, while its single-cell resolution ability is limited by the high channel depths used to enhance …",American Chemical Society,,2025
1442,Teaching societal and ethical implications of nanotechnology to engineering students through science fiction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VysKO84AAAAJ&citation_for_view=VysKO84AAAAJ:u-x6o8ySG0sC,"Societal and ethical implications of nanotechnology have become a hot topic of public debates in many countries because both revolutionary changes and strong public concerns are expected from its development. Because nanotechnology is, at this point, mostly articulated in visionary and futuristic terms, it is difficult to apply standard methods of technology assessment and even more difficult to consider it in engineering ethics courses. In this article, the authors suggest using selected science fiction stories in the engineering ethics classroom to provide students with ethical skills and cultural knowledge required for engaging in public debates and for responsible decision making. Against the background of general debates on teaching engineering ethics, they do so by discussing the advantages and possible drawbacks of this approach and by presenting two examples of nano-science fiction classics.",Sage Publications,,2005
1443,"Nanotalk: Conversations with scientists and engineers about ethics, meaning, and belief in the development of nanotechnology",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VysKO84AAAAJ&citation_for_view=VysKO84AAAAJ:u5HHmVD_uO8C,"No one really knows where nanotechnology is leading, what its pursuit will mean, and how it may affect human and other forms of life. Nevertheless, its research and development are moving briskly into that unknown. Nanotalk is a book of conversations and explorations with thirty five such nano-research scientists and engineers who share their ideas",CRC Press,,2005
1444,Towards the conscientious development of ethical nanotechnology,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VysKO84AAAAJ&citation_for_view=VysKO84AAAAJ:d1gkVwhDpl0C,"Nanotechnology, the emerging capability of human beings to observe and organize matter at the atomic level, has captured the attention of the federal government, science and engineering communities, and the general public. Some proponents are referring to nanotechnology as “the next technological revolution”. Applications projected for this new evolution in technology span a broad range from the design and fabrication of new membranes, to improved fuel cells, to sophisticated medical prosthesis techniques, to tiny intelligent machines whose impact on humankind is unknowable. As with the appropriation of technological innovation generally, nanotechnology is likely to eventually bring dramatic and unpredictable new capabilities to human material existence, along with resulting ethical challenges and social changes to be reconciled. But as of yet, aside from a few simple new consumer goods, such as paint …",Kluwer Academic Publishers,,2004
1445,Science fiction in computer science education,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VysKO84AAAAJ&citation_for_view=VysKO84AAAAJ:LkGwnXOMwfcC,"The use of science fiction (SF) to engage students in computer science learning is becoming more popular [1-6]. There is ample material available to help both undergraduate and graduate students make connections between technical content and human experience, from Star Trek to The Hitchhiker's Guide to the Galaxy to 2001: A Space Odyssey to I, Robot and many others. Fiction can be included in technical courses or used to draw students into the field in introductory classes. The panelists, who represent a range of schools, perspectives and classes, will present brief overviews (5-8 minutes) of how they have used science fiction to engage students in technical topics as well as ethical and societal issues related to computing. After the overviews, there will be plenty of time for discussion of examples used within the community and ways to make connections between science fiction and particular classes or …",,,2012
1446,"Ethics, technology, and the future: an intergenerational experience in engineering education",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VysKO84AAAAJ&citation_for_view=VysKO84AAAAJ:9yKSN-GCB0IC,"How do engineering educators adequately and richly introduce to young engineers the perplexing ethical issues associated with the development of new technologies? Robotics, nanotechnology, cloning, cyberintelligence, and genetic engineering, for example, each hold the potential to radically alter the fundamental nature of human life. Senior citizens in our society have a lifetime of experience adopting new technologies into their lives. Through an intergenerational dialogue, undergraduate engineers can come to appreciate and understand what technological change can really mean, both in practical and ethical terms. This article explores the use of intergenerational dialogue as a learning tool, with a focus on the experience of students enrolled in a required engineering ethics course. Reactions and thoughts recounted in this article from both undergraduate engineers and senior citizens signify the …",Sage Publications,,2003
1447,"Animals, Ethics, and Engineering: Intersections and Implications",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VysKO84AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=VysKO84AAAAJ:PELIpwtuRlgC,"Animals, Ethics, and Engineering: Intersections and Implications is a seminal work that explores the intricate relationship between technology, ethics, and the welfare of nonhuman animals. Edited by Rosalyn W. Berne, this volume brings together leading scholars and practitioners to examine the ethical responsibilities inherent in technological progress and its impact on animal well-being.",CRC Press,,2025
1448,Non-human Animals and a New Ethics for Engineering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VysKO84AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=VysKO84AAAAJ:Y5dfb0dijaUC,"The sixth mass extinction is underway. Earth's animal populations have declined by an average of 69% since 1970, partly due to unsustainable use of land, water, and energy, and resulting climate change. This paper submits that engineering education has a critical role to play in helping prepare the next generation of engineers to address this ecological urgency. However, to this will require a new framework of ethics for engineering; one that must first dismantle the nature-technology distinction, and the perceived separation of humans and other animals, which are at the foundation of engineering design and practice. Indeed, non-human animals have long been disregarded and devalued under the rationalist worldview that persists in the culture of engineering. By disconnecting our identity from Earth’s non-human others, essentially treating them as technologies for our use, we human have put not just other …",,,2023
1449,"Race and ethics in the design of biomedical technologies: the pulse oximeter as a case in point (The Daniel W. Foster, MD, Visiting Lectureship in Medical Ethics)",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VysKO84AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=VysKO84AAAAJ:D_sINldO8mEC,"There were clear indications from studies done in 2005 and 2007 that pulse oximeters overestimate arterial oxygen saturation during hypoxia in dark-skinned individuals. And yet, years later, the device remains essentially unaltered. This disregard has been particularly significant during the coronavirus pandemic. Patients diagnosed with COVID-19 who present with silent hypoxemia, but are not sick enough to warrant hospital admission, have been guided to monitor their arterial oxygenation by pulse oximetry at home, and present for care when they show evidence of hypoxemia. Others in the general public have used the device simply for personal assurance. Whether or not these uses are appropriate is debatable. Nevertheless, that a racial bias is embedded in this technology is indisputable. The pulse oximeter serves as a timely case in point of how race can become a matter of ethics in the design of biomedical devices.",,,2021
1450,Race Matters in Engineering and Technology,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VysKO84AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=VysKO84AAAAJ:eq2jaN3J8jMC,"The ASEM DE/I series featured aa provocative talk entitled"" Race Matters in Engineering and Technology"" with Professor Rosalyn W. Berne, Department of Engineering and Society at the University of Virginia. This webinar discusses values in the development of technology and how we can use those values to create more ethically designed technology.",American Society for Engineering Management,,2021
1451,A practical guide to hydrogels for cell culture,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=q58P-VsAAAAJ&citation_for_view=q58P-VsAAAAJ:kzcSZmkxUKAC,"There is growing appreciation of the role that the extracellular environment plays in regulating cell behavior. Mechanical, structural, and compositional cues, either alone or in concert, can drastically alter cell function. Biomaterials, and particularly hydrogels, have been developed and implemented to present defined subsets of these cues for investigating countless cellular processes as a means of understanding morphogenesis, aging, and disease. Although most scientists concede that standard cell culture materials (tissue culture plastic and glass) do a poor job of recapitulating native cellular milieus, there is currently a knowledge barrier for many researchers in regard to the application of hydrogels for cell culture. Here, we introduce hydrogels to those who may be unfamiliar with procedures to culture and study cells with these systems, with a particular focus on commercially available hydrogels.",Nature Publishing Group,,2016
1452,N-cadherin adhesive interactions modulate matrix mechanosensing and fate commitment of mesenchymal stem cells,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=q58P-VsAAAAJ&citation_for_view=q58P-VsAAAAJ:EPG8bYD4jVwC,"During mesenchymal development, the microenvironment gradually transitions from one that is rich in cell–cell interactions to one that is dominated by cell–ECM (extracellular matrix) interactions. Because these cues cannot readily be decoupled in vitro or in vivo, how they converge to regulate mesenchymal stem cell (MSC) mechanosensing is not fully understood. Here, we show that a hyaluronic acid hydrogel system enables, across a physiological range of ECM stiffness, the independent co-presentation of the HAVDI adhesive motif from the EC1 domain of N-cadherin and the RGD adhesive motif from fibronectin. Decoupled presentation of these cues revealed that HAVDI ligation (at constant RGD ligation) reduced the contractile state and thereby nuclear YAP/TAZ localization in MSCs, resulting in altered interpretation of ECM stiffness and subsequent changes in downstream cell proliferation and differentiation …",Nature Research,,2016
1453,Dimensionality and spreading influence MSC YAP/TAZ signaling in hydrogel environments,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=q58P-VsAAAAJ&citation_for_view=q58P-VsAAAAJ:BrOSOlqYqPUC,"Improved fundamental understanding of how cells interpret microenvironmental signals is integral to designing better biomaterial therapies. YAP/TAZ are key mediators of mechanosensitive signaling; however, it is not clear how they are regulated by the complex interplay of microenvironmental factors (e.g., stiffness and degradability) and culture dimensionality. Using covalently crosslinked norbornene-functionalized hyaluronic acid (HA) hydrogels with controlled stiffness (via crosslink density) and degradability (via susceptibility of crosslinks to proteolysis), we found that human mesenchymal stem cells (MSCs) displayed increased spreading and YAP/TAZ nuclear localization when cultured atop stiffer hydrogels; however, the opposite trend was observed when MSCs were encapsulated within degradable hydrogels. When stiffness-matched hydrogels of reduced degradability were used, YAP/TAZ nuclear …",Elsevier,,2016
1454,Matching material and cellular timescales maximizes cell spreading on viscoelastic substrates,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=q58P-VsAAAAJ&citation_for_view=q58P-VsAAAAJ:JTqpx9DYBaYC,"Recent evidence has shown that, in addition to rigidity, the viscous response of the extracellular matrix (ECM) significantly affects the behavior and function of cells. However, the mechanism behind such mechanosensitivity toward viscoelasticity remains unclear. In this study, we systematically examined the dynamics of motor clutches (i.e., focal adhesions) formed between the cell and a viscoelastic substrate using analytical methods and direct Monte Carlo simulation. Interestingly, we observe that, for low ECM rigidity, maximum cell spreading is achieved at an optimal level of viscosity in which the substrate relaxation time falls between the timescale for clutch binding and its characteristic binding lifetime. That is, viscosity serves to stiffen soft substrates on a timescale faster than the clutch off-rate, which enhances cell−ECM adhesion and cell spreading. On the other hand, for substrates that are stiff, our model …",National Academy of Sciences,,2018
1455,"The effect of anisotropic collagen-GAG scaffolds and growth factor supplementation on tendon cell recruitment, alignment, and metabolic activity",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=q58P-VsAAAAJ&citation_for_view=q58P-VsAAAAJ:YOwf2qJgpHMC,"Current surgical and tissue engineering approaches for treating tendon injuries have shown limited success, suggesting the need for new biomaterial strategies. Here we describe the development of an anisotropic collagen-glycosaminoglycan (CG) scaffold and use of growth factor supplementation strategies to create a 3D platform for tendon tissue engineering. We fabricated cylindrical CG scaffolds with aligned tracks of ellipsoidal pores that mimic the native physiology of tendon by incorporating a directional solidification step into a conventional lyophilization strategy. By modifying the freezing temperature, we created a homologous series of aligned CG scaffolds with constant relative density and degree of anisotropy but a range of pore sizes (55–243 μm). Equine tendon cells showed greater levels of attachment, metabolic activity, and alignment as well as less cell-mediated scaffold contraction, when cultured in …",Elsevier,,2011
1456,Substrate stiffness and viscoelasticity influence fibroblast senescence,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=q58P-VsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=q58P-VsAAAAJ:pYKElYtJMmwC,"Senescent cell accumulation has been implicated in aging and fibrotic disease, which are both characterized by increased tissue stiffness. However, the direct connection between tissue mechanics and senescence induction remains disputed in the literature. Thus, this work investigates the influence of hydrogel stiffness and viscoelasticity in promoting fibroblast senescence both in combination with genotoxic stress and independently. We show that while lung fibroblast YAP signaling declines with senescence induction, senescent fibroblasts maintain their mechanosensing capabilities with increased YAP nuclear localization on higher stiffness hydrogels. Most notably, we find a unique role for hydrogel viscoelasticity in senescence induction with soft (2 kPa) viscoelastic substrates promoting both the onset and amplification of senescence, even in the absence of genotoxic stress. These changes are not associated with a decline in YAP activity, but instead with a decline in nuclear DAPI intensity, suggesting a role of nuclear organization in driving this phenotype. Overall, this work highlights the influence of mechanics on the induction of senescence and supports the key role of viscoelasticity.",Cold Spring Harbor Laboratory,,2025
1457,Norbornene homopolymerization limits cell spreading in thiol–ene photoclick hydrogels,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=q58P-VsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=q58P-VsAAAAJ:n3vGvpFsckwC,"Thiol–ene click chemistry is a powerful tool for engineering tissue‐mimicking hydrogels permissive to 3D cell spreading. Thiol–norbornene chemistry allows precise control over crosslinking while seemingly avoiding alkene homopolymerization that can restrict 3D cell spreading. However, limited stress relaxation of a guest–host crosslinked norbornene‐modified hyaluronic acid (NorHA) hydrogel employing a thiol–norbornene photoclick reaction prompts investigation into unintended norbornene homopolymerization. Norbornene conversion exceeds 1:1 thiol–ene expectations across various formulations, implicating homopolymerization. Reducing the number of norbornenes per NorHA chain (f) mitigates network formation via norbornene homopolymerization. Guest–host hydrogels fabricated with Nor8HA (f = 8) exhibit 93.0 ± 1.6% relaxation, while those fabricated with Nor40HA (f = 40) achieve only 42.3 ± 0.1 …",,,2025
1458,M2 macrophage co-culture overrides viscoelastic hydrogel mechanics to promote IL-6-dependent fibroblast activation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=q58P-VsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=q58P-VsAAAAJ:nPTYJWkExTIC,"Fibroblast activation drives fibrotic disease; however, the complex interplay of how tissue mechanics and macrophage signaling combine to influence fibroblast activation remains unclear. Using hyaluronic acid hydrogels to mimic lung stiffness and viscoelasticity, we investigated macrophage influence on fibroblast activation. Fibroblasts cultured on stiff (50 kPa) hydrogels mimicking fibrotic tissue exhibit increased activation, as measured by cell spreading and type I collagen and cadherin-11 expression, compared with fibroblasts cultured on soft (1 kPa) viscoelastic hydrogels mimicking normal lung. Macrophage-conditioned media did not alter these trends, however co-culture with M2 macrophages increased fibroblast activation independent of direct macrophage contact, even on soft viscoelastic hydrogels. Blocking interleukin-6 (IL-6) signaling mitigated this pro-fibrotic effect but did not affect fibroblast-only cultures …",Elsevier,,2025
1459,Freeze-dried porous collagen scaffolds for the repair of volumetric muscle loss injuries,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=q58P-VsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=q58P-VsAAAAJ:4e5Qn2KL_jwC,"Volumetric muscle loss (VML) injuries are characterized by the traumatic loss of skeletal muscle, resulting in permanent damage to both tissue architecture and electrical excitability. To address this challenge, we previously developed a three-dimensional (3D) aligned collagen-glycosaminoglycan (CG) scaffold platform that supported in vitro myotube alignment and maturation. In this work, we assessed the ability of CG scaffolds to facilitate functional muscle recovery in a rat tibialis anterior (TA) model of VML. Functional muscle recovery was assessed following implantation of either nonconductive CG or electrically conductive CG-polypyrrole (PPy) scaffolds at 4, 8, and 12 weeks postinjury by in vivo electrical stimulation of the peroneal nerve. After 12 weeks, scaffold-treated muscles produced maximum isometric torque that was significantly greater than nontreated tissues. Histological analysis further supported …",American Chemical Society,,2025
1460,Heparin-modified aligned collagen scaffolds enhance in vitro myogenesis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=q58P-VsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=q58P-VsAAAAJ:PQEM9vzQD9gC,"Biomaterial-based skeletal muscle tissue engineering approaches have largely focused on mimicking the 3D aligned architecture of native muscle, which is critical for guiding myotube formation and force transmission. In contrast, fewer studies incorporate glycosaminoglycan (GAG)-mediated biochemical cues despite their known role in regulating myogenesis and growth factor sequestration. In this study, we develop aligned collagen-GAG (CG) scaffolds using directional freeze-drying and systematically vary GAG content by incorporating GAGs of increasing sulfation levels (hyaluronic acid, chondroitin sulfate, and heparin). While all scaffold variants support myoblast adhesion, metabolic activity, and myotube alignment, heparin-modified collagen scaffolds significantly enhance myoblast metabolic activity and myogenic differentiation as measured by myosin heavy chain (MHC) expression and myotube size. We additionally show that heparin-modified scaffolds sequester and retain significantly higher levels of insulin-like growth factor-1 (IGF-1), a potent promoter of myogenesis, compared to other scaffold groups. Together, these results highlight the importance of optimizing GAG content in CG scaffolds for targeted applications and underscore the promise of heparin-modified CG scaffolds as a material platform for skeletal muscle tissue engineering.",Cold Spring Harbor Laboratory,,2025
1461,Perspectives on thermoelectrics: from fundamentals to device applications.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IhNwSN4AAAAJ&citation_for_view=IhNwSN4AAAAJ:4hFrxpcac9AC,"This review is an update of a previous review (A. J. Minnich, et al., Energy Environ. Sci., 2009, 2, 466) published two years ago by some of the co-authors, focusing on progress made in thermoelectrics over the past two years on charge and heat carrier transport, strategies to improve the thermoelectric figure of merit, with new discussions on device physics and applications, and assessing challenges on these topics. Understanding of phonon transport in bulk materials has advanced significantly as the first-principles calculations are applied to thermoelectric materials, and experimental tools are being developed. Some new strategies have been developed to improve electron transport in thermoelectric materials. Fundamental questions on phonon and electron transport across interfaces and in thermoelectric materials remain. With thermoelectric materials reaching high ZT values well above one, the field is ready to …",,,2012
1462,Enhancement of thermoelectric properties by modulation-doping in silicon germanium alloy nanocomposites,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IhNwSN4AAAAJ&citation_for_view=IhNwSN4AAAAJ:VLnqNzywnoUC,"Modulation-doping was theoretically proposed and experimentally proved to be effective in increasing the power factor of nanocomposites (Si80Ge20)70(Si100B5)30 by increasing the carrier mobility but not the figure-of-merit (ZT) due to the increased thermal conductivity. Here we report an alternative materials design, using alloy Si70Ge30 instead of Si as the nanoparticles and Si95Ge5 as the matrix, to increase the power factor but not the thermal conductivity, leading to a ZT of 1.3 ± 0.1 at 900 °C.",American Chemical Society,,2012
1463,Power factor enhancement by modulation doping in bulk nanocomposites,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IhNwSN4AAAAJ&citation_for_view=IhNwSN4AAAAJ:JoZmwDi-zQgC,"We introduce the concept of modulation doping in three-dimensional nanostructured bulk materials to increase the thermoelectric figure of merit. Modulation-doped samples are made of two types of nanograins (a two-phase composite), where dopants are incorporated only into one type. By band engineering, charge carriers could be separated from their parent grains and moved into undoped grains, which would result in enhanced mobility of the carriers in comparison to uniform doping due to a reduction of ionized impurity scattering. The electrical conductivity of the two-phase composite can exceed that of the individual components, leading to a higher power factor. We here demonstrate the concept via experiment using composites made of doped silicon nanograins and intrinsic silicon germanium grains.",American Chemical Society,,2011
1464,Thermoelectric power factor: Enhancement mechanisms and strategies for higher performance thermoelectric materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IhNwSN4AAAAJ&citation_for_view=IhNwSN4AAAAJ:TIZ-Mc8IlK0C,,doi:10.1016/j.mser.2015.08.001,,2015
1465,High-performance thermoelectric nanocomposites from nanocrystal building blocks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IhNwSN4AAAAJ&citation_for_view=IhNwSN4AAAAJ:tuHXwOkdijsC,"The efficient conversion between thermal and electrical energy by means of durable, silent and scalable solid-state thermoelectric devices has been a long standing goal. While nanocrystalline materials have already led to substantially higher thermoelectric efficiencies, further improvements are expected to arise from precise chemical engineering of nanoscale building blocks and interfaces. Here we present a simple and versatile bottom–up strategy based on the assembly of colloidal nanocrystals to produce consolidated yet nanostructured thermoelectric materials. In the case study on the PbS–Ag system, Ag nanodomains not only contribute to block phonon propagation, but also provide electrons to the PbS host semiconductor and reduce the PbS intergrain energy barriers for charge transport. Thus, PbS–Ag nanocomposites exhibit reduced thermal conductivities and higher charge carrier concentrations and …",Nature Publishing Group UK,,2016
1466,Innovation in thermoelectric materials: From fundamental physics to practical applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IhNwSN4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=IhNwSN4AAAAJ:cK4Rrx0J3m0C,"Since the last comprehensive report in MRS Bulletin in 2018, the field of thermoelectricity has witnessed remarkable advancements. These innovations have been driven by a deeper understanding of the underlying physics, inventive material design, and progress in computational and experimental techniques. Developments in first-principles-based methods, molecular dynamics, and computational heat transfer have enhanced our understanding of efficient heat-to-electricity conversion. Simultaneously, data science, particularly machine learning, has enabled efficient screening and design of thermoelectric materials. A sustainable futuristic economy requires the development of thermoelectric modules and materials that are highly efficient, mechanically, thermally, and chemically stable, and composed of earth-abundant, nontoxic elements. This issue of MRS Bulletin highlights key innovations, from spin …",Springer International Publishing,MRS Bulletin,2025
1467,Enhanced Thomson and Unusual Nernst Coefficients in 1T‐TiSe2 Due to Bipolar Transport and CDW Phase Transition,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IhNwSN4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=IhNwSN4AAAAJ:jL-93Qbq4QoC,"Thermoelectric coolers utilizing the Peltier effect have dominated the field of solid‐state cooling but their efficiency is hindered by material limitations. Alternative routes based on the Thomson and Nernst effects offer new possibilities. Here, we present a comprehensive investigation of the thermoelectric properties of 1T‐TiSe2, focusing on these effects around the charge density wave transition (≈200 K). The abrupt Fermi surface reconstruction associated with this transition leads to an exceptional peak in the Thomson coefficient of 450 μV K−1 at 184 K, surpassing the Seebeck coefficient. Furthermore, 1T‐TiSe2 exhibits a remarkably broad temperature range (170–400 K) with a Thomson coefficient exceeding 190 μV K−1, a characteristic highly desirable for the development of practical Thomson coolers with extended operational ranges. Additionally, the Nernst coefficient exhibits an unusual temperature …",,,2025
1468,Spin-lattice entanglement in,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IhNwSN4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=IhNwSN4AAAAJ:BzfGm06jWhQC,"Complex chalcogenides in the PS family of materials ( = Mn, Fe, Co, and Ni) display remarkably different phase progressions depending upon the metal center orbital filling, character of the P-P linkage, and size of the van der Waals gap. There is also a stacking pattern and spin state difference between the lighter and heavier transition metal-containing systems that places CoPS at the nexus of these activities. Despite these unique properties, this compound is under-explored. Here, we bring together Raman scattering spectroscopy and infrared absorption spectroscopy with X-ray techniques to identify a structural component to the 119 K magnetic ordering transition as well as a remarkable lower temperature set of magnon-phonon pairs that engage in avoided crossings along with a magnetic scattering continuum that correlates with phonon lifetime effects. These findings point to strong spin-phonon entanglement as well as opportunities to control these effects under external stimuli.",,,2025
1469,High thermoelectric power factor in Ni-Fe alloy for active cooling applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IhNwSN4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=IhNwSN4AAAAJ:U4n9YNQMCAIC,"Metallic thermoelectric materials are promising candidates for active cooling applications, where high thermal conductivity and a high thermoelectric power factor are essential to maximize effective thermal conductivity. While metals inherently possess high thermal and electrical conductivities, they typically exhibit low Seebeck coefficients. In this work, we create a database of the Seebeck coefficient of binary metallic alloys and apply machine learning techniques to identify alloys with large Seebeck coefficients. Specifically, we identify Ni–Fe as a promising candidate for active cooling around room temperature. We then fabricate Ni–Fe ingots and demonstrate thermoelectric power factor values as high as 120 μW cm−1 K−2 at 200 K for these stable alloys, which are composed of cost-effective and abundant elements. Furthermore, we demonstrate that the effective thermal conductivity of these alloys, under small …",https://pubs.rsc.org/en/content/articlelanding/2025/mh/d5mh00524h,,2025
1470,Sign Reversal of Hall Conductivity in Polycrystalline FeRh Films via the Topological Hall Effect in the Antiferromagnetic Phase,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IhNwSN4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=IhNwSN4AAAAJ:CaZNVDsoPx4C,"The intrinsic Berry curvature in ferromagnetic (FM) materials significantly influences Hall conductivity during the antiferromagnetic (AFM)-to-FM phase transition, as demonstrated through the anomalous Hall effect (AHE). First-principles calculations indicate negligible spin Hall conductivity in FeRh materials in the AFM phase due to time-reversal symmetry breaking. To date, the contribution of the Berry curvature to the spin Hall effect remains unexamined in the context of AHE measurements. This study presents the temperature-dependent spin and carrier transport properties of FeRh thin films across AFM-to-FM transitions. In the AFM phase, a nonzero AHE signal is observed and even reverses its sign when the film transitions to the FM phase (above T = 175 K). This nonzero AHE signal contrasts with predictions from density functional theory calculations. Notably, an additional Hall conductivity contribution …",American Chemical Society,,2025
1471,Saint Venant’s torsion of homogeneous and composite bars by the finite volume method,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XQPKcPUAAAAJ&citation_for_view=XQPKcPUAAAAJ:u5HHmVD_uO8C,"We propose a new finite-volume based approach to the solution of Saint Venant’s torsion problems of homogeneous and composite prismatic bars subjected to pure torsion. The semi-inverse approach is employed to construct an approximate displacement field characteristic of pure torsion within the subvolumes of the beam’s discretized cross section such that the governing differential equation for the warping function is locally satisfied in each subvolume in an integral sense. Orthotropic subvolumes are admitted in the formulation to enable analysis of bars comprised of heterogeneous microstructures, including composite materials with orthotropic shear moduli. Continuity of both displacements and tractions across subvolumes’ interfaces is satisfied in a surface-average sense, together with traction-free lateral boundary conditions. Closed-form expressions for the stiffness matrix elements that relate surface …",Elsevier,,2020
1472,Parametric finite-volume method for Saint Venant’s torsion of arbitrarily shaped cross sections,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XQPKcPUAAAAJ&citation_for_view=XQPKcPUAAAAJ:u-x6o8ySG0sC,We extend our recent finite-volume based approach to the solution of Saint Venant’s torsion problems of bars and beams comprised of rectangular sections to enable analysis of arbitrary cross sections characterized by curved boundaries. This is accomplished by incorporating parametric mapping based on transfinite grid generation to enable discretization of the bar cross section by quadrilateral rather than rectangular subvolumes employed in the original version. The construction of the local stiffness matrix that relates the surface-averaged subvolume warping functions to the corresponding tractions is carried out in the reference plane such that the subvolume equilibrium in the physical plane is satisfied in a surface-averaged sense. This produces explicit expressions for the stiffness matrix elements that may be readily coded. Orthotropic subvolumes are intrinsic in the method’s construction so that bars with …,Elsevier,,2021
1473,Response of Complex Microstructure Composites via an Integrated API Based on Finite-Volume Homogenization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XQPKcPUAAAAJ&citation_for_view=XQPKcPUAAAAJ:bFI3QPDXJZMC,,https://imece.secure-platform.com/a/solicitations/261/sessiongallery/schedule/items/21250,,2025
1474,An Integrated Homogenization Engine Based on Microgravity Driven Microstructure Generation for Random Unidirectional Composites,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XQPKcPUAAAAJ&citation_for_view=XQPKcPUAAAAJ:yD5IFk8b50cC,,The International Council on Materials Education,,2024
1475,DNA purification using dynamic solid-phase extraction on a rotationally-driven polyethylene-terephthalate microdevice,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mpx4oLUAAAAJ&citation_for_view=mpx4oLUAAAAJ:_FxGoFyzp5QC,"We report the development of a disposable polyester toner centrifugal device for semi-automated, dynamic solid phase DNA extraction (dSPE) from whole blood samples. The integration of a novel adhesive and hydrophobic valving with a simple and low cost microfabrication method allowed for sequential addition of reagents without the need for external equipment for fluid flow control. The spin-dSPE method yielded an average extraction efficiency of ∼45% from 0.6 μL of whole blood. The device performed single sample extractions or accommodate up to four samples for simultaneous DNA extraction, with PCR-readiness DNA confirmed by effective amplification of a β-globin gene. The purity of the DNA was challenged by a multiplex amplification with 16 targeted amplification sites. Successful multiplexed amplification could routinely be obtained using the purified DNA collected post an on-chip extraction, with …",Elsevier,,2016
1476,Designing a spatially aware and autonomous quadcopter,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mpx4oLUAAAAJ&citation_for_view=mpx4oLUAAAAJ:qjMakFHDy7sC,"The United States creates or acquires increasingly more complex intelligence, surveillance, and reconnaissance (ISR) systems to maintain a strong, leading presence within the world. As a result, ISR systems have become more costly and difficult to manage. The research team focused on continuing previous year efforts of another team to utilize commercial off-the-shelf (COTS) technologies in the development of more flexible and cost-effective ISR systems. The primary goal was to design and implement an autonomous quadcopter that integrated an Android smartphone, an Arduino microcontroller, and several ultrasonic sensors to independently explore and map an unknown area. The project was broken down into three main tasks: construction of the quadcopter and integration of ultrasonic sensors, Android phone, and Arduino microcontroller, development of an Android application that generates navigation …",IEEE,,2013
1477,Thin-film aerogel thermal conductivity measurements via 3ω,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mpx4oLUAAAAJ&citation_for_view=mpx4oLUAAAAJ:UeHWp8X0CEIC,"The limiting constraint in a growing number of nano systems is the inability to thermally tune devices. Silica aerogel is widely accepted as the best solid thermal insulator in existence and offers a promising solution for microelectronic systems needing superior thermal isolation. In this study, thin-film silica aerogel films varying in thickness from 250 to 1280 nm were deposited on SiO2 substrates under a variety of deposition conditions. These samples were then thermally characterized using the 3ω technique. Deposition processes for depositing the 3ω testing mask to the sample were optimized and it was demonstrated that thin-film aerogel can maintain its structure in common fabrication processes for microelectromechanical systems. Results indicate that thin-film silica aerogel can maintain the unique, ultra-low thermal conductivity commonly observed in bulk aerogel, with a directly measured thermal conductivity …",North-Holland,,2011
1478,Hematocrit analysis through the use of an inexpensive centrifugal polyester-toner device with finger-to-chip blood loading capability,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mpx4oLUAAAAJ&citation_for_view=mpx4oLUAAAAJ:zYLM7Y9cAGgC,"Hematocrit (HCT) measurements are important clinical diagnostic variables that help physicians diagnose and treat various medical conditions, ailments, and diseases. In this work, we present the HCT Disc, a centrifugal microdevice fabricated by a Print, Cut and Laminate (PCL) method to generate a 12-sample HCT device from materials costing <0.5 USD (polyester and toner or PeT). Following introduction from a drop of blood (finger stick), whole blood metering and cell sedimentation are controlled by centrifugal force, only requiring a CD player motor as external hardware and, ultimately, a cell phone for detection. The sedimented volume from patient blood in the HCT Disc was analyzed using a conventional scanner/custom algorithm for analysis of the image to determine a hematocrit value, and these were compared to values generated in a clinical laboratory, which correlated well. To enhance portability and …",Elsevier,,2016
1479,Rapid detection of Clostridium difficile via magnetic bead aggregation in cost-effective polyester microdevices with cell phone image analysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mpx4oLUAAAAJ&citation_for_view=mpx4oLUAAAAJ:Tyk-4Ss8FVUC,"Pathogen detection has traditionally been accomplished by utilizing methods such as cell culture, immunoassays, and nucleic acid amplification tests; however, these methods are not easily implemented in resource-limited settings because special equipment for detection and thermal cycling is often required. In this study, we present a magnetic bead aggregation assay coupled to an inexpensive microfluidic fabrication technique that allows for cell phone detection and analysis of a notable pathogen in less than one hour. Detection is achieved through the use of a custom-built system that allows for fluid flow control via centrifugal force, as well as manipulation of magnetic beads with an adjustable rotating magnetic field. Cell phone image capture and analysis is housed in a 3D-printed case with LED backlighting and a lid-mounted Android phone. A custom-written application (app.) is employed to interrogate …",Royal Society of Chemistry,,2016
1480,Optimized Biomanufacturing for Treatment of Volumetric Muscle Loss Enables Physiomimetic Recovery,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mpx4oLUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=mpx4oLUAAAAJ:0EnyYjriUFMC,"Volumetric muscle loss (VML) injuries are defined by loss of sufficient skeletal muscle to produce persistent deficits in muscle form and function, with devastating lifelong consequences to both soldiers and civilians. There are currently no satisfactory treatments for VML injuries. The work described herein details the implementation of a fully enclosed bioreactor environment (FEBE) system that efficiently interfaces with our existing automated bioprinting and advanced biomanufacturing methods for cell deposition on sheet-based scaffolds for our previously described tissue-engineered muscle repair (TEMR) technology platform. Briefly, the TEMR technology consists of a porcine bladder acellular matrix seeded with skeletal muscle progenitor cells and preconditioned via 10% uniaxial cyclic stretch in a bioreactor. Overall, TEMR implantation in an established rat tibialis anterior (TA) VML injury model can result in 60 to …","Mary Ann Liebert, Inc., publishers",,2025
1481,Hermetically or aseptically sealed bioreactor system and related method thereof,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mpx4oLUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=mpx4oLUAAAAJ:UebtZRa9Y70C,"the present disclosure relates generally to artificially manufacturing cells and tissues for use in medical procedures. More particularly, the present disclosure relates to using cyclic motion to stimulate cell growth and/or maturation in an enclosed bioreactor which can be sealed off from external contaminants.",,,2023
1482,Bioreactor controller device and related method thereof,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mpx4oLUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=mpx4oLUAAAAJ:LkGwnXOMwfcC,"The present invention provides a bioreactor controller with a simple user interface comprising a microcontroller and a linear motor. The bioreactor controller is microcontroller based, has a greater temporal accuracy, and inexpensive. The microcontroller of the bioreactor controller selects a proto col mode and a setup mode by the user, runs the protocol mode if the setup mode is not selected by the user, stops running the protocol mode for a predetermined time if the protocol mode is selected by the user until the user is (Continued)",,,2022
1483,Development And Evaluation Of A Fully Enclosed Bioreactor Environment (FEBE) For Automated Biofabrication Of Implantable Tissue Engineered Muscle Repair Constructs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mpx4oLUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=mpx4oLUAAAAJ:Se3iqnhoufwC,,"MARY ANN LIEBERT, INC",,2022
1484,System for monitoring and maintaining separation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mpx4oLUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=mpx4oLUAAAAJ:hqOjcs7Dif8C,,,,2022
1485,Data-driven phenotypic dissection of AML reveals progenitor-like cells that correlate with prognosis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wHUbRh4AAAAJ&citation_for_view=wHUbRh4AAAAJ:ufrVoPGSRksC,"Acute myeloid leukemia (AML) manifests as phenotypically and functionally diverse cells, often within the same patient. Intratumor phenotypic and functional heterogeneity have been linked primarily by physical sorting experiments, which assume that functionally distinct subpopulations can be prospectively isolated by surface phenotypes. This assumption has proven problematic, and we therefore developed a data-driven approach. Using mass cytometry, we profiled surface and intracellular signaling proteins simultaneously in millions of healthy and leukemic cells. We developed PhenoGraph, which algorithmically defines phenotypes in high-dimensional single-cell data. PhenoGraph revealed that the surface phenotypes of leukemic blasts do not necessarily reflect their intracellular state. Using hematopoietic progenitors, we defined a signaling-based measure of cellular phenotype, which led to isolation of a …",Elsevier,,2015
1486,A pharmacological map of the PI3-K family defines a role for p110α in insulin signaling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wHUbRh4AAAAJ&citation_for_view=wHUbRh4AAAAJ:u5HHmVD_uO8C,"Phosphoinositide 3-kinases (PI3-Ks) are an important emerging class of drug targets, but the unique roles of PI3-K isoforms remain poorly defined. We describe here an approach to pharmacologically interrogate the PI3-K family. A chemically diverse panel of PI3-K inhibitors was synthesized, and their target selectivity was biochemically enumerated, revealing cryptic homologies across targets and chemotypes. Crystal structures of three inhibitors bound to p110γ identify a conformationally mobile region that is uniquely exploited by selective compounds. This chemical array was then used to define the PI3-K isoforms required for insulin signaling. We find that p110α is the primary insulin-responsive PI3-K in cultured cells, whereas p110β is dispensable but sets a phenotypic threshold for p110α activity. Compounds targeting p110α block the acute effects of insulin treatment in vivo, whereas a p110β inhibitor has no …",Elsevier,,2006
1487,Multiplexed mass cytometry profiling of cellular states perturbed by small-molecule regulators,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wHUbRh4AAAAJ&citation_for_view=wHUbRh4AAAAJ:UeHWp8X0CEIC,"Mass cytometry facilitates high-dimensional, quantitative analysis of the effects of bioactive molecules on human samples at single-cell resolution, but instruments process only one sample at a time. Here we describe mass-tag cellular barcoding (MCB), which increases mass cytometry throughput by using n metal ion tags to multiplex up to 2n samples. We used seven tags to multiplex an entire 96-well plate, and applied MCB to characterize human peripheral blood mononuclear cell (PBMC) signaling dynamics and cell-to-cell communication, signaling variability between PBMCs from eight human donors, and the effects of 27 inhibitors on this system. For each inhibitor, we measured 14 phosphorylation sites in 14 PBMC types at 96 conditions, resulting in 18,816 quantified phosphorylation levels from each multiplexed sample. This high-dimensional, systems-level inquiry allowed analysis across cell-type and …",Nature Publishing Group US,,2012
1488,Palladium-based mass tag cell barcoding with a doublet-filtering scheme and single-cell deconvolution algorithm,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wHUbRh4AAAAJ&citation_for_view=wHUbRh4AAAAJ:W7OEmFMy1HYC,"Mass-tag cell barcoding (MCB) labels individual cell samples with unique combinatorial barcodes, after which they are pooled for processing and measurement as a single multiplexed sample. The MCB method eliminates variability between samples in antibody staining and instrument sensitivity, reduces antibody consumption and shortens instrument measurement time. Here we present an optimized MCB protocol. The use of palladium-based labeling reagents expands the number of measurement channels available for mass cytometry and reduces interference with lanthanide-based antibody measurement. An error-detecting combinatorial barcoding scheme allows cell doublets to be identified and removed from the analysis. A debarcoding algorithm that is single cell–based rather than population-based improves the accuracy and efficiency of sample deconvolution. This debarcoding algorithm has been …",Nature Publishing Group UK,,2015
1489,Highly multiplexed simultaneous detection of RNAs and proteins in single cells,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wHUbRh4AAAAJ&citation_for_view=wHUbRh4AAAAJ:Se3iqnhoufwC,"To enable the detection of expression signatures specific to individual cells, we developed PLAYR (proximity ligation assay for RNA), a method for highly multiplexed transcript quantification by flow and mass cytometry that is compatible with standard antibody staining. When used with mass cytometry, PLAYR allowed for the simultaneous quantification of more than 40 different mRNAs and proteins. In primary cells, we quantified multiple transcripts, with the identity and functional state of each analyzed cell defined on the basis of the expression of a separate set of transcripts or proteins. By expanding high-throughput deep phenotyping of cells beyond protein epitopes to include RNA expression, PLAYR opens a new avenue for the characterization of cellular metabolism.",Nature Publishing Group US,,2016
1490,Atypical CD11c+ B-cells Expand In Idiopathic Pulmonary Fibrosis And Are Associated With IgA Antibodies Against Oxidized Cholesterol,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wHUbRh4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wHUbRh4AAAAJ:M3NEmzRMIkIC,"Background: Idiopathic pulmonary fibrosis (IPF) is interstitial lung disease characterized by dysregulated response to injury, increased oxidative stress and progressive lung scarring. Oxidation-specific epitopes (OSEs) are neoantigens that form during oxidative stress and can trigger immune response and further inflammation. OSEs have been described in animal models of lung injury, but their role in IPF is unknown. Antibodies against OSEs can limit inflammation, and we previously reported that anti-OSE IgA against oxidized cholesterol is elevated in interstitial lung diseases including IPF. In the current study, we identified unique B-cell phenotypes associated with anti-OSE IgA in IPF and further explored anti-OSE IgA role in IPF. Methods: We performed deep phenotyping of circulating B-cells in a cohort of 20 patients with IPF and 9 healthy controls utilizing mass cytometry time of flight (CyTOF). We utilized a …",American Thoracic Society,,2025
1491,Characterizing Microglial Signaling Dynamics During Inflammation Using Single‐Cell Mass Cytometry,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wHUbRh4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wHUbRh4AAAAJ:r0BpntZqJG4C,"Microglia play a critical role in maintaining central nervous system (CNS) homeostasis and display remarkable plasticity in their response to inflammatory stimuli. However, the specific signaling profiles that microglia adopt during such challenges remain incompletely understood. Traditional transcriptomic approaches provide valuable insights, but fail to capture dynamic post‐translational changes. In this study, we utilized time‐resolved single‐cell mass cytometry (CyTOF) to measure distinct signaling pathways activated in microglia upon exposure to bacterial and viral mimetics—lipopolysaccharide (LPS) and polyinosinic‐polycytidylic acid (Poly(I:C)), respectively. Furthermore, we evaluated the immunomodulatory role of astrocytes on microglial signaling in mixed cultures. Microglia or mixed cultures derived from neonatal mice were treated with LPS or Poly(I:C) for 48 h. Cultures were stained with a panel of 33 …","John Wiley & Sons, Inc.",,2025
1492,Extrinsic Apoptosis and Necroptosis in Telencephalic Development: A Single-Cell Mass Cytometry Study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wHUbRh4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wHUbRh4AAAAJ:maZDTaKrznsC,"Regulated cell death is integral to sculpting the developing brain, yet the relative contributions of extrinsic apoptosis and necroptosis remain unclear. Here, we leverage single-cell mass cytometry (CyTOF) to characterize the cellular landscape of the mouse telencephalon in wild-type (WT), RIPK3 knockout (RIPK3 KO), and RIPK3/Caspase-8 double knockout (DKO) mice. Strikingly, combined deletion of RIPK3 and Caspase-8 leads to a 12.6% increase in total cell count, challenging the prevailing notion that intrinsic apoptosis exclusively governs developmental cell elimination. Detailed subpopulation analysis reveals that DKO mice display selective enrichment of Tbr2⁺ intermediate progenitors and endothelial cells, underscoring distinct, cell type–specific roles for extrinsic apoptotic and necroptotic pathways. These findings provide a revised framework for understanding the coordinated regulation of cell number …",,,2025
1493,A single-cell mass cytometry-based atlas of the developing mouse brain,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wHUbRh4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wHUbRh4AAAAJ:isC4tDSrTZIC,"Development of the mammalian brain requires precise molecular changes across diverse cell lineages. While single-cell RNA abundances in the developing brain have been characterized by single-cell RNA sequencing (scRNA-seq), single-cell protein abundances have not been characterized. To address this gap, we performed mass cytometry on the whole brain at embryonic day (E)11.5–E12.5 and the telencephalon, the diencephalon, the mesencephalon and the rhombencephalon at E13.5–postnatal day (P)4 from C57/BL6 mice. Using a 40-antibody panel to analyze 24,290,787 cells from two to four biological replicates per sample, we identify 85 molecularly distinct cell clusters from distinct lineages. Our analyses confirm canonical molecular pathways of neurogenesis and gliogenesis, and predict two distinct trajectories for cortical oligodendrogenesis. Differences in protein versus RNA expression from …",Nature Publishing Group US,,2025
1494,Condemned to connection? Network communitarianism in Mark Zuckerberg’s “Facebook Manifesto”,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U8ry4r0AAAAJ&citation_for_view=U8ry4r0AAAAJ:9yKSN-GCB0IC,"This article considers Mark Zuckerberg’s 2017 open letter titled “Building Global Community” as a political manifesto. Published just prior to an ongoing series of scandals involving Facebook and the misuse of customer data, the letter outlines Zuckerberg’s plans for the future direction of the company. Using an approach based on Luc Boltanski and Eve Chiapello’s connexionism, combined with Benjamin Bratton’s understanding of platforms and John Bellamy Foster and Robert W. McChesney’s, as well as Shoshana Zuboff’s, analysis of surveillance capitalism, this article argues that the letter remains significant because it constitutes a coherent statement about ubiquitous social media and the future of government in an era characterized by a global turn to authoritarianism. Evoking Japanese philosopher Hiroki Azuma’s reworking of Rousseau’s concept of “General Will” in the social media age, this article warns …",SAGE Publications,,2019
1495,Leveraging liminality: How San Diego taxi drivers used their precarious status to win reform,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U8ry4r0AAAAJ&citation_for_view=U8ry4r0AAAAJ:u-x6o8ySG0sC,"Using a case study in San Diego, California, we explore the complexities of precarious employment for taxi drivers. We seek to answer the following question: how do the ambiguities of taxi drivers’ status as independent contractors shape drivers’ work conditions and opportunities for resistance? Our study is based on 331 surveys, 20 in-depth interviews, participant observation, and policy analysis over two years. While drivers were objectively disempowered by the independent contracting designation, lacking both the protections granted employees and the prerogatives of ownership, they were empowered by the alliances this duality facilitated. Drivers used their marginal identities as workers and as entrepreneurs to their advantage in their campaign for reform. This case presents an alternative narrative to previous research, which generally highlights how independent contractors either accept their status in …",Routledge,,2019
1496,The privacy paradox: How market privacy facilitates government surveillance,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U8ry4r0AAAAJ&citation_for_view=U8ry4r0AAAAJ:u5HHmVD_uO8C,"Although most surveillance studies scholars assume privacy is antithetical to surveillance, critics have recently warned that privacy-based criticisms may facilitate surveillance. That being said, we do not yet have data that show whether privacy claims were used in the past to legitimate government surveillance. This paper addresses that gap by analyzing claims made over one of the U.S.’s most controversial surveillance issues: government control over encryption technologies. A review of Congressional hearings and statements on the Congressional Record (n = 112) reveals that from 1993 to 1999, public debates were dominated by a market liberalization discourse in which participants supported loosening encryption controls as a way to protect privacy from criminal intrusions in market transactions. Also playing a role was a strong skepticism toward government power and a preference for markets as …",Routledge,,2018
1497,"Building ideal workplaces: Labor, affect, and identity in tech for good projects",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U8ry4r0AAAAJ&citation_for_view=U8ry4r0AAAAJ:zYLM7Y9cAGgC,"Nascent organizations emerging from a mixture of public and private interests are attempting to collaboratively innovate new ways to build digital technologies premised on the robust support of citizens and public goods—known broadly as “Tech for Good” initiatives. Drawing on 6 months of participant observation and in-depth interviews with civic technologists in the San Francisco Bay Area, I argue that Tech for Good initiatives are thoroughly structured by technologists’ affective attachments to their careers. While participants work to build digital technologies to benefit the common good, they simultaneously work through feelings of disillusionment, unfulfillment, and disappointment with their jobs in the high-tech sector—a set of practices that I call repair work. By engaging in repair work, participants repurpose civic technology organizations into idealized versions of their workplaces. Accounting for the constitutive role of repair work in Tech for Good projects is critical for future design justice efforts.",,,2022
1498,Volunteering the Valley: Designing technology for the common good in the San Francisco Bay Area,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U8ry4r0AAAAJ&citation_for_view=U8ry4r0AAAAJ:qjMakFHDy7sC,"How can digital technologies be designed for good rather than harm? Dozens of civic organizations under the “tech for good” banner have emerged in recent years to address exactly this question. Although these organizations have commendable goals, many scholars have criticized them for naively believing that technologies can solve complex social problems. However, we do not yet have empirical data on how they are, in practice, working to address local social problems. This study investigates one particular effort to design digital technologies for the common good: civic technology. Civic technology organizations are made up of technologists employed or seeking employment in the high-tech industry who volunteer in their spare time to build digital technologies to be used by municipal employees and local residents. Drawing on participant observation and interviews with civic technologists in the San …",,,2021
1499,Centering Race in Analyses and Practices of Countersurveillance Advocacy: Mythologies of the Racialized Other in the Crypto Wars,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U8ry4r0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=U8ry4r0AAAAJ:UeHWp8X0CEIC,"Encryption is commonly understood as a technology which can provide universal privacy protection and as a countersurveillance tool. However, researchers have recently criticized crypto advocates for ignoring questions of race and of narrowing countersurveillance advocacy to circumscribed technosolutions. This chapter adds to this growing scholarship by presenting an analysis of how race has shaped the development and regulation of encryption technologies. Drawing on a discourse analysis of US federal congressional hearings from 1990 to 2016 (the so-called “Crypto Wars”), we demonstrate how state and private actors mobilized racialized mythological constructions of criminals in negotiating how to regulate encryption. We conclude it is important to center the systematically racist carceral culture of the US in seemingly disconnected areas such as the policy debates of the Crypto Wars.",Routledge,,2022
1500,Reliable broadcast of safety messages in vehicular ad hoc networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s1NC4EMAAAAJ&citation_for_view=s1NC4EMAAAAJ:u5HHmVD_uO8C,"Broadcast communications is critically important in vehicular networks. Many safety applications need safety warning messages to be broadcast to all vehicles present in an area. Design of a medium access control (MAC) protocol for vehicular networks is an interesting problem because of challenges posed by broadcast traffic, high mobility, high reliability and low delay requirements of these networks. In this article, we propose a topology-transparent broadcast protocol and present a detailed mathematical analysis for obtaining the probability of success and the average delay. We show, by analysis and simulations, that the proposed protocol outperforms two existing protocols for vehicular networks with topology-transparent properties and provides reliable broadcast communications for delivering safety messages under load conditions deemed to be common in vehicular environments.",IEEE,,2009
1501,Duplication-correcting codes for data storage in the DNA of living organisms,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s1NC4EMAAAAJ&citation_for_view=s1NC4EMAAAAJ:yqoGN6RLRZoC,"The ability to store data in the DNA of a living organism has applications in a variety of areas including synthetic biology and watermarking of patented genetically modified organisms. Data stored in this medium are subject to errors arising from various mutations, such as point mutations, indels, and tandem duplication, which need to be corrected to maintain data integrity. In this paper, we provide error-correcting codes for errors caused by tandem duplications, which create a copy of a block of the sequence and insert it in a tandem manner, i.e., next to the original. In particular, we present two families of codes for correcting errors due to tandem duplications of a fixed length: the first family can correct any number of errors, while the second corrects a bounded number of errors. We also study codes for correcting tandem duplications of length up to a given constant k, where we are primarily focused on the cases of k …",IEEE,,2017
1502,Error-Correction in Flash Memories via Codes in the Ulam Metric,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s1NC4EMAAAAJ&citation_for_view=s1NC4EMAAAAJ:HIFyuExEbWQC,"<?Pub Dtl=""""?>We consider rank modulation codes for flash memories that allow for handling arbitrary charge-drop errors. Unlike classical rank modulation codes used for correcting errors that manifest themselves as swaps of two adjacently ranked elements, the proposed translocation rank codes account for more general forms of errors that arise in storage systems. Translocations represent a natural extension of the notion of adjacent transpositions and as such may be analyzed using related concepts in combinatorics and rank modulation coding. Our results include derivation of the asymptotic capacity of translocation rank codes, construction techniques for asymptotically good codes, as well as simple decoding methods for one class of constructed codes. As part of our exposition, we also highlight the close connections between the new code family and permutations with short common subsequences, deletion …",IEEE,,2013
1503,Capacity and expressiveness of genomic tandem duplication,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s1NC4EMAAAAJ&citation_for_view=s1NC4EMAAAAJ:nVrZBo8bIpAC,"The majority of the human genome consists of repeated sequences. An important type of repeated sequences common in the human genome are tandem repeats, where identical copies appear next to each other. For example, in the sequence AGTCTGTGC, TGTG is a tandem repeat, that may be generated from AGTCTGC by a tandem duplication of length 2. In this paper, we investigate the possibility of generating a large number of sequences from a seed, i.e. a small initial string, by tandem duplications of bounded length. We study the capacity of such a system, a notion that quantifies the system's generating power. Our results include exact capacity values for certain tandem duplication string systems. In addition, motivated by the role of DNA sequences in expressing proteins via RNA and the genetic code, we define the notion of the expressiveness of a tandem duplication system as the capability of expressing …",IEEE,,2017
1504,The Capacity of String-Duplication Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s1NC4EMAAAAJ&citation_for_view=s1NC4EMAAAAJ:3htObqc8RwsC,"It is known that the majority of the human genome consists of duplicated sequences. Furthermore, it is believed that a significant part of the rest of the genome also originated from duplicated sequences and has mutated to its current form. In this paper, we investigate the possibility of constructing an exponentially large number of sequences from a short initial sequence using simple duplication rules, including those resembling genomic-duplication processes. In other words, our goal is to find the capacity, or the expressive power, of these string-duplication systems. Our results include exact capacities, and bounds on the capacities, of four fundamental string-duplication systems. The study of these fundamental biologically inspired systems is an important step toward modeling and analyzing more complex biological processes.",IEEE,,2016
1505,Constrained coding for error mitigation in nanopore-based DNA data storage,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s1NC4EMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=s1NC4EMAAAAJ:sszUF3NjhM4C,"DNA has been proposed as an alternative to magnetic and solid-state devices for storing digital data. In DNA data storage, writing data is performed through DNA synthesis, and reading is done via sequencing. Nanopore devices for sequencing DNA, like those produced by Oxford Nanopore Technologies, allow long reads and real-time sequencing but with lower accuracy compared to other sequencers, such as Illumina. To improve the reliability of data storage in DNA, we aim to combat the high error rate of nanopore sequencing using constrained coding. Certain aspects of the physical process underlying nanopore sequencing mean that some sequences are more prone to sequencing errors than others. We leverage this observation to design constrained codes using constrained de Bruijn graphs, along with a state-splitting encoder and a Viterbi-based decoder. We find that the overall performance of our novel …",Nature Publishing Group UK,,2025
1506,Asymptotically Optimal Codes Correcting One Substring Edit,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s1NC4EMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=s1NC4EMAAAAJ:jFemdcug13IC,"The substring edit error is the operation of replacing a substring of with another string , where the lengths of and are bounded by a given constant . It encompasses localized insertions, deletions, and substitutions within a window. Codes correcting one substring edit have redundancy at least . In this paper, we construct codes correcting one substring edit with redundancy , which is asymptotically optimal.",,,2025
1507,Linear List Decodable Edit-Correcting Codes with Rate Approaching,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s1NC4EMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=s1NC4EMAAAAJ:NDuN12AVoxsC,"Linear codes correcting one deletions have rate at most . In this paper, we construct linear list decodable codes correcting edits with rate approaching and reasonable list size. Our encoder and decoder run in polynomial time.",,,2025
1508,Optimal Codes Correcting a Substring Edit,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s1NC4EMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=s1NC4EMAAAAJ:Dem6FJhTUoYC,"The substring edit error replaces a substring of with another string , where the lengths of and are bounded by a given constant k. It encompasses localized insertions, deletions, and substitutions within a window. Codes correcting one substring edit have redundancy at least . In this paper, we construct codes correcting one substring edit with redundancy , which is almost optimal. We also study the average-case document-exchange problem under one substring edit and construct a hash with an expected length of approximately for any iid distribution for the documents.",IEEE,,2025
1509,Correcting a substring edit error of bounded length,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=s1NC4EMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=s1NC4EMAAAAJ:rHJHxKgnXwkC,"Localized errors, which occur in windows with bounded lengths, are common in a range of applications. Such errors can be modeled as k-substring edits, which replace one substring with another string, both with lengths upper bounded by k. This generalizes errors such as localized deletions or burst substitutions studied in the literature. In this paper, we show through statistical analysis of real data that substring edits better describe differences between related documents compared to independent edits, and thus commonly arise in problems related to data synchronization. We also show that for the dataset under study, assuming codes exist that can achieve the Gilbert-Varshamov (GV) bound, substring-edit-correcting codes can synchronize two documents with much lower overhead compared to general indel/substitution-correcting codes. Furthermore, given a constant k, we construct binary codes of length n for …",IEEE,,2025
1510,Rethinking the design of presentation slides: A case for sentence headlines and visual evidence,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1VHZn3QAAAAJ&citation_for_view=1VHZn3QAAAAJ:k_IJM867U9cC,"The traditional design of presentation slides calls for a phrase headline supported by a bulleted list. Recently, many critics have challenged the effectiveness of this design. This article argues for a significantly different design that offers numerous advantages in most communication contexts but that is particularly well suited to technical presentations. Originating at Lawrence Livermore National Laboratory and refined in more than 400 critique sessions at Virginia Tech, this alternative design is characterized by a succinct sentence headline supported by visual evidence. What distinguishes this design from other visual -evidence designs are its specific layout and typography guidelines, which were chosen to make the communication efficient, memorable, and persuasive. Although more difficult to construct than the traditional design, the alternative design shows much promise as a more effective means of conveying …",Society for Technical Communication,,2005
1511,"Mary Somerville: science, illumination, and the female mind",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1VHZn3QAAAAJ&citation_for_view=1VHZn3QAAAAJ:Tyk-4Ss8FVUC,"In an era when science was perceived as a male domain, Mary Somerville (1780-1872) became both the leading woman scientist of her day and an integral part of the British scientific community. Her scientific writings contributed to one of the most important cultural projects of Victorian Britain: establishing science as a distinct, integral, and unifying element of culture. By the time of her death, Somerville had achieved near-mythic status in Britain. Her works reflect both the power of science to capture imagination and the influence of cultural factors in the development of science. They provide a window into a particularly lucid and illuminated mind and into one of the most formative periods in the evolution of modern scientific culture. This retelling of Somerville's story focuses on the factors that allowed her to become an eminent scientist and argues for rethinking the story of women's participation in science.",Cambridge University Press,,2001
1512,Liberal education in twenty-first century engineering: Responses to ABET/EC 2000 Criteria,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1VHZn3QAAAAJ&citation_for_view=1VHZn3QAAAAJ:IWHjjKOFINEC,"Twenty-first century engineering education must meet radically revised national accreditation standards, known colloquially as EC2000. This book shows paths forward for all faculty involved in the «liberal education» of engineering undergraduates. Beginning with an exhortation for liberal education, it includes the EC2000 criteria and its historical origin, as well as example institutional and individual responses to these criteria-which include topics in communication, ethics and professional responsibility, contemporary issues, art and aesthetics, and the integration of engineering and the humanities. The variety of curricular responses presented indicate that this is a formative-perhaps even revolutionary-period in engineering education.",Peter Lang,,2004
1513,Woman as mediatrix: Women as writers on science and technology in the eighteenth and nineteenth centuries,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1VHZn3QAAAAJ&citation_for_view=1VHZn3QAAAAJ:aqlVkmm33-oC,"It is argued that although the writing on science and technology produced by women in the eighteenth and nineteenth centuries has usually been considered peripheral to scientific and technological advancement, the history of the mediatrix, or woman mediator, reveals that women writers carried out essential tasks. History suggests that women assumed the role of mediatrix much more frequently than they assumed other roles, largely because that role allowed women to contribute to science and technology without seriously violating gender norms. The careers and writing of four women mediators are described, showing that mediation is an unrecognized but crucially important aspect of the intellectual activity of science and that mediative writing often clarifies, rather than debases, scientific knowledge. The history of women mediators also suggests that intermediaries are essential for the functioning of the …",IEEE,,2002
1514,Discovering the power of PowerPoint: Rethinking the design of presentation slides from a skillful user's perspective,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1VHZn3QAAAAJ&citation_for_view=1VHZn3QAAAAJ:kNdYIx-mwKoC,"Slides projected as overheads or by computers have become a conventional and dominant feature of engineering presentations in academia, business, and professional societies. The traditional format for presentation slides-a phrase headline supported by a bullet list-has recently come under harsh criticism. In this paper, we propose an alternative to the traditional design that can communicate engineering content more effectively. The alternative design relies on a succinct sentence headline supported by visual evidence. Its chief strength is that it aids the audience's understanding of the engineering principles and arguments being presented, as opposed to the traditional phrase headline/bullet list design, which tends to function more as notes for the speaker. Although the alternative design offers several clear advantages in an engineering presentation many engineering students and faculty strongly resist veering from the traditional format defaults of PowerPoint. This paper outlines the key features and advantages of the alternative design and explores the ways in which resistance to the alternative design can be seen as a measure of how embedded a particular way of using PowerPoint has become in engineering professional practice. Drawing upon student and faculty resistance to the design, this paper uses PowerPoint as a case study in the ways skillful users adapt tools such as PowerPoint to better accomplish their own goals rather than simply accepting the default approaches encouraged by the tool.",,,2005
1515,Engineering Communication as an Area of Specialization and a Fundamentally Interdisciplinary Domain: What We Can Learn from Fred Newton Scott,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1VHZn3QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1VHZn3QAAAAJ:3s1wT3WcHBgC,"The importance of communication in engineering practice and the communication deficits of engineering graduates are enduring themes in engineering education. Perhaps more significantly, communication is the only domain in which engineering experts are consistently (if grudgingly) willing to yield space in the curriculum. Although there are ample intellectual resources available for designing and delivering communication instruction to engineering students, these resources have yet to be deployed in a systematic way, largely because most engineering faculty and administrators appear to be unaware of the existence of those resources. The vacuum produced by this knowledge gap has been filled by conventional wisdom that reduces engineering communication to technical writing and imagines the teaching and learning of technical writing as a joyless activity devoid of intellectual foundations and human significance. This paper puts forth the scholarship of Fred Newton Scott (1860-1931), professor of English and rhetoric at the University of Michigan, as a resource for articulating a view of engineering communication that is both humanistic and functional, humanistic because it is grounded in fundamental notions about human beings, their mental activities, and their social interactions, functional in the sense of being designed to achieve specific purposes. It draws on the history of English as a discipline and engineering communication as a subject to illuminate the sources of misconceptions and analyzes two of Scott’s many publications to delineate a success orientation to the teaching of engineering communication.",,,2025
1516,Expanding the Audience for the Discourse on Diversity by Recognizing the Framing Power of Implicit Messages,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1VHZn3QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1VHZn3QAAAAJ:M05iB0D1s5AC,"Given the strong arguments in favor of diversity and the costs of perpetuating inequity, the persistence of underrepresentation is striking and suggests that we, as advocates for diversity, are not reaching audiences beyond those already committed to promoting diversity. This paper explores how our ways of talking about diversity, equity, inclusion, and social justice (DEISJ) when we address people already committed to diversity may have the unintended consequence of deterring people outside the diversity community from interacting with us. It draws on rhetorical theory, social psychology, discourse analysis, and the concept of analogical imagination to illuminate the ways implicit messages can frame the discourse of diversity in ways that inadvertently deter audiences who do not see themselves as being part of the diversity community. It argues that the rhetorical mode of conversation (sermo) is more suitable than the commonly used epideictic mode (the rhetoric of praise and blame) and offers examples of thematic framing that are more conducive to conversation and thus likely to be more useful in expanding the audience for the discourse on diversity.",,,2024
1517,"Knowledge Integration as the Foundation of Ethical Action: or, Why You Need All Three Legs of a Three-Legged Stool",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1VHZn3QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1VHZn3QAAAAJ:RYcK_YlVTxYC,"While discussions of engineering ethics often refer to “integrating ethics into engineering,” there is no clear consensus about what constitutes integration or how it is best achieved. This paper describes a systems approach to engineering ethics that situates it in the context of goal-oriented sociotechnical systems that are designed and managed by human beings with diverse experiences and forms of expertise. This approach recognizes the organizational, cultural, and technical contexts that both shape and are shaped by, enable and constrain, ethical awareness and action. It integrates three essential and complementary components of the successful, ethical practice of engineering:• Sociotechnical systems thinking, which equips students to analyze the contexts in which new technical capability is developed and implemented and where goals/impacts are realized. It also provides a flexible framework for understanding the many different contexts in which engineers work.• Communication ability, which is essential for articulating individual values, developing shared goals within groups, and synthesizing diverse perspectives into a common understanding that provides the basis for collective and individual action. It encompasses but goes beyond individual capabilities such as writing or speaking to consider group processes and organizations.• Engineering ethics, as traditionally defined, that is, codes, moral reasoning, and case studies. The content of two widely-read engineering ethics texts will serve as evidence of the extent to which these three aspects are implicit in engineering ethics.",,,2023
1518,The Person behind the Mann Report: Charles Riborg Mann as an Influential but Elusive Figure in Engineering Education,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1VHZn3QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1VHZn3QAAAAJ:J_g5lzvAfSwC,"The earliest comprehensive report on engineering education in America was A Study of Engineering Education: Prepared for the Joint Committee on Engineering Education of the National Engineering Societies (1918). It is usually referred to as The Mann Report not only because that title is much more manageable but also because it was authored by a single person, Charles Riborg Mann. Like many individuals whose expertise crosses multiple disciplinary boundaries, Mann is not easy to describe in a few words, much less a single word like “physicist” or “applied scientist.” In addition to his report on engineering education, he published a widely used physics textbook, a Manual of Advanced Optics, The Teaching of Physics for Purposes of General Education, and several books on education, including The American Spirit in Education, Education in the Army, 1919-1925, and Living and Learning. Mann rooted his analysis of engineering education in its history, focusing largely on the dynamics that shaped the system. He identified two methods of administration in civilian (vs. military) engineering schools:“the autonomous department type,” which generated what he called “centrifugal forces,” and “the well-designed cooperative type,” which generated “centripetal forces” that coordinated the various elements so that they function as a system. Many of his observations and criticisms could well have been written over 100 years later. Fortunately, the innovative approaches he recognizes and recommends are still relevant (if not widely followed) today. His integrative approach to humanistic studies for engineers, an approach that was grounded in what …",,,2023
1519,Remote epitaxy through graphene enables two-dimensional material-based layer transfer,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Us0JCUwAAAAJ&citation_for_view=Us0JCUwAAAAJ:4JMBOYKVnBMC,"Epitaxy—the growth of a crystalline material on a substrate—is crucial for the semiconductor industry, but is often limited by the need for lattice matching between the two material systems. This strict requirement is relaxed for van der Waals epitaxy,,,,,,,,,, in which epitaxy on layered or two-dimensional (2D) materials is mediated by weak van der Waals interactions, and which also allows facile layer release from 2D surfaces,. It has been thought that 2D materials are the only seed layers for van der Waals epitaxy,,,,,,,. However, the substrates below 2D materials may still interact with the layers grown during epitaxy (epilayers), as in the case of the so-called wetting transparency documented for graphene,,. Here we show that the weak van der Waals potential of graphene cannot completely screen the stronger potential field of many substrates, which enables epitaxial growth to occur despite its presence. We use density …",Nature Publishing Group UK,,2017
1520,Dynamic kirigami structures for integrated solar tracking,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Us0JCUwAAAAJ&citation_for_view=Us0JCUwAAAAJ:W7OEmFMy1HYC,"Optical tracking is often combined with conventional flat panel solar cells to maximize electrical power generation over the course of a day. However, conventional trackers are complex and often require costly and cumbersome structural components to support system weight. Here we use kirigami (the art of paper cutting) to realize novel solar cells where tracking is integral to the structure at the substrate level. Specifically, an elegant cut pattern is made in thin-film gallium arsenide solar cells, which are then stretched to produce an array of tilted surface elements which can be controlled to within ±1°. We analyze the combined optical and mechanical properties of the tracking system, and demonstrate a mechanically robust system with optical tracking efficiencies matching conventional trackers. This design suggests a pathway towards enabling new applications for solar tracking, as well as inspiring a broader range …",Nature Publishing Group UK,,2015
1521,Controlled crack propagation for atomic precision handling of wafer-scale two-dimensional materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Us0JCUwAAAAJ&citation_for_view=Us0JCUwAAAAJ:blknAaTinKkC,"Although flakes of two-dimensional (2D) heterostructures at the micrometer scale can be formed with adhesive-tape exfoliation methods, isolation of 2D flakes into monolayers is extremely time consuming because it is a trial-and-error process. Controlling the number of 2D layers through direct growth also presents difficulty because of the high nucleation barrier on 2D materials. We demonstrate a layer-resolved 2D material splitting technique that permits high-throughput production of multiple monolayers of wafer-scale (5-centimeter diameter) 2D materials by splitting single stacks of thick 2D materials grown on a single wafer. Wafer-scale uniformity of hexagonal boron nitride, tungsten disulfide, tungsten diselenide, molybdenum disulfide, and molybdenum diselenide monolayers was verified by photoluminescence response and by substantial retention of electronic conductivity. We fabricated wafer-scale van der …",American Association for the Advancement of Science,,2018
1522,Heterogeneous integration of single-crystalline complex-oxide membranes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Us0JCUwAAAAJ&citation_for_view=Us0JCUwAAAAJ:4OULZ7Gr8RgC,"Complex-oxide materials exhibit a vast range of functional properties desirable for next-generation electronic, spintronic, magnetoelectric, neuromorphic, and energy conversion storage devices, , –. Their physical functionalities can be coupled by stacking layers of such materials to create heterostructures and can be further boosted by applying strain, –. The predominant method for heterogeneous integration and application of strain has been through heteroepitaxy, which drastically limits the possible material combinations and the ability to integrate complex oxides with mature semiconductor technologies. Moreover, key physical properties of complex-oxide thin films, such as piezoelectricity and magnetostriction, are severely reduced by the substrate clamping effect. Here we demonstrate a universal mechanical exfoliation method of producing freestanding single-crystalline membranes made from a wide range of …",Nature Publishing Group UK,,2020
1523,Non-destructive wafer recycling for epitaxial lift-off thin-film device using a superlattice epitaxial layer,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Us0JCUwAAAAJ&citation_for_view=Us0JCUwAAAAJ:TQgYirikUcIC,"The present disclosure relates to methods and growth struc tures for making thin-film electronic and optoelectronic devices, such as flexible photovoltaic devices, using epi taxial lift-off (ELO). In particular, disclosed herein are wafer protection schemes that preserve the integrity of the wafer surface during ELO and increase the number of times that the wafer may be used for regrowth. The wafer protection schemes use growth structures that include at least one superlattice layer.",,,2020
1524,Simultaneous Determination of Transition Dipole Moment Orientation and Refractive Index in Morphologically Non‐Uniform Nanoscale Films,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Us0JCUwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Us0JCUwAAAAJ:AXPGKjj_ei8C,"A high‐precision, single‐shot technique simultaneously quantifies the refractive index and transition dipole moment orientation in nanoscale emissive films using Fourier imaging microscopy. Direct capture of momentum‐space (k‐space) emission patterns in a polarization‐resolved setup enables characterization of anisotropic optical properties. This approach overcomes limitations of conventional ellipsometry and angle‐dependent photoluminescence measurements, which typically require predefined refractive index models and atomically smooth interfaces. The method determines anisotropic refractive indices and in‐plane transition dipole moment orientations across various emissive systems, including organic films, quasi‐2D perovskite layers, and quantum dot layers, even in the presence of nanoscale morphological disorder. The experimental result yields parameters with a precision of within 1% and 0.01 …",,,2025
1525,Microdisplay technologies in augmented reality and virtual reality headsets,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Us0JCUwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Us0JCUwAAAAJ:WA5NYHcadZ8C,"Augmented reality (AR) and virtual reality (VR) technologies enable interactive and immersive user experiences through head-worn devices that contain microdisplays. These microdisplays must have superior pixel density, brightness, contrast and response times, owing to the proximity of the AR glasses or VR headset to the eyes. Advanced microdisplay technologies in light engines such as liquid crystal on silicon (LCoS), organic light-emitting diodes on silicon (OLEDoS) and light-emitting diodes on silicon (LEDoS) have emerged to meet the demands of AR and VR, and are typically integrated with optical components such as free-space, freeform or waveguide combiners. In this Perspective, we explore the key requirements for AR and VR microdisplays, consider the advantages of each light-engine technology and discuss how their performance can be accurately characterized. We also examine how LCoS …",Nature Publishing Group UK,Nature Reviews Electrical Engineering,2025
1526,Fabrication of piezoelectric polymer and metal–organic framework composite thin films using solution shearing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Us0JCUwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Us0JCUwAAAAJ:Mojj43d5GZwC,"Polymer-metal–organic framework (polymer-MOF) composites have garnered significant interest as polymers can enhance the processability and industrial applicability of MOFs. Thin films of these composites are particularly attractive for applications in sensing, separations, and flexible electronics. Solution shearing, a meniscus-guided coating technique, has emerged as a scalable process for fabricating thin films of MOFs, and can produce large-area films within minutes. In this study, we utilized solution shearing to fabricate composite thin films of a MOF UiO-66 and a piezoelectric polymer poly(vinylidene fluoride-trifluoroethylene) (P(VDF-TrFE)), investigating how polymer concentration during MOF synthesis and composite formation influences thin film properties, including crystallinity, surface coverage, and piezoelectric performance. Additionally, solid-state NMR spectroscopy was utilized to probe the …",American Chemical Society,,2025
1527,EAS-CiM 2.0: Event-driven Asynchronous Stream-based Compute-in-Memory Kernels with Scalable Precision,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Us0JCUwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Us0JCUwAAAAJ:HE397vMXCloC,"Traditional edge accelerators struggle to balance performance, accuracy, and power consumption. Our solution leverages Asynchronous Stream Computing (ASC) to implement a fully asynchronous, clockless system where data is encoded in the frequency and duty cycle of streams. This architecture adapts dynamically to available energy resources, adjusting computational precision and speed in response to workload demands. A stimulus-driven model allows the system to process data efficiently when actionable information is present. Analytical and experimental results highlight a tunable trade-off between latency and precision, aligning system performance with real-time requirements. To validate these concepts, we implement a Compute-in-Memory (CiM) based dot product architecture to accelerate Word2Vec Algorithms for Natural Language Processing (NLP) tasks and have exhibited a relative semantic …",IEEE,,2025
1528,Artificial Intelligence in Advanced Manufacturing: Current Status and Future Outlook,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TfPemJcAAAAJ&citation_for_view=TfPemJcAAAAJ:RmcNAhKkducC,"Today’s manufacturing systems are becoming increasingly complex, dynamic, and connected. The factory operations face challenges of highly nonlinear and stochastic activity due to the countless uncertainties and interdependencies that exist. Recent developments in artificial intelligence (AI), especially Machine Learning (ML) have shown great potential to transform the manufacturing domain through advanced analytics tools for processing the vast amounts of manufacturing data generated, known as Big Data. The focus of this paper is threefold: (1) review the state-of-the-art applications of AI to representative manufacturing problems, (2) provide a systematic view for analyzing data and process dependencies at multiple levels that AI must comprehend, and (3) identify challenges and opportunities to not only further leverage AI for manufacturing, but also influence the future development of AI to better meet …",,,2020
1529,Data driven bottleneck detection of manufacturing systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TfPemJcAAAAJ&citation_for_view=TfPemJcAAAAJ:ldfaerwXgEUC,"Bottlenecks within a production line significantly reduce the productivity. Quick and correct identification of the bottleneck locations can lead to an improvement in the operation management of utilising finite manufacturing resources, increasing the system throughput, and minimising the total cost of production. Most of the current bottleneck detection schemes focus on the long-term bottleneck detection problem and an analytical or simulation model is usually needed. Due to recent developments, short-term process control and quick decision making on the plant floor have emerged as important qualities for operation management. This research proposes a new data driven method for throughput bottleneck detection in both the short and long term. The method utilises the production line blockage and starvation probabilities and buffer content records to identify the production constraints without building an analytical …",Taylor & Francis Group,,2009
1530,Recurrent neural network for motion trajectory prediction in human-robot collaborative assembly,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TfPemJcAAAAJ&citation_for_view=TfPemJcAAAAJ:w5CyTnyFq80C,"Effective and safe human-robot collaboration in assembly requires accurate prediction of human motion trajectory, given a sequence of past observations such that a robot can proactively provide assistance to improve operation efficiency while avoiding collision. This paper presents a deep learning-based method to parse visual observations of human actions in an assembly setting, and forecast the human operator's future motion trajectory for online robot action planning and execution. The method is built upon a recurrent neural network (RNN) that can learn the time-dependent mechanisms underlying the human motions. The effectiveness of the developed method is demonstrated for an engine assembly.",Elsevier,,2020
1531,Deep reinforcement learning based preventive maintenance policy for serial production lines,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TfPemJcAAAAJ&citation_for_view=TfPemJcAAAAJ:C5mqfHIFIucC,"In the manufacturing industry, the preventive maintenance (PM) is a common practice to reduce random machine failures by replacing/repairing the aged machines or parts. The decision on when and where the preventive maintenance needs to be carried out is nontrivial due to the complex and stochastic nature of a serial production line with intermediate buffers. In order to improve the cost efficiency of the serial production lines, a deep reinforcement learning based approach is proposed to obtain PM policy. A novel modeling method for the serial production line is adopted during the learning process. A reward function is proposed based on the system production loss evaluation. The algorithm based on the Double Deep Q-Network is applied to learn the PM policy. Using the simulation study, the learning algorithm is proved effective in delivering PM policy that leads to an increased throughput and reduced cost …",Pergamon,,2020
1532,Data driven production modeling and simulation of complex automobile general assembly plant,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TfPemJcAAAAJ&citation_for_view=TfPemJcAAAAJ:ZHo1McVdvXMC,"Flexible manufacturing and customization has long been a topic in modern manufacturing society. However, challenges still remain on the responsiveness of production system to the fluctuation of market demand. In this paper, we developed a data driven simulation methodology to automatically model a production system and rapidly modify the model corresponding to dynamic requirements and real time information. This methodology provides a “rapid prototyping” capability for production system modeling and enables a quick analyzing and remodeling capability to respond to the fluctuation of demands. The approach is developed and applied to an automotive general assembly plant with an online material handling system. A complete information model based on IDEF1X is constructed for this domain specific modeling and simulation. The main simulation modules for assembly line and material handling system …",Elsevier,,2011
1533,Generative AI-powered planning: A hybrid graph-diffusion approach for demand-driven flexible manufacturing systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TfPemJcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TfPemJcAAAAJ:DTjSuSUbmXsC,"Flexible Smart Manufacturing Systems (FSMS) are critical to achieving mass customization and operational agility under Industry 4.0. However, planning effective FSMS configurations remains challenging due to fluctuating market demands, heterogeneous system components, complex interdependencies, and the need to optimize resource utilization. Conventional planning methods often require predefined line configurations and lack adaptability, scalability, and awareness of dynamic system properties. This paper presents a novel Hybrid Graph-Diffusion Based Planning Framework that integrates generative AI with system-theoretic modeling to autonomously generate optimal FSMS configurations based on different market demands. Specifically, we introduce a system model-embedded Heterogeneous Graph (HG) to represent the structure and properties of an FSMS and infuse it within a system property-tailored …",Elsevier,,2025
1534,"Advances in Modeling, Analysis, and Control of Manufacturing Systems: Methods, Gaps, and Research Frontiers",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TfPemJcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TfPemJcAAAAJ:pe4chHNxNLUC,"This review paper provides a comprehensive synthesis of system-level modeling, analysis, and control methodologies in manufacturing, encompassing classical analytical techniques, simulation-based techniques, and cutting-edge artificial intelligence and machine learning approaches. Emphasizing a holistic perspective, it highlights the interdependencies among system components and the importance of integrated frameworks for optimizing multi-stage production systems. Key challenges and emerging opportunities are identified to guide future research and practical advancements, aiming to improve throughput, adaptability, efficiency, resilience, and sustainability in modern manufacturing environments.",,Journal of Computing and Information Science in Engineering,2025
1535,Demand-driven hierarchical integrated planning-scheduling control for a mobile robot-operated flexible smart manufacturing system,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TfPemJcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TfPemJcAAAAJ:XR3BWSlh_xcC,"The rapid advancement of Industry 4.0 has transformed manufacturing, giving rise to Flexible Smart Manufacturing Systems (FSMS) capable of adapting to fluctuating market demands and operational uncertainties—essential for achieving mass customization. However, conventional approaches that separate long-term planning from real-time scheduling struggle to meet the demands of modern manufacturing environments, particularly in adapting to frequent demand fluctuations, managing system complexity, and ensuring rapid responsiveness. To address this challenge, this paper presents a demand-driven hierarchical framework that integrates planning and scheduling for flexible smart manufacturing, enabled by a mobile, multi-skilled, robot-operated system. First, a novel system identification model is developed using behavioral cloning to extract essential system properties that inform decision-making. Next, a …",Pergamon,,2025
1536,Can pre-trained LLMs be used as out-of-the-box bottleneck detectors? An explorative study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TfPemJcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TfPemJcAAAAJ:aVq8r21TQD4C,"The manufacturing sector is experiencing a rapid digital transformation, fuelled by advancements in 5G, AI, and cloud computing. However, complex tasks like bottleneck detection, which are critical for optimizing production efficiency, remain challenging due to the knowledge-intensive nature of these processes and the need for domain-specific expertise. Traditional bottleneck detection techniques often require extensive customization and computational resources, limiting their accessibility for small to medium enterprises. This study explores whether pre-trained Large Language Models (LLMs), specifically GPT-4, can function as out-of-the-box bottleneck detectors without domain-specific fine-tuning. We evaluate three prompting techniques with increasing levels of domain knowledge: single text prompts (minimal guidance), image-based prompts (structured event representations), and stepwise prompts (guided …",Elsevier,,2025
1537,"Train small, deploy large: Scaling multi-agent reinforcement learning for multi-stage manufacturing lines",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TfPemJcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TfPemJcAAAAJ:ZYLUaBFA95QC,"We present a novel control framework using Multi Agent Reinforcement learning (MARL) that is scalable in the number of workstations in a multi-stage manufacturing line. We show that the dynamics of any production line, regardless of size, can be decoupled into three fundamental expressions. These expressions capture the dynamics of (1) the first workstation,(2) all intermediate workstations, and (3) the last workstation. This decoupling, combined with observation engineering enables training a characteristic 3-workstation, 2-buffer model using MARL methods, which can then generalize to production lines with w workstations with arbitrary cycle times, buffer capacities and reliability models. A numerical study is then conducted to validate the framework.",Elsevier,,2025
1538,A Neural Network Approach to Context-Sensitive Generation of Conversational Responses,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pg02-e8AAAAJ&citation_for_view=pg02-e8AAAAJ:mVmsd5A6BfQC,"We present a novel response generation system that can be trained end to end on large quantities of unstructured Twitter conversations. A neural network architecture is used to address sparsity issues that arise when integrating contextual information into classic statistical models, allowing the system to take into account previous dialog utterances. Our dynamic-context generative models show consistent gains over both context-sensitive and non-context-sensitive Machine Translation and Information Retrieval baselines.",Association for Computational Linguistics,,2015
1539,Dynet: The dynamic neural network toolkit,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pg02-e8AAAAJ&citation_for_view=pg02-e8AAAAJ:RGFaLdJalmkC,"We describe DyNet, a toolkit for implementing neural network models based on dynamic declaration of network structure. In the static declaration strategy that is used in toolkits like Theano, CNTK, and TensorFlow, the user first defines a computation graph (a symbolic representation of the computation), and then examples are fed into an engine that executes this computation and computes its derivatives. In DyNet's dynamic declaration strategy, computation graph construction is mostly transparent, being implicitly constructed by executing procedural code that computes the network outputs, and the user is free to use different network structures for each input. Dynamic declaration thus facilitates the implementation of more complicated network architectures, and DyNet is specifically designed to allow users to implement their models in a way that is idiomatic in their preferred programming language (C++ or Python). One challenge with dynamic declaration is that because the symbolic computation graph is defined anew for every training example, its construction must have low overhead. To achieve this, DyNet has an optimized C++ backend and lightweight graph representation. Experiments show that DyNet's speeds are faster than or comparable with static declaration toolkits, and significantly faster than Chainer, another dynamic declaration toolkit. DyNet is released open-source under the Apache 2.0 license and available at http://github.com/clab/dynet.",,,2017
1540,Creative writing with a machine in the loop: Case studies on slogans and stories,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pg02-e8AAAAJ&citation_for_view=pg02-e8AAAAJ:ldfaerwXgEUC,"As the quality of natural language generated by artificial intelligence systems improves, writing interfaces can support interventions beyond grammar-checking and spell-checking, such as suggesting content to spark new ideas. To explore the possibility of machine-in-the-loop creative writing, we performed two case studies using two system prototypes, one for short story writing and one for slogan writing. Participants in our studies were asked to write with a machine in the loop or alone (control condition). They assessed their writing and experience through surveys and an open-ended interview. We collected additional assessments of the writing from Amazon Mechanical Turk crowdworkers. Our findings indicate that participants found the process fun and helpful and could envision use cases for future systems. At the same time, machine suggestions do not necessarily lead to better written artifacts. We therefore …",,,2018
1541,Representation Learning for Text-level Discourse Parsing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pg02-e8AAAAJ&citation_for_view=pg02-e8AAAAJ:3fE2CSJIrl8C,"Text-level discourse parsing is notoriously difficult, as distinctions between discourse relations require subtle semantic judgments that are not easily captured using standard features. In this paper, we present a representation learning approach, in which we transform surface features into a latent space that facilitates RST discourse parsing. By combining the machinery of large-margin transition-based structured prediction with representation learning, our method jointly learns to parse discourse while at the same time learning a discourse-driven projection of surface features. The resulting shift-reduce discourse parser obtains substantial improvements over the previous state-of-the-art in predicting relations and nuclearity on the RST Treebank.",Association for Computational Linguistics,,2014
1542,Better Document-level Sentiment Analysis from RST Discourse Parsing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pg02-e8AAAAJ&citation_for_view=pg02-e8AAAAJ:Wp0gIr-vW9MC,"Discourse structure is the hidden link between surface features and document-level properties, such as sentiment polarity. We show that the discourse analyses produced by Rhetorical Structure Theory (RST) parsers can improve document-level sentiment analysis, via composition of local information up the discourse tree. First, we show that reweighting discourse units according to their position in a dependency representation of the rhetorical structure can yield substantial improvements on lexicon-based sentiment analysis. Next, we present a recursive neural network over the RST structure, which offers significant improvements over classification-based methods.",,,2015
1543,Syntactic Blind Spots: How Misalignment Leads to LLMs Mathematical Errors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pg02-e8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pg02-e8AAAAJ:N5tVd3kTz84C,"Large Language Models (LLMs) demonstrate strong mathematical problem-solving abilities but frequently fail on problems that deviate syntactically from their training distribution. We identify a systematic failure mode, syntactic blind spots, in which models misapply familiar reasoning strategies to problems that are semantically straightforward but phrased in unfamiliar ways. These errors are not due to gaps in mathematical competence, but rather reflect a brittle coupling between surface form and internal representation. To test this, we rephrase incorrectly answered questions using syntactic templates drawn from correct examples. These rephrasings, which preserve semantics while reducing structural complexity, often lead to correct answers. We quantify syntactic complexity using a metric based on Dependency Locality Theory (DLT), and show that higher DLT scores are associated with increased failure rates across multiple datasets. Our findings suggest that many reasoning errors stem from structural misalignment rather than conceptual difficulty, and that syntax-aware interventions can reveal and mitigate these inductive failures.",,,2025
1544,Optimizing Latent Dimension Allocation in Hierarchical VAEs: Balancing Attenuation and Information Retention for OOD Detection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pg02-e8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pg02-e8AAAAJ:5awf1xo2G04C,"Out-of-distribution (OOD) detection is a critical task in machine learning, particularly for safety-critical applications where unexpected inputs must be reliably flagged. While hierarchical variational autoencoders (HVAEs) offer improved representational capacity over traditional VAEs, their performance is highly sensitive to how latent dimensions are distributed across layers. Existing approaches often allocate latent capacity arbitrarily, leading to ineffective representations or posterior collapse. In this work, we introduce a theoretically grounded framework for optimizing latent dimension allocation in HVAEs, drawing on principles from information theory to formalize the trade-off between information loss and representational attenuation. We prove the existence of an optimal allocation ratio under a fixed latent budget, and empirically show that tuning this ratio consistently improves OOD detection performance across datasets and architectures. Our approach outperforms baseline HVAE configurations and provides practical guidance for principled latent structure design, leading to more robust OOD detection with deep generative models.",,,2025
1545,""" CASE: Contrastive Activation for Saliency Estimation",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pg02-e8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pg02-e8AAAAJ:eq2jaN3J8jMC,"Saliency methods are widely used to visualize which input features are deemed relevant to a model's prediction. However, their visual plausibility can obscure critical limitations. In this work, we propose a diagnostic test for class sensitivity: a method's ability to distinguish between competing class labels on the same input. Through extensive experiments, we show that many widely used saliency methods produce nearly identical explanations regardless of the class label, calling into question their reliability. We find that class-insensitive behavior persists across architectures and datasets, suggesting the failure mode is structural rather than model-specific. Motivated by these findings, we introduce CASE, a contrastive explanation method that isolates features uniquely discriminative for the predicted class. We evaluate CASE using the proposed diagnostic and a perturbation-based fidelity test, and show that it produces faithful and more class-specific explanations than existing methods.",,,2025
1546,A strain-driven morphotropic phase boundary in BiFeO3,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z8xpCYsAAAAJ&citation_for_view=z8xpCYsAAAAJ:u5HHmVD_uO8C,"Piezoelectric materials, which convert mechanical to electrical energy and vice versa, are typically characterized by the intimate coexistence of two phases across a morphotropic phase boundary. Electrically switching one to the other yields large electromechanical coupling coefficients. Driven by global environmental concerns, there is currently a strong push to discover practical lead-free piezoelectrics for device engineering. Using a combination of epitaxial growth techniques in conjunction with theoretical approaches, we show the formation of a morphotropic phase boundary through epitaxial constraint in lead-free piezoelectric bismuth ferrite (BiFeO3) films. Electric field–dependent studies show that a tetragonal-like phase can be reversibly converted into a rhombohedral-like phase, accompanied by measurable displacements of the surface, making this new lead-free system of interest for probe-based data …",American Association for the Advancement of Science,,2009
1547,Photovoltaic effects in BiFeO3,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z8xpCYsAAAAJ&citation_for_view=z8xpCYsAAAAJ:9yKSN-GCB0IC,We report a photovoltaic effect in ferroelectric BiFeO 3 thin films. The all-oxide heterostructures with SrRuO 3 bottom and tin doped indium oxide top electrodes are characterized by open-circuit voltages∼ 0.8–0.9 V and external quantum efficiencies up to∼ 10% when illuminated with the appropriate light. Efficiencies are at least an order of magnitude larger than the maximum efficiency under sunlight (AM 1.5) thus far reported for ferroelectric-based devices. The dependence of the measured open-circuit voltage on film thickness suggests contributions to the large open-circuit voltage from both the ferroelectric polarization and band offsets at the BiFeO 3/tin doped indium oxide interface.,AIP Publishing,,2009
1548,Realizing optical magnetism from dielectric metamaterials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z8xpCYsAAAAJ&citation_for_view=z8xpCYsAAAAJ:roLk4NBRz8UC,"We demonstrate, for the first time, an all-dielectric metamaterial composite in the midinfrared based on micron-sized, high-index tellurium dielectric resonators. Dielectric resonators are desirable compared to conventional metallodielectric metamaterials at optical frequencies as they are largely angular invariant, free of Ohmic loss, and easily integrated into three-dimensional volumes. Measurements and simulation provide evidence of optical magnetism, which could be used for infrared magnetic mirrors, hard or soft surfaces, and subwavelength cavities.",American Physical Society,,2012
1549,Optical band gap of BiFeO3 grown by molecular-beam epitaxy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z8xpCYsAAAAJ&citation_for_view=z8xpCYsAAAAJ:d1gkVwhDpl0C,"Bi Fe O 3 thin films have been deposited on (001) Sr Ti O 3 substrates by adsorption-controlled reactive molecular-beam epitaxy. For a given bismuth overpressure and oxygen activity, single-phase Bi Fe O 3 films can be grown over a range of deposition temperatures in accordance with thermodynamic calculations. Four-circle x-ray diffraction reveals phase-pure, epitaxial films with ω rocking curve full width at half maximum values as narrow as 29 arc sec (0.008). Multiple-angle spectroscopic ellipsometry reveals a direct optical band gap at 2.74 eV for stoichiometric as well as 5% bismuth-deficient single-phase Bi Fe O 3 films.",AIP Publishing,,2008
1550,Linear and nonlinear optical properties of BiFeO3,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z8xpCYsAAAAJ&citation_for_view=z8xpCYsAAAAJ:2osOgNQ5qMEC,"Using spectroscopic ellipsometry, the room temperature refractive index and absorption versus wavelength of the ferroelectric antiferromagnet bismuth ferrite, Bi Fe O 3⁠, are reported. The material has a direct band gap at 442 nm wavelength (2.81 eV)⁠. Using optical second harmonic generation, the nonlinear optical coefficients were determined to be d 15∕ d 22= 0.20±0.01⁠, d 31∕ d 22= 0.35±0.02⁠, d 33∕ d 22=− 11.4±0.20⁠, and∣ d 22∣= 298.4±6.1 pm∕ V at a fundamental wavelength of 800 nm⁠.",AIP Publishing,,2008
1551,Nanoscale Phase Identification Using Two-Dimensional Pair Correlation Functions: A Case Study on Hafnium Oxide,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z8xpCYsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=z8xpCYsAAAAJ:Azgs6IHzeyYC,"Accurate identification of local phases in nanocrystalline materials is essential for understanding their functional properties, but it remains a significant challenge for polymorphic materials to locally differentiate them at nanoscale. This challenge is further compounded in polycrystalline materials with randomly oriented grains and the coexistence of multiple phases. In this report, we present a methodology for phase and orientation identification at the nanoscale by leveraging vector pair correlation functions extracted from atomically resolved scanning transmission electron microscopy (STEM) images. We demonstrate the accuracy of the methodology on both simulated and experimental data from HfO2-based films, a material that exhibits multiple coexisting phases in films with thicknesses ranging from 5 to 20 nm. While demonstrated on HfO2 films, the methodology can be extended to other polymorphic …",Oxford University Press,,2025
1552,"Characterization of fluorite-structured ferroelectrics using transmission electron microscopy: Techniques, challenges, and recent advances",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=z8xpCYsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=z8xpCYsAAAAJ:7Frjd3zlGBUC,"Fluorite-structured ferroelectrics, such as hafnium oxide and its alloyed variants, are key candidates for next-generation memory devices. Yet, fundamental questions about switching mechanisms, domain dynamics, and phase evolution remain open. Transmission electron microscopy (TEM) provides unique capabilities to address these challenges by simultaneously resolving the positions of anions and cations, chemical variations, and structural transformations. Recent advances—including in situ heating, electron beam-induced switching, electron energy loss spectroscopy, and differential phase contrast imaging—have revealed critical insights into phase transitions, potential switching pathways, and oxygen vacancy behavior. However, experimental barriers such as TEM sample-preparation-induced artifacts, high coercive fields, and imaging constraints persist, especially for polycrystalline films. By offering a …",AIP Publishing,Applied Physics Letters,2025
1553,Ischemia‐reperfusion injury in chronic pressure ulcer formation: a skin model in the rat,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2hdOlMAAAAAJ&citation_for_view=2hdOlMAAAAAJ:u5HHmVD_uO8C,"Most animal models of chronic pressure ulcers were designed to study only the role of ischemic injury in wound formation, often using single applications of constant pressure. The purpose of this study was to develop and characterize a reproducible model of cyclic ischemia‐reperfusion injury in the skin of small un‐anesthetized animals using clinically relevant pressures and durations. Ischemia‐reperfusion injury was created in a 9 cm2 region of dorsal skin in male rats by periodically compressing skin under a pressure of 50 mm Hg using an implanted metal plate and an overlying magnet. We varied the total number of ischemia‐reperfusion cycles, examined the effect of varying the frequency and duration of ischemic insult, and compared ischemia‐induced injury to ischemia‐reperfusion‐induced injury with this model. Tissue injury increased with an increasing number of total ischemia‐reperfusion cycles, duration …",Blackwell Science Inc,,2000
1554,Macrophages: an inflammatory link between angiogenesis and lymphangiogenesis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2hdOlMAAAAAJ&citation_for_view=2hdOlMAAAAAJ:N6_Y7JlWxwsC,"Angiogenesis and lymphangiogenesis often occur in response to tissue injury or in the presence of pathology (e.g., cancer), and it is these types of environments in which macrophages are activated and increased in number. Moreover, the blood vascular microcirculation and the lymphatic circulation serve as the conduits for entry and exit for monocyte‐derived macrophages in nearly every tissue and organ. Macrophages both affect and are affected by the vessels through which they travel. Therefore, it is not surprising that examination of macrophage behaviors in both angiogenesis and lymphangiogenesis has yielded interesting observations that suggest macrophages may be key regulators of these complex growth and remodeling processes. In this review, we will take a closer look at macrophages through the lens of angiogenesis and lymphangiogenesis, examining how their dynamic behaviors may regulate …",,Microcirculation,2016
1555,Multiscale computational models of complex biological systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2hdOlMAAAAAJ&citation_for_view=2hdOlMAAAAAJ:4DMP91E08xMC,"Integration of data across spatial, temporal, and functional scales is a primary focus of biomedical engineering efforts. The advent of powerful computing platforms, coupled with quantitative data from high-throughput experimental methodologies, has allowed multiscale modeling to expand as a means to more comprehensively investigate biological phenomena in experimentally relevant ways. This review aims to highlight recently published multiscale models of biological systems, using their successes to propose the best practices for future model development. We demonstrate that coupling continuous and discrete systems best captures biological information across spatial scales by selecting modeling techniques that are suited to the task. Further, we suggest how to leverage these multiscale models to gain insight into biological systems using quantitative biomedical engineering methods to analyze data in …",Annual Reviews,Annual review of biomedical engineering,2013
1556,Non-classical monocytes are biased progenitors of wound healing macrophages during soft tissue injury,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2hdOlMAAAAAJ&citation_for_view=2hdOlMAAAAAJ:kyf61JL59OoC,"Successful tissue repair requires the activities of myeloid cells such as monocytes and macrophages that guide the progression of inflammation and healing outcome. Immunoregenerative materials leverage the function of endogenous immune cells to orchestrate complex mechanisms of repair; however, a deeper understanding of innate immune cell function in inflamed tissues and their subsequent interactions with implanted materials is necessary to guide the design of these materials. Blood monocytes exist in two primary subpopulations, characterized as classical inflammatory or non-classical. While classical monocytes extravasate into inflamed tissue and give rise to macrophages or dendritic cells, the recruitment kinetics and functional role of non-classical monocytes remains unclear. Here, we demonstrate that circulating non-classical monocytes are directly recruited to polymer films within skin injuries …",Nature Publishing Group UK,,2017
1557,Human adipose-derived stromal cells accelerate diabetic wound healing: impact of cell formulation and delivery,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2hdOlMAAAAAJ&citation_for_view=2hdOlMAAAAAJ:WF5omc3nYNoC,"Human adipose-derived stromal cells (ASCs) have been shown to possess therapeutic potential in a variety of settings, including cutaneous wound healing; however, it is unknown whether the regenerative properties of this cell type can be applied to diabetic ulcers. ASCs collected from elective surgical procedures were used to treat full-thickness dermal wounds in leptin receptor-deficient (db/db) mice. Cells were delivered either as multicellular aggregates or as cell suspensions to determine the impact of cell formulation and delivery methods on biological activity and in vivo therapeutic effect. After treatment with ASCs that were formulated as multicellular aggregates, diabetic wounds experienced a significant increase in the rate of wound closure compared to wounds treated with an equal number of ASCs delivered in suspension. Analysis of culture supernatant and gene arrays indicated that ASCs formulated as …","Mary Ann Liebert, Inc.",,2010
1558,Multimodal analysis identifies pericyte-centered signaling programs altered by sex and brain region in Alzheimer’s Disease,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2hdOlMAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2hdOlMAAAAAJ:zI847uFkBp4C,"Pericytes are critical components of the neurovascular unit (NVU), regulating endothelial cell (EC) stability, blood-brain barrier (BBB) integrity, and neuroimmune signaling. However, their role in Alzheimer’s Disease (AD), particularly in the context of sex differences and brain region specificity, remains poorly defined. Here, we use single-nucleus RNA sequencing (snRNA-seq) to characterize transcriptional and intercellular signaling changes in pericytes across the middle temporal gyrus (MTG) and dorsolateral prefrontal cortex (DLPFC) of the same AD and non-AD donors, stratified by sex. Using LIANA and Tensor-cell2cell, we identify latent communication programs altered in female AD donors, including a pericyte-EC signaling pattern that activates TGFβ via extracellular matrix ligands and is upregulated in the MTG but not the DLPFC. A second communication pattern, downregulated in female AD donors, reveals impaired estrogen pathway signaling through ligand-receptor interactions between pericytes and astrocytes. Supporting this, we observe reduced expression of pericyte-derived neuroligins and increased pericyte-astrocyte separation in a spatial transcriptomic subset. Additionally, we identify a microglia-to-pericyte signaling program conserved across brain regions, enriched for inflammatory pathways including hypoxia and p53, and elevated in both male and female AD donors with regional specificity. This result contrasts with the more sex-and region-specific pericyte signaling programs and suggests parallel mechanisms of NVU disruption between brain regions in AD. Our findings reveal brain region-specific and sex-specific …",Cold Spring Harbor Laboratory,,2025
1559,Pericyte capillary constriction in the hyperglycemic brain similar to in Alzheimer's Disease,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2hdOlMAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2hdOlMAAAAAJ:2YKEWf8Wbo8C,,ALZ,,2025
1560,Mechanically Tunable Poly (Ethylene Glycol) Diacrylate Hydrogels Reveal Stiffness‐Related Impairments in Capillary Sprouting in Experimental Lung Fibrosis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2hdOlMAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2hdOlMAAAAAJ:CPlVwKnI7G4C,"Objective Synthetic hydrogels that support 3D cell culture are widely used as platforms for modeling disease, such as tissue fibrosis, which leads to mechanical stiffening of the extracellular matrix (ECM). To interrogate how mechanical stiffness of the ECM affects microvascular remodeling, we developed a bioactive poly(ethylene glycol) diacrylate (PEGDA) hydrogel model with tunable stiffness that permits microvascular sprouting. Methods Lung explants harvested from healthy and fibrotic mice were cultured ex vivo on PEGDA hydrogels for 7 days. Capillary sprouting from lung segments was evaluated via imaging and secreted angiogenic markers. Results Healthy lung explants had decreased sprout formation and length on stiffer hydrogels. The sprouts from fibrotic lung explants, however, were not impacted by hydrogel stiffness. This difference was associated with higher expression of angiogenic markers …",,,2025
1561,Two‐Photon microscopy functional assays for serial imaging of brain microvessels and the neurovascular unit through disease progression,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2hdOlMAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2hdOlMAAAAAJ:zaWPYk0SwtcC,"Microvascular impairments are a major issue in many diseases of the brain. In fact, they are often considered the earliest pathological phenomena in neurodegenerative diseases like Alzheimer's Disease or the locus of pathology as in stroke. Still, little is known about the mechanistic and cellular level events that contribute to these impairments. Given the importance of the neurovascular unit (NVU) in maintaining functional brain tissue, alterations to NVU cell types are important to study in the context of disease progression. With the use of two‐photon microscopy, microvessels and cells can be imaged and evaluated throughout disease progression. Herein we aim to provide a comprehensive protocol for setting up and using two‐photon microscopy for serial imaging of neurovascular unit cell types (i.e., pericytes, astrocytes, and microglia). We also describe interpreting results from cell and vessel changes based on …",,,2025
1562,Generative diffusion model surrogates for mechanistic agent-based biological models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2hdOlMAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2hdOlMAAAAAJ:0J7bdoE8TH0C,"Mechanistic, multicellular, agent-based models are commonly used to investigate tissue, organ, and organism-scale biology at single-cell resolution. The Cellular-Potts Model (CPM) is a powerful and popular framework for developing and interrogating these models. CPMs become computationally expensive at large space- and time- scales making application and investigation of developed models difficult. Surrogate models may allow for the accelerated evaluation of CPMs of complex biological systems. However, the stochastic nature of these models means each set of parameters may give rise to different model configurations, complicating surrogate model development. In this work, we leverage denoising diffusion probabilistic models to train a generative AI surrogate of a CPM used to investigate in vitro vasculogenesis. We describe the use of an image classifier to learn the characteristics that define unique …",,,2025
1563,Fast Preisach-based magnetization model and fast inverse hysteresis model,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qmyfPLQAAAAJ&citation_for_view=qmyfPLQAAAAJ:u5HHmVD_uO8C,"Fast computational methods for Preisach-based models and their inverses are presented. The methods are based on a differential equation approach to computing a sequence of magnetization values due to a sequence of applied fields. The method used to speed up calculations can be applied to any Preisach model. The Della Torre, Oti, Kadar model was used here as an illustration. Sequential computations for the magnetization model are substantially faster than for standard Preisach models with comparable output error. Computations for the inverse hysteresis model are even faster than for the model. Using the inverse, open loop control of magnetic hysteresis is simulated, showing hysteretic material tracking a desired magnetization in a linear manner for both major loops and minor loops, with less than 2% error in inversion for the waveforms used. The effect of misidentification of material parameters on …",IEEE,,2002
1564,Implementation of the Preisach DOK magnetic hysteresis model in a commercial finite element package,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qmyfPLQAAAAJ&citation_for_view=qmyfPLQAAAAJ:u-x6o8ySG0sC,"The very accurate magnetic hysteresis representation available from Preisach-based models is not currently offered in commercial finite element (FE) packages. The major obstacle to using more accurate magnetization models is that they can cause convergence problems in the FE solution cycle. A method has been developed to integrate the fast DOK (Della Torre-Oti-Kadar) model, a Preisach based magnetization model, into the ANSYS FE program. Small-scale tests show that the FE solutions match expected values and that the use of the Preisach model does not effect the convergence of the FE solution.",IEEE,,2002
1565,Fast Preisach based magnetostriction model for highly magnetostrictive materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qmyfPLQAAAAJ&citation_for_view=qmyfPLQAAAAJ:9yKSN-GCB0IC,"A Preisach based magnetization model is presented to work specifically on highly magnetostrictive materials. The model accounts for the additional anisotropy introduced when a prestress is used to activate the high strain, by using a bimodal structure. The necessity of strain feedback to deal with the magneto-mechanical effect is discussed for Terfenol-D specifically. The model is based on a fast implementation of the DOK magnetization model, so it is suitable for real time control applications.",IEEE,,1999
1566,Isotropic media and the simplified vector Preisach model,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qmyfPLQAAAAJ&citation_for_view=qmyfPLQAAAAJ:IjCSPb-OGe4C,"This paper addresses an orientation error discovered when the simplified vector Preisach model (SVPM) was applied to an isotropic medium. For a smoothly rotating field, the magnetization of an isotropic medium should rotate smoothly. Instead, the SVPM predicts a ratcheting motion. A correction for this problem is suggested.",North-Holland,,2001
1567,Preisach modeling of aftereffect in a magneto-optical medium with perpendicular magnetization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qmyfPLQAAAAJ&citation_for_view=qmyfPLQAAAAJ:2osOgNQ5qMEC,"The aftereffect of Co/Pt multilayer films with perpendicular magnetization has been measured with a magneto-optical Kerr effect (MOKE) magnetometer and calculated with a newly developed Preisach model. Compared to materials such as traditional magnetic recording media, Co/Pt multilayer films show a more complete picture of the progression of aftereffect because the magnetization of this material decays from saturation almost all the way to a ground state in a reasonable length of time. The magnetization measurements for times equal to negative and positive infinity are asymptotically horizontal, with a transition region that is linear on a logarithmic time scale. In contrast, typical published aftereffect analyses exhibit only a very small percentage of the total aftereffect that could be observed if time were not a factor in making measurements. A Preisach–Arrhenius model is used to calculate the magnetic …",North-Holland,,2000
1568,Fast Preisach-based vector magnetization model,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qmyfPLQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qmyfPLQAAAAJ:d1gkVwhDpl0C,"The Preisach based DOK (Della Torre-Oti-Kadar) model was reformulated to increase its speed of computation so that is could be integrated into a commercial finite element (FE) modeling package. This allowed the FE package to offer a more accurate representation of magnetic material behavior than had been previously available. The next logical step is to offer vector magnetization calculation. Vector models are more complicated, though, due to the cross-coupling effect applied field directions have on magnetization. The simplified vector Preisach model is reformulated here to speed its computations by extending the use of the ""cobweb"" grid in defining the Preisach function for this multi-dimensional model.",IEEE,,2002
1569,Implementation of the simplified vector model,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qmyfPLQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qmyfPLQAAAAJ:qjMakFHDy7sC,"The simplified vector Preisach model (SVPM) is a three-dimensional (3-D) magnetization model developed for fast computations. In this paper, a new algorithm for the SVPM is detailed, which accomplishes two goals: 1) to extend the model from a two-dimensional to a 3-D model and 2) to provide efficient implementation of the model.",IEEE,,2002
1570,Dominant Role of Entropy in Stabilizing Sugar Isomerization Transition States within Hydrophobic Zeolite Pores,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8XRwqsIAAAAJ&citation_for_view=8XRwqsIAAAAJ:2osOgNQ5qMEC,"Lewis acid sites in zeolites catalyze aqueous-phase sugar isomerization at higher turnover rates when confined within hydrophobic rather than within hydrophilic micropores; however, relative contributions of competitive water adsorption at active sites and preferential stabilization of isomerization transition states have remained unclear. Here, we employ a suite of experimental and theoretical techniques to elucidate the effects of coadsorbed water on glucose isomerization reaction coordinate free energy landscapes. Transmission IR spectra provide evidence that water forms extended hydrogen-bonding networks within hydrophilic but not hydrophobic micropores of Beta zeolites. Aqueous-phase glucose isomerization turnover rates measured on Ti-Beta zeolites transition from first-order to zero-order dependence on glucose thermodynamic activity, as Lewis acidic Ti sites transition from water-covered to glucose …",American Chemical Society,,2018
1571,Structure and solvation of confined water and water–ethanol clusters within microporous Brønsted acids and their effects on ethanol dehydration catalysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8XRwqsIAAAAJ&citation_for_view=8XRwqsIAAAAJ:W7OEmFMy1HYC,"Aqueous-phase reactions within microporous Brønsted acids occur at active centers comprised of water-reactant-clustered hydronium ions, solvated within extended hydrogen-bonded water networks that tend to stabilize reactive intermediates and transition states differently. The effects of these diverse clustered and networked structures were disentangled here by measuring turnover rates of gas-phase ethanol dehydration to diethyl ether (DEE) on H-form zeolites as water pressure was increased to the point of intrapore condensation, causing protons to become solvated in larger clusters that subsequently become solvated by extended hydrogen-bonded water networks, according to in situ IR spectra. Measured first-order rate constants in ethanol quantify the stability of SN2 transition states that eliminate DEE relative to (C2H5OH)(H+)(H2O)n clusters of increasing molecularity, whose structures were respectively …",Royal Society of Chemistry,,2020
1572,Heterogeneous MNC Catalysts for Aerobic Oxidation Reactions: Lessons from Oxygen Reduction Electrocatalysts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8XRwqsIAAAAJ&citation_for_view=8XRwqsIAAAAJ:Se3iqnhoufwC,,,,2023
1573,Distinct Catalytic Reactivity of Sn Substituted in Framework Locations and at Defect Grain Boundaries in Sn-Zeolites,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8XRwqsIAAAAJ&citation_for_view=8XRwqsIAAAAJ:UeHWp8X0CEIC,"Measurements of turnover rates of gas-phase bimolecular ethanol dehydration to diethyl ether (404–438 K) on a suite of hydrophobic and hydrophilic Sn-zeolites (Sn-Beta, Sn-BEC, Sn-MFI) of varying Sn content, together with quantitative titration of active Sn sites by pyridine during catalysis, identify two types of Sn sites with reactivity differing by more than an order of magnitude (>20×). Apparent activation entropies to form bimolecular dehydration transition states from predominantly ethanol monomer-covered sites are less negative (ΔΔSapp⧧ = 48 ± 22 J mol–1 K–1) at the more reactive subset of Sn sites, which are present in amounts equivalent to 17–26% of the Sn sites quantified by the peak centered at 2308 cm–1 in CD3CN IR spectra (Sn2308) but not correlated with that at 2316 cm–1 (Sn2316). Synthetic and postsynthetic treatments to prepare Sn-zeolites containing Sn sites hosted within diverse local …",American Chemical Society,,2019
1574,"First principles, microkinetic, and experimental analysis of Lewis acid site speciation during ethanol dehydration on Sn-Beta zeolites",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8XRwqsIAAAAJ&citation_for_view=8XRwqsIAAAAJ:9yKSN-GCB0IC,"Density functional theory calculations are combined with kinetic measurements of ethanol dehydration to diethyl ether to identify the relative catalytic contributions of structurally distinct speciations of Sn sites in zeolite Beta frameworks. The structural complexities of the Beta framework require nonstandard techniques for entropy and energy calculations, including consideration of anharmonic effects in vibrational modes, employment of quasi-harmonic densities of states methods to evaluate entropies, and use of hybrid density functionals to evaluate binding energies. Calculated energies and entropies are used to construct a microkinetic model that is iteratively refined to identify all kinetically and thermodynamically sensitive reaction steps and intermediates which are subsequently treated with the higher-level methods. The rate and equilibrium constants obtained from this tiered approach agree well with measured …",Academic Press,,2018
1575,Progress and pitfalls in designing heterogeneous catalysts with molecular precision,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8XRwqsIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8XRwqsIAAAAJ:8k81kl-MbHgC,"Atomically dispersed heterogeneous catalysts offer the opportunity to design active sites with molecular precision. A recent proliferation of synthetic strategies and advanced characterization tools has propelled broad interest in leveraging these catalysts in diverse areas of chemistry beyond thermal heterogeneous catalysis, including but not limited to organic synthesis, electrochemistry, photochemistry and environmental chemistry. This Perspective aims to arm researchers in this area with the methodological framework and fundamental principles to accurately assess the degree of uniformity of heterogeneous catalyst active sites, and to link the synthesis, structure and function of atomically dispersed catalysts to one another. A paedagogical discussion of catalyst structural dynamics and active-site-specific characterization is supplemented with recent case studies that illustrate these fundamentals. This analysis …",Nature Publishing Group UK,,2025
1576,Chemical kinetics of heterogeneous catalysis: experimental research methodologies and case studies of site-isolated materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8XRwqsIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8XRwqsIAAAAJ:5nxA0vEk-isC,"Heterogeneous catalysts mediate chemical reactions at fluid–solid interfaces and contain active sites of diverse structure and function. Chemical kinetic processes at surfaces connect to macroscopic measurements through transport processes; thus, intrinsic kinetic measurements require rendering irrelevant, or accurately modeling the influences of, gradients in thermodynamic activity and temperature between active sites and bulk fluid phases. Quantifying turnover rates further requires methods to quantify the density of putative active sites on catalyst surfaces. This review discusses experimental research methodologies to perform quantitative kinetic studies of heterogeneous catalysis, highlighting examples from contemporary research reports with a focus on site-isolated materials.",Taylor & Francis,Catalysis Reviews,2025
1577,Recommendations for improving rigor and reproducibility in site specific characterization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8XRwqsIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8XRwqsIAAAAJ:hqOjcs7Dif8C,"Heterogeneous catalysis is driven by the interaction of reactant molecules and the catalyst surface. The locus of this interaction as well as the surrounding ensemble of atoms is referred to as the catalyst active site. Active site characterization attempts to distinguish active catalytic sites from inactive surface sites, to elucidate the structural and chemical nature of active sites, and to quantify active site concentration. Numerous techniques have been demonstrated to provide compositional and structural information about the active sites within a catalyst. However, each technique has its own limitations and experimental pitfalls that can lead to data misinterpretation or irreproducible results. This work aims to provide an overview of the types of data that can be collected, to outline common experimental challenges and how to avoid them, and to assemble relevant references for the most used active site characterization …",Academic Press,,2024
1578,Chemical Kinetic Method for Active-Site Quantification in Fe-NC Catalysts and Correlation with Molecular Probe and Spectroscopic Site-Counting Methods,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=8XRwqsIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=8XRwqsIAAAAJ:UebtZRa9Y70C,"Mononuclear Fe ions ligated by nitrogen (FeNx) dispersed on nitrogen-doped carbon (Fe-N-C) serve as active centers for electrocatalytic O2 reduction and thermocatalytic aerobic oxidations. Despite their promise as replacements for precious metals in a variety of practical applications, such as fuel cells, the discovery of new Fe-N-C catalysts has relied primarily on empirical approaches. In this context, the development of quantitative structure–reactivity relationships and benchmarking of catalysts prepared by different synthetic routes and by different laboratories would be facilitated by the broader adoption of methods to quantify atomically dispersed FeNx active centers. In this study, we develop a kinetic probe reaction method that uses the aerobic oxidation of a model hydroquinone substrate to quantify the density of FeNx centers in Fe-N-C catalysts. The kinetic method is compared with low-temperature …",American Chemical Society,,2023
1579,Mechanisms underlying rhythmic locomotion: dynamics of muscle activation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dZPFvw8AAAAJ&citation_for_view=dZPFvw8AAAAJ:2osOgNQ5qMEC,"We have studied the dynamical properties of tension development in leech longitudinal muscle during swimming. A new method is proposed for modeling muscle properties under functionally relevant conditions where the muscle is subjected to both periodic activation and rhythmic length changes. The ‘dual-sinusoid’ experiments were conducted on preparations of leech nerve cord and body wall. The longitudinal muscle was activated periodically by injection of sinusoidal currents into an identified motoneuron. Simultaneously, sinusoidal length changes were imposed on the body wall with prescribed phase differences (12 values equally spaced over 2π radians) with respect to the current injection. Through the singular value decomposition of appropriately constructed tension data matrices, the leech muscle was found to have a multiplicative structure in which the tension was expressed as the product of …",Company of Biologists,,2011
1580,Muscle function in animal movement: passive mechanical properties of leech muscle,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dZPFvw8AAAAJ&citation_for_view=dZPFvw8AAAAJ:qjMakFHDy7sC,"We investigated passive properties of leech body wall as part of a larger project to understand better mechanisms that control locomotion and to establish mathematical models that predict such dynamical behavior. In tests of length-tension relationships in 2-segment-long preparations of body wall through step-stretch manipulations (step size = 1 mm), we discovered that these relationships are nonlinear, with significant hysteresis, even for the relatively small changes in length that occur during swimming. We developed a mathematical model comprising three nonlinear springs, two in series with nonlinear dashpots that describe well the tension statics and dynamics for step-stretch experiments. This model suggested that body wall dynamics are slow enough to be neglected when predicting the tension generated by imposed sinusoidal length changes (about ±10% of nominal) at 1–3 Hz, mimicking swimming. We …",Springer-Verlag,,2007
1581,Analysis of impulse adaptation in motoneurons,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dZPFvw8AAAAJ&citation_for_view=dZPFvw8AAAAJ:u-x6o8ySG0sC,"Animal locomotion results from muscle contraction and relaxation cycles that are generated within the central nervous system and then are relayed to the periphery by motoneurons. Thus, motoneuron function is an essential element for understanding control of animal locomotion. This paper presents motoneuron input–output relationships, including impulse adaptation, in the medicinal leech. We found that although frequency-current graphs generated by passing 1-s current pulses in neuron somata were non-linear, peak and steady-state graphs of frequency against membrane potential were linear, with slopes of 5.2 and 2.9 Hz/mV, respectively. Systems analysis of impulse frequency adaptation revealed a static threshold nonlinearity at −43 mV (impulse threshold) and a single time constant (τ = 88 ms). This simple model accurately predicts motoneuron impulse frequency when tested by intracellular injection of …",Springer-Verlag,,2010
1582,A design approach in an Introduction to Engineering course,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dZPFvw8AAAAJ&citation_for_view=dZPFvw8AAAAJ:IjCSPb-OGe4C,"A design approach in an Introduction to Engineering courseJust as each person reads Shakespeare differently, every professor teaches Introduction toEngineering differently. I taught my introduction course as a design course because I believe thatengineering design is the essence of engineering. We are a small liberal art university, where only a few engineering courses offered. Unlike inengineering schools in large research universities typically a series of two semesters or moreengineering design courses are provided in their programs, we have none currently in ourcurriculum. Due to its core values in engineering education and research as well as in industry, Ihave decided to incorporate engineering design as the main theme into the Introduction toEngineering course. Inspired by the ideas in Calder’s Uncoverage: Towards a SignaturePedagogy for the History Survey, I emphasized thinking, doing, and evaluating as professionalswould in this course. I introduced two collaborative design projects–design and build a solarpowered cell phone charger and a persistence of vision wand. In addition to designing andbuilding functional devices as end products, students have to develop plans of work, keeprecords in their lab notebooks, consider alternative designs, write final reports including marketanalysis, and present their work in visual aided presentations. In the process, students learned touse design software–Autodesk Inventor to design the cases housing the circuit boards of thesolar powered chargers and the wands encasing LED circuits. The cases were then printed out ona three-dimensional printer. They also learned to design …",,,2014
1583,Muscle function and neuromuscular transformation in leech swimming,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dZPFvw8AAAAJ&citation_for_view=dZPFvw8AAAAJ:9yKSN-GCB0IC,"To explore the neuromuscular transformation in the context of leech swimming behavior, realistic patterns in motoneuron activity expressed as membrane potential oscillation, as well as sinusoidal length changes in body length were exploited. Active muscle tension was modeled as a product of a length-dependent exponential function and a frequency-dependent factor that is described by a second order transfer function with a time delay and a nonlinear static function. The model describes well the complex transformation from motoneuron impulse rates to muscle contraction strengths. A complete systems model for the neuromuscular system receiving input signals from central oscillators was built to predict tensions generated in swimming leeches and to capture the phase-dependence of tension development on motoneuron activity and body wall length.",ProQuest,,2008
1584,Navigating AI-Assisted Literature Reviews in First-Year Engineering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dZPFvw8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dZPFvw8AAAAJ:eQOLeE2rZwMC,"In our institution, all first-year engineering students take a two-semester sequence of Engineering Foundations (EF 1 in the fall and EF 2 in the spring). In EF 2, student teams work on semester-long, client-based design projects. These projects guide students through the design process, from problem definition and ideation to prototyping and testing. A crucial component during the early stages is the literature review, an opportunity for students to ground their problem understanding, investigate existing knowledge, identify gaps, and provide evidence for design decisions. This component has often been challenging for students. Many rely on surface-level internet searches rather than engaging with scholarly sources, largely due to limited familiarity with academic literature and its relevance to engineering design. As a result, literature reviews tend to lack depth, critical analysis, or meaningful integration into their project work. To address this challenge, the course instructor began collaborating with the engineering librarian in Spring 2024, who led an in-class session on traditional search methods using university library resources. Students were introduced to library databases, search techniques, and source evaluation. We modeled how to narrow a topic, identify effective keywords, and locate peer-reviewed articles. Many students were unfamiliar with these methods, and the session helped demystify academic research. But as Generative AI (GenAI) tools like Consensus and ChatGPT gained traction, we began to consider how such technologies might reshape students’ approaches to the literature review.",,,2025
1585,GIFTS: Integrating Generative AI into First-Year Engineering Education: From Knowledge Acquisition and Arduino Projects to Defining Accessibility Problems and Solutions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dZPFvw8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dZPFvw8AAAAJ:_FxGoFyzp5QC,"The objective of this Great Ideas for Teaching Students (GIFTS) paper is to present two approaches to employing Generative AI (GenAI) in the engineering design process with first-year engineering students at [REDACTED] school. These activities aim to build understanding of and analytical approaches to using GenAI tools such as Copilot and ChatGPT. This is motivated by the drive to leverage this evolving technology in ways that help students. As this technology evolves, it is increasingly apparent that we need to develop and share more promising practices for faculty and students to navigate various applications and limitations of Gen AI tools. This GIFTS paper will delve into using GenAI as a tool both for acquiring new knowledge and for ideation in two unique settings while scaffolding opportunities for students to grow in their proficiency for using these tools. In each activity, students integrate technical skills with social and ethical thinking as they explore and evaluate how GenAI can enhance or hinder their engineering design process. In order to make this a meaningful and applicable discussion, these topics are woven into two team-based design challenges.",,,2025
1586,WIP: Assessing the Progression of Design Process Learning in First-Year Engineering Students,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dZPFvw8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dZPFvw8AAAAJ:ufrVoPGSRksC,"This Work in Progress paper investigates how first-year engineering students internalize and apply design process knowledge, a critical skill for success in upper-level design projects and professional practice. This study specifically explores how students’ design knowledge evolves during their first year in a two-semester Engineering Foundations course sequence and evaluates the influence of prior high school engineering design experiences on their learning. The findings will inform curricular improvements and contribute to broader discussions on how to effectively teach design thinking at the secondary and postsecondary levels.",,,2025
1587,Workshop-Leveraging Different Scales of Course Feedback for Enhanced Student Learning and Growth,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dZPFvw8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dZPFvw8AAAAJ:YsMSGLbcyi4C,"Purpose: This workshop explores how various modes and methods of feedback support facets of student development and, when used in concert, support holistic growth. This workshop will support first-year instructors, administrators, career development staff, and academic advisors in shaping the way they collect, process, and apply student feedback in pursuit of helping their students grow.",,,2024
1588,Detection of cracks in nuclear power plant using spatial-temporal grouping of local patches,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RevIbSkAAAAJ&citation_for_view=RevIbSkAAAAJ:ZuybSZzF8UAC,"Robust inspection is important to ensure the safety of nuclear power plant components. An automated approach would require detecting often low contrast cracks that could be surrounded by or even within textures with similar appearances such as welding, scratches and grind marks. We propose a crack detection method for nuclear power plant inspection videos by fine tuning a deep neural network for detecting local patches containing cracks which are then grouped in spatial-temporal space for group-level classification. We evaluate the proposed method on a data set consisting of 17 videos consisting of nearly 150,000 frames of inspection video and provide comparison to prior methods.",IEEE,,2016
1589,Thinking about computational thinking: Origins of computational thinking in educational computing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RevIbSkAAAAJ&citation_for_view=RevIbSkAAAAJ:uLbwQdceFCQC,"An educational team founded by Seymour Papert at MIT has developed an evolving series of computing environments designed to facilitate computational thinking. Papert outlined the goal of developing educational environments to facilitate the use of computer as a computational object in a seminal publication, Teaching Children Thinking (1970). He subsequently introduced the term Computational Thinking in Mindstorms: Children, Computers, and Powerful Ideas (1980). The understanding gained through five decades of research provides an important context for contemporary efforts to integrate computational thinking in schools.",Routledge,,2020
1590,Improving pollen classification with less training effort,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RevIbSkAAAAJ&citation_for_view=RevIbSkAAAAJ:Tyk-4Ss8FVUC,"The pollen grains of different plant taxa exhibit various shapes and sizes. This structural diversity has made the identification and classification of pollen grains an important tool in many fields. Despite the myriad of applications, the classification of pollen grains is still a tedious and time-consuming process that must be performed by highly skilled specialists. In this paper, we propose an automatic classification method to discriminate pollen grains coming from a variety of taxonomic types. First, we develop a new feature that captures the spikes of pollen to improve the classification accuracy. Second, we take advantage of the classification rules extracted from the existing pollen types and apply them to the new types. Third, we introduce a new selection criterion to obtain the most valuable training samples from the unlabeled data and therefore reduce the number of needed training samples. Our experiment …",IEEE,,2013
1591,Hydrogen sulfide modulates sinusoidal constriction and contributes to hepatic micorcirculatory dysfunction during endotoxemia,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RevIbSkAAAAJ&citation_for_view=RevIbSkAAAAJ:UeHWp8X0CEIC,"Hydrogen sulfide (H2S) affects vascular resistance; however, its effect on the hepatic microcirculation has not been investigated. Hepatic sinusoidal perfusion is dysregulated during sepsis, contributing to liver injury. Therefore, the present study determined the effect of H2S on the hepatic microcirculation and the contribution of endogenous H2S to hepatic microcirculatory dysfunction in an endotoxin model of sepsis. Portal infusion of H2S increased portal pressure in vivo (6.8 ± 0.2 mmHg before H2S vs. 8.6 ± 0.8 mmHg peak during H2S infusion, P < 0.05). Using intravital microscopy, we observed decreased sinusoidal diameter (6.2 ± 0.27 μm before H2S vs. 5.7 ± 0.3 μm after H2S, P < 0.05) and increased sinusoidal heterogeneity during H2S infusion (P < 0.05) and net constriction. Since hepatic H2S levels are elevated during sepsis, we used the cystathionine γ lyase inhibitor dl-propargylglycine (PAG) to …",American Physiological Society,,2013
1592,Tracking colliding cells in vivo microscopy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RevIbSkAAAAJ&citation_for_view=RevIbSkAAAAJ:d1gkVwhDpl0C,"Leukocyte motion represents an important component in the innate immune response to infection. Intravital microscopy is a powerful tool as it enables in vivo imaging of leukocyte motion. Under inflammatory conditions, leukocytes may exhibit various motion behaviors, such as flowing, rolling, and adhering. With many leukocytes moving at a wide range of speeds, collisions occur. These collisions result in abrupt changes in the motion and appearance of leukocytes. Manual analysis is tedious, error prone, time consuming, and could introduce technician-related bias. Automatic tracking is also challenging due to the noise inherent in in vivo images and abrupt changes in motion and appearance due to collision. This paper presents a method to automatically track multiple cells undergoing collisions by modeling the appearance and motion for each collision state and testing collision hypotheses of possible transitions …",IEEE,,2011
1593,The NTLS microscope prototyping system,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RevIbSkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RevIbSkAAAAJ:9Nmd_mFXekcC,The National Technology Leadership Society (NTLS) is a coalition of twelve national educational technology associations and was established to advance effective use of technology for teaching and learning. The International Technology and Engineering Educators Association (ITEEA) is a founding member.,,,2025
1594,Sensor Fusion Enhances Anomaly Detection in a Flood Forecasting System,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RevIbSkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RevIbSkAAAAJ:z_wVstp3MssC,"To build an Internet of Things (IoT) infrastructure that provides flood susceptibility forecasts for granular geographic levels, an extensive network of IoT weather sensors in local regions is crucial. However, these IoT devices may exhibit anomalistic behavior due to factors such as diminished signal strength, physical disturbance, low battery life, and more. To ensure that incorrect readings are identified and addressed appropriately, we devise a novel method for multi-stream sensor data verification and anomaly detection. Our method uses time-series anomaly detection to identify incorrect readings. We expand on the state-of-the-art by incorporating sensor fusion mechanisms between nearby devices to improve anomaly detection ability. Our system pairs nearby devices and fuses them by creating a new time series with the difference between the corresponding readings. This new time series is then input into a time-series anomaly detection model which identifies if any readings are anomalistic. By testing our system with nine different machine learning anomaly detection methods on synthetic data based on one year of real weather data, we find that our system outperforms the previous anomaly detection methods by improving F1-Score by 10.8%.",MDPI,,2025
1595,AI in Informal and Formal Education: A Historical Perspective,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RevIbSkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RevIbSkAAAAJ:nrtMV_XWKgEC,"This paper traces the evolution of educational technology through three major waves of innovation: the advent of microcomputers in the 1970s, the rise of the Internet, and the current emergence of generative artificial intelligence (AI). The historical analysis reveals that educational computing and AI have been intertwined since their inception, beginning with foundational work at MIT's Artificial Intelligence Laboratory, where Logo was developed as the first programming language expressly designed for children. The paper examines key developments from the 1950s through the present, including the creation of LISP and Logo, the establishment of Robert Taylor's influential framework of the computer as tutor, tool, and tutee, and the global adoption of computer literacy programs from the 1980s through the 2000s. The analysis demonstrates how each technological wave built upon previous innovations, with the …",,,2025
1596,Creating an Impactful and Cost-Effective Flood Prediction Platform,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RevIbSkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RevIbSkAAAAJ:VLnqNzywnoUC,"Creating an effective data platform for flood forecasting requires careful planning, selection of the right technologies, data sources, and a scalable infrastructure that can be easily adapted. Our Flood-Watch project aims to advance flood monitoring and prediction capabilities, improve community awareness, and contribute to the development of sustainable flood management strategies in the face of climate change. By combining historical data, real-time observations, and weather forecasts, this flood prediction platform can provide communities with timely information to evacuate or take preventive measures. This paper will showcase the current pipeline used to collect weather data through the LoRa protocol, which will be utilized in other critical operations within FloodWatch, such as flood risk forecasting and visualization.",IEEE,,2024
1597,"Age prediction from 12-lead electrocardiograms using deep learning: a comparison of four models on a contemporary, freely available dataset",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RevIbSkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RevIbSkAAAAJ:-_dYPAW6P2MC,Objective The 12-lead electrocardiogram (ECG) is routine in clinical use and deep learning approaches have been shown to have the identify features not immediately apparent to human interpreters including age and sex. Several models have been published but no direct comparisons exist. Approach We implemented three previously published models and one unpublished model to predict age and sex from a 12-lead ECG and then compared their performance on an open-access data set. Main results All models converged and were evaluated on the holdout set. The best preforming age prediction model had a hold-out set mean absolute error of 8.06 years. The best preforming sex prediction model had a hold-out set area under the receiver operating curve of 0.92. Significance We compared performance of four models on an open-access dataset.,IOP Publishing,,2024
1598,Deepflash: An efficient network for learning-based medical image registration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EGBMBTwAAAAJ&citation_for_view=EGBMBTwAAAAJ:35N4QoGY0k4C,"This paper presents DeepFLASH, a novel network with efficient training and inference for learning-based medical image registration. In contrast to existing approaches that learn spatial transformations from training data in the high dimensional imaging space, we develop a new registration network entirely in a low dimensional bandlimited space. This dramatically reduces the computational cost and memory footprint of an expensive training and inference. To achieve this goal, we first introduce complex-valued operations and representations of neural architectures that provide key components for learning-based registration models. We then construct an explicit loss function of transformation fields fully characterized in a bandlimited space with much fewer parameterizations. Experimental results show that our method is significantly faster than the state-of-the-art deep learning based image registration methods, while producing equally accurate alignment. We demonstrate our algorithm in two different applications of image registration: 2D synthetic data and 3D real brain magnetic resonance (MR) images.",,,2020
1599,Probabilistic principal geodesic analysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EGBMBTwAAAAJ&citation_for_view=EGBMBTwAAAAJ:u-x6o8ySG0sC,"Principal geodesic analysis (PGA) is a generalization of principal component analysis (PCA) for dimensionality reduction of data on a Riemannian manifold. Currently PGA is defined as a geometric fit to the data, rather than as a probabilistic model. Inspired by probabilistic PCA, we present a latent variable model for PGA that provides a probabilistic framework for factor analysis on manifolds. To compute maximum likelihood estimates of the parameters in our model, we develop a Monte Carlo Expectation Maximization algorithm, where the expectation is approximated by Hamiltonian Monte Carlo sampling of the latent variables. We demonstrate the ability of our method to recover the ground truth parameters in simulated sphere data, as well as its effectiveness in analyzing shape variability of a corpus callosum data set from human brain images.",,,2013
1600,Bayesian estimation of regularization and atlas building in diffeomorphic image registration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EGBMBTwAAAAJ&citation_for_view=EGBMBTwAAAAJ:u5HHmVD_uO8C,"This paper presents a generative Bayesian model for diffeomorphic image registration and atlas building. We develop an atlas estimation procedure that simultaneously estimates the parameters controlling the smoothness of the diffeomorphic transformations. To achieve this, we introduce a Monte Carlo Expectation Maximization algorithm, where the expectation step is approximated via Hamiltonian Monte Carlo sampling on the manifold of diffeomorphisms. An added benefit of this stochastic approach is that it can successfully solve difficult registration problems involving large deformations, where direct geodesic optimization fails. Using synthetic data generated from the forward model with known parameters, we demonstrate the ability of our model to successfully recover the atlas and regularization parameters. We also demonstrate the effectiveness of the proposed method in the atlas estimation problem for 3D …",Springer Berlin Heidelberg,,2013
1601,Finite-Dimensional Lie Algebras for Fast Diffeomorphic Image Registration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EGBMBTwAAAAJ&citation_for_view=EGBMBTwAAAAJ:eQOLeE2rZwMC,"This paper presents a fast geodesic shooting algorithm for diffeomorphic image registration. We first introduce a novel finite-dimensional Lie algebra structure on the space of bandlimited velocity fields. We then show that this space can effectively represent initial velocities for diffeomorphic image registration at much lower dimensions than typically used, with little to no loss in registration accuracy. We then leverage the fact that the geodesic evolution equations, as well as the adjoint Jacobi field equations needed for gradient descent methods, can be computed entirely in this finite-dimensional Lie algebra. The result is a geodesic shooting method for large deformation metric mapping (LDDMM) that is dramatically faster and less memory intensive than state-of-the-art methods. We demonstrate the effectiveness of our model to register 3D brain images and compare its registration accuracy, runtime, and memory …",,,2015
1602,Fast diffeomorphic image registration via Fourier-approximated Lie algebras,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EGBMBTwAAAAJ&citation_for_view=EGBMBTwAAAAJ:k_IJM867U9cC,"This paper introduces Fourier-approximated Lie algebras for shooting (FLASH), a fast geodesic shooting algorithm for diffeomorphic image registration. We approximate the infinite-dimensional Lie algebra of smooth vector fields, i.e., the tangent space at the identity of the diffeomorphism group, with a low-dimensional, bandlimited space. We show that most of the computations for geodesic shooting can be carried out entirely in this low-dimensional space. Our algorithm results in dramatic savings in time and memory over traditional large-deformation diffeomorphic metric mapping algorithms, which require dense spatial discretizations of vector fields. To validate the effectiveness of FLASH, we run pairwise image registration on both 2D synthetic data and real 3D brain images and compare with the state-of-the-art geodesic shooting methods. Experimental results show that our algorithm dramatically reduces the …",Springer US,,2019
1603,Interior Object Geometry via Fitted Frames,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EGBMBTwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=EGBMBTwAAAAJ:EkHepimYqZsC,"We propose a means of computing fitted frames on the boundary and in the interior of objects and using them to provide the basis for producing geometric features from them that are not only alignment-free but most importantly can be made to correspond locally across a population of objects. We describe a representation targeted for anatomic objects which is designed to enable this strong locational correspondence within object populations and thus to provide powerful object statistics. It accomplishes this by understanding an object as the diffeomorphic deformation of the closure of the interior of an ellipsoid and by using a skeletal representation fitted throughout the deformation to produce a model of the target object, where the object is provided initially in the form of a boundary mesh. Via classification performance on hippocampi shape between individuals with a disorder vs. others, we compare our method to …",,,2025
1604,Unsupervised Cardiac Video Translation Via Motion Feature Guided Diffusion Model,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EGBMBTwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=EGBMBTwAAAAJ:ipzZ9siozwsC,,,,2025
1605,IGG: Image Generation Informed by Geodesic Dynamics in Deformation Spaces,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EGBMBTwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=EGBMBTwAAAAJ:yB1At4FlUx8C,"Generative models have recently gained increasing attention in image generation and editing tasks. However, they often lack a direct connection to object geometry, which is crucial in sensitive domains such as computational anatomy, biology, and robotics. This paper presents a novel framework for Image Generation informed by Geodesic dynamics (IGG) in deformation spaces. Our IGG model comprises two key components: (i) an efficient autoencoder that explicitly learns the geodesic path of image transformations in the latent space; and (ii) a latent geodesic diffusion model that captures the distribution of latent representations of geodesic deformations conditioned on text instructions. By leveraging geodesic paths, our method ensures smooth, topology-preserving, and interpretable deformations, capturing complex variations in image structures while maintaining geometric consistency. We validate the proposed …",,,2025
1606,Robust Deep Convolutional Dictionary Model with Alignment Assistance for Multi-Contrast MRI Super-resolution,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EGBMBTwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=EGBMBTwAAAAJ:0KyAp5RtaNEC,"Multi-contrast magnetic resonance imaging (MCMRI) super-resolution (SR) methods aims to leverage the complementary information present in multi-contrast images. However, existing methods encounter several limitations. Firstly, most current networks fail to appropriately model the correlations of multi-contrast images and lack certain interpretability. Secondly, they often overlook the negative impact of spatial misalignment between modalities in clinical practice. Thirdly, existing methods do not effectively constrain the complementary information learned between multi-contrast images, resulting in information redundancy and limiting their model performance. In this paper, we propose a robust alignment-assisted multi-contrast convolutional dictionary (A2-CDic) model to address these challenges. Specifically, we develop an observation model based on convolutional sparse coding to explicitly represent multi …",,,2025
1607,Performance degradation and gassing of Li4Ti5O12/LiMn2O4 lithium-ion cells,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BU3UxUgAAAAJ&citation_for_view=BU3UxUgAAAAJ:Zph67rFs4hoC,"Batteries comprised of LiMn 2 O 4 cathodes (LMO) and Li 4 Ti 5 O 12 anodes (LTO) have potential advantages in terms of cost, safety, and power for transportation applications. In this manuscript, we present results from a cycle and calendar life study of 2 Ah LTO/LMO cells held at temperatures of 30 C, 45 C, and 60 C for 5 months. The cells held at elevated temperatures had measurable loss of capacity and severe loss of power. The LTO anodes harvested from the cells were found to have developed a coating during testing comprised of manganese, phosphorous, and fluorine, which likely resulted in the decreased cycling and power performances. In addition, there was significant gas generation inside of the cells predominantly consisting of hydrogen. We report on the initial diagnostics of the power loss and gas generation for these LTO/LMO cells.",IOP Publishing,,2012
1608,Electrochemistry and safety of Li4Ti5O12 and graphite anodes paired with LiMn2O4 for hybrid electric vehicle Li-ion battery applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BU3UxUgAAAAJ&citation_for_view=BU3UxUgAAAAJ:kNdYIx-mwKoC,"A promising anode material for hybrid electric vehicles (HEVs) is Li4Ti5O12 (LTO). LTO intercalates lithium at a voltage of ∼1.5V relative to lithium metal, and thus this material has a lower energy compared to a graphite anode for a given cathode material. However, LTO has promising safety and cycle life characteristics relative to graphite anodes. Herein, we describe electrochemical and safety characterizations of LTO and graphite anodes paired with LiMn2O4 cathodes in pouch cells. The LTO anode outperformed graphite with regards to capacity retention on extended cycling, pulsing impedance, and calendar life and was found to be more stable to thermal abuse from analysis of gases generated at elevated temperatures and calorimetric data. The safety, calendar life, and pulsing performance of LTO make it an attractive alternative to graphite for high power automotive applications, in particular when paired …",Elsevier,,2011
1609,A Review on Synthesis and Engineering of Crystal Precursors Produced Via Coprecipitation for Multicomponent Lithium-Ion Battery Cathode Materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BU3UxUgAAAAJ&citation_for_view=BU3UxUgAAAAJ:u_35RYKgDlwC,"Interest in developing high performance lithium-ion rechargeable batteries has motivated research in precise control over the composition, phase, and morphology during materials synthesis of battery active material particles for decades. Coprecipitation, as one of the most reported methods in the literature to produce precursors for lithium-ion battery active materials, has drawn attention due to its simplicity, scalability, homogeneous mixing at the atomic scale, and tunability over particle morphology. This highlight summarizes the advancements that have been made in producing crystalline particles of tunable and complex morphologies via coprecipitation for use as lithium-ion battery precursor materials. Comparison among different crystallization reagents, solution conditions that influence the properties of crystal particles, and the fundamental knowledge from equilibrium and/or kinetic study of the coprecipitation …",,,2020
1610,Growth mechanism of Ni0. 3Mn0. 7CO3 precursor for high capacity Li-ion battery cathodes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BU3UxUgAAAAJ&citation_for_view=BU3UxUgAAAAJ:KlAtU1dfN6UC,"Transition metal carbonate (Ni0.3Mn0.7CO3) was co-precipitated as the precursor for Li- and Mn-enriched composite materials used as advanced cathodes for lithium-ion batteries. The optimal pH range for synthesis of Ni0.3Mn0.7CO3 in a continuous stirred tank reactor (CSTR) at the pilot scale was predicted by taking into account the chemical equilibriums between the products and reactants. The nucleation and growth of precursor particles were investigated during the CSTR process by monitoring particle size distributions, particle morphologies, chemical compositions, and structures with time. It was found that in the early stage of co-precipitation both the particle size distribution and the chemical composition were not homogeneous; a lead time of about 5 hours under our experiment conditions was necessary to achieve the uniformity in particle shape and chemical composition. The latter was not altered during …",Royal Society of Chemistry,,2011
1611,Composition-tailored synthesis of gradient transition metal precursor particles for lithium-ion battery cathode materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BU3UxUgAAAAJ&citation_for_view=BU3UxUgAAAAJ:0EnyYjriUFMC,"We report the tailored synthesis of particles with internal gradients in transition metal composition aided by the use of a general process model. Tailored synthesis of transition metal particles was achieved using a coprecipitation reaction with tunable control over the process conditions. Gradients in the internal composition of the particles was monitored and confirmed experimentally by analysis of particles collected during regularly timed intervals. Particles collected from the reactor at the end of the process were used as the precursor material for the solid-state synthesis of Li1.2(Mn0.62Ni0.38)0.8O2, which was electrochemically evaluated as the active cathode material in a lithium battery. The Li1.2(Mn0.62Ni0.38)0.8O2 material was the first example of a structurally integrated multiphase material with a tailored internal gradient in relative transition metal composition as the active cathode material in a lithium-ion …",American Chemical Society,,2011
1612,Sulfonated Cation Exchange Membrane for Selective Transport in Non-Aqueous Redox Flow Battery Applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BU3UxUgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BU3UxUgAAAAJ:uJ-U7cs_P_0C,,ECS,,2025
1613,Poly (Phenylene Oxide) Backbone Membrane Separators for Lithium-Metal Batteries,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BU3UxUgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BU3UxUgAAAAJ:-_dYPAW6P2MC,,ECS,,2025
1614,Lithium capture from simulated geothermal brine via chemical reduction of iron phosphate in a packed bed reactor,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BU3UxUgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BU3UxUgAAAAJ:z_wVstp3MssC,"Rise in lithium demand, driven by use in lithium-ion batteries in electric vehicles and portable electronic devices, has led to increased interest in technologies for efficient and selective extraction of lithium from brines. Herein, an alternative approach driven by chemical reduction of an intercalation material is explored for low input energy lithium capture. In this study, we introduce the use of a packed bed reactor (PBR) loaded with solid intercalation host particles that capture lithium from simulated geothermal brine, where capture is driven by chemical reduction of the particles. The PBR approach is a scalable extraction process with minimal electrical energy consumption, as no external electrical potential driving force is applied to drive lithium capture. A Fe2+-citrate complex reduces the chemical potential of the brine, thereby providing the thermodynamic driving force for lithium capture. The selectivity for capturing Li …",Elsevier,,2025
1615,Selective Cation Exchange Membrane for Nonaqueous Flow Battery Separator,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BU3UxUgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BU3UxUgAAAAJ:VLnqNzywnoUC,"Membranes are a critical component for redox flow battery (RFB) systems. Ideal RFB membranes must be stable in the electrolyte and process environment, while facilitating transport of the charge compensating ion and minimizing crossover of the dissolved electroactive species (e.g., redox shuttles). More established aqueous RFB systems often leverage commercial membranes, such as sulfonated fluoropolymers, and have been demonstrated in RFB power stacks at industrial scales. Recently, there has been in pursuing RFB systems moving beyond the more established vanadium RFBs. One route is to develop nonaqueous, or organic, RFBs. A potential advantage of a nonaqueous RFB is the accessibility of higher voltages per cell, which would result in higher energy density for the RFB system. Also, nonaqueous electrolytes opens up the range of possibilities for soluble redox shuttles that can be used for the …","The Electrochemical Society, Inc.",,2025
1616,Evaluation of All Active Material Electrodes with Varying Thickness in Lithium-Ion Batteries,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BU3UxUgAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BU3UxUgAAAAJ:NJ774b8OgUMC,"In general, increasing electrode thickness in a battery system will increase energy density at the cell level due to reductions in relative volume allocated to inactive components including current collectors and separators. Increased thickness improves volumetric energy density, but there are tradeoffs of increases in ionic and/or electronic cell overpotential. Thus, there are balances between rate of charge/discharge and volumetric energy when considering changes in electrode thickness. We have developed methods to fabricate thick lithium-ion battery electrodes comprised of only electroactive material [1]. Because there is no binder or conductive additive within the electrode microstructure, we refer to these as all active material electrodes. Electrode processing includes thermal treatment to maintain porosity sufficient for percolated ionic transport – thus there is still liquid electrolyte within the porous microstructure …","The Electrochemical Society, Inc.",,2025
1617,Adaptive sensitivity encoding incorporating temporal filtering (TSENSE),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UVXDMQ8AAAAJ&citation_for_view=UVXDMQ8AAAAJ:u5HHmVD_uO8C,"A number of different methods have been demonstrated which increase the speed of MR acquisition by decreasing the number of sequential phase encodes. The UNFOLD technique is based on time interleaving of k‐space lines in sequential images and exploits the property that the outer portion of the field‐of‐view is relatively static. The differences in spatial sensitivity of multiple receiver coils may be exploited using SENSE or SMASH techniques to eliminate the aliased component that results from undersampling k‐space. In this article, an adaptive method of sensitivity encoding is presented which incorporates both spatial and temporal filtering. Temporal filtering and spatial encoding may be combined by acquiring phase encodes in an interleaved manner. In this way the aliased components are alternating phase. The SENSE formulation is not altered by the phase of the alias artifact; however, for imperfect …","John Wiley & Sons, Inc.",,2001
1618,Cardiovascular magnetic resonance phase contrast imaging,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UVXDMQ8AAAAJ&citation_for_view=UVXDMQ8AAAAJ:FQ36aI_S1AEC,"Cardiovascular magnetic resonance (CMR) phase contrast imaging has undergone a wide range of changes with the development and availability of improved calibration procedures, visualization tools, and analysis methods. This article provides a comprehensive review of the current state-of-the-art in CMR phase contrast imaging methodology, clinical applications including summaries of past clinical performance, and emerging research and clinical applications that utilize today's latest technology.",Elsevier,Journal of Cardiovascular Magnetic Resonance,2015
1619,Myocardial tissue tracking with two-dimensional cine displacement-encoded MR imaging: development and initial evaluation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UVXDMQ8AAAAJ&citation_for_view=UVXDMQ8AAAAJ:u-x6o8ySG0sC,"A breath-hold two-dimensional cine magnetic resonance (MR) pulse sequence based on displacement encoding with stimulated echoes (DENSE) for quantitative myocardial motion tracking was developed and evaluated. In the sequence, complementary spatial modulation of magnetization was used for time-independent artifact suppression, and echo-planar imaging was used for rapid data sampling. Twelve healthy volunteers underwent cine DENSE MR imaging, and six of them also underwent conventional MR imaging myocardial tagging. The circumferential shortening component of strain (Ecc) was measured on cine DENSE MR images and conventional tagged MR images. With complementary spatial modulation of magnetization, 10% or less of the total cine DENSE MR image energy was attributed to an artifact-generating echo during systolic imaging. Two-dimensional intramyocardial displacement and …",Radiological Society of North America,,2004
1620,Collagen-targeted MRI contrast agent for molecular imaging of fibrosis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UVXDMQ8AAAAJ&citation_for_view=UVXDMQ8AAAAJ:ufrVoPGSRksC,"Fibrosis is the formation or development of excess fibrous connective tissue (largely type I collagen) in a tissue as a result of a reparative or reactive process. Fibrosis, or scarring, is a common outcome in many chronic diseases of the heart, kidney, liver, lungs, or vasculature. Hepatic fibrosis is a result of chronic injury in response to insults such as viral hepatitis, alcohol or drug abuse, and increasingly from non-alcoholic steato hepatitis (NASH).[1] Fibrosis is a hallmark of end-stage renal disease.[2] Pulmonary fibrosis occurs in conditions such as chronic obstructive pulmonary disease.[3] Atherosclerosis involves vascular lesions with fibrous caps, and the thickness of this cap has been implicated in lesion (plaque) rupture resulting in thrombosis.[4] In the heart, hypertrophy from high blood pressure results in increased collagen levels.[5] Following heart attack, necrotic myocytes are replaced by extracellular matrix components, mainly collagen, to form a fibrotic myocardial scar.[6] For all of these pathologies it would be useful to noninvasively detect, assess, and monitor fibrosis. Treatment decisions hinge on both the identity and severity of the disease. For instance NASH, which afflicts 1–2% of the US population, progresses to cirrhosis of the liver in about 20% of cases. Early detection and accurate characterization of liver fibrosis can improve patient outcomes.[7] Currently liver fibrosis is detected by liver biopsy, but biopsy is not wellsuited to screening/monitoring disease because of its cost,","John Wiley & Sons, Ltd",,2007
1621,Macrophage subpopulations are essential for infarct repair with and without stem cell therapy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UVXDMQ8AAAAJ&citation_for_view=UVXDMQ8AAAAJ:sNmaIFBj_lkC,"Objectives This study sought to investigate the hypothesis that the favorable effects of mesenchymal stromal cells (MSCs) on infarct repair are mediated by macrophages. Background The favorable effects of MSC therapy in myocardial infarction (MI) are complex and not fully understood. Methods We induced MI in mice and allocated them to bone marrow MSCs, mononuclear cells, or saline injection into the infarct, with and without early (4 h before MI) and late (3 days after MI) macrophage depletion. We then analyzed macrophage phenotype in the infarcted heart by flow cytometry and macrophage secretome in vitro. Left ventricular remodeling and global and regional function were assessed by echocardiography and speckle-tracking based strain imaging. Results The MSC therapy significantly increased the percentage of reparative M2 macrophages (F4/80+CD206+) in the infarcted myocardium, compared with …",American College of Cardiology Foundation,,2013
1622,Multiparametric CMR identifies macrophage NOS2-mediated benefits of preventive SGLT2 inhibition in a mouse model of metabolic heart disease,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UVXDMQ8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=UVXDMQ8AAAAJ:E10ZYwHxBI8C,"Background Sodium-glucose cotransporter 2 (SGLT2) inhibitors improve metabolic and cardiovascular outcomes, but the mechanisms remain incompletely understood. We utilized cardiac magnetic resonance (CMR) and complementary methods to investigate whether preventive SGLT2 inhibitor administration attenuates the development of metabolic heart disease in a high-fat, high-sucrose diet (HFHSD) mouse model. Methods Male wild type (WT) C57BL/6 J mice were fed an HFHSD for 18 weeks to induce obesity, coronary microvascular disease, and diastolic dysfunction. WT mice treated preventively with an SGLT2 inhibitor, empagliflozin (EMPA), were compared to untreated WT mice, and mice fed either an HFHSD or standard chow diet with myeloid cell-specific knockout of the Nos2 gene (Nos2LysMCre) were compared to floxed controls (Nos2fl/fl). CMR assessed epicardial adipose tissue (EAT) volume, fatty …",Elsevier,,2025
1623,Prospective Evaluation of the Cardiovascular Effects of BRAF and MEK Inhibitors in Patients With Melanoma,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UVXDMQ8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=UVXDMQ8AAAAJ:f-E_jMG6T4AC,"Background Rapidly accelerated fibrosarcoma B-type (BRAF) and MEK inhibitors have revolutionized outcomes for patients with BRAF-mutated melanoma. However, they are associated with cardiovascular adverse effects. The real-world incidence and risk factors for these effects are poorly described. Objectives The aim of this study was to characterize the incidence and risk factors for BRAF inhibitor– and MEK inhibitor–associated hypertension and cancer therapy–related cardiac dysfunction (CTRCD) in a real-world setting. Methods A prospective, longitudinal, cohort study was undertaken among patients with melanoma treated with BRAF and MEK inhibitors in a regional cancer network (March 2021 to March 2023). Baseline cardiotoxicity risk stratification was assessed using the European Society of Cardiology cardio-oncology guideline–recommended tool. Comprehensive cardiovascular assessment was …",Elsevier,,2025
1624,Preclinical MRI of proinflammatory epicardial adipose tissue: Accelerated methods for simultaneous fatty acid composition and relaxation parameter mapping with relationships to …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UVXDMQ8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=UVXDMQ8AAAAJ:uQyLbZAWguAC,"Background Epicardial adipose tissue (EAT) plays a central role in metabolic heart disease through local inflammatory signaling. In obesity, EAT undergoes pathological remodeling marked by increased adipocyte size, saturated fatty acids (SFAs), macrophage infiltration, and inflammatory cytokine secretion. Proton density fat fraction (PDFF), T1, and the fatty acid composition (FAC) (the amount of SFAs, monounsaturated fatty acids [MUFAs], and polyunsaturated fatty acids [PUFAs]) are promising metrics of EAT quality, yet their role as biomarkers of proinflammatory EAT has not been established. This study presents an accelerated CMR method for simultaneous EAT FAC and T1 mapping and evaluates their relationships with histological and cytokine markers of inflammation. Methods An ECG-gated inversion recovery multi-echo gradient-echo sequence with radial golden-angle sampling was developed for …",Elsevier,,2025
1625,DENSE-Guided Deep Motion Networks Accounted by Large Rotations to Improve Myocardial Strain Analysis from Routine Cine MRI,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UVXDMQ8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=UVXDMQ8AAAAJ:X1xEhyGaivYC,"Myocardial strain imaging provides a valuable tool for detecting subclinical left ventricular (LV) dysfunction and adding prognostic value in assessing various types of heart disease. Recent studies have utilized highly accurate strain-dedicated techniques, such as displacement encoding with stimulated echoes (DENSE), to train a deep learning (DL) framework to predict the myocardial displacements/deformations from routine cine balanced steady state free precession (bSSFP) images. However, these methods have shown limited performance in capturing the large rotational motion of the myocardium associated with twist and torsion over time, which are important aspects of myocardial mechanics. To address this gap, this paper introduces a novel DENSE-guided DL network that explicitly accounts for large rotational motion to further improve strain analysis of standard cine bSSFP images. Specifically, our …",IEEE,,2025
1626,Tensor decomposition for signal processing and machine learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZOkfkFMAAAAJ&citation_for_view=ZOkfkFMAAAAJ:artPoR2Yc-kC,"Tensors or multiway arrays are functions of three or more indices (i, j, k, . . . )-similar to matrices (two-way arrays), which are functions of two indices (r, c) for (row, column). Tensors have a rich history, stretching over almost a century, and touching upon numerous disciplines; but they have only recently become ubiquitous in signal and data analytics at the confluence of signal processing, statistics, data mining, and machine learning. This overview article aims to provide a good starting point for researchers and practitioners interested in learning about and working with tensors. As such, it focuses on fundamentals and motivation (using various application examples), aiming to strike an appropriate balance of breadth and depth that will enable someone having taken first graduate courses in matrix algebra and probability to get started doing research and/or developing tensor algorithms and software. Some …",IEEE,,2017
1627,Transmit beamforming for physical-layer multicasting,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZOkfkFMAAAAJ&citation_for_view=ZOkfkFMAAAAJ:8k81kl-MbHgC,"This paper considers the problem of downlink transmit beamforming for wireless transmission and downstream precoding for digital subscriber wireline transmission, in the context of common information broadcasting or multicasting applications wherein channel state information (CSI) is available at the transmitter. Unlike the usual ""blind"" isotropic broadcasting scenario, the availability of CSI allows transmit optimization. A minimum transmission power criterion is adopted, subject to prescribed minimum received signal-to-noise ratios (SNRs) at each of the intended receivers. A related max-min SNR ""fair"" problem formulation is also considered subject to a transmitted power constraint. It is proven that both problems are NP-hard; however, suitable reformulation allows the successful application of semidefinite relaxation (SDR) techniques. SDR yields an approximate solution plus a bound on the optimum value of the …",IEEE,,2006
1628,Towards k-means-friendly spaces: Simultaneous deep learning and clustering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZOkfkFMAAAAJ&citation_for_view=ZOkfkFMAAAAJ:6yz0xqPARnAC,"Most learning approaches treat dimensionality reduction (DR) and clustering separately (ie, sequentially), but recent research has shown that optimizing the two tasks jointly can substantially improve the performance of both. The premise behind the latter genre is that the data samples are obtained via linear transformation of latent representations that are easy to cluster; but in practice, the transformation from the latent space to the data can be more complicated. In this work, we assume that this transformation is an unknown and possibly nonlinear function. To recover theclustering-friendly’latent representations and to better cluster the data, we propose a joint DR and K-means clustering approach in which DR is accomplished via learning a deep neural network (DNN). The motivation is to keep the advantages of jointly optimizing the two tasks, while exploiting the deep neural network’s ability to approximate any nonlinear function. This way, the proposed approach can work well for a broad class of generative models. Towards this end, we carefully design the DNN structure and the associated joint optimization criterion, and propose an effective and scalable algorithm to handle the formulated optimization problem. Experiments using different real datasets are employed to showcase the effectiveness of the proposed approach.",PMLR,,2017
1629,Learning to optimize: Training deep neural networks for interference management,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZOkfkFMAAAAJ&citation_for_view=ZOkfkFMAAAAJ:v1_lew4L6wgC,"Numerical optimization has played a central role in addressing key signal processing (SP) problems. Highly effective methods have been developed for a large variety of SP applications such as communications, radar, filter design, and speech and image analytics, just to name a few. However, optimization algorithms often entail considerable complexity, which creates a serious gap between theoretical design/analysis and real-time processing. In this paper, we aim at providing a new learning-based perspective to address this challenging issue. The key idea is to treat the input and output of an SP algorithm as an unknown nonlinear mapping and use a deep neural network (DNN) to approximate it. If the nonlinear mapping can be learned accurately by a DNN of moderate size, then SP tasks can be performed effectively-since passing the input through a DNN only requires a small number of simple operations. In …",IEEE,,2018
1630,Parallel factor analysis in sensor array processing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZOkfkFMAAAAJ&citation_for_view=ZOkfkFMAAAAJ:5nxA0vEk-isC,"This paper links multiple invariance sensor array processing (MI-SAP) to parallel factor (PARAFAC) analysis, which is a tool rooted in psychometrics and chemometrics. PARAFAC is a common name for low-rank decomposition of three- and higher way arrays. This link facilitates the derivation of powerful identifiability results for MI-SAP, shows that the uniqueness of single- and multiple-invariance ESPRIT stems from uniqueness of low-rank decomposition of three-way arrays, and allows tapping on the available expertise for fitting the PARAFAC model. The results are applicable to both data-domain and subspace MI-SAP formulations. The paper also includes a constructive uniqueness proof for a special PARAFAC model.",IEEE,,2002
1631,Subspace Clustering of Subspaces: Unifying Canonical Correlation Analysis and Subspace Clustering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZOkfkFMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ZOkfkFMAAAAJ:RMgMIBzvq-4C,"We introduce a novel framework for clustering a collection of tall matrices based on their column spaces, a problem we term Subspace Clustering of Subspaces (SCoS). Unlike traditional subspace clustering methods that assume vectorized data, our formulation directly models each data sample as a matrix and clusters them according to their underlying subspaces. We establish conceptual links to Subspace Clustering and Generalized Canonical Correlation Analysis (GCCA), and clarify key differences that arise in this more general setting. Our approach is based on a Block Term Decomposition (BTD) of a third-order tensor constructed from the input matrices, enabling joint estimation of cluster memberships and partially shared subspaces. We provide the first identifiability results for this formulation and propose scalable optimization algorithms tailored to large datasets. Experiments on real-world hyperspectral imaging datasets demonstrate that our method achieves superior clustering accuracy and robustness, especially under high noise and interference, compared to existing subspace clustering techniques. These results highlight the potential of the proposed framework in challenging high-dimensional applications where structure exists beyond individual data vectors.",,,2025
1632,The Vertex-Attribute-Constrained Densest -Subgraph Problem,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZOkfkFMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ZOkfkFMAAAAJ:In6cVmBjs0IC,"Dense subgraph mining is a fundamental technique in graph mining, commonly applied in fraud detection, community detection, product recommendation, and document summarization. In such applications, we are often interested in identifying communities, recommendations, or summaries that reflect different constituencies, styles or genres, and points of view. For this task, we introduce a new variant of the Densest -Subgraph (DS) problem that incorporates the attribute values of vertices. The proposed Vertex-Attribute-Constrained Densest -Subgraph (VAC-DS) problem retains the NP-hardness and inapproximability properties of the classical DS. Nevertheless, we prove that a suitable continuous relaxation of VAC-DS is tight and can be efficiently tackled using a projection-free Frank--Wolfe algorithm. We also present an insightful analysis of the optimization landscape of the relaxed problem. Extensive experimental results demonstrate the effectiveness of our proposed formulation and algorithm, and its ability to scale up to large graphs. We further elucidate the properties of VAC-DS versus classical DS in a political network mining application, where VAC-DS identifies a balanced and more meaningful set of politicians representing different ideological camps, in contrast to the classical DS solution which is unbalanced and rather mundane.",,,2025
1633,Linearly Precoded Signal Alignment: How to Excise Interference with Little Rate Loss,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZOkfkFMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ZOkfkFMAAAAJ:Y0-TYkg6YM4C,"How can we communicate reliably in the presence of unpredictable and potentially debilitating interference? As wireless communication becomes ever more ubiquitous, congestion and interference become increasingly inevitable, especially in contested scenarios. We have recently proposed a simple and practical method that uses packet repetition and multi-antenna reception to build two mixed signal and interference matrix views that contain the same packet in their span - in what we call signal alignment. This enables geometric/algebraic packet recovery via subspace intersection backed by theoretical guarantees - even in the face of adverse interference. A drawback is that the rate is halved owing to the repetition. This paper introduces a repetitionless signal alignment strategy that guarantees interference excision at controllable rate loss, which can be made practically negligible. This new family of signal …",IEEE,,2025
1634,Densest k-subgraph mining via a provably tight relaxation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZOkfkFMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ZOkfkFMAAAAJ:M0leSnx2MbUC,"Given an unweighted, undirected, and simple graph, the Densest k-Subgraph (DkS) problem aims to find a subgraph of k vertices that has the maximum average induced degree. In this paper, we consider an equivalent reformulation of the DkS problem via diagonal loading. On relaxing the combinatorial constraint of the reformulated problem, we show that the resulting non-convex, continuous relaxation is tight under certain conditions by leveraging an extension of the Motzkin-Straus theorem. We utilize two projection-free approaches to solve the relaxed problem: one based on the Frank-Wolfe algorithm and the other on explicit constraint parameterization. We compare their performance to state-of-the-art baselines across various benchmarks. Our empirical results show that the Frank-Wolfe-based algorithm proposed in this paper outperforms existing baselines in terms of subgraph density and computational complexity.",,,2025
1635,Interference-Resilient Hybrid Multi-Antenna ARQ,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZOkfkFMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ZOkfkFMAAAAJ:lg2tdxc6qMwC,"Hybrid automatic repeat request (HARQ) protocols use forward error correction and detection to trigger additional transmissions, until a packet is correctly decoded. Type-I HARQ (HARQ-I) uses packet retransmission and so-called chase combining of the received packets. HARQ protocols are widely used at the radio link / transport layer of wireless standards like 5G and WiFi to guarantee practically error-free end-to-end message delivery. Existing HARQ protocols are not designed to handle strong interference, which must be normally dealt with at the physical layer. On the other hand, recent work has shown that, with the right kind of multi-antenna signal processing at the receiver, based on canonical correlation analysis (CCA), retransmissions can be leveraged to eliminate interference. This creates an opportunity for synergistic cross-layer design, where a modified HARQ protocol will also excise interference. This …",IEEE,,2025
1636,"Campaign disclosure, privacy and transparency",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=at82kgsAAAAJ&citation_for_view=at82kgsAAAAJ:u5HHmVD_uO8C,"The United States has a long history of creating"" public records"" and viewing at least some of these as an essential part of government accountability.'Public records minimize opportunities for secrecy which might shield the actions of elected and appointed officials from public scrutiny. Historically, decisions to require public disclosure of information were made with particular limited purposes in mind: purposes associated with the public or democratic value of the disclosure. 2 Freedom of Information Act requirements, at both the federal and state levels, further opened access to government information and facilitated further disclosures of government information.'The Internet has exponentially escalated access to public records; information posted on the Internet is effectively broadcasted to anyone in the world who may be interested. The interested viewers may have benign, nefarious or legitimate reasons for being …",,,2010
1637,Surveillance and transparency as sociotechnical systems of accountability,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=at82kgsAAAAJ&citation_for_view=at82kgsAAAAJ:d1gkVwhDpl0C,"In this paper we argue that surveillance can be illuminated by framing surveillance regimes as sociotechnical systems of accountability, and then comparing surveillance to transparency regimes also framed as sociotechnical systems of accountability. We begin by grounding our understanding of accountability in the relationship between technology and democracy. We next explore surveillance and transparency regimes as traditionally and separately conceived and then show how they both function as mechanisms of accountability in democratic societies. The framing allows us, first, to compare the systems and ask a set of questions about how each kind of system constructs and positions individuals, what role information technology (IT) plays in constituting the system, and how relationships of power are arranged and maintained.",Routledge-Cavendish,,2010
1638,From reverse culture shock to global competency: Helping education abroad students learn from the shock of the return home,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=at82kgsAAAAJ&citation_for_view=at82kgsAAAAJ:5nxA0vEk-isC,"Steps Toward a “Wrap-Around” Approach for International ExperiencesInternational Division—Possible Session Topics:• Comparison and Assessment of Various Study Abroad Models in Achieving Global Competencies• Integration of International Programs in the Engineering Curriculum (year long, semester, short-term/study abroad, co-op, and service learning)• Experiential and Project-based Learning in Engineering Programs OverseasDowney and others have defined the globally competent engineer as one who can understandhow engineers from other cultural locations define problems differently and who can work withthose engineers to solve those problems. On-campus courses can help students begin tounderstand these differing perspectives, but having a rich experience in another culturalenvironment can lead to much more profound learning. Yet simply going to another place is notsufficient. One can travel to Spain or Mexico or South Africa and not have one’s frame ofreference much challenged. Engineering educators therefore must focus on the quality of studentlearning even as they work to increase the quantity of students having international experiences. One way to improve student learning is to offer a “wrap-around” approach to internationalexperiences. In this approach students have coursework before departing to prepare them to beopen to other points of view; small assignments, journal prompts, or exercises during their timeabroad; and then an intensive course upon their return to help them to reflect on and process theirexperience so that they can integrate it into a new way of understanding the world. This approachuses …",,,2015
1639,Working across disciplines and chipping away at silos with SLCE: An interdisciplinary approach to educating science and engineering students,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=at82kgsAAAAJ&citation_for_view=at82kgsAAAAJ:UeHWp8X0CEIC,"A co-curricular approach to service-learning and community engagement (SLCE) designed to begin breaking through these institutional and personal silos that inhibit exchanges of knowledge between students, faculty and communities, is presented. This approach seeks to create a continuum of engagement and learning for students, faculty, and communities to redirect students and faculty away from the drive to solely produce a competitive product (or trophy) and toward an appreciation of the ongoing process of engagement. To construct this continuum, we draw on the idea of an intellectual apprenticeship. The students in this model serve as the apprentices, while the faculty, along with community partners and other colleagues, act as mentors in a guild of “artisans” dedicated to putting useful knowledge into action. We present the principles of engagement that underlay the entire process (respect, reciprocity and relationship), the stages of the apprenticeship, evidence that supports its effectiveness and challenges to the approach. The goal of the paper is to share the approach with the larger community so that others may borrow what they find useful and add what they believe to be missing to ultimately improve experiential education about SLCE for engineers and scientists.",,,2013
1640,"“It’s not an Airplane, It’s my Baby”: Using a Gender Metaphor to Make Sense of Old Warplanes in North America’",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=at82kgsAAAAJ&citation_for_view=at82kgsAAAAJ:8k81kl-MbHgC,,,,2014
1641,Going To The Field: Immersing Student Researchers in Coupled Human-Natural Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=at82kgsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=at82kgsAAAAJ:_FxGoFyzp5QC,,AGU,,2015
1642,Carbon nitride deposited using energetic species: A review on XPS studies,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k4KF6r8AAAAJ&citation_for_view=k4KF6r8AAAAJ:u5HHmVD_uO8C,"This paper reviews x-ray photoelectron spectroscopy studies on carbon nitride (CN) and reports on results obtained from CN thin films prepared by mass selected ion-beam deposition. The core-level spectra of samples deposited at room temperature show that nitrogen is incorporated into the amorphous network in two different bonding configurations; carbon has three main bonding configurations whose relative contributions vary as a function of the nitrogen content. For samples deposited at elevated temperatures an ordering of the amorphous CN network towards a crystalline graphitelike structure is observed. Furthermore, both deposition at elevated temperatures (350 C) and post-deposition ion irradiation have a strong influence on the bonding configuration in the CN films. Based on these results and the results reported in the reviewed literature a picture of the microstructure of carbon nitride deposited using …",American Physical Society,Physical Review B,1998
1643,Influence of the ion energy on the growth and structure of thin hydrocarbon films,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k4KF6r8AAAAJ&citation_for_view=k4KF6r8AAAAJ:u-x6o8ySG0sC,"Noncrystalline hydrocarbon films were deposited from methane plasmas in an electron‐cyclotron‐resonance plasma reactor. The films were characterized by infrared spectroscopy and high‐energy ion‐beam analysis. Film properties were investigated as a function of the energy of ions impinging on the surface of the growing film. The ion energy was varied by applying a dc bias to the sample in the range from 30 to 200 eV. The ion energy was measured with a retarding field analyzer under identical experimental conditions. An abrupt change was found in the sp3/sp2 ratio in the energy interval from 80 to 120 eV. Other film properties such as the refractive index, density, and hydrogen‐to‐carbon ratio exhibit a more or less monotonic dependence on the ion energy. The results are compared with published data on hydrocarbon films. An analytical model was developed to describe the energy dependence of the …",American Institute of Physics,,1993
1644,Bonding characteristics of DC magnetron sputtered B–C–N thin films investigated by Fourier-transformed infrared spectroscopy and X-ray photoelectron spectroscopy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k4KF6r8AAAAJ&citation_for_view=k4KF6r8AAAAJ:9yKSN-GCB0IC,B–C–N thin films of a wide composition range were deposited by reactive DC magnetron sputtering of targets with different B/C ratios in an Ar/N2 atmosphere. The bonding characteristics of these amorphous films were investigated by Fourier-transformed infrared spectroscopy (FTIR) and X-ray photoelectron spectroscopy (XPS). The results of both characterisation methods indicate that real ternary compounds in which all three elements are bonded to each other are only formed when at least one element has a low concentration in the film—and therefore could be considered as an impurity. Otherwise the deposited material tends to a phase separation into binary compounds and single phases.,Elsevier,,2004
1645,Electron spectroscopy on boron nitride thin films: Comparison of near-surface to bulk electronic properties,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k4KF6r8AAAAJ&citation_for_view=k4KF6r8AAAAJ:d1gkVwhDpl0C,"Combining spectroscopic methods probing both occupied as well as unoccupied electronic states, the surface electronic structure of ex situ prepared boron-nitride films is analyzed and compared to experimental and theoretical bulk-electronic properties taken from the literature. X-ray photoelectron spectroscopy is applied to probe the core-level and valence-band electronic states, electron-energy-loss spectroscopy in the reflection geometry to investigate conduction band states as well as excitations like plasmons and core excitons. For films with hexagonal structure, the results from the near-surface region are found to reflect both the ground state and the many-body properties of the bulk material. Cubic boron nitride films in all cases exhibit a hexagonal-like top layer with a thickness of about 0.9 nm. Low-energy ion bombardment at room temperature is found to significantly increase the amount of disorder in both …",American Physical Society,,1999
1646,Structural changes in diamond and amorphous carbon induced by low-energy ion irradiation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k4KF6r8AAAAJ&citation_for_view=k4KF6r8AAAAJ:qjMakFHDy7sC,In the present work we describe an investigation of the influence of low-energy ion irradiation (1-keV Ar+) on the surface structure of polycrystalline diamond and amorphous carbon films with various degrees of graphitization. Photoelectron spectroscopy (PES) with excitation energies in the ultraviolet and x-ray regime is employed to monitor the radiation-induced modification of the electronic structure of the surface which is closely linked to the local bonding environment of the carbon atoms. A comparison of the mean photoelectron escape depth and the thickness of the irradiation affected layer also illustrates the suitability of PES for this investigation. For the chemical vapor deposition (CVD)-diamond film a gradual change from typical diamond features to amorphous carbon is observed for ion doses surpassing 6× 10 14 cm− 2. The structural changes in the diamond lattice are expressed in a broadening of the C 1s …,American Physical Society,,1996
1647,Critical differences in early-stage oxidation of Ni-Cr and Ni-Cr-Mo alloys,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k4KF6r8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=k4KF6r8AAAAJ:kuK5TVdYjLIC,"The early-stage oxidation of Ni-22Cr-6Mo (wt%) is studied for low O2 exposure (0-60 Langmuir) in-situ with ultra-high-vacuum synchrotron-based X-ray photoemission electron microscopy (XPEEM) and X-ray photoelectron spectroscopy (XPS). X-ray absorption spectroscopic (XAS) hyperspectral and time-resolved XPEEM images delivers chemical, time resolved, and structural information about oxide growth. Oxide distribution in the XAS hyperspectral images is quantified with cosine similarity. In contrast to what has been observed for binary Ni-Cr, the oxide of the ternary Ni-Cr-Mo grows in a layer-by-layer growth mode for all five grain orientations studied. The oxide is exclusively Cr2O3 in the corundum structure with a (0001) termination with small admixtures of Mo-oxides predominantly as Mo(IV). Mechanisms for the role of Mo in changing the oxide growth mode are discussed.",Nature Publishing Group UK,,2025
1648,Operando study of Ni-22Cr oxidation dynamics with nanoscale resolution in an X-ray photoemission electron microscope,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k4KF6r8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=k4KF6r8AAAAJ:KUbvn5osdkgC,"Understanding the initial oxidation pathways on binary Ni-Cr surfaces is import for alloy development and rational design. The early-stage oxidation of Ni-22wt% Cr is studied in-situ and in-operando with synchrotron-based x-ray photoelectron microscopy (XPEEM) and x-ray photoelectron spectroscopy (XPS) at 500 °C and oxygen exposure from 0 to 65 Langmuir. Preferential Cr oxidation is accompanied by Cr depletion in the alloy. Analysis of XPEEM timeseries and hyperspectral datasets presented the combined challenge of large datasets and varying image background. Hyperspectral data was approached using a combination of data dimensionality reduction techniques including principal component analysis (PCA), non-negative matrix approximation (NNMA), cosine similarity (CS), and tiling. These methods deliver spatially resolved chemical identification and extract the evolution of oxide island distribution …",Elsevier,,2025
1649,"Impact of high-power impulse magnetron sputtering pulse width on the nucleation, crystallization, microstructure, and ferroelectric properties of hafnium oxide thin films",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k4KF6r8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=k4KF6r8AAAAJ:4MWp96NkSFoC,"The impact of the high-power impulse magnetron sputtering (HiPIMS) pulse width on the crystallization, microstructure, and ferroelectric properties of undoped HfO 2 films is investigated. HfO 2 films were sputtered from a hafnium metal target in an Ar/O 2 atmosphere, varying the instantaneous power density by changing the HiPIMS pulse width with fixed time-averaged power and pulse frequency. The pulse width is shown to affect the ion-to-neutral ratio in the depositing species with the shortest pulse durations leading to the highest ion fraction. In situ x-ray diffraction measurements during crystallization demonstrate that the HiPIMS pulse width impacts nucleation and phase formation, with an intermediate pulse width of 110 μs stabilizing the ferroelectric phase over the widest temperature range. Although the pulse width impacts the grain size with the lowest pulse width resulting in the largest grain size, the grain …",AIP Publishing,,2024
1650,"Corrosion resistance, composition, and stratification of passive films: Ni-22Cr and Ni-22Cr-6Mo alloys passivated and exposure aged in acidic chloride solutions",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k4KF6r8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=k4KF6r8AAAAJ:ML0RJ9NH7IQC,"Ni-Cr based super-alloys have exceptional corrosion resistance, which is further improved with Mo alloying. The correlation between passive layer performance and composition was studied to gain a deeper mechanistic understanding of the role of Mo by comparing the behavior of Ni-22Cr to Ni-22Cr-6Mo (wt%) alloys. The passive layers were formed using galvanostatic holds to create fast and slow growth conditions using high and low current densities. A potentiostatic hold was added to initiate exposure aging. The passive film was characterized using electrochemical impedance spectroscopy (EIS), linear sweep voltammetry (LSV), atomic emission spectro-electrochemistry (AESEC), and X-ray photoelectron spectroscopy (XPS). Combined electrochemical and XPS characterization offered insight in cation concentrations and stratification, bonding states (oxide, hydroxide), and their modulation as a function of …",IOP Publishing,,2024
1651,Distributed constraint optimization problems and applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ASf9Q04AAAAJ&citation_for_view=ASf9Q04AAAAJ:NJ774b8OgUMC,,,,2018
1652,End-to-End Constrained Optimization Learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ASf9Q04AAAAJ&citation_for_view=ASf9Q04AAAAJ:LO7wyVUgiFcC,,,,2021
1653,Predicting AC optimal power flows: Combining deep learning and Lagrangian dual methods,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ASf9Q04AAAAJ&citation_for_view=ASf9Q04AAAAJ:lmc2jWPfTJgC,"The Optimal Power Flow (OPF) problem is a fundamental building block for the optimization of electrical power systems. It is nonlinear and nonconvex and computes the generator setpoints for power and voltage, given a set of load demands. It is often solved repeatedly under various conditions, either in real-time or in large-scale studies. This need is further exacerbated by the increasing stochasticity of power systems due to renewable energy sources in front and behind the meter. To address these challenges, this paper presents a deep learning approach to the OPF. The learning model exploits the information available in the similar states of the system (which is commonly available in practical applications), as well as a dual Lagrangian method to satisfy the physical and engineering constraints present in the OPF. The proposed model is evaluated on a large collection of realistic medium-sized power systems. The experimental results show that its predictions are highly accurate with average errors as low as 0.2%. Additionally, the proposed approach is shown to improve the accuracy of the widely adopted linear DC approximation by at least two orders of magnitude.",,,2020
1654,"Decision-focused learning: Foundations, state of the art, benchmark and future opportunities",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ASf9Q04AAAAJ&citation_for_view=ASf9Q04AAAAJ:zCSUwVk65WsC,"Decision-focused learning (DFL) is an emerging paradigm that integrates machine learning (ML) and constrained optimization to enhance decision quality by training ML models in an end-to-end system. This approach shows significant potential to revolutionize combinatorial decision-making in real-world applications that operate under uncertainty, where estimating unknown parameters within decision models is a major challenge. This paper presents a comprehensive review of DFL, providing an in-depth analysis of both gradient-based and gradient-free techniques used to combine ML and constrained optimization. It evaluates the strengths and limitations of these techniques and includes an extensive empirical evaluation of eleven methods across seven problems. The survey also offers insights into recent advancements and future research directions in DFL.",,Journal of Artificial Intelligence Research,2024
1655,Lagrangian duality for constrained deep learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ASf9Q04AAAAJ&citation_for_view=ASf9Q04AAAAJ:XvxMoLDsR5gC,"This paper explores the potential of Lagrangian duality for learning applications that feature complex constraints. Such constraints arise in many science and engineering domains, where the task amounts to learning to predict solutions for constraint optimization problems which must be solved repeatedly and include hard physical and operational constraints. The paper also considers applications where the learning task must enforce constraints on the predictor itself, either because they are natural properties of the function to learn or because it is desirable from a societal standpoint to impose them. This paper demonstrates experimentally that Lagrangian duality brings significant benefits for these applications. In energy domains, the combination of Lagrangian duality and deep learning can be used to obtain state of the art results to predict optimal power flows, in energy systems, and optimal compressor settings …",,,2020
1656,Constrained Language Generation with Discrete Diffusion Models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ASf9Q04AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ASf9Q04AAAAJ:WC23djZS0W4C,"Constraints are critical in text generation as LLM outputs are often unreliable when it comes to ensuring generated outputs adhere to user defined instruction or general safety guidelines. To address this gap, we present Constrained Discrete Diffusion (CDD), a novel method for enforcing constraints on natural language by integrating discrete diffusion models with differentiable optimization. Unlike conventional text generators, which often rely on post-hoc filtering or model retraining for controllable generation, we propose imposing constraints directly into the discrete diffusion sampling process. We illustrate how this technique can be applied to satisfy a variety of natural language constraints, including (i) toxicity mitigation by preventing harmful content from emerging,(ii) character and sequence level lexical constraints, and (iii) novel molecule sequence generation with specific property adherence. Experimental …",,,2025
1657,Training-free constrained generation with stable diffusion models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ASf9Q04AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ASf9Q04AAAAJ:j7_hQOaDUrUC,"Stable diffusion models represent the state-of-the-art in data synthesis across diverse domains and hold transformative potential for applications in science and engineering, e.g., by facilitating the discovery of novel solutions and simulating systems that are computationally intractable to model explicitly. While there is increasing effort to incorporate physics-based constraints into generative models, existing techniques are either limited in their applicability to latent diffusion frameworks or lack the capability to strictly enforce domain-specific constraints. To address this limitation this paper proposes a novel integration of stable diffusion models with constrained optimization frameworks, enabling the generation of outputs satisfying stringent physical and functional requirements. The effectiveness of this approach is demonstrated through material design experiments requiring adherence to precise morphometric properties, challenging inverse design tasks involving the generation of materials inducing specific stress-strain responses, and copyright-constrained content generation tasks.",,,2025
1658,The Disparate Impacts of Speculative Decoding,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ASf9Q04AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ASf9Q04AAAAJ:jFemdcug13IC,"The practice of speculative decoding, whereby inference is probabilistically supported by a smaller, cheaper, ``drafter'' model, has become a standard technique for systematically reducing the decoding time of large language models. This paper conducts an analysis of speculative decoding through the lens of its potential disparate speed-up rates across tasks. Crucially, the paper shows that speed-up gained from speculative decoding is not uniformly distributed across tasks, consistently diminishing for under-fit, and often underrepresented tasks. To better understand this phenomenon, we derive an analysis to quantify this observed ``unfairness'' and draw attention to the factors that motivate such disparate speed-ups to emerge. Further, guided by these insights, the paper proposes a mitigation strategy designed to reduce speed-up disparities and validates the approach across several model pairs, revealing on average a 12% improvement in our fairness metric.",,,2025
1659,Learning to Solve Optimization Problems Constrained with Partial Differential Equations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ASf9Q04AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ASf9Q04AAAAJ:6_hjMsCP8ZoC,"Partial differential equation (PDE)-constrained optimization arises in many scientific and engineering domains, such as energy systems, fluid dynamics and material design. In these problems, the decision variables (e.g., control inputs or design parameters) are tightly coupled with the PDE state variables, and the feasible set is implicitly defined by the governing PDE constraints. This coupling makes the problems computationally demanding, as it requires handling high dimensional discretization and dynamic constraints. To address these challenges, this paper introduces a learning-based framework that integrates a dynamic predictor with an optimization surrogate. The dynamic predictor, a novel time-discrete Neural Operator (Lu et al.), efficiently approximate system trajectories governed by PDE dynamics, while the optimization surrogate leverages proxy optimizer techniques (Kotary et al.) to approximate the associated optimal decisions. This dual-network design enables real-time approximation of optimal strategies while explicitly capturing the coupling between decisions and PDE dynamics. We validate the proposed approach on benchmark PDE-constrained optimization tasks inlacing Burgers' equation, heat equation and voltage regulation, and demonstrate that it achieves solution quality comparable to classical control-based algorithms, such as the Direct Method and Model Predictive Control (MPC), while providing up to four orders of magnitude improvement in computational speed.",,,2025
1660,Chance-constrained Flow Matching for High-Fidelity Constraint-aware Generation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ASf9Q04AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ASf9Q04AAAAJ:AXkvAH5U_nMC,"Generative models excel at synthesizing high-fidelity samples from complex data distributions, but they often violate hard constraints arising from physical laws or task specifications. A common remedy is to project intermediate samples onto the feasible set; however, repeated projection can distort the learned distribution and induce a mismatch with the data manifold. Thus, recent multi-stage procedures attempt to defer projection to clean samples during sampling, but they increase algorithmic complexity and accumulate errors across steps. This paper addresses these challenges by proposing a novel training-free method, Chance-constrained Flow Matching (CCFM), that integrates stochastic optimization into the sampling process, enabling effective enforcement of hard constraints while maintaining high-fidelity sample generation. Importantly, CCFM guarantees feasibility in the same manner as conventional repeated projection, yet, despite operating directly on noisy intermediate samples, it is theoretically equivalent to projecting onto the feasible set defined by clean samples. This yields a sampler that mitigates distributional distortion. Empirical experiments show that CCFM outperforms current state-of-the-art constrained generative models in modeling complex physical systems governed by partial differential equations and molecular docking problems, delivering higher feasibility and fidelity.",,,2025
1661,The Web of Modularity: Arithmetic of the Coefficients of Modular Forms and -series: Arithmetic of the Coefficients of Modular Forms and Q-series,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dNT5QmQAAAAJ&citation_for_view=dNT5QmQAAAAJ:u5HHmVD_uO8C,"Modular forms appear in many ways in number theory. They play a central role in the theory of quadratic forms, in particular, as generating functions for the number of representations of integers by positive definite quadratic forms. They are also key players in the recent spectacular proof of Fermat's Last Theorem. Modular forms are at the center of an immense amount of current research activity. Also detailed in this volume are other roles that modular forms and -series play in number theory, such as applications and connections to basic hypergeometric functions, Gaussian hypergeometric functions, super-congruences, Weierstrass points on modular curves, singular moduli, class numbers, -values, and elliptic curves. The first three chapters provide some basic facts and results on modular forms, which set the stage for the advanced areas that are treated in the remainder of the book. Ono gives ample motivation on topics where modular forms play a role. Rather than cataloging all of the known results, he highlights those that give their flavor. At the end of most chapters, he gives open problems and questions. The book is an excellent resource for advanced graduate students and researchers interested in number theory.",American Mathematical Soc.,,2004
1662,Distribution of the partition function modulo m,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dNT5QmQAAAAJ&citation_for_view=dNT5QmQAAAAJ:u-x6o8ySG0sC,"A partition of a positive integer n is any nonincreasing sequence of positive integers whose sum is n. Let p (n) denote the number of partitions of n (as usual, we adopt the convention that p (O)= 1 and p (a)= 0 if a 0 N). Ramanujan proved for every nonnegative integer n that p (5n+ 4) 0 (mod 5), p (7n+ 5)-O (mod 7), p (lln n+ 6) _0 (mod 11), and he conjectured further such congruences modulo arbitrary powers of 5, 7, and 11. Although the work of A. 0. L. Atkin and GN Watson settled these conjectures many years ago, the congruences have continued to attract much attention. For example, subsequent works by G. Andrews, AOL Atkin, F. Garvan, D. Kim, D. Stanton, and HPF Swinnerton-Dyer ([An-G],[G],[GKS],[At-Sw2]), in the spirit of F. Dyson, have gone a long way towards providing combinatorial and physical explanations for their existence. Ramanujan [Ra, p. xix] already observed that his congruences were quite …","Annals of Mathematics, Trustees of Princeton University on Behalf of the Annals of Mathematics, Mathematics Department, Princeton University",,2000
1663,Harmonic Maass forms and mock modular forms: theory and applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dNT5QmQAAAAJ&citation_for_view=dNT5QmQAAAAJ:buQ7SEKw-1sC,"Modular forms and Jacobi forms play a central role in many areas of mathematics. Over the last 10–15 years, this theory has been extended to certain non-holomorphic functions, the so-called “harmonic Maass forms”. The first glimpses of this theory appeared in Ramanujan's enigmatic last letter to GH Hardy written from his deathbed. Ramanujan discovered functions he called “mock theta functions” which over eighty years later were recognized as pieces of harmonic Maass forms. This book contains the essential features of the theory of harmonic Maass forms and mock modular forms, together with a wide variety of applications to algebraic number theory, combinatorics, elliptic curves, mathematical physics, quantum modular forms, and representation theory.",American Mathematical Soc.,,2017
1664,The f(q) mock theta function conjecture and partition ranks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dNT5QmQAAAAJ&citation_for_view=dNT5QmQAAAAJ:9yKSN-GCB0IC,"In 1944, Freeman Dyson initiated the study of ranks of integer partitions. Here we solve the classical problem of obtaining formulas for Ne(n) (resp. No(n)), the number of partitions of n with even (resp. odd) rank. Thanks to Rademacher’s celebrated formula for the partition function, this problem is equivalent to that of obtaining a formula for the coefficients of the mock theta function f(q), a problem with its own long history dating to Ramanujan’s last letter to Hardy. Little was known about this problem until Dragonette in 1952 obtained asymptotic results. In 1966, G.E. Andrews refined Dragonette’s results, and conjectured an exact formula for the coefficients of f(q). By constructing a weak Maass-Poincaré series whose “holomorphic part” is q-1f(q24), we prove the Andrews-Dragonette conjecture, and as a consequence obtain the desired formulas for Ne(n) and No(n).",Springer-Verlag,,2006
1665,Unearthing the visions of a master: harmonic Maass forms and number theory,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dNT5QmQAAAAJ&citation_for_view=dNT5QmQAAAAJ:2osOgNQ5qMEC,"Together with his collaborators, most notably Kathrin Bringmann and Jan Bruinier, the author has been researching harmonic Maass forms. These non-holomorphic modular forms play central roles in many subjects: arithmetic geometry, combinatorics, modular forms, and mathematical physics. Here we outline the general facets of the theory, and we give several applications to number theory: partitions and q-series, modular forms, singular moduli, Borcherds products, extensions of theorems of Kohnen-Zagier and Waldspurger on modular L-functions, and the work of Bruinier and Yang on Gross-Zagier formulae. What is surprising is that this story has an unlikely beginning: the pursuit of the solution to a great mathematical mystery. Modular forms are central in contemporary mathematics. Indeed, modular forms play crucial roles in algebraic number theory, algebraic topology, arithmetic geometry, combinatorics …",International Press of Boston,,2009
1666,Quasimodular forms arising from Jacobi's theta function and special symmetric polynomials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dNT5QmQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dNT5QmQAAAAJ:AZju0d2GQJ0C,"Ramanujan derived a sequence of even weight 2n quasimodular forms U 2 n (q) from derivatives of Jacobi's weight 3/2 theta function. Using the generating function for this sequence, one can construct sequences of quasimodular forms of all nonnegative integer weights with minimal input: a weight 1 modular form and a power series F (X). Using the weight 1 form θ (q) 2 and F (X)= exp⁡(X/2), we obtain a sequence {Y n (q)} of weight n quasimodular forms on Γ 0 (4) whose symmetric function avatars Y˜ n (x k) are the symmetric polynomials T n (x k) that arise naturally in the study of syzygies of numerical semigroups. With this information, we settle two conjectures about the T n (x k). Finally, we note that these polynomials are systematically given in terms of the Borel-Hirzebruch A ˆ-genus for spin manifolds, where one identifies power sum symmetric functions p i with Pontryagin classes.",Academic Press,,2026
1667,Mathematical discovery in the age of artificial intelligence,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dNT5QmQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dNT5QmQAAAAJ:qmtmRrLr0tkC,"In this comment, we consider how artificial intelligence tools are reshaping the way mathematical research is conducted and discuss how future developments of this technology will transform mathematical practice.",Nature Publishing Group UK,,2025
1668,Distribution of hooks in self-conjugate partitions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dNT5QmQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dNT5QmQAAAAJ:KWzIFqRkAKkC,"We confirm the speculation that the distribution of t-hooks among unrestricted integer partitions essentially descends to self-conjugate partitions. Namely, we prove that the number of hooks of length t among the size n self-conjugate partitions is asymptotically normally distributed with mean μ t (n) and variance σ t (n) 2 μ t (n)∼ 6 n π+ 3 π 2− t 2+ δ t 4 and σ t 2 (n)∼(π 2− 6) 6 n π 3, where δ t:= 1 if t is odd and is 0 otherwise.",North-Holland,,2025
1669,Modularity from -series,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dNT5QmQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dNT5QmQAAAAJ:4e5Qn2KL_jwC,"In 1975, G. E. Andrews challenged the community to provide a proof that takes the summatory forms of the Rogers--Ramanujan -series as input and directly establishes their modularity. This question is important because many different -series appearing in combinatorics, representation theory, and physics often seem to be mysteriously modular, yet there is no general test to confirm this directly from the exotic -series expressions. In this note, solve this general problem using -series algebra and -series systems of differential equations. Specifically, we establish a necessary and sufficient condition for when holomorphic -series on form a vector-valued modular function. This result offers a clear and conceptual path to modularity for ""strange"" -series.",,,2025
1670,Modular forms for chromatic homotopy: Supersingular congruences,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dNT5QmQAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dNT5QmQAAAAJ:sfnaS5RM6jYC,"In this note, we confirm a conjecture of Larson that arises in the Adams--Novikov spectral sequence (ANSS) for the stable homotopy groups of spheres and, specifically, in Behrens' program on explicit modular forms detecting --periodic classes in the divided -family. The conjecture predicts the supersingular order of the weight form , when attached to the Hecke correspondence. We prove the prediction for all primes , thereby providing the precise modular input that calibrates the relevant ANSS differentials in the Behrens program and removes the last obstruction to using pure -power across the range of indices where Hodge-scaling cancels.",,,2025
1671,The protein data bank,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y9q2zZAAAAAJ&citation_for_view=Y9q2zZAAAAAJ:7VEv-pLvLSsC,"The Protein Data Bank (PDB; http://www.rcsb.org/pdb/ ) is the single worldwide archive of structural data of biological macromolecules. This paper describes the goals of the PDB, the systems in place for data deposition and access, how to obtain further information, and near-term plans for the future development of the resource.",Oxford University Press,,2000
1672,The FAIR Guiding Principles for scientific data management and stewardship,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y9q2zZAAAAAJ&citation_for_view=Y9q2zZAAAAAJ:s9ia6_kGH2AC,"There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders—representing academia, industry, funding agencies, and scholarly publishers—have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.",Nature Publishing Group,,2016
1673,Protein structure alignment by incremental combinatorial extension (CE) of the optimal path.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y9q2zZAAAAAJ&citation_for_view=Y9q2zZAAAAAJ:u-x6o8ySG0sC,"A new algorithm is reported which builds an alignment between two protein structures. The algorithm involves a combinatorial extension (CE) of an alignment path defined by aligned fragment pairs (AFPs) rather than the more conventional techniques using dynamic programming and Monte Carlo optimization. AFPs, as the name suggests, are pairs of fragments, one from each protein, which confer structure similarity. AFPs are based on local geometry, rather than global features such as orientation of secondary structures and overall topology. Combinations of AFPs that represent possible continuous alignment paths are selectively extended or discarded thereby leading to a single optimal alignment. The algorithm is fast and accurate in finding an optimal structure alignment and hence suitable for database scanning and detailed analysis of large protein families. The method has been tested and compared …",,,1998
1674,ElliPro: a new structure-based tool for the prediction of antibody epitopes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y9q2zZAAAAAJ&citation_for_view=Y9q2zZAAAAAJ:Wp0gIr-vW9MC,"Background Reliable prediction of antibody, or B-cell, epitopes remains challenging yet highly desirable for the design of vaccines and immunodiagnostics. A correlation between antigenicity, solvent accessibility, and flexibility in proteins was demonstrated. Subsequently, Thornton and colleagues proposed a method for identifying continuous epitopes in the protein regions protruding from the protein's globular surface. The aim of this work was to implement that method as a web-tool and evaluate its performance on discontinuous epitopes known from the structures of antibody-protein complexes. Results Here we present ElliPro, a web-tool that implements Thornton's method and, together with a residue clustering algorithm, the MODELLER program and the Jmol viewer, allows the prediction and visualization of antibody epitopes in a given protein sequence or structure. ElliPro has been tested on a benchmark …",BioMed Central,,2008
1675,How open science helps researchers succeed,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y9q2zZAAAAAJ&citation_for_view=Y9q2zZAAAAAJ:BCdnXsLIVDwC,"Open access, open data, open source and other open scholarship practices are growing in popularity and necessity. However, widespread adoption of these practices has not yet been achieved. One reason is that researchers are uncertain about how sharing their work will affect their careers. We review literature demonstrating that open research is associated with increases in citations, media attention, potential collaborators, job opportunities and funding opportunities. These findings are evidence that open research practices bring significant benefits to researchers relative to more traditional closed practices. DOI: http://dx.doi.org/10.7554/eLife.16800.001","eLife Sciences Publications, Ltd",,2016
1676,AI-powered programmable virtual humans toward human physiologically-based drug discovery,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y9q2zZAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Y9q2zZAAAAAJ:IX653JsL2_EC,"Artificial intelligence (AI) has generated great interest in drug discovery, but current approaches merely digitize existing experiments, failing to predict clinical outcomes of new compounds. Likewise, pharmacology digital twins, designed for late-phase drug development, lack the ability to bridge translational gaps, limiting their value in early-stage drug discovery. The true potential of AI lies in enabling virtual experiments impossible in the real world, ‘testing’ novel compounds directly within the human body. Advances in AI, high-throughput assays, and single-cell and spatial omics now enable programmable virtual humans: dynamic, multiscale models that establish a new paradigm of physiologically-based drug discovery. This approach offers a transformative path to evaluate and optimize compound efficacy and safety earlier than ever in the drug discovery process.",Elsevier Current Trends,Drug Discovery Today,2025
1677,Programmable Virtual Humans Toward Human Physiologically-Based Drug Discovery,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y9q2zZAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Y9q2zZAAAAAJ:wUCFpcnEedwC,"Artificial intelligence (AI) has sparked immense interest in drug discovery, but most current approaches only digitize existing high-throughput experiments. They remain constrained by conventional pipelines. As a result, they do not address the fundamental challenges of predicting drug effects in humans. Similarly, biomedical digital twins, largely grounded in real-world data and mechanistic models, are tailored for late-phase drug development and lack the resolution to model molecular interactions or their systemic consequences, limiting their impact in early-stage discovery. This disconnect between early discovery and late development is one of the main drivers of high failure rates in drug discovery. The true promise of AI lies not in augmenting current experiments but in enabling virtual experiments that are impossible in the real world: testing novel compounds directly in silico in the human body. Recent advances in AI, high-throughput perturbation assays, and single-cell and spatial omics across species now make it possible to construct programmable virtual humans: dynamic, multiscale models that simulate drug actions from molecular to phenotypic levels. By bridging the translational gap, programmable virtual humans offer a transformative path to optimize therapeutic efficacy and safety earlier than ever before. This perspective introduces the concept of programmable virtual humans, explores their roles in a new paradigm of drug discovery centered on human physiology, and outlines key opportunities, challenges, and roadmaps for their realization.",,,2025
1678,CACHE Challenge# 2: Targeting the RNA Site of the SARS-CoV-2 Helicase Nsp13,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y9q2zZAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Y9q2zZAAAAAJ:eJjLl3UG7CkC,"A critical assessment of computational hit-finding experiments (CACHE) challenge was conducted to predict ligands for the SARS-CoV-2 Nsp13 helicase RNA binding site, a highly conserved COVID-19 target. Twenty-three participating teams comprised of computational chemists and data scientists used protein structure and data from fragment-screening paired with advanced computational and machine learning methods to each predict up to 100 inhibitory ligands. Across all teams, 1957 compounds were predicted and were subsequently procured from commercial catalogs for biophysical assays. Of these compounds, 0.7% were confirmed to bind to Nsp13 in a surface plasmon resonance assay. The six best-performing computational workflows used fragment growing, active learning, or conventional virtual screening with and without complementary deep-learning scoring functions. Follow-up functional assays …",American Chemical Society,,2025
1679,Advances in reversible covalent kinase inhibitors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y9q2zZAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Y9q2zZAAAAAJ:wlzmIqt2EaEC,"Reversible covalent kinase inhibitors (RCKIs) are a class of novel kinase inhibitors attracting increasing attention because they simultaneously show the selectivity of covalent kinase inhibitors yet avoid permanent protein‐modification‐induced adverse effects. Over the last decade, RCKIs have been reported to target different kinases, including Atypical group of kinases. Currently, three RCKIs are undergoing clinical trials. Here, advances in RCKIs are reviewed to systematically summarize the characteristics of electrophilic groups, chemical scaffolds, nucleophilic residues, and binding modes. In so doing, we integrate key insights into privileged electrophiles, the distribution of nucleophiles, and hence effective design strategies for the development of RCKIs. Finally, we provide a further perspective on future design strategies for RCKIs, including those that target proteins other than kinases.",,Medicinal Research Reviews,2025
1680,Biological databases in the age of generative artificial intelligence,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Y9q2zZAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Y9q2zZAAAAAJ:qQc65DSaYXMC,"Summary Modern biological research critically depends on public databases. The introduction and propagation of errors within and across databases can lead to wasted resources as scientists are led astray by bad data or have to conduct expensive validation experiments. The emergence of generative artificial intelligence systems threatens to compound this problem owing to the ease with which massive volumes of synthetic data can be generated. We provide an overview of several key issues that occur within the biological data ecosystem and make several recommendations aimed at reducing data errors and their propagation. We specifically highlight the critical importance of improved educational programs aimed at biologists and life scientists that emphasize best practices in data engineering. We also argue for increased theoretical and empirical research on data provenance, error …",Oxford University Press,Bioinformatics Advances,2025
1681,Rib fractures under anterior–posterior dynamic loads: experimental and finite-element study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TiQ7DR4AAAAJ&citation_for_view=TiQ7DR4AAAAJ:2osOgNQ5qMEC,"The purpose of this study was to investigate whether using a finite-element (FE) mesh composed entirely of hexahedral elements to model cortical and trabecular bone (all-hex model) would provide more accurate simulations than those with variable thickness shell elements for cortical bone and hexahedral elements for trabecular bone (hex–shell model) in the modeling human ribs. First, quasi-static non-injurious and dynamic injurious experiments were performed using the second, fourth, and tenth human thoracic ribs to record the structural behavior and fracture tolerance of individual ribs under anterior–posterior bending loads. Then, all-hex and hex–shell FE models for the three ribs were developed using an octree-based and multi-block hex meshing approach, respectively. Material properties of cortical bone were optimized using dynamic experimental data and the hex–shell model of the fourth rib and …",Elsevier,,2010
1682,Experiments for establishing pedestrian-impact lower limb injury criteria,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TiQ7DR4AAAAJ&citation_for_view=TiQ7DR4AAAAJ:u5HHmVD_uO8C,"Previous lateral knee bending and shear tests have reported knee joint failure moments close to failure bending moments for the tibia and femur. Eight tibias, eight femurs and three knee joints were tested in lateral bending and two knee joints were tested in lateral shear. Seven previous studies on femur bending, five previous studies on tibia bending, two previous studies on knee joint bending, and one on shear were reviewed and compared with the current tests. All knee joint failures in the current study were either epiphysis fractures of the femur or soft tissue failures. The current study reports an average lateral failure bending moment for the knee joint (134 Nm SD 7) that is dramatically lower than that reported in the literature (284-351 Nm), that reported in the current study for the tibia (291 Nm SD 69) and for femur (382 Nm SD 103). While this research has demonstrated the importance of realistic boundary …",SAE Technical Paper,,2003
1683,Kinematic corridors for PMHS tested in full-scale pedestrian impact tests,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TiQ7DR4AAAAJ&citation_for_view=TiQ7DR4AAAAJ:u-x6o8ySG0sC,"A primary function of pedestrian dummies is biofidelic representation of whole body kinematics. To assess the biofidelity of a pedestrian dummy, corridors for the kinematic response of post-mortem human surrogates (PMHS) tested in full-scale pedestrian impact tests were developed. Three PMHS were tested in full-scale pedestrian impact tests using a late-model small sedan with an impact velocity of 40 km/h. Three additional tests using the Polar-II dummy were conducted in identical conditions to those used in the PMHS tests. All impacts were conducted with the PMHS or dummy positioned laterally at the center line of the vehicle, in a mid-stance gait position, with the struckside limb positioned posteriorly and the upper limbs placed anterior to the torso. Initially supported by a harness, each surrogate was released prior to impact and was unconstrained through a 250 ms interaction with the vehicle.",,,2005
1684,Tolerance of the human leg and thigh in dynamic latero-medial bending,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TiQ7DR4AAAAJ&citation_for_view=TiQ7DR4AAAAJ:qjMakFHDy7sC,"The goal of the current study was to perform dynamic bending experiments on legs and thighs from post mortem human surrogates (PMHS) and combine the failure data with that of previous applicable studies to perform an injury risk analysis. Four leg and 12 thigh specimens were loaded dynamically (∼1.5 m/s) in latero-medial 3-point bending. The four leg specimens and six of the thigh specimens were loaded at the mid-diaphysis and the other 6 thigh specimens were loaded at a third of the length from the distal end. Data from four other studies were used with data from the current study to develop injury risk functions for the human thigh loaded at the distal third (50% probability of femur fracture = 372 Nm), and at the mid shaft (50% probability of femur fracture = 447 Nm) and for the human leg loaded at the mid shaft (50% probability of tibia fracture = 312 Nm).",WoodHead Publishing,,2004
1685,Using anthropometry-based scaling to predict responses across sex in reclined frontal impact sled tests,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TiQ7DR4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TiQ7DR4AAAAJ:zLWjf1WUPmwC,"Objective Field data studies have suggested greater injury risk in motor vehicle crashes for females compared to males. Data on female responses may provide more insight into these sex-based differences in injury risk, but few sled tests have been conducted with female subjects, with most cases being of either small or obese anthropometries. Since numerous sled tests have been conducted using mid-size male post mortem human subjects, anthropometry-based scaling of mid-size male responses is a potential approach to leverage this mid-size male data for a broader range of applicability. This study aimed to determine if scaling to predict female responses from male responses is suitable for a reclined condition and evaluate the effectiveness of varying anthropometry-based scaling techniques in predicting female responses from male responses. Methods Data from frontal impact sled tests conducted on four …",Taylor & Francis,,2025
1686,"The ethics, applications, and contributions of cadaver testing in injury prevention research",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TiQ7DR4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=TiQ7DR4AAAAJ:nrtMV_XWKgEC,"Objective This study aims to establish best practices and guidelines to ensure that experimental research utilizing Postmortem Human Subjects (PMHS) for injury prevention adheres to relevant ethical principles, which are also commonly accepted in research involving human tissues and living subjects. Furthermore, it reviews existing literature to underscore the pivotal role of PMHS testing in evaluating the efficacy of safety systems, with a particular focus on airbag performance. Methods This paper conducts an examination of the primary ethical principles governing human subject research as outlined in the Declaration of Helsinki (1965) and traces their evolution up to the latest framework proposed by the Council for International Organizations of Medical Sciences (CIOMS) in 2002. Input was solicited from international experts and laboratories experienced in PMHS testing to understand how these ethical principles …",Taylor & Francis,Traffic Injury Prevention,2024
1687,Solving problems on concurrent processors. Vol. 1: General techniques and regular problems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dJ-fD-sAAAAJ&citation_for_view=dJ-fD-sAAAAJ:tE63oHuI4N0C,Hsu J Banerjee P (2019) Performance measurement and trace driven simulation of parallel CAD and numeric applications on a hypercube multicomputer ACM SIGARCH Computer Architecture News 10.1145/325096.325152 18: 2SI (260-269) Online publication date: 28-Feb-2019,"Prentice-Hall, Inc.",,1988
1688,Observables for the analysis of event shapes in e+ e− annihilation and other processes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dJ-fD-sAAAAJ&citation_for_view=dJ-fD-sAAAAJ:u5HHmVD_uO8C,"We present a set of rotationally invariant observables which characterizes the"" shapes"" of events, and is calculable in quantum-chromodynamics perturbation theory for final states consisting of quarks and gluons (G). We include the effects of fragmentation to hadrons in comparing the shapes of events from the processes e+ e−→ q q, e+ e−→ q q G, and e+ e−→ heavy resonance→ GGG, and from heavy-quark and lepton production. We indicate how our analysis may be extended to deep-elastic lepton-hadron interactions and hadron-hadron collisions involving large transverse momenta.",American Physical Society,,1978
1689,Overview of the book: grid computing–making the global infrastructure a reality,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dJ-fD-sAAAAJ&citation_for_view=dJ-fD-sAAAAJ:uK3zKZX60NsC,"This book, Grid Computing: Making the Global Infrastructure a Reality,[1] brings together many of the major projects that are driving and shaping an emerging global Grid. In the chapters of this book you will find the perspectives of a pioneering group of Grid developers, researchers and application scientists whose vision forms the present and provides a view into the future of Grid computing. Many of the chapters in this book provide definitions and characterizations of the Grid–peruse these and you will form your own view. Common to all perspectives is the notion that the Grid supports the integration of resources (computers, networks, data archives, instruments etc.). To build an integrated system, individuals and communities","John Wiley & Sons, Ltd",,2003
1690,Twister: a runtime for iterative mapreduce,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dJ-fD-sAAAAJ&citation_for_view=dJ-fD-sAAAAJ:_B80troHkn4C,"MapReduce programming model has simplified the implementation of many data parallel applications. The simplicity of the programming model and the quality of services provided by many implementations of MapReduce attract a lot of enthusiasm among distributed computing communities. From the years of experience in applying MapReduce to various scientific applications we identified a set of extensions to the programming model and improvements to its architecture that will expand the applicability of MapReduce to more classes of applications. In this paper, we present the programming model and the architecture of Twister an enhanced MapReduce runtime that supports iterative MapReduce computations efficiently. We also show performance comparisons of Twister with other similar runtimes such as Hadoop and DryadLINQ for large scale data parallel applications.",,,2010
1691,Examining the challenges of scientific workflows,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dJ-fD-sAAAAJ&citation_for_view=dJ-fD-sAAAAJ:WbkHhVStYXYC,"Workflows have emerged as a paradigm for representing and managing complex distributed computations and are used to accelerate the pace of scientific progress. A recent National Science Foundation workshop brought together domain, computer, and social scientists to discuss requirements of future scientific applications and the challenges they present to current workflow technologies.",IEEE,,2007
1692,From Local Earthquake Nowcasting to Natural Time Forecasting: A Simple Do-It-Yourself (DIY) Method,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dJ-fD-sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dJ-fD-sAAAAJ:kOSmcaXA1tUC,"Previous papers have outlined nowcasting methods to track the current state of earthquake hazard using only observed seismic catalogs. The basis for one of these methods, the ""counting method"", is the Gutenberg-Richter (GR) magnitude-frequency relation. The GR relation states that for every large earthquake of magnitude greater than MT , there are on average NGR small earthquakes of magnitude MS. In this paper we use this basic relation, combined with the Receiver Operating Characteristic (ROC) formalism from machine learning, to compute the probability of a large earthquake. The probability is conditioned on the number of small earthquakes n(t) that have occurred since the last large earthquake. We work in natural time, which is defined as the count of small earthquakes between large earthquakes. We do not need to assume a probability model, which is a major advantage. Instead, the probability is computed as the Positive Predictive Value (PPV) associated with the ROC curve. We find that the PPV following the last large earthquake initially decreases as more small earthquakes occur, indicating the property of temporal clustering of large earthquakes as is observed. As the number of small earthquakes continues to accumulate, the PPV subsequently begins to increase. Eventually a point is reached beyond which the rate of increase becomes much larger and more dramatic. Here we describe and illustrate the method by applying it to a local region around Los Angeles, California, following the January 17, 1994 magnitude M6.7 Northridge earthquake.",,,2025
1693,Towards Experiment Execution in Support of Community Benchmark Workflows for HPC,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dJ-fD-sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dJ-fD-sAAAAJ:1jSx-IFpb-IC,"A key hurdle is demonstrating compute resource capability with limited benchmarks. We propose workflow templates as a solution, offering adaptable designs for specific scientific applications. Our paper identifies common usage patterns for these templates, drawn from decades of HPC experience, including recent work with the MLCommons Science working group. We found that focusing on simple experiment management tools within the broader computational workflow improves adaptability, especially in education. This concept, which we term benchmark carpentry, is validated by two independent tools: Cloudmesh's Experiment Executor and Hewlett Packard Enterprise's SmartSim. Both frameworks, with significant functional overlap, have been tested across various scientific applications, including conduction cloudmask, earthquake prediction, simulation-AI/ML interactions, and the development of computational fluid dynamics surrogates.",,,2025
1694,Conditioned quantum-assisted deep generative surrogate for particle-binary vector indicating thecalorimeter interactions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dJ-fD-sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dJ-fD-sAAAAJ:Y2wsZ1s-vmcC,"Particle collisions at accelerators like the Large Hadron Collider (LHC), recorded by experiments such as ATLAS and CMS, enable precise standard model measurements and searches for new phenomena. Simulating these collisions significantly influences experiment design and analysis but incurs immense computational costs, projected at millions of CPU-years annually during the high luminosity LHC (HL-LHC) phase. Currently, simulating a single event with Geant4 consumes around 1000 CPU seconds, with calorimeter simulations especially demanding. To address this, we propose a conditioned quantum-assisted generative model, integrating a conditioned variational autoencoder (VAE) and a conditioned restricted Boltzmann machine (RBM). Our RBM architecture is tailored for D-Wave’s Pegasus-structured advantage quantum annealer for sampling, leveraging the flux bias for conditioning. This …",Nature Publishing Group UK,,2025
1695,The first 18 months of JGR: MLC,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dJ-fD-sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dJ-fD-sAAAAJ:H4GFzQhrpr4C,"As editors of Journal of Geophysical Research: Machine Learning and Computation, we are delighted to celebrate the successes of our first 18 months.",,Journal of Geophysical Research: Machine Learning and Computation,2025
1696,"Evaluating the effects of orchestrated, game-based learning in virtual environments for informal education",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xum8Ti0AAAAJ&citation_for_view=xum8Ti0AAAAJ:zYLM7Y9cAGgC,"In informal learning spaces employing digital content, such as museums, visitors often do not get adequate exposure to content, or they passively receive instruction offered by a museum docent to the whole group. This research aims to identify which elements of co-located group collaboration, virtual environments, and serious games can be leveraged for an enhanced museum learning and entertaining experience. We developed C-OLiVE, an interactive virtual environment supporting tripartite group collaboration, which we used to explore our hypothesis that synchronous, co-located, group collaboration will afford greater learning compared to conventional approaches. In an empirical study, we found some evidence supporting this hypothesis, taking into consideration other factors such as game experience and social presence. Students participating in the three-player condition demonstrated a better …",,,2014
1697,RaBit EscAPE: a board game for computational thinking,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xum8Ti0AAAAJ&citation_for_view=xum8Ti0AAAAJ:IjCSPb-OGe4C,"Computational thinking (CT) is increasingly seen as a core literacy skill for the modern world on par with the longestablished skills of reading, writing, and arithmetic. To promote the learning of CT at a young age we capitalized on children's interest in play. We designed RabBit EscApe, a board game that challenges children, ages 610, to orient tangible, magnetized manipulatives to complete or create paths. We also ran an informal study to investigate the effectiveness of the game in fostering children's problemsolving capacity during collaborative game play. We used the results to inform our instructional interaction design that we think will better support the learning activities and help children hone the involved CT skills. Overall, we believe in the power of such games to challenge children to grow their understanding of CT in a focused and engaging activity.",,,2014
1698,Supporting social engagement for young audiences with serious games and virtual environments in museums,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xum8Ti0AAAAJ&citation_for_view=xum8Ti0AAAAJ:LkGwnXOMwfcC,"Considering the shift of museums toward digital experiences that can satiate the interests of their young audiences, we suggest an integrated schema for socially engaging large visitor groups. As a means to present our position, we propose a framework for audience involvement with complex educational material, combining serious games and virtual environments along with a theory of contextual learning in museums. We suggest that effective learning with school groups visiting museums can occur through the facilitation of coordinated activities of young participants with appropriately designed technological mediation. We use the term orchestrated learning to present our rationale on how such activities can lead to enhanced learning through increased motivation and social interactions. In order to validate our framework, we built a testbed application that supports collaborative gameplay of small and large …",Springer International Publishing,,2018
1699,Poster: Exploring the integrality and separability of the Leap Motion Controller for direct manipulation 3D interaction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xum8Ti0AAAAJ&citation_for_view=xum8Ti0AAAAJ:qjMakFHDy7sC,"In this paper, we evaluate a new generation 5DOF tracker, the Leap Motion Controller, and the mouse for performing integral and separable 3D manipulation tasks in a stage lighting application. Based on the hypothesis that the Leap would outperform the mouse for the integral tasks of position and rotation while the mouse will prove better for the separable tasks of position and light intensity, as shown in a similar study by Jacob et al. [3], we designed an experiment to test this claim. Our findings did not support our hypothesis with the mouse performing significantly better both in terms of completion time and angular and position errors.",IEEE,,2014
1700,Small group learning with games in museums: effects of interactivity as mediated by cultural differences,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xum8Ti0AAAAJ&citation_for_view=xum8Ti0AAAAJ:Y0pCki6q_DkC,"Museums are rich and complex learning experiences, using a variety of interactive approaches to engage their audiences. However, the largely unstructured nature of free-choice learning calls for alternative approaches that can effectively engage groups of school age students with diverse cultural backgrounds. In this paper, we present our findings from a recent study in a museum in Greece, where triads of students had to learn about olive oil production using a game enabling different levels of interactivity and collaboration. We found that facilitation by an expert guide led to greater learning gains as compared to students playing alone, with one or three simultaneous game controllers. We also compared these results with a previous controlled experiment conducted in the US with middle school students, using the same game but without the ecologically valid facilitation. Drawing ideas from sociocultural and …",,,2015
1701,Creating effective project-based courses: personal relevance and its relations to successful group work,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xum8Ti0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xum8Ti0AAAAJ:kNdYIx-mwKoC,"Group projects are expected in contemporary engineering curricula, and yet they often pose a challenge to students and instructors alike. Could making projects personally relevant help? The present study created and tested a conceptual framework regarding the impact of personal relevance on groupwork in a project-based learning (PBL) course. We examined how measures of personal relevance (PR), both at the course level (value, interest in specialisation) and specifically regarding projects (interest and investment in the project, and contribution to the project idea) relate to students’ expectancy, group connectedness, team dynamics (effectiveness, conflict, satisfaction, interdependence, and cohesiveness), and perceived effort; whether PR differs based on students’ gender, academic year, or time of the semester; and whether PR predicts students’ project performance. Seventy-one undergraduates in a project …",Taylor & Francis,,2023
1702,Assessing the Impact of Feedback on Student Learning Using e2Logos: A Novel Grading Tool for Online Student Reports,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xum8Ti0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xum8Ti0AAAAJ:MXK_kJrjxJIC,"A common instructional approach to many CS and engineering classes involves designing a new software system, by providing real-world, open-ended, client-driven, team-based problems, most known as Model-Eliciting Activities (MEAs). A significant challenge imposed by this approach comes from accurately and consistently assessing student work where more than one solution can be correct. Therefore, timely feedback is pivotal for student success. Such feedback is fundamental in supporting grading consistency and efficiency for graders, but importantly to scaffold student understanding for student teams working on complex, ill-defined, real-world problems. This poster presents the next step in a two-phase evaluation (the first being a usability test) of a new grading and annotation tool for online technical reports, called e2Logos (evaluating electronic logos). We propose a plan for evaluating the educational …",,,2023
1703,e2Logos: A Novel Software for Evaluating Online Student Project Reports,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xum8Ti0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xum8Ti0AAAAJ:3fE2CSJIrl8C,,,,2023
1704,Marcus: A Chatbot for Depression Screening Based on the PHQ-9 Assessment,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xum8Ti0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xum8Ti0AAAAJ:8k81kl-MbHgC,"College students are a population particularly sus-ceptible to anxiety and depression, with financial struggles and social stigmatization creating a barrier to seeking psychological support. The recent pandemic has exacerbated these issues, with lockdowns and remote instruction creating extra stress factors and making access to consultation services even harder. Online depression screening tools have tried to address such problems and the development of chatbots for the detection and even therapeutic use of anxiety symptoms has been on the rise. This work reports findings from testing Marcus, a depression screening chatbot based on a popular depression assessment tool, the Patient Health Questionnaire (PHQ-9). Our results indicate that Marcus was comparable to the online version of PHQ-9 in detecting depression based on produced scores, using a withinsubjects experimental design with predominantly college students in the USA. Nonetheless, the chatbot was not found to be the most effective method based on comparing participant preferences and initiation rates. Implications of our findings for the development of similar computer-based screening tools are discussed, as well as recommendations for future work in this area.",,,2023
1705,Designing for Meaningful Interactions and Digital Wellbeing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xum8Ti0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=xum8Ti0AAAAJ:5nxA0vEk-isC,"In the contemporary attention economy, tech companies design the interfaces of their digital platforms by adopting attention-capture dark patterns to drive their behavior and maximize time spent and daily visits. Two popular examples are viral recommendations and content autoplay on social networks. As these patterns exploit people’s psychological vulnerabilities and may contribute to technology overuse and problematic behaviors, there is the need of promoting the design of technology that better align with people’s digital wellbeing. This workshop seeks to advance this timely and urgent need, by inviting researchers and practitioners in interdisciplinary domains to engage in conversation around the design of interfaces that allow people to take advantage of digital platforms in a meaningful and conscious way.",,,2022
1706,"An experimental and theoretical investigation of the dilution, pressure and flow-field effects on the extinction condition of methane-air-nitrogen diffusion flames",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3K79_UkAAAAJ&citation_for_view=3K79_UkAAAAJ:u5HHmVD_uO8C,"Velocity fields, and extinction conditions for methane-air diffusion flames are measured for an opposed-flow nozzle-type burner system and calculated by a numerical-integration, routine for pressures from 0.25 to 2.5 atm and for dilutions having fixed stoichiometric mixture fractions with oxidizer-stream oxygen mass fractions from 0.233 to 0.190. Imposition of boundary conditions ranging from potential flow to plug flow reveals that changes on the order of a factor of two in the oxidizer-side strain rate at extinction can be produced by changes in opposed-flow burner design. It is shown that the maximum velocity gradient, however which occurs on the fuel side of the main reaction zone, achieves a value at extinction that is relatively insensitive to the boundary conditions of the flow. The results explain differences found by different investigators on influences of dilution on extinction strain rates and show that most …",Elsevier,,1991
1707,Dynamics of water droplets in a counterflow field and their effect on flame extinction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3K79_UkAAAAJ&citation_for_view=3K79_UkAAAAJ:u-x6o8ySG0sC,"The effect of fine-water droplets in extinguishing steady, laminar counterflow methane–air nonpremixed flames is investigated here, using a numerical approach. A new two-phase model using a hybrid Eulerian–Lagrangian formulation for the gas-droplet flow is developed as part of this work. A key feature of the model developed is that it can avoid the singularity associated with the droplet number density equation in a consistent manner by using a Lagrangian equation for droplet flux fraction. The gas phase is described by a detailed model involving full chemical kinetics and transport, whereas droplet evaporation and heat transfer are modeled assuming quasisteady conditions. Application of the model to several monodisperse sizes of water droplets, ranging from 5–50 μm, revealed an interesting nonmonotonic dependence of the flame extinction strain rate on droplet size. This phenomenon is attributed to the …",Elsevier,,1998
1708,Extinction of nonpremixed flames with halogenated fire suppressants,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3K79_UkAAAAJ&citation_for_view=3K79_UkAAAAJ:d1gkVwhDpl0C,"An experimental, analytical, and numerical study was performed to elucidate the influence of eleven gaseous agents, considered to be substitutes for CF3Br, on the structure and critical conditions of extinction of diffusion flames burning liquid hydrocarbon fuels. The effectiveness of these agents in quenching flames was compared to those of CF3Br and an inert diluent such as nitrogen. Experiments were performed on diffusion flames stabilized in the counterflowing as well as in the coflowing configuration. The fuels tested were heptane in the counterflowing configuration, and heptane, the jet fuels JP-8, and JP-5, and hydraulic fluids (military specifications 5606 and 83282) in the coflowing configuration. The oxidizing gas was a mixture of air and the agent. On a mass and mole basis CF3Br was found to be most effective in quenching the flames and the mass-based effectiveness of the other eleven agents was …",Elsevier,,1994
1709,Modeling of graphite oxidation in a stagnation-point flow field using detailed homogeneous and semiglobal heterogeneous mechanisms with comparisons to experiments,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3K79_UkAAAAJ&citation_for_view=3K79_UkAAAAJ:qjMakFHDy7sC,"Numerical simulation results are presented on the mass burning rate and the gas-phase flame structure of a heated cylindrical graphite rod in a stagnation-point flow field, using detailed homogeneous chemical kinetics and semiglobal heterogeneous chemical kinetics. Extensive comparisons with new experimental data and data from the literature are shown for various oxidizer compositions, pressures and strain rates. The relative importance of the carbon-radical reactions in the two semiglobal heterogeneous mechanisms employed is demonstrated, while the deficiencies and limitations of applying semiglobal heterogeneous mechanisms for graphite rod oxidations are identified. Under simplifying assumptions, a method for including the graphite porosity in the present quasi-one dimensional formulation is described. The need to develop elementary reaction mechanisms for the heterogeneous kinetics and the …",Elsevier,,1996
1710,Extinction conditions of non-premixed flames with fine droplets of water and water/NaOH solutions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3K79_UkAAAAJ&citation_for_view=3K79_UkAAAAJ:IjCSPb-OGe4C,"Interactions of fine droplets of water and water/NaOH solutions with a steady, laminar counterflow methane/air nonpremixed flame are in vestigated experimentally and numerically. A water atomizer generating a polydisperse distribution of droplet sizes with a median diameter of 20 μm is used in experiments with steady feed rate. Comparisons of the measured flame extinction condition as a function of droplet mass fraction in the air stream indicate a trend similar to that predicted previously using 20 μm monodisperse water droplets. The hybrid Eulerian-Lagrangian numerical model previously developed is generalized to include polydisperse distribution of drop sizes: however, the differences seen between experiments and the numerical predictions at high water mass fractions could not be attributed to variation in size distribution alone. Present experiments support the conclusions of an earlier modeling work that …",Elsevier,,2000
1711,Skeletal Reaction Models for Gasoline Surrogate Combustion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3K79_UkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=3K79_UkAAAAJ:LjlpjdlvIbIC,"Skeletal reaction models are derived for a four-component gasoline surrogate model via an instantaneous local sensitivity analysis technique. The sensitivities of the species mass fractions and the temperature with respect to the reaction rates are estimated by a reduced-order modeling (ROM) methodology. Termed ""implicit time-dependent basis CUR (implicit TDB-CUR),"" this methodology is based on the CUR matrix decomposition and incorporates implicit time integration for evolving the bases. The estimated sensitivities are subsequently analyzed to develop skeletal reaction models with a fully automated procedure. The 1389-species gasoline surrogate model developed at Lawrence Livermore National Laboratory (LLNL) is selected as the detailed kinetics model. The skeletal reduction procedure is applied to this model in a zero-dimensional constant-pressure reactor over a wide range of initial conditions. The performances of the resulting skeletal models are appraised by comparison against the results via the LLNL detailed model, and also predictions via other skeletal models. Two new skeletal models are developed consisting of 679 and 494 species, respectively. The first is an alternative to an existing model with the same number of species. The predictions with this model reproduces the detailed models vital flame results with less than 1% errors. The errors via the second model are less than 10%.",,,2025
1712,Skeletal reaction models for methane combustion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3K79_UkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=3K79_UkAAAAJ:eq2jaN3J8jMC,"A local-sensitivity-analysis technique is employed to generate new skeletal reaction models for methane combustion from the foundational fuel chemistry model (FFCM-1). The sensitivities of the thermo-chemical variables with respect to the reaction rates are computed via the forced-optimally time dependent (f-OTD) methodology. In this methodology, the large sensitivity matrix containing all local sensitivities is modeled as a product of two low-rank time-dependent matrices. The evolution equations of these matrices are derived from the governing equations of the system. The modeled sensitivities are computed for the auto-ignition of methane at atmospheric and high pressures with different sets of initial temperatures, and equivalence ratios. These sensitivities are then analyzed to rank the most important (sensitive) species. A series of skeletal models with different number of species and levels of accuracy in …",Elsevier,,2024
1713,Development of a Boron Nitride Precursor Chemical Kinetic Model Using Reaction Mechanism Generator (RMG) Framework,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3K79_UkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=3K79_UkAAAAJ:N5tVd3kTz84C,"Ceramic fibers coated with thin films of boron nitride (BN) is one approach to extend the survivability of high-temperature ceramic-matrix composite (CMC) materials in aerospace applications. Similarly, boron carbide (BC) is extensively used in various high-temperature industrial applications. Detailed chemical kinetic models that describe both BN and BC deposition pathways are needed to better understand the finite-rate effects that influence the quality and quantification of deposition process. Currently, only very limited models are available that describe the deposition of either BC or BN coatings. In this work, the Reaction Mechanism Generator (RMG) program which currently excludes boron chemistry is expanded to include a comprehensive set of species and reactions associated with boron. Newly generated kinetic models are then used in CANTERA reactor framework to predict the reagent decomposition …",,,2024
1714,Life Cycle Analysis of SiC Samples in a Stagnation-Point Reacting Flow,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3K79_UkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=3K79_UkAAAAJ:WqliGbK-hY8C,"A laboratory scale high-pressure flow reactor has been developed to study the interaction of a steam jet with various advanced ceramic and environmental barrier coating materials. Previous research studies were conducted at close to atmospheric pressure and have proposed an empirical relation for material surface recession. But none of them have been able to extract a pressure dependence factor with high fidelity. To address this deficiency, in the present study test conditions of steam at 1400 Celsius, pressures up to 5 atm, and velocities exceeding 200 m/s (positioned at 1 mm from the surface and at variable impinging angles) have been considered. These conditions mimic the local water molecule number density and velocity in actual gas turbine engine components, with test duration exceeding 24 hours. The initial life cycle data of Chemical Vapour Deposited Silicon Carbide (CVD SiC) interactions …",American Society of Mechanical Engineers,,2023
1715,Skeletal Reaction Models for Atmospheric and High Pressure Combustion of Methane,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3K79_UkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=3K79_UkAAAAJ:JoZmwDi-zQgC,"Skeletal reaction mechanisms for atmospheric and high pressure combustion of methane are generated from the foundational fuel chemistry model (FFCM-1) via the forced-optimally time dependent (f-OTD) methodology. In the f-OTD methodology, the sensitivity matrix, ie, a large matrix containing all local sensitivities of a system, is modeled as the multiplication of two low-rank time-dependent matrices. The evolution equations of these matrices are derived from the governing equations of the system. For skeletal mechanism reduction, the sensitivity of mass fractions and temperature with respect to the reaction rates are considered. These modeled sensitivities are computed for the auto-ignition problem with different sets of initial temperatures, pressures, and equivalence ratios. The calculated sensitivities are then analyzed to rank the most sensitive species. A series of skeletal mechanisms with different levels of …",American Physical Society,,2022
1716,Mobile data offloading through opportunistic communications and social participation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=diIore8AAAAJ&citation_for_view=diIore8AAAAJ:WJVC3Jt7v1AC,"3G networks are currently overloaded, due to the increasing popularity of various applications for smartphones. Offloading mobile data traffic through opportunistic communications is a promising solution to partially solve this problem, because there is almost no monetary cost for it. We propose to exploit opportunistic communications to facilitate information dissemination in the emerging Mobile Social Networks (MoSoNets) and thus reduce the amount of mobile data traffic. As a case study, we investigate the target-set selection problem for information delivery. In particular, we study how to select the target set with only k users, such that we can minimize the mobile data traffic over cellular networks. We propose three algorithms, called Greedy, Heuristic, and Random, for this problem and evaluate their performance through an extensive trace-driven simulation study. Our simulation results verify the efficiency of these …",IEEE,,2011
1717,Simple heuristics for unit disk graphs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=diIore8AAAAJ&citation_for_view=diIore8AAAAJ:nRpfm8aw39MC,"Unit disk graphs are intersection graphs of circles of unit radius in the plane. We present simple and provably good heuristics for a number of classical NP‐hard optimization problems on unit disk graphs. The problems considered include maximum independent set, minimum vertex cover, minimum coloring, and minimum dominating set. We also present an on‐line coloring heuristic which achieves a competitive ratio of 6 for unit disk graphs. Our heuristics do not need a geometric representation of unit disk graphs. Geometric representations are used only in establishing the performance guarantees of the heuristics. Several of our approximation algorithms can be extended to intersection graphs of circles of arbitrary radii in the plane, intersection graphs of regular polygons, and intersection graphs of higher dimensional regular objects.","Wiley Subscription Services, Inc., A Wiley Company",,1995
1718,Algorithmic aspects of topology control problems for ad hoc networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=diIore8AAAAJ&citation_for_view=diIore8AAAAJ:hsZV8lGYWTMC,"Topology control problems are concerned with the assignment of power values to the nodes of an ad hoc network so that the power assignment leads to a graph topology satisfying some specified properties. This paper considers such problems under several optimization objectives, including minimizing the maximum power and minimizing the total power. A general approach leading to a polynomial algorithm is presented for minimizing maximum power for a class of graph properties called textbf monotone properties. The difficulty of generalizing the approach to properties that are not monotone is discussed. Problems involving the minimization of total power are known to be bf NP -complete even for simple graph properties. A general approach that leads to an approximation algorithm for minimizing the total power for some monotone properties is presented. Using this approach, a new approximation algorithm for …",,,2002
1719,NC-approximation schemes for NP-and PSPACE-hard problems for geometric graphs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=diIore8AAAAJ&citation_for_view=diIore8AAAAJ:jU7OWUQzBzMC,"We present NC-approximation schemes for a number of graph problems when restricted to geometric graphs including unit disk graphs and graphs drawn in a civilized manner. Our approximation schemes exhibit the same time versus performance trade-off as the best known approximation schemes for planar graphs. We also define the concept of λ-precision unit disk graphs and show that for such graphs the approximation schemes have a better time versus performance trade-off than the approximation schemes for arbitrary unit disk graphs. Moreover, compared to unit disk graphs, we show that for λ-precision unit disk graphs many more graph problems have efficient approximation schemes. Our NC-approximation schemes can also be extended to obtain efficient NC-approximation schemes for several PSPACE-hard problems on unit disk graphs specified using a restricted version of the hierarchical specification …",Academic Press,,1998
1720,"Scenario Projections of COVID-19 Burden in the US, 2024-2025",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=diIore8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=diIore8AAAAJ:v_xunPV0uK0C,"Importance COVID-19 remains a disease with high burden in the US, prompting continued debate about optimal targets for annual vaccination. Objective To project COVID-19 burden in the US for April 2024 to April 2025 under 6 scenarios of immune escape (20% and 50% per year) and levels of vaccine recommendation (no recommendation, vaccination for individuals at high risk only, vaccination for all eligible groups) and to assess the potential benefit of vaccine recommendations in reducing disease burden. Design, Setting, and Participants For this decision analytical model, the US Scenario Modeling Hub, a collaborative modeling effort, convened 9 teams to provide scenario projections of US COVID-19 hospitalizations and deaths for April 2024 to April 2025, under 6 scenarios combining levels of immune escape and possible vaccine recommendations. Exposure Annually reformulated vaccines were assumed to …",American Medical Association,,2025
1721,Welfare optimization for resource allocation with peer effects,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=diIore8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=diIore8AAAAJ:ufKn5pxu7C0C,"Allocating students to schools or universities, people to teams or groups, people to urban housing, and matching users on social platforms are prominent examples of allocating limited goods, spaces, or positions to optimize social welfare. We study a welfare maximization problem that arises when such resource allocation scenarios involve peer effects, where people have preferences over the others who are nearby (e.g. their classmates, teammates, neighbors, or partners). We first develop a unified mathematical framework for this “position allocation problem,” which assigns people to positions in a given network, with people caring about both their positions and their neighbors’ attributes. We show that welfare maximization for the corresponding position allocation problem is computationally intractable, even when people have preferences that depend only on who is allocated to nearby positions, and those …",Oxford University Press,,2025
1722,Localized risk perception triggers early behavioral adaptations in epidemics on networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=diIore8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=diIore8AAAAJ:wkm4DBaukwsC,"The contact structure of the population shapes the progression of epidemics. Nonetheless, the joint evolution of individual behavioral adaptations and disease dynamics on networks remains poorly understood. We use a behavioral-epidemiological model to study the joint evolution of human behavior and epidemic dynamics on networks. Our results reveal how the adaptation of local social structures, influenced by risk-benefit trade-offs, affects the dynamics of epidemics. We allow the epidemic and population-level behavior dynamics to emerge from the heterogeneous behavioral responses of individuals. Our framework assumes that individuals adjust their contact structure by temporarily dropping or maintaining connections based on perceived benefits and risks. Our results show that behavioral responses induced by localized risk perceptions lead to premature population-level responses relative to epidemic dynamics. Specifically, individual efforts peak at the epidemic maximum, while population-level efforts remain modest. We explore the robustness and extensions incorporating heterogeneous subpopulations.",,,2025
1723,IGraSS: Learning to Identify Infrastructure Networks from Satellite Imagery by Iterative Graph-constrained Semantic Segmentation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=diIore8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=diIore8AAAAJ:CCeGMaHljPEC,"Accurate canal network mapping is essential for water management, including irrigation planning and infrastructure maintenance. State-of-the-art semantic segmentation models for infrastructure mapping, such as roads, rely on large, well-annotated remote sensing datasets. However, incomplete or inadequate ground truth can hinder these learning approaches. Many infrastructure networks have graph-level properties such as reachability to a source (like canals) or connectivity (roads) that can be leveraged to improve these existing ground truth. This paper develops a novel iterative framework IGraSS, combining a semantic segmentation module-incorporating RGB and additional modalities (NDWI, DEM)-with a graph-based ground-truth refinement module. The segmentation module processes satellite imagery patches, while the refinement module operates on the entire data viewing the infrastructure network as a graph. Experiments show that IGraSS reduces unreachable canal segments from around 18% to 3%, and training with refined ground truth significantly improves canal identification. IGraSS serves as a robust framework for both refining noisy ground truth and mapping canal networks from remote sensing imagery. We also demonstrate the effectiveness and generalizability of IGraSS using road networks as an example, applying a different graph-theoretic constraint to complete road networks.",,,2025
1724,More adaptive algorithms for adversarial bandits,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2L2cR-kAAAAJ&citation_for_view=2L2cR-kAAAAJ:2osOgNQ5qMEC,"We develop a novel and generic algorithm for the adversarial multi-armed bandit problem (or more generally the combinatorial semi-bandit problem). When instantiated differently, our algorithm achieves various new data-dependent regret bounds improving previous work. Examples include: 1) a regret bound depending on the variance of only the best arm; 2) a regret bound depending on the first-order path-length of only the best arm; 3) a regret bound depending on the sum of the first-order path-lengths of all arms as well as an important negative term, which together lead to faster convergence rates for some normal form games with partial feedback; 4) a regret bound that simultaneously implies small regret when the best arm has small loss {\it and} logarithmic regret when there exists an arm whose expected loss is always smaller than those of other arms by a fixed gap (eg the classic iid setting). In some cases, such as the last two results, our algorithm is completely parameter-free. The main idea of our algorithm is to apply the optimism and adaptivity techniques to the well-known Online Mirror Descent framework with a special log-barrier regularizer. The challenges are to come up with appropriate optimistic predictions and correction terms in this framework. Some of our results also crucially rely on using a sophisticated increasing learning rate schedule.",PMLR,Conference On Learning Theory,2018
1725,Linear last-iterate convergence in constrained saddle-point optimization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2L2cR-kAAAAJ&citation_for_view=2L2cR-kAAAAJ:0EnyYjriUFMC,"Optimistic Gradient Descent Ascent (OGDA) and Optimistic Multiplicative Weights Update (OMWU) for saddle-point optimization have received growing attention due to their favorable last-iterate convergence. However, their behaviors for simple bilinear games over the probability simplex are still not fully understood - previous analysis lacks explicit convergence rates, only applies to an exponentially small learning rate, or requires additional assumptions such as the uniqueness of the optimal solution. In this work, we significantly expand the understanding of last-iterate convergence for OGDA and OMWU in the constrained setting. Specifically, for OMWU in bilinear games over the simplex, we show that when the equilibrium is unique, linear last-iterate convergence is achieved with a learning rate whose value is set to a universal constant, improving the result of (Daskalakis & Panageas, 2019b) under the same assumption. We then significantly extend the results to more general objectives and feasible sets for the projected OGDA algorithm, by introducing a sufficient condition under which OGDA exhibits concrete last-iterate convergence rates with a constant learning rate whose value only depends on the smoothness of the objective function. We show that bilinear games over any polytope satisfy this condition and OGDA converges exponentially fast even without the unique equilibrium assumption. Our condition also holds for strongly-convex-strongly-concave functions, recovering the result of (Hsieh et al., 2019). Finally, we provide experimental results to further support our theory.",,,2021
1726,"A new algorithm for non-stationary contextual bandits: Efficient, optimal and parameter-free",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2L2cR-kAAAAJ&citation_for_view=2L2cR-kAAAAJ:IjCSPb-OGe4C,"We propose the first contextual bandit algorithm that is parameter-free, efficient, and optimal in terms of dynamic regret. Specifically, our algorithm achieves dynamic regret for a contextual bandit problem with rounds, actions, switches and total variation in data distributions. Importantly, our algorithm is adaptive and does not need to know or ahead of time, and can be implemented efficiently assuming access to an ERM oracle. Our results strictly improve the bound of (Luo et al., 2018), and greatly generalize and improve the result of (Auer et al., 2018) that holds only for the two-armed bandit problem without contextual information. The key novelty of our algorithm is to introduce {\it replay phases}, in which the algorithm acts according to its previous decisions for a certain amount of time in order to detect non-stationarity while maintaining a good balance between exploration and exploitation.",PMLR,,2019
1727,Efficient contextual bandits in non-stationary worlds,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2L2cR-kAAAAJ&citation_for_view=2L2cR-kAAAAJ:Tyk-4Ss8FVUC,"Most contextual bandit algorithms minimize regret against the best fixed policy, a questionable benchmark for non-stationary environments that are ubiquitous in applications. In this work, we develop several efficient contextual bandit algorithms for non-stationary environments by equipping existing methods for iid problems with sophisticated statistical tests so as to dynamically adapt to a change in distribution. We analyze various standard notions of regret suited to non-stationary environments for these algorithms, including interval regret, switching regret, and dynamic regret. When competing with the best policy at each time, one of our algorithms achieves regret if there are rounds with stationary periods, or more generally where is some non-stationarity measure. These results almost match the optimal guarantees achieved by an inefficient baseline that is a variant of the classic Exp4 algorithm. The dynamic regret result is also the first one for efficient and fully adversarial contextual bandit. Furthermore, while the results above require tuning a parameter based on the unknown quantity or , we also develop a parameter free algorithm achieving regret . This improves and generalizes the best existing result by Karnin and Anava (2016) which only holds for the two-armed bandit problem.",PMLR,,2018
1728,Non-stationary reinforcement learning without prior knowledge: An optimal black-box approach,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2L2cR-kAAAAJ&citation_for_view=2L2cR-kAAAAJ:ULOm3_A8WrAC,"We propose a black-box reduction that turns a certain reinforcement learning algorithm with optimal regret in a (near-) stationary environment into another algorithm with optimal dynamic regret in a non-stationary environment, importantly without any prior knowledge on the degree of non-stationarity. By plugging different algorithms into our black-box, we provide a list of examples showing that our approach not only recovers recent results for (contextual) multi-armed bandits achieved by very specialized algorithms, but also significantly improves the state of the art for (generalzed) linear bandits, episodic MDPs, and infinite-horizon MDPs in various ways. Specifically, in most cases our algorithm achieves the optimal dynamic regret where is the number of rounds and and are the number and amount of changes of the world respectively, while previous works only obtain suboptimal bounds and/or require the knowledge of and .",PMLR,,2021
1729,An Improved Model-Free Decision-Estimation Coefficient with Applications in Adversarial MDPs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2L2cR-kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2L2cR-kAAAAJ:35N4QoGY0k4C,"We study decision making with structured observation (DMSO). Previous work (Foster et al., 2021b, 2023a) has characterized the complexity of DMSO via the decision-estimation coefficient (DEC), but left a gap between the regret upper and lower bounds that scales with the size of the model class. To tighten this gap, Foster et al. (2023b) introduced optimistic DEC, achieving a bound that scales only with the size of the value-function class. However, their optimism-based exploration is only known to handle the stochastic setting, and it remains unclear whether it extends to the adversarial setting. We introduce Dig-DEC, a model-free DEC that removes optimism and drives exploration purely by information gain. Dig-DEC is always no larger than optimistic DEC and can be much smaller in special cases. Importantly, the removal of optimism allows it to handle adversarial environments without explicit reward estimators. By applying Dig-DEC to hybrid MDPs with stochastic transitions and adversarial rewards, we obtain the first model-free regret bounds for hybrid MDPs with bandit feedback under several general transition structures, resolving the main open problem left by Liu et al. (2025). We also improve the online function-estimation procedure in model-free learning: For average estimation error minimization, we refine the estimator in Foster et al. (2023b) to achieve sharper concentration, improving their regret bounds from to (on-policy) and from to (off-policy). For squared error minimization in Bellman-complete MDPs, we redesign their two-timescale procedure, improving the regret bound from to . This is the first time a DEC …",,,2025
1730,An Improved Algorithm for Adversarial Linear Contextual Bandits via Reduction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2L2cR-kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2L2cR-kAAAAJ:vV6vV6tmYwMC,"We present an efficient algorithm for linear contextual bandits with adversarial losses and stochastic action sets. Our approach reduces this setting to misspecification-robust adversarial linear bandits with fixed action sets. Without knowledge of the context distribution or access to a context simulator, the algorithm achieves regret and runs in time, where is the feature dimension, is an upper bound on the number of linear constraints defining the action set in each round, is an upper bound on the number of actions in each round, and is number of rounds. This resolves the open question by Liu et al. (2023) on whether one can obtain regret in polynomial time independent of the number of actions. For the important class of combinatorial bandits with adversarial losses and stochastic action sets where the action sets can be described by a polynomial number of linear constraints, our algorithm is the first to achieve regret in polynomial time, while no prior algorithm achieves even regret in polynomial time to our knowledge. When a simulator is available, the regret bound can be improved to , where is the cumulative loss of the best policy.",,,2025
1731,From Average-Iterate to Last-Iterate Convergence in Games: A Reduction and Its Applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2L2cR-kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2L2cR-kAAAAJ:RYcK_YlVTxYC,"The convergence of online learning algorithms in games under self-play is a fundamental question in game theory and machine learning. Among various notions of convergence, last-iterate convergence is particularly desirable, as it reflects the actual decisions made by the learners and captures the day-to-day behavior of the learning dynamics. While many algorithms are known to converge in the average-iterate, achieving last-iterate convergence typically requires considerably more effort in both the design and the analysis of the algorithm. Somewhat surprisingly, we show in this paper that for a large family of games, there exists a simple black-box reduction that transforms the average iterates of an uncoupled learning dynamics into the last iterates of a new uncoupled learning dynamics, thus also providing a reduction from last-iterate convergence to average-iterate convergence. Our reduction applies to games where each player's utility is linear in both their own strategy and the joint strategy of all opponents. This family includes two-player bimatrix games and generalizations such as multi-player polymatrix games. By applying our reduction to the Optimistic Multiplicative Weights Update algorithm, we obtain new state-of-the-art last-iterate convergence rates for uncoupled learning dynamics in two-player zero-sum normal-form games: (1) an last-iterate convergence rate under gradient feedback, representing an exponential improvement in the dependence on the dimension (i.e., the maximum number of actions available to either player); and (2) an last-iterate convergence rate under bandit feedback, improving upon the previous best …",,,2025
1732,Decision Making in Hybrid Environments: A Model Aggregation Approach,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2L2cR-kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2L2cR-kAAAAJ:NaGl4SEjCO4C,"Recent work by Foster et al. (2021, 2022, 2023b) and Xu and Zeevi (2023) developed the framework of decision estimation coefficient (DEC) that characterizes the complexity of general online decision making problems and provides a general algorithm design principle. These works, however, either focus on the pure stochastic regime where the world remains fixed over time, or the pure adversarial regime where the world arbitrarily changes over time. For the hybrid regime where the dynamics of the world is fixed while the reward arbitrarily changes, they only give pessimistic bounds on the decision complexity. In this work, we propose a general extension of DEC that more precisely characterizes this case. Besides applications in special cases, our framework leads to a flexible algorithm design where the learner learns over subsets of the hypothesis set, trading estimation complexity with decision complexity, which could be of independent interest. Our work covers model-based learning and model-free learning in the hybrid regime, with a newly proposed extension of the bilinear classes (Du et al., 2021) to the adversarial-reward case. In addition, our method improves the best-known regret bounds for linear Q*/V* MDPs in the pure stochastic regime.",,,2025
1733,"HANQ: Hypergradients, Asymmetry, and Normalization for Fast and Stable Deep -Learning",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2L2cR-kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2L2cR-kAAAAJ:lSLTfruPkqcC,"In reinforcement learning (RL), deep \$Q\$-learning algorithms are often more sample- and compute-efficient than alternatives like the Monte Carlo policy gradient, but tend to suffer from instability that limits their use in practice. Some of this instability can be mitigated through a delayed *target network*, yet this doubles memory usage and arguably slows down convergence. In this work, we explore the possibility of stabilization (returns do not drop with further gradient steps) without sacrificing the speed of convergence (high returns do not require many gradient steps). Inspired by self-supervised learning (SSL) and adaptive optimization, we empirically arrive at three modifications to the standard deep \$Q\$-network (DQN) — no two of which work well alone in our experiments. These modifications are, in the order of our experiments: 1) an **A**symmetric *predictor* in the neural network, 2) a particular combination of **N**ormalization layers, and 3) **H**ypergradient descent on the learning rate. Aligning with prior work in SSL, **HANQ** (pronounced ""*hank*"") avoids DQN's target network, uses the same number of hyperparameters as DQN, and yet matches or exceeds DQN's performance in our offline RL experiments on three out of four environments.",,,2025
1734,Deep colorization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DiQc-qEAAAAJ&citation_for_view=DiQc-qEAAAAJ:u5HHmVD_uO8C,"This paper investigates into the colorization problem which converts a grayscale image to a colorful version. This is a very difficult problem and normally requires manual adjustment to achieve artifact-free quality. For instance, it normally requires human-labelled color scribbles on the grayscale target image or a careful selection of colorful reference images (eg, capturing the same scene in the grayscale target image). Unlike the previous methods, this paper aims at a high-quality fully-automatic colorization method. With the assumption of a perfect patch matching technique, the use of an extremely large-scale reference database (that contains sufficient color images) is the most reliable solution to the colorization problem. However, patch matching noise will increase with respect to the size of the reference database in practice. Inspired by the recent success in deep learning techniques which provide amazing modeling of large-scale data, this paper re-formulates the colorization problem so that deep learning techniques can be directly employed. To ensure artifact-free quality, a joint bilateral filtering based post-processing step is proposed. Numerous experiments demonstrate that our method outperforms the state-of-art algorithms both in terms of quality and speed.",,,2015
1735,A bayesian perspective on the deep image prior,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DiQc-qEAAAAJ&citation_for_view=DiQc-qEAAAAJ:UeHWp8X0CEIC,"The deep image prior was recently introduced as a prior for natural images. It represents images as the output of a convolutional network with random inputs. For"" inference"", gradient descent is performed to adjust network parameters to make the output match observations. This approach yields good performance on a range of image reconstruction tasks. We show that the deep image prior is asymptotically equivalent to a stationary Gaussian process prior in the limit as the number of channels in each layer of the network goes to infinity, and derive the corresponding kernel. This informs a Bayesian approach to inference. We show that by conducting posterior inference using stochastic gradient Langevin dynamics we avoid the need for early stopping, which is a drawback of the current approach, and improve results for denoising and impainting tasks. We illustrate these intuitions on a number of 1D and 2D signal reconstruction tasks.",,,2019
1736,Machine unlearning of pre-trained large language models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DiQc-qEAAAAJ&citation_for_view=DiQc-qEAAAAJ:-FonjvnnhkoC,"This study investigates the concept of the `right to be forgotten' within the context of large language models (LLMs). We explore machine unlearning as a pivotal solution, with a focus on pre-trained models--a notably under-researched area. Our research delineates a comprehensive framework for machine unlearning in pre-trained LLMs, encompassing a critical analysis of seven diverse unlearning methods. Through rigorous evaluation using curated datasets from arXiv, books, and GitHub, we establish a robust benchmark for unlearning performance, demonstrating that these methods are over times more computationally efficient than retraining. Our results show that integrating gradient ascent with gradient descent on in-distribution data improves hyperparameter robustness. We also provide detailed guidelines for efficient hyperparameter tuning in the unlearning process. Our findings advance the discourse on ethical AI practices, offering substantive insights into the mechanics of machine unlearning for pre-trained LLMs and underscoring the potential for responsible AI development.",,,2024
1737,A realistic evaluation of semi-supervised learning for fine-grained classification,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DiQc-qEAAAAJ&citation_for_view=DiQc-qEAAAAJ:Y0pCki6q_DkC,"We evaluate the effectiveness of semi-supervised learning (SSL) on a realistic benchmark where data exhibits considerable class imbalance and contains images from novel classes. Our benchmark consists of two fine-grained classification datasets obtained by sampling classes from the Aves and Fungi taxonomy. We find that recently proposed SSL methods provide significant benefits, and can effectively use out-of-class data to improve performance when deep networks are trained from scratch. Yet their performance pales in comparison to a transfer learning baseline, an alternative approach for learning from a few examples. Furthermore, in the transfer setting, while existing SSL methods provide improvements, the presence of out-of-class is often detrimental. In this setting, standard fine-tuning followed by distillation-based self-training is the most robust. Our work suggests that semi-supervised learning with experts on realistic datasets may require different strategies than those currently prevalent in the literature.",,,2021
1738,Colorization using neural network ensemble,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DiQc-qEAAAAJ&citation_for_view=DiQc-qEAAAAJ:9yKSN-GCB0IC,"This paper investigates into the colorization problem, which converts a grayscale image to a colorful version. This is a difficult problem and normally requires manual adjustment to achieve artifact-free quality. For instance, it normally requires human-labeled color scribbles on the grayscale target image or a careful selection of colorful reference images. The recent learning-based colorization techniques automatically colorize a grayscale image using a single neural network. Since different scenes usually have distinct color styles, it is difficult to accurately capture the color characteristics using a single neural network. We propose a mixture learning model representing the presence of sub-color-style within an overall image data set. We, therefore, ensemble multiple neural networks to obtain better color estimation performance than could be obtained from any of the constituent neural network alone. A two-step …",IEEE,,2017
1739,Representation Learning for Predicting Shape Selectivity in Nanoporous Zeolites,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DiQc-qEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DiQc-qEAAAAJ:mNrWkgRL2YcC,,AIChE,,2025
1740,Frame In-N-Out: Unbounded Controllable Image-to-Video Generation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DiQc-qEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DiQc-qEAAAAJ:cWzG1nlazyYC,"Controllability, temporal coherence, and detail synthesis remain the most critical challenges in video generation. In this paper, we focus on a commonly used yet underexplored cinematic technique known as Frame In and Frame Out. Specifically, starting from image-to-video generation, users can control the objects in the image to naturally leave the scene or provide breaking new identity references to enter the scene, guided by user-specified motion trajectory. To support this task, we introduce a new dataset curated semi-automatically, a comprehensive evaluation protocol targeting this setting, and an efficient identity-preserving motion-controllable video Diffusion Transformer architecture. Our evaluation shows that our proposed approach significantly outperforms existing baselines.",,,2025
1741,Probing the Mid-level Vision Capabilities of Self-Supervised Learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DiQc-qEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DiQc-qEAAAAJ:9c2xU6iGI7YC,"Mid-level vision capabilities--such as generic object localization and 3D geometric understanding--are not only fundamental to human vision but are also crucial for many real-world applications of computer vision. These abilities emerge with minimal supervision during the early stages of human visual development. Despite their significance, current self-supervised learning (SSL) approaches are primarily designed and evaluated for high-level recognition tasks, leaving their mid-level vision capabilities largely unexamined. In this study, we introduce a suite of benchmark protocols to systematically assess mid-level vision capabilities and present a comprehensive, controlled evaluation of 22 prominent SSL models across 8 mid-level vision tasks. Our experiments reveal a weak correlation between mid-level and high-level task performance. We also identify several SSL methods with highly imbalanced performance across mid-level and high-level capabilities, as well as some that excel in both. Additionally, we investigate key factors contributing to mid-level vision performance, such as pretraining objectives and network architectures. Our study provides a holistic and timely view of what SSL models have learned, complementing existing research that primarily focuses on high-level vision tasks. We hope our findings guide future SSL research to benchmark models not only on high-level vision tasks but on mid-level as well.",,,2025
1742,Learning 3D Representations from Procedural 3D Programs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DiQc-qEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DiQc-qEAAAAJ:QYdC8u9Cj1oC,"Self-supervised learning has emerged as a promising approach for acquiring transferable 3D representations from unlabeled 3D point clouds. Unlike 2D images, which are widely accessible, acquiring 3D assets requires specialized expertise or professional 3D scanning equipment, making it difficult to scale and raising copyright concerns. To address these challenges, we propose learning 3D representations from procedural 3D programs that automatically generate 3D shapes using simple primitives and augmentations. Remarkably, despite lacking semantic content, the 3D representations learned from the procedurally generated 3D shapes perform on par with state-of-the-art representations learned from semantically recognizable 3D models (e.g., airplanes) across various downstream 3D tasks, including shape classification, part segmentation, and masked point cloud completion. We provide a detailed analysis on factors that make a good 3D procedural program. Extensive experiments further suggest that current self-supervised learning methods on point clouds do not rely on the semantics of 3D shapes, shedding light on the nature of 3D representations learned.",,,2024
1743,Open vocabulary monocular 3d object detection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DiQc-qEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=DiQc-qEAAAAJ:IUKN3-7HHlwC,"In this work, we pioneer the study of open-vocabulary monocular 3D object detection, a novel task that aims to detect and localize objects in 3D space from a single RGB image without limiting detection to a predefined set of categories. We formalize this problem, establish baseline methods, and introduce a class-agnostic approach that leverages open-vocabulary 2D detectors and lifts 2D bounding boxes into 3D space. Our approach decouples the recognition and localization of objects in 2D from the task of estimating 3D bounding boxes, enabling generalization across unseen categories. Additionally, we propose a target-aware evaluation protocol to address inconsistencies in existing datasets, improving the reliability of model performance assessment. Extensive experiments on the Omni3D dataset demonstrate the effectiveness of the proposed method in zero-shot 3D detection for novel object categories, validating its robust generalization capabilities. Our method and evaluation protocols contribute towards the development of open-vocabulary object detection models that can effectively operate in real-world, category-diverse environments.",,,2024
1744,Transforming consumer health informatics through a patient work framework: connecting patients to context,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EnCQmzUAAAAJ&citation_for_view=EnCQmzUAAAAJ:lSLTfruPkqcC,"Designing patient-centered consumer health informatics (CHI) applications requires understanding and creating alignment with patients’ and their family members’ health-related activities, referred to here as ‘patient work’. A patient work approach to CHI draws on medical social science and human factors engineering models and simultaneously attends to patients, their family members, activities, and context. A patient work approach extends existing approaches to CHI design that are responsive to patients’ biomedical realities and personal skills and behaviors. It focuses on the embeddedness of patients’ health management in larger processes and contexts and prioritizes patients’ perspectives on illness management. Future research is required to advance (1) theories of patient work, (2) methods for assessing patient work, and (3) techniques for translating knowledge of patient work into CHI application …",Oxford University Press,,2015
1745,Ensuring full participation of people with disabilities in an era of telehealth,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EnCQmzUAAAAJ&citation_for_view=EnCQmzUAAAAJ:b0M2c_1WBrUC,"The widespread use of telehealth resulting from the COVID-19 pandemic has the potential to further exacerbate inequities faced by people with disabilities. Although, for some members of the disability community, the option to engage with telehealth may result in reduced barriers to care, for others, inadequate attention to the design, implementation, and policy dimensions may be detrimental. Addressing such considerations is imperative to mitigate health inequities faced by the disability community.",Oxford University Press,,2021
1746,Macroergonomic factors in the patient work system: examining the context of patients with chronic illness,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EnCQmzUAAAAJ&citation_for_view=EnCQmzUAAAAJ:YsMSGLbcyi4C,"Human factors/ergonomics recognises work as embedded in and shaped by levels of social, physical and organisational context. This study investigates the contextual or macroergonomic factors present in the health-related work performed by patients. We performed a secondary content analysis of findings from three studies of the work of chronically ill patients and their informal caregivers. Our resulting consolidated macroergonomic patient work system model identified 17 factors across physical, social and organisational domains and household and community levels. These factors are illustrated with examples from the three studies and discussed as having positive, negative or varying effects on health and health behaviour. We present three brief case studies to illustrate how macroergonomic factors combine across domains and levels to shape performance in expected and unexpected ways. Findings …",Taylor & Francis,,2017
1747,Patient ergonomics: 10-year mapping review of patient-centered human factors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EnCQmzUAAAAJ&citation_for_view=EnCQmzUAAAAJ:NaGl4SEjCO4C,"Patient ergonomics is the application of human factors or related disciplines to study and improve patients' and other non-professionals’ performance of effortful work activities in pursuit of health goals. We performed a mapping review of 212 full-text patient ergonomics publications in two conference proceedings, 2007–2017. The review revealed a robust and growing body of literature on patient ergonomics, particularly in the areas of aging and chronic disease, tools and technologies, and evaluations of patient-centered interventions on outcomes such as usability, user acceptance, and performance. Findings highlighted gaps deserving future research, including research with understudied populations such as children, informal caregivers, networks and collectives (groups), and marginalized populations; on topics such as health promotion and transitions of care; and using longitudinal and experimental study …",Elsevier,Applied ergonomics,2020
1748,Beyond traditional advertisements: leveraging Facebook’s social structures for research recruitment,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EnCQmzUAAAAJ&citation_for_view=EnCQmzUAAAAJ:IWHjjKOFINEC,"Background Obtaining access to a demographically and geographically diverse sample for health-related research can be costly and time consuming. Previous studies have reported mixed results regarding the potential of using social media-based advertisements to overcome these challenges. Objective Our aim was to develop and assess the feasibility, benefits, and challenges of recruiting for research studies related to consumer health information technology (IT) by leveraging the social structures embedded in the social networking platform, Facebook. Methods Two recruitment strategies that involved direct communication with existing Facebook groups and pages were developed and implemented in two distinct populations. The first recruitment strategy involved posting a survey link directly to consenting groups and pages and was used to recruit Filipino-Americans to a study assessing the perceptions, use of, and preferences for consumer health IT. This study took place between August and December 2013. The second recruitment strategy targeted individuals with type 2 diabetes and involved creating a study-related Facebook group and asking administrators of other groups and pages to publicize our group to their members. Group members were then directly invited to participate in an online pre-study survey. This portion of a larger study to understand existing health management practices as a foundation for consumer health IT design took place between May and June 2014. In executing both recruitment strategies, efforts were …",JMIR Publications Inc.,,2014
1749,Designing and implementing exoskeleton devices for nurses with acute and chronic pain,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EnCQmzUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=EnCQmzUAAAAJ:t7zJ5fGR-2UC,"Nursing is classified as a high-risk occupation due to significant physical demands and lack of ergonomic support. With age, nurses are increasingly likely to develop acute and/or chronic pain (ACP), exacerbating the nursing shortage. Nurses/nurse managers with ACP may benefit from exoskeletons tailored to their ergonomic needs. Our objective was to elicit the social and organizational factors important to exoskeleton design and implementation for nurses/nurse managers with ACP working in long-term care facilities. We conducted a thematic analysis of surveys and interview data of predominantly. Black/African American nurses/nurse managers. Results highlighted potential social impacts on disabled patients being cared for by a nurse in an exoskeleton, exoskeleton training considerations for leaders of long-term care facilities, anticipated pressures to increase productivity due to exoskeleton use, and …",Elsevier,,2025
1750,"A perspective on engaging the disability community in exoskeleton design, implementation, and policymaking",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EnCQmzUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=EnCQmzUAAAAJ:0KyAp5RtaNEC,"Cutting-edge exoskeleton technologies are being developed to rehabilitate older adult patients in medical settings and prevent injury of able-bodied individuals in industrial settings. However, both medical and occupational exoskeletons offer yet underrecognized opportunities to support individuals across the full range of disabled experiences. This perspective piece offers guidance towards design, implementation, and policy for exoskeletons to be used by a diverse set of disabled individuals. To improve the usefulness, usability, and safety of exoskeletons for disabled users, ergonomists can employ inclusive design, universal design, user-centered design, and participatory design principles. In applying these principles, ergonomists must partner with disabled users as they are experts of their own different and overlapping physical, cognitive, sensory, and mental-health-related disabilities. This partnership should …",Taylor & Francis,Ergonomics,2025
1751,Disability data futures: Achievable imaginaries for AI and disability data justice,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EnCQmzUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=EnCQmzUAAAAJ:ZfRJV9d4-WMC,"Data are the medium through which individuals’ identities and experiences are represented in contemporary practice, and AI is increasingly mediating between people, data, and decisions. The history of data and AI is often one of disability exclusion, oppression, and the reduction of disabled experience; left unchallenged, the current proliferation of AI and data systems thus risks further automating ableism behind the veneer of algorithmic neutrality. However, exclusionary histories do not preclude inclusive futures, and intersectional, interdisciplinary, and disability-led visions can chart new paths for collective action to achieve futures founded in disability justice. This chapter brings together an international and transdisciplinary team of academics, disabled scholars and disability advocates working at the nexus of disability, data, and AI, to articulate achievable imaginaries for artificial intelligence and disability data …",Springer Nature Switzerland,,2025
1752,"Using American Sign Language–Fluent Community Health Navigators to Advance Cancer Screening Adherence through Videoconferencing With Deaf, Deafblind, and Hard of Hearing Adults …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EnCQmzUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=EnCQmzUAAAAJ:nrtMV_XWKgEC,"Background Cancer screening nonadherence persists among adults who are deaf, deafblind, and hard of hearing (DDBHH). These barriers span individual, clinician, and health care system levels, contributing to difficulties understanding cancer information, accessing screening services, and following treatment directives. Critical communication barriers include ineffective patient-physician communication, limited access to American Sign Language (ASL) cancer information, misconceptions about medical procedures, insurance navigation difficulties, and intersectional barriers for multiply marginalized individuals. Objective This randomized controlled trial addresses these barriers by implementing the first videoconference-based study of ASL-fluent community health navigators (ASL-CHNs) to improve cancer screening adherence among adults who are DDBHH. The study tests whether ASL-CHN intervention results in greater adherence to cancer screening guidelines, improved patient-physician communication ratings, and increased cancer knowledge compared to standard care. Methods The study uses a videoconference-delivered, block-randomized design stratifying 200 participants who are DDBHH by age and sex, with 100 participants assigned to the ASL-CHN intervention and 100 to standard care. All participants are confirmed as nonadherent to at least 1 of 5 age-appropriate cancer screening guidelines recommended by the United States Preventive Services Task Force for breast, cervical, colorectal, lung, and prostate cancers. Recruitment occurred nationwide through multiple …","JMIR Publications Inc., Toronto, Canada",,2025
1753,A call for integrated approaches in digital technology design for aging and disability,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=EnCQmzUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=EnCQmzUAAAAJ:j8SEvjWlNXcC,"The fields of aging and disability often proceed as 2 distinct lines of inquiry and action in terms of digital technology design. Guidelines and standards in both spaces (e.g., web content accessibility guidelines) have had suboptimal impact due to limited comprehensiveness enforcement mechanisms. Standards also rarely account for variations within the disability and aging communities and the structural power of ageism and ableism. These concerns proliferate in the context of contemporary technology discourse (e.g., data privacy, generative artificial intelligence). There is an opportunity to bridge both fields given that aging and disability can lead to distinct but overlapping experiences and technological needs and because of the multiple ways aging and disability may be simultaneously experienced. Joint efforts are essential to building the political power necessary to address current limitations and …",Oxford University Press,The Gerontologist,2025
1754,Caveolin-1 null mice are viable but show evidence of hyperproliferative and vascular abnormalities,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhrxAmAAAAAJ&citation_for_view=RhrxAmAAAAAJ:u5HHmVD_uO8C,"Caveolin-1 is the principal structural protein of caveolae membranes in fibroblasts and endothelia. Recently, we have shown that the human CAV-1 gene is localized to a suspected tumor suppressor locus, and mutations in Cav-1 have been implicated in human cancer. Here, we created a caveolin-1 null (CAV-1 −/−) mouse model, using standard homologous recombination techniques, to assess the role of caveolin-1 in caveolae biogenesis, endocytosis, cell proliferation, and endothelial nitric-oxide synthase (eNOS) signaling. Surprisingly, Cav-1 null mice are viable. We show that these mice lack caveolin-1 protein expression and plasmalemmal caveolae. In addition, analysis of cultured fibroblasts from Cav-1 null embryos reveals the following: (i) a loss of caveolin-2 protein expression; (ii) defects in the endocytosis of a known caveolar ligand, i.e.fluorescein isothiocyanate-albumin; and (iii) a hyperproliferative …",Elsevier,,2001
1755,Physiology of penile erection and pathophysiology of erectile dysfunction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhrxAmAAAAAJ&citation_for_view=RhrxAmAAAAAJ:hGdtkIFZdKAC,"Until recently, erectile dysfunction (ED) was treated by either sexual counseling or penile prosthesis implantation. The advent of intracavernous and transurethral agents has expanded the number of therapeutic options available to ED patients. Furthermore, the approval of oral sildenafil for the treatment of ED in 1998 has prompted an increased awareness of the disease process. With ED now amenable to pharmacologic solutions, research is continuously underway to elucidate the mechanisms underlying the pathophysiologic basis of ED. The hemodynamic changes associated with each erectile event require the integrity of the penile vasculature and neural pathways. Studies that scrutinize the pathophysiology of ED have revealed various modulators or agents that may play a significant role in penile erection. These agents have been demonstrated to mediate their effects through modulation with gap junctions …",Current Medicine Group,Atlas of Male Sexual Dysfunction,2004
1756,The influence of electrospun aligned poly (epsilon-caprolactone)/collagen nanofiber meshes on the formation of self-aligned skeletal muscle myotubes.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhrxAmAAAAAJ&citation_for_view=RhrxAmAAAAAJ:pYKElYtJMmwC,"Current treatment options for restoring large skeletal muscle tissue defects due to trauma or tumor ablation are limited by the host muscle tissue availability and donor site morbidity of muscle flap implantation. Creation of implantable functional muscle tissue that could restore muscle defects may bea possible solution. To engineer functional muscle tissue for reconstruction, scaffolds that mimic native fibers need to be developed. In this study we examined the feasibility of using poly (epsilon-caprolactone)(PCL)/collagen based nanofibers using electrospinning as a scaffold system for implantable engineered muscle. We investigated whether electrospun nanofibers could guide morphogenesis of skeletal muscle cells and enhance cellular organization. Nanofibers with different fiber orientations were fabricated by electrospinning with a blend of PCL and collagen. Human skeletal muscle cells (hSkMCs) were seeded onto the electrospun PCL/collagen nanofiber meshes and analyzed for cell adhesion, proliferation and organization. Our results show that unidirectionally oriented nanofibers significantly induced muscle cell alignment and myotube formation as compared to randomly oriented nanofibers. The aligned composite nanofiber scaffolds seeded with skeletal muscle cells may provide implantable functional muscle tissues for patients with large muscle defects.",,,2008
1757,Summary of the recommendations on sexual dysfunctions in men,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhrxAmAAAAAJ&citation_for_view=RhrxAmAAAAAJ:u-x6o8ySG0sC,"Introduction There are few published guidelines for the management of sexual dysfunctions in men and women, despite the prevalence and lack of attention to these problems. Disorders of sexual function in men include erectile dysfunction, orgasm/ejaculation disorders, priapism, and Peyronie's disease. Aim To provide evidence‐based and expert‐opinion consensus guidelines for the clinical management of men's sexual dysfunctions. Methods An International Consultation in collaboration with major urological and sexual medicine societies assembled over 200 multidisciplinary experts from 60 countries into 17 consultation committees. Committee members established the scope and objectives for each chapter. Following intensive review of available data and publications, committees developed evidence‐based guidelines in each area …",Oxford University Press,,2004
1758,Caveolin-2-deficient mice show evidence of severe pulmonary dysfunction without disruption of caveolae,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhrxAmAAAAAJ&citation_for_view=RhrxAmAAAAAJ:9yKSN-GCB0IC,"Caveolin-2 is a member of the caveolin gene family with no known function. Although caveolin-2 is coexpressed and heterooligomerizes with caveolin-1 in many cell types (most notably adipocytes and endothelial cells), caveolin-2 has traditionally been considered the dispensable structural partner of the widely studied caveolin-1. We now directly address the functional significance of caveolin-2 by genetically targeting the caveolin-2 locus (Cav-2) in mice. In the absence of caveolin-2 protein expression, caveolae still form and caveolin-1 maintains its localization in plasma membrane caveolae, although in certain tissues caveolin-1 is partially destabilized and shows modestly diminished protein levels. Despite an intact caveolar membrane system, the Cav-2-null lung parenchyma shows hypercellularity, with thickened alveolar septa and an increase in the number of endothelial cells. As a result of these …",Taylor & Francis,,2002
1759,Bioreactor and reseeding chamber system and related methods thereof,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhrxAmAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RhrxAmAAAAAJ:z6xuaG2dYH0C,An integrated bioreactor and reseeding chamber system and a separate bioreactor and complimentary reseeding chamber system comprising a bioreactor and a separate reseeding chamber. The bioreactor comprises a bioreactor chamber; a first groove attached to the bioreactor chamber; a second groove removably attached to the bioreactor chamber. A first bar and a second bar may be removably inserted into the first groove and the second groove respectively. Each of the first bar and the second bar may have at least an oval hole. At least a crossbar is attached substantially perpendicularly to the first bar and the second bar to form a crossbar-bars construct through the oval holes. A knob may be installed on each of the crossbars. The reseeding chamber may comprise dividers fixedly attached to a bottom of the reseeding chamber.,,,2025
1760,Cell-scale porosity minimizes foreign body reaction and promotes innervated myofiber formation after volumetric muscle loss,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhrxAmAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RhrxAmAAAAAJ:YPNY0knpFBYC,"Volumetric muscle loss (VML) from severe traumatic injuries results in irreversible loss of contractile tissue and permanent functional deficits. These injuries resist endogenous healing and clinical treatment due to excessive inflammation, leading to fibrosis, muscle fiber denervation, and impaired regeneration. Using a rodent tibialis anterior VML model, this study demonstrates microporous annealed particle (MAP) hydrogel scaffolds as a biomaterial platform for improved muscle regeneration. Unlike bulk (nanoporous) hydrogel scaffolds, MAP scaffolds enhance integration by preventing a foreign body reaction, slowing implant degradation, and promoting regenerative macrophage polarization. Cell migration and angiogenesis occur throughout the implant before MAP scaffold degradation, with muscle fibers and neuromuscular junctions forming within the scaffolds. These structures continue developing as the …",Nature Publishing Group UK,,2025
1761,التقييم الوظيفي في الجسم الحي لعضلة الجرذ بعد الإنشاء الجراحي لإصابة فقدان العضلات الحجمي (VML),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RhrxAmAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=RhrxAmAAAAAJ:rLGzs9wiiwIC,ينتشر فقدان العضلات الحجمي (VML) في السكان المدنيين والعسكريين ويمثل إصابة عضلية هيكلية منهكة تتجاوز قدرة الجسم على التجدد الطبيعية. لا تعطل هذه الإصابات ألياف العضلات فحسب ، بل تعطل أيضا الأعصاب والأوعية الدموية والمصفوفة خارج الخلية ، مما يطغى على القدرة التجددية للعضلات الهيكلية ويؤدي إلى تليف شديد وأوجه قصور دائمة في بنية العضلات ووظيفتها. الإدارة السريرية الحالية لها العديد من القيود ، وبالتالي ، فإن البحث مستمر لتطوير مناهج علاجية أكثر فعالية. ومع ذلك ، والجدير بالذكر أن الكثير من التركيز قبل السريري على إصابات VML قد ركز على عضلات الأطراف والجذع ، مع تحقيق محدود في العضلات القحفية الوجهية. قد توفر الاختلافات في بيولوجيا النمو والقدرة التجديدية بين عضلات القحف الوجهية والأطراف / الجذع رؤى حاسمة تقود المزيد من خيارات علاج VML الخاصة بالإصابة. علاوة على ذلك ، يعد تقييم التعافي الوظيفي أمرا بالغ الأهمية لإثبات الفعالية العلاجية. في هذا الصدد ، يعد اختبار تقلص العضلات في الجسم الحي مع تحفيز …,,,2024
1762,"A review of communication, driver characteristics, and controls aspects of cooperative adaptive cruise control (CACC)",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W0Cx7ZAAAAAJ&citation_for_view=W0Cx7ZAAAAAJ:sA9dB-pw3HoC,"Cooperative adaptive cruise control (CACC) systems have the potential to increase traffic throughput by allowing smaller headway between vehicles and moving vehicles safely in a platoon at a harmonized speed. CACC systems have been attracting significant attention from both academia and industry since connectivity between vehicles will become mandatory for new vehicles in the USA in the near future. In this paper, we review three basic and important aspects of CACC systems: communications, driver characteristics, and controls to identify the most challenging issues for their real-world deployment. Different routing protocols that support the data communication requirements between vehicles in the CACC platoon are reviewed. Promising and suitable protocols are identified. Driver characteristics related issues, such as how to keep drivers engaged in driving tasks during CACC operations, are discussed …",IEEE,IEEE Transactions on Intelligent Transportation Systems,2015
1763,A manifesto for future generation cloud computing: Research directions for the next decade,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W0Cx7ZAAAAAJ&citation_for_view=W0Cx7ZAAAAAJ:Gb6Hms-Uo9kC,"The Cloud computing paradigm has revolutionised the computer science horizon during the past decade and has enabled the emergence of computing as the fifth utility. It has captured significant attention of academia, industries, and government bodies. Now, it has emerged as the backbone of modern economy by offering subscription-based services anytime, anywhere following a pay-as-you-go model. This has instigated (1) shorter establishment times for start-ups, (2) creation of scalable global enterprise applications, (3) better cost-to-value associativity for scientific and high-performance computing applications, and (4) different invocation/execution models for pervasive and ubiquitous applications. The recent technological developments and paradigms such as serverless computing, software-defined networking, Internet of Things, and processing at network edge are creating new opportunities for Cloud …",ACM,ACM computing surveys (CSUR),2018
1764,Task failure prediction in cloud data centers using deep learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W0Cx7ZAAAAAJ&citation_for_view=W0Cx7ZAAAAAJ:5rMqqAh47xYC,"A large-scale cloud data center needs to provide high service reliability and availability with low failure occurrence probability. However, current large-scale cloud data centers still face high failure rates due to many reasons such as hardware and software failures, which often result in task and job failures. Such failures can severely reduce the reliability of cloud services and also occupy huge amount of resources to recover the service from failures. Therefore, it is important to predict task or job failures before occurrence with high accuracy to avoid unexpected wastage. Many machine learning and deep learning based methods have been proposed for the task or job failure prediction by analyzing past system message logs and identifying the relationship between the data and the failures. In order to further improve the failure prediction accuracy of the previous machine learning and deep learning based methods …",IEEE,,2020
1765,Machine learning based workload prediction in cloud computing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W0Cx7ZAAAAAJ&citation_for_view=W0Cx7ZAAAAAJ:j7XjBeKFbTsC,"As a widely used IT service, more and more companies shift their services to cloud datacenters. It is important for cloud service providers (CSPs) to provide cloud service resources with high elasticity and cost-effectiveness and then achieve good quality of service (QoS) for their clients. However, meeting QoS with cost-effective resource is a challenging problem for CSPs because the workloads of Virtual Machines (VMs) experience variation over time. It is highly necessary to provide an accurate VMs workload prediction method for resource provisioning to efficiently manage cloud resources. In this paper, we first compare the performance of representative state-of-the-art workload prediction methods. We suggest a method to conduct the prediction a certain time before the predicted time point in order to allow sufficient time for task scheduling based on predicted workload. To further improve the prediction accuracy …",IEEE,,2020
1766,A survey of mobile crowdsensing techniques: A critical component for the internet of things,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W0Cx7ZAAAAAJ&citation_for_view=W0Cx7ZAAAAAJ:natZJ_-F0IUC,"Mobile crowdsensing serves as a critical building block for emerging Internet of Things (IoT) applications. However, the sensing devices continuously generate a large amount of data, which consumes much resources (e.g., bandwidth, energy, and storage) and may sacrifice the Quality-of-Service (QoS) of applications. Prior work has demonstrated that there is significant redundancy in the content of the sensed data. By judiciously reducing redundant data, data size and load can be significantly reduced, thereby reducing resource cost and facilitating the timely delivery of unique, probably critical information and enhancing QoS. This article presents a survey of existing works on mobile crowdsensing strategies with an emphasis on reducing resource cost and achieving high QoS. We start by introducing the motivation for this survey and present the necessary background of crowdsensing and IoT. We then present …",ACM,,2018
1767,Hack: Homomorphic acceleration via compression of the key-value cache for disaggregated llm inference,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W0Cx7ZAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=W0Cx7ZAAAAAJ:aCwMkEyfDy8C,"Disaggregated Large Language Model (LLM) inference decouples the compute-intensive prefill stage from the memory-intensive decode stage, allowing low-end, compute-focused GPUs for prefill and high-end, memory-rich GPUs for decode, which reduces cost while maintaining high throughput. However, transmitting Key-Value (KV) data between the two stages can be a bottleneck, especially for long prompts. Additionally, the computational overhead in the two stages is key for optimizing Job Completion Time (JCT), and KV data size can become prohibitive for long prompts and sequences. Existing KV quantization methods can alleviate transmission and memory bottlenecks, but they introduce significant dequantization overhead, exacerbating the computation time. We propose Homomorphic Acceleration via Compression of the KV cache (HACK) for disaggregated LLM inference. HACK eliminates the heavy …",,,2025
1768,Revisiting the Straggling Problem in GPU-based Distributed Deep Learning Training,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W0Cx7ZAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=W0Cx7ZAAAAAJ:eIKNFFVQvJAC,"The straggler problem has been extensively studied in CPU-based distributed deep learning (DL) training but has not received significant attention in homogeneous GPU-based distributed training, possibly because GPUs do not typically become bottlenecks in this scenario. In this paper, we conduct experiment measurements and find that the straggler problems persist in this scenario, primarily stemming from communication hurdles, compounded by computation delays, and stragglers substantially inflate resource consumption and training time by ∼50%. Existing straggler mitigation methods do not directly address the communication stragglers in this scenario, and they suffer from drawbacks such as prolonged latency in straggler removal, high resource consumption, or compromised training accuracy. To tackle these limitations, based on the insights derived from thorough measurements, we propose a Straggler …",IEEE,,2025
1769,Deep Learning Training Job Scheduling for Proactive Straggler Reduction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W0Cx7ZAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=W0Cx7ZAAAAAJ:sfsSB7lKuh0C,"In this work, from our trace-driven experimental measurements, we observed that despite employing homogeneous GPUs for distributed deep learning (DDL) training, stragglers persistently emerge, significantly prolonging time-to-accuracy (TTA) and squandering GPU resources. Previous approaches typically react to stragglers as they occur or are imminent during execution after scheduling, resulting in training delays before they are addressed and introducing additional overhead. To reduce the number of stragglers, this paper introduces a novel DDL training job scheduler for proactive straggler reduction (STRN), the first effort in mitigating stragglers during scheduling. STRN is devised based on our findings that various DDL jobs exhibit distinct sensitivities to straggling and a particular resource's overload, and the optimal synchronization strategy for a job hinges on its specific characteristics and operational …",IEEE,,2025
1770,MobiRescue: Optimal Dispatching of Rescue Teams under Flooding Disasters,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W0Cx7ZAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=W0Cx7ZAAAAAJ:r56sNq9gaawC,"Effective dispatching of rescue teams under flooding disasters is crucial. However, previous methods are either incapable of handling flooding disaster situations, or cannot accurately estimate the distribution of rescue requests and accordingly adjust the search of the rescue teams. We propose MobiRescue, a human Mobility based Rescue team dispatching system, which aims to maximize the total number of rescued people, minimize the rescue delay and the number of serving rescue teams. We studied a city-scale human mobility dataset collected under the Hurricane Florence, and observed that several natural and demographic factors are closely related to impact severity, and road segment passability must be considered. Accordingly, we first propose a Support Vector Machine based method to predict the distribution of rescue requests considering the disaster-related factors. Then, we design an Euler path …",IEEE,,2025
1771,DeepCompile: A Compiler-Driven Approach to Optimizing Distributed Deep Learning Training,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W0Cx7ZAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=W0Cx7ZAAAAAJ:CMPXdcK5v8EC,"The increasing scale of deep learning models has led to the development of various parallelization strategies for distributed training across accelerators. For example, fully sharded approaches like DeepSpeed ZeRO-3 and FSDP partition the parameters of each layer across multiple GPUs and gather them through communication when needed. These methods rely on optimizations such as prefetching, which initiates communication early to overlap it with computation and reduce communication overhead, and unsharding, which retains as many parameters in their unsharded form as possible to reduce communication volume. Although the timing of prefetching should be adjusted in response to dynamic memory usage during execution, these systems lack the flexibility to control it, which limits the benefits of prefetching. Moreover, they cannot anticipate how memory usage will change after prefetching is applied, making it difficult to combine it effectively with other optimizations such as unsharding. We present DeepCompile, which compiles user-defined models into computation graphs and applies a sequence of profiling-guided optimization passes for distributed training. Taking dynamic memory usage into account, these passes flexibly insert, reorder, or remove operations to improve communication-computation overlap, reduce memory pressure, and coordinate multiple optimizations in a unified manner. To evaluate the effectiveness of this design, we implemented a fully sharded approach like ZeRO-3 and FSDP on top of DeepCompile, along with three optimizations: proactive prefetching, selective unsharding, and adaptive offloading. We …",,,2025
1772,Shear deformation and fracture of human cortical bone,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yVzvXbkAAAAJ&citation_for_view=yVzvXbkAAAAJ:UeHWp8X0CEIC,"Bone can be viewed as a nano-fibrous composite with complex hierarchical structures. Its deformation and fracture behaviors depend on both the local structure and the type of stress applied. In contrast to the extensive studies on bone fracture under compression and tension, there is a lack of knowledge on the fracture process under shear, a stress state often exists in hip fracture. This study investigated the mechanical behavior of human cortical bone under shear, with the focus on the relation between the fracture pattern and the microstructure. Iosipescu shear tests were performed on notched rectangular bar specimens made from human cortical bone. They were prepared at different angles (i.e. 0°, 30°, 60° and 90°) with respect to the long axis of the femoral shaft. The results showed that human cortical bone behaved as an anisotropic material under shear with the highest shear strength (~ 50 MPa) obtained …",Elsevier,,2015
1773,Processing–structure–property relationships of Bi2WO6 nanostructures as visible-light-driven photocatalyst,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yVzvXbkAAAAJ&citation_for_view=yVzvXbkAAAAJ:u5HHmVD_uO8C,"QDS modified Bi2WO6 (BWO) nanostructures were processed by calcination at different temperatures. A strong correlation was found among the processing, structure and properties of the samples. With increasing calcination temperature from 200°C to 500°C, the crystallinity increased and the BWO QDS gradually disappeared from the nanostructures. Both surface area and band gap of the samples decreased. The light absorption of the samples became lower for the long-wavelength range, accompanied by a red shift of the absorption edge. The photocatalytic activity of the samples decreased after calcination at higher temperature. The competitive relations between crystallinity and surface area in affecting photocatalytic activity were discussed. The role of BWO QDS that played in enhancement of photocatalytic activity was also revealed by studying structure and property evolution of the calcined samples.",Elsevier,,2010
1774,"Three-dimensional structural interrelations between cells, extracellular matrix, and mineral in normally mineralizing avian leg tendon",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yVzvXbkAAAAJ&citation_for_view=yVzvXbkAAAAJ:Y0pCki6q_DkC,"The spatial-temporal relationship between cells, extracellular matrices, and mineral deposits is fundamental for an improved understanding of mineralization mechanisms in vertebrate tissues. By utilizing focused ion beam-scanning electron microscopy with serial surface imaging, normally mineralizing avian tendons have been studied with nanometer resolution in three dimensions with volumes exceeding tens of micrometers in range. These parameters are necessary to yield sufficiently fine ultrastructural details while providing a comprehensive overview of the interrelationships between the tissue structural constituents. Investigation reveals a complex lacuno-canalicular network in highly mineralized tendon regions, where ∼100 nm diameter canaliculi emanating from cell (tenocyte) lacunae surround extracellular collagen fibril bundles. Canaliculi are linked to smaller channels of ∼40 nm diameter, occupying …",National Academy of Sciences,,2020
1775,Bone mineral organization at the mesoscale: a review of mineral ellipsoids in bone and at bone interfaces,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yVzvXbkAAAAJ&citation_for_view=yVzvXbkAAAAJ:_FxGoFyzp5QC,"Much debate still revolves around bone architecture, especially at the nano- and microscale. Bone is a remarkable material where high strength and toughness coexist thanks to an optimized composition of mineral and protein and their hierarchical organization across several distinct length scales. At the nanoscale, mineralized collagen fibrils act as building block units. Despite their key role in biological and mechanical functions, the mechanisms of collagen mineralization and the precise arrangement of the organic and inorganic constituents in the fibrils remains not fully elucidated. Advances in three-dimensional (3D) characterization of mineralized bone tissue by focused ion beam-scanning electron microscopy (FIB-SEM) revealed mineral-rich regions geometrically approximated as prolate ellipsoids, much larger than single collagen fibrils. These structures have yet to become prominently recognized, studied …",Elsevier,Acta Biomaterialia,2022
1776,Breast cancer–secreted factors perturb murine bone growth in regions prone to metastasis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yVzvXbkAAAAJ&citation_for_view=yVzvXbkAAAAJ:WF5omc3nYNoC,"Breast cancer frequently metastasizes to bone, causing osteolytic lesions. However, how factors secreted by primary tumors affect the bone microenvironment before the osteolytic phase of metastatic tumor growth remains unclear. Understanding these changes is critical as they may regulate metastatic dissemination and progression. To mimic premetastatic bone adaptation, immunocompromised mice were injected with MDA-MB-231–conditioned medium [tumor-conditioned media (TCM)]. Subsequently, the bones of these mice were subjected to multiscale, correlative analysis including RNA sequencing, histology, micro–computed tomography, x-ray scattering analysis, and Raman imaging. In contrast to overt metastasis causing osteolysis, TCM treatment induced new bone formation that was characterized by increased mineral apposition rate relative to control bones, altered bone quality with less matrix and …",American Association for the Advancement of Science,,2021
1777,Mesoscale Mineral Clusters in Osteonal Bone Follow the Twisted Plywood Structure of Collagen,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yVzvXbkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=yVzvXbkAAAAJ:aqlVkmm33-oC,"The structure of bone at the nano to microscale contributes to its functions, including its mechanical strength. A new hierarchical feature was recently discovered at the mesoscale: ellipsoidal-shaped mineral clusters. While a great deal of imaging has been completed on bone, the packing and spatial organization between the mesoscale mineral clusters and nanoscale features, such as collagen fibrils, is largely absent. This is partly due to the technical 3D nanoscale imaging challenges, which have impacted the ability to resolve collagen fibril banding in fully mineralized bone in multiple planes, and partly due to a lack of image processing tools to visualize characteristic details of the collagen fibril and mineral cluster arrangement from 3D volumes. Herein, FIB-SEM nanotomography of mineralized osteonal bone revealed mineral clusters with an average diameter of 600-700 nm yielding an estimate of 8 clusters per …",Elsevier,,2025
1778,Recent Advances in Focused Ion Beam Methodologies for 3D Analysis of Biomineralizing Tissues across Multiple Length Scales,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yVzvXbkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=yVzvXbkAAAAJ:4TOpqqG69KYC,"Biomineralizing tissues such as bone, cartilage, and tendon exhibit a remarkable hierarchical organization, with structural features spanning the macro-to nanometer length scales [1, 2]. Historically, capturing these features in 3D posed a significant challenge because conventional methods such as transmission electron microscopy (TEM) and laboratory micro-CT cannot simultaneously provide ultrastructural details and a sufficiently large volume to encompass entire cells and their surrounding matrix. Focused ion beam-scanning electron microscopy (FIB-SEM), originally developed in the semiconductor industry, has emerged as a powerful solution to bridge this gap, enabling researchers to examine how minerals and organic matrices interrelate at multiple length scales–a key step for understanding tissue formation, growth, adaptation, and disease progression. Early FIB tomography studies of bone often involved …",Oxford University Press,Microscopy and Microanalysis,2025
1779,Gradients in lacunar morphology and cartilage mineralization reflect the mechanical function of the mouse femoral head epiphysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yVzvXbkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=yVzvXbkAAAAJ:_kc_bZDykSQC,"Mouse femurs are widely used to study bone development and disorders. The mammalian femoral head epiphysis, located between articular cartilage and a growth plate, critically maintains joint integrity during weight-bearing and supports femoral growth. Murine femoral head epiphyses are unusual in having no secondary ossification center (SOC). In this regard, a key question arises: How is the extracellular matrix (ECM) of the mouse femoral head epiphysis structured to balance the competing demands of mechanical stability and nutrient transport in the absence of a SOC? This study investigates the microstructure and ECM organization of normal young mouse femoral head epiphyses across multiple length scales and identifies distinct gradients in lacunar size, shape, mineral content, and collagen and mineral organization. Chondrocyte lacunae in deep epiphyseal zones are significantly larger, more spherical …",Elsevier,,2025
1780,Skeletal and dental tissue mineralization: The potential role of the endoplasmic reticulum/Golgi complex and the endolysosomal and autophagic transport systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yVzvXbkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=yVzvXbkAAAAJ:ULOm3_A8WrAC,"This paper presents a review of the potential role of the endoplasmic reticulum/Golgi complex and intracellular vesicles in mediating events leading to or associated with vertebrate tissue mineralization. The possible importance of these organelles in this process is suggested by observations that calcium ions accumulate in the tubules and lacunae of the endoplasmic reticulum and Golgi. Similar levels of calcium ions (approaching millimolar) are present in vesicles derived from endosomes, lysosomes and autophagosomes. The cellular level of phosphate ions in these organelles is also high (millimolar). While the source of these ions for mineral formation has not been identified, there are sound reasons for considering that they may be liberated from mitochondria during the utilization of ATP for anabolic purposes, perhaps linked to matrix synthesis. Published studies indicate that calcium and phosphate ions or …",Elsevier,Bone,2025
1781,Exploring Biomineralization Processes Using In Situ Liquid Transmission Electron Microscopy: A Review (Small 2/2025),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yVzvXbkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=yVzvXbkAAAAJ:YOwf2qJgpHMC,"Liquid electron microscopy is a newly established technique to study dynamic reactions at the nanoscale. In article number 2407539, Kathryn Grandfield and co-workers provide new insights into physiological and pathological biomineralization processes for a wide range of organisms, from bones and teeth to mineralizing bacteria.",,Small,2025
1782,Single-shot ultrafast coherent anti-Stokes Raman scattering of vibrational/rotational nonequilibrium,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pYJPFSAAAAAJ&citation_for_view=pYJPFSAAAAAJ:GnPB-g6toBAC,"The study of internal molecular energy transfer is important for a variety of nonequilibrium and nonthermal environments, including plasma-based manufacturing and materials treatment, medical device treatment applications, and plasma-assisted combustion. In the current work, hybrid femtosecond/picosecond coherent anti-Stokes Raman scattering spectroscopy is demonstrated for simultaneous, single-shot measurement of pure-rotational and rovibrational energy distributions in the highly nonequilibrium environment of a dielectric barrier discharge plasma. Detailed spatial distributions and shot-to-shot fluctuations of rotational temperatures spanning 325–450 K and corresponding vibrational temperatures of 1200–5000 K are recorded across the plasma and surrounding flow with high precision and accuracy. This approach allows concise measurements of vibrational/rotational energy distributions in …",Optical Society of America,,2017
1783,Interference-free gas-phase thermometry at elevated pressure using hybrid femtosecond/picosecond rotational coherent anti-Stokes Raman scattering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pYJPFSAAAAAJ&citation_for_view=pYJPFSAAAAAJ:4JMBOYKVnBMC,"Rotational-level-dependent dephasing rates and nonresonant background can lead to significant uncertainties in coherent anti-Stokes Raman scattering (CARS) thermometry under high-pressure, low-temperature conditions if the gas composition is unknown. Hybrid femtosecond/picosecond rotational CARS is employed to minimize or eliminate the influence of collisions and nonresonant background for accurate, frequency-domain thermometry at elevated pressure. The ability to ignore these interferences and achieve thermometric errors of <5% is demonstrated for N_2 and O_2 at pressures up to 15 atm. Beyond 15 atm, the effects of collisions cannot be ignored but can be minimized using a short probe delay (~6.5 ps) after Raman excitation, thereby improving thermometric accuracy with a time- and frequency-resolved theoretical model.",Optical Society of America,,2012
1784,Non-intrusive measurement techniques for flow characterization of hypersonic wind tunnels,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pYJPFSAAAAAJ&citation_for_view=pYJPFSAAAAAJ:vV6vV6tmYwMC,"This manuscript describes the wide variety of optical measurement techniques for characterizing the flow in hypersonic wind tunnels. The introduction briefly describes different types of hypersonic wind tunnels, why they are used, and typical freestream conditions including fluctuating quantities. Description of these conditions defines the challenge for measurement techniques which have varying degrees of accuracy and precision, and work only in certain temperature, density and/or speed regimes. The rest of the manuscript is broken up into sections, by measurement technique. Each technique is described and then several examples are provided. The concluding chapter compares and contrasts different aspects of the measurement techniques including accuracy, precision, spatial resolution and temporal resolution.",,"STO-VKI-LS on"" Flow Characterization and Modeling of Hypersonic Wind Tunnels""",2018
1785,Dual-pump vibrational/rotational femtosecond/picosecond coherent anti-Stokes Raman scattering temperature and species measurements,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pYJPFSAAAAAJ&citation_for_view=pYJPFSAAAAAJ:maZDTaKrznsC,"A method for simultaneous ro-vibrational and pure-rotational hybrid femtosecond/picosecond coherent anti-Stokes Raman scattering (fs/ps CARS) is presented for multi-species detection and improved temperature sensitivity from room temperature to flame conditions. vibrational and rotational Raman coherences are excited simultaneously using fs pump pulses at 660 and 798 nm, respectively, and a common fs Stokes pulse at 798 nm. A fourth narrowband 798 nm ps pulse probes all coherence states at a time delay that minimizes nonresonant background and the effects of collisions. The transition strength is concentration dependent, while the distribution among observed transitions is related to temperature through the Boltzmann distribution. The broadband excitation pulses and multiplexed signal are demonstrated for accurate thermometry from 298 to 2400 K and concentration …",Optical Society of America,,2014
1786,Vibrational femtosecond/picosecond coherent anti‐Stokes Raman scattering with enhanced temperature sensitivity for flame thermometry from 300 to 2400 K,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pYJPFSAAAAAJ&citation_for_view=pYJPFSAAAAAJ:M3NEmzRMIkIC,"Hybrid femtosecond/picosecond coherent anti‐Stokes Raman scattering (fs/ps CARS) of N2 has recently been demonstrated for gas‐phase thermometry in reacting flows, enabling frequency‐domain detection at high repetition rates with excellent chemical specificity and independence from the effects of collisions and nonresonant background. In this work, we overcome the limited sensitivity of vibrational fs/ps CARS thermometry of N2 below 1200 K by spectrally resolving J‐dependent rovibrational coherence revivals that occur 32 ps after initial excitation. The N2 rovibrational coherence is excited using broadband, 100‐fs pump and Stokes pulses and probed as a function of time using a narrowband, 5.8‐ps probe pulse (bandwidth of 2.5 cm−1). The rovibrational features exhibit sufficient temperature sensitivity below 1200 K for accurate thermometry using a simple, time‐dependent phenomenological model …",,,2015
1787,Potential of Sensing Ultraviolet Radiation for Hypersonic Flight,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pYJPFSAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pYJPFSAAAAAJ:738O_yMBCRsC,"Ultraviolet radiation from postshock excited-state species is a possible measurement target for flight parameter feedback sensors, but the feasibility and utility of such sensors have not yet been explored. This paper employs numerical simulations of hypersonic flowfields to estimate ultraviolet radiation generated by the bow shock of a hypothetical blunt-nosed vehicle. Multiple flowfields were generated to investigate the sensitivity of the ultraviolet radiation’s spectral features to varying freestream velocity and vehicle angle of attack. Computational solutions were reached by solving the Navier–Stokes equations coupled with a 19-species, two-temperature, finite-rate kinetic model for a two-dimensional grid around a blunt-nosed cone using NASA’s Data Parallel Line Relaxation fluid dynamic simulation suite. Discrete species and temperature compositions were extracted from the flow solutions along lines of sight …",American Institute of Aeronautics and Astronautics,,2025
1788,Counter-propagating fs/ps CARS for sub-100?? µm resolution gas-phase thermometry,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pYJPFSAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pYJPFSAAAAAJ:bFI3QPDXJZMC,"A novel, to our knowledge, counter-propagating (CoP) phase-matching configuration of hybrid femtosecond/picosecond coherent anti-Stokes Raman scattering (fs/ps CARS) for ultra-high-resolution measurements of gas temperature is demonstrated. The resulting spatial resolution is on the order of 10s of µm—more than an order of magnitude improvement over traditional phase-matching geometries—which enables spatially resolved gas-phase measurements of steep temperature gradients and minimizes effects of spatial averaging. Two additional advantages of this measurement system are the ability to simply control the location of the measurement volume by adjusting relative pulse timing and the size of the probe volume by adjusting pulse duration. The spatial resolution of the counter-propagating CARS (CoPCARS) system was quantified, and the gas temperature across a high-velocity microscale jet …",Optica Publishing Group,,2025
1789,Post-Shock Thermometry Using One-Dimensional fs/ps Coherent Anti-Stokes Raman Scattering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pYJPFSAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pYJPFSAAAAAJ:Tiz5es2fbqcC,"Spatially resolved measurements of post-shock temperatures in environments composed of predominately CO2 are performed using one-dimensional fs/ps CARS. Shifting from zero-dimensional to one-dimensional fs/ps CARS enables quantitative measurements along a line, allowing temperature gradients to be observed while also providing more measurement points to increase the likelihood of observing the propagating shock wave within the vicinity of the measurement location. Considerations for applying 1-D CARS in a post-shock environment relevant to atmospheric entry conditions are discussed.",,,2025
1790,Spatially-Resolved In-Situ Characterization of a Supersonic Combustor Using fs/ps CARS,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pYJPFSAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pYJPFSAAAAAJ:XiSMed-E-HIC,Temperature and qualitative C2H4 / N2 concentration measurements using hybrid femtosecond/picosecond coherent anti-Stokes Raman scattering (fs/ps CARS) are presented for an ethylene-fueled dual-mode scramjet combustor with a cavity flameholder in the University of Virginia Supersonic Combustion Facility (UVASCF). CARS measurements in locations which were previously inaccessible due to the use of high-energy nanosecond laser pulses are reported. The current work expands upon efforts deploying fs/ps CARS in the UVASCF to investigate how fuel injection impacts local thermodynamic properties and flame structure in the combustor. CARS temperature measurements in a fine grid throughout the cavity and relative C2H4 / N2 concentrations near the fuel injectors and above the cavity are presented for two fueling conditions of interest.,,,2025
1791,Coherent Control for Selective Excitation of Combustion Species in a Benchtop Flame Using fs/ps CARS,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pYJPFSAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=pYJPFSAAAAAJ:u9iWguZQMMsC,Hybrid fs/ps coherent anti-Stokes Raman scattering employing coherent control is presented for selective excitation of combustion-relevant species. Femtosecond pulse shaping is accomplished experimentally using a 4-f pulse shaper with a spatial light modulator at the Fourier plane. A feedback-controlled genetic algorithm for adaptive pulse shaping is used to optimize for the selective excitation of CO2 (near 1388 1/cm) and O2 (near 1556 1/cm) rovibrational transitions in a non-reacting flow. 0D fs/ps CARS measurements acquired in a near-adiabatic flame demonstrate the use of coherent control in a combustion environment.,,,2025
1792,NoDoze: Combatting Threat Alert Fatigue with Automated Provenance Triage,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09SohzcAAAAJ&citation_for_view=09SohzcAAAAJ:eQOLeE2rZwMC,"Large enterprises are increasingly relying on threat detection softwares (e.g., Intrusion Detection Systems) to allow them to spot suspicious activities. These softwares generate alerts which must be investigated by cyber analysts to figure out if they are true attacks. Unfortunately, in practice, there are more alerts than cyber analysts can properly investigate. This leads to a “threat alert fatigue” or information overload problem where cyber analysts miss true attack alerts in the noise of false alarms. In this paper, we present NoDoze to combat this challenge using contextual and historical information of generated threat alert in an enterprise. NoDoze first generates a causal dependency graph of an alert event. Then, it assigns an anomaly score to each event in the dependency graph based on the frequency with which related events have happened before in the enterprise. NoDoze then propagates those scores along the edges of the graph using a novel network diffusion algorithm and generates a subgraph with an aggregate anomaly score which is used to triage alerts. Evaluation on our dataset of 364 threat alerts shows that NoDoze decreases the volume of false alarms by 86%, saving more than 90 hours of analysts’ time, which was required to investigate those false alarms. Furthermore, NoDoze generated dependency graphs of true alerts are 2 orders of magnitude smaller than those generated by traditional tools without sacrificing the vital information needed for the investigation. Our system has a low average runtime overhead and can be deployed with any threat detection software.",,,2019
1793,Tactical Provenance Analysis for Endpoint Detection and Response Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09SohzcAAAAJ&citation_for_view=09SohzcAAAAJ:hqOjcs7Dif8C,"Endpoint Detection and Response (EDR) tools provide visibility into sophisticated intrusions by matching system events against known adversarial behaviors. However, current solutions suffer from three challenges: 1) EDR tools generate a high volume of false alarms, creating backlogs of investigation tasks for analysts; 2) determining the veracity of these threat alerts requires tedious manual labor due to the overwhelming amount of low-level system logs, creating a ""needle-in-a-haystack"" problem; and 3) due to the tremendous resource burden of log retention, in practice the system logs describing long-lived attack campaigns are often deleted before an investigation is ever initiated.This paper describes an effort to bring the benefits of data provenance to commercial EDR tools. We introduce the notion of Tactical Provenance Graphs (TPGs) that, rather than encoding low-level system event dependencies, reason …",,,2020
1794,You are what you do: Hunting stealthy malware via data provenance analysis.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09SohzcAAAAJ&citation_for_view=09SohzcAAAAJ:Se3iqnhoufwC,"To subvert recent advances in perimeter and host security, the attacker community has developed and employed various attack vectors to make a malware much stealthier than before to penetrate the target system and prolong its presence. Advanced malware or “stealthy malware” makes use of various techniques to impersonate or abuse benign applications and legitimate system tools to minimize its footprints in the target system. Thus, it is difficult for traditional detection tools, such as malware scanners, to detect it, as the malware normally does not expose its malicious payload in a file and hides its malicious behaviors among the benign behaviors of the processes. In this paper, we present PROVDETECTOR, a provenancebased approach for detecting stealthy malware. Our insight behind the PROVDETECTOR approach is that although stealthy malware attempts to blend into benign processes, the malicious behaviors inevitably interact with the underlying operating system (OS), which will be exposed to and captured by provenance monitoring. Based on this intuition, PROVDETECTOR first employs a novel selection algorithm to identify possible malicious parts in the OS-level provenance data of a process. It then applies a neural embedding and machine learning pipeline to automatically detect any behavior that deviates significantly from normal behaviors. We evaluate our approach on a large provenance dataset from an enterprise network and demonstrate that it achieves very high detection performance of stealthy malware (an average F1 score of 0.974). Further, we conduct thorough interpretability studies to understand the internals of …",,,2020
1795,Fear and logging in the internet of things,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09SohzcAAAAJ&citation_for_view=09SohzcAAAAJ:Y0pCki6q_DkC,"As the Internet of Things (IoT) continues to proliferate, diagnosing incorrect behavior within increasingly-automated homes becomes considerably more difficult. Devices and apps may be chained together in long sequences of trigger-action rules to the point that from an observable symptom (e.g., an unlocked door) it may be impossible to identify the distantly removed root cause (e.g., a malicious app). This is because, at present, IoT audit logs are siloed on individual devices, and hence cannot be used to reconstruct the causal relationships of complex workflows. In this work, we present ProvThings, a platform-centric approach to centralized auditing in the Internet of Things. ProvThings performs efficient automated instrumentation of IoT apps and device APIs in order to generate data provenance that provides a holistic explanation of system activities, including malicious behaviors. We prototype ProvThings for the Samsung SmartThings platform, and benchmark the efficacy of our approach against a corpus of 26 IoT attacks. Through the introduction of a selective code instrumentation optimization, we demonstrate in evaluation that ProvThings imposes just 5% overhead on physical IoT devices while enabling real time querying of system behaviors, and further consider how ProvThings can be leveraged to meet the needs of a variety of stakeholders in the IoT ecosystem.",,,2018
1796,OmegaLog: High-fidelity attack investigation via transparent multi-layer log analysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09SohzcAAAAJ&citation_for_view=09SohzcAAAAJ:LkGwnXOMwfcC,"Recent advances in causality analysis have enabled investigators to trace multi-stage attacks using whole- system provenance graphs. Based on system-layer audit logs (e.g., syscalls), these approaches omit vital sources of application context (e.g., email addresses, HTTP response codes) that can found in higher layers of the system. Although this information is often essential to understanding attack behaviors, incorporating this evidence into causal analysis engines is difficult due to the semantic gap that exists between system layers. To address this shortcoming, we propose the notion of universal provenance, which encodes all forensically-relevant causal dependencies regardless of their layer of origin. To transparently realize this vision on commodity systems, we present ωLOG (“Omega Log”), a provenance tracking mechanism that bridges the semantic gap between system and application logging contexts. ωLOG analyzes program binaries to identify and model application-layer logging behaviors, enabling application events to be accurately reconciled with system-layer accesses. ωLOG then intercepts applications’ runtime logging activities and grafts those events onto the system-layer provenance graph, allowing investigators to reason more precisely about the nature of attacks. We demonstrate that ωLOG is widely-applicable to existing software projects and can transparently facilitate execution partitioning of dependency graphs without any training or developer intervention. Evaluation on real-world attack scenarios shows that universal provenance graphs are concise and rich with semantic information as compared to the state-of-the …",NDSS,,2020
1797,HADES: Detecting and Investigating Active Directory Attacks via Whole Network Provenance Analytics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09SohzcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=09SohzcAAAAJ:-f6ydRqryjwC,"Due to its crucial role in identity and access management in modern enterprise networks, Active Directory (AD) is a top target of Advanced Persistence Threat (APT) actors. Conventional intrusion detection systems (IDS) excel at identifying malicious behaviors caused by malware, but often fail to detect stealthy attacks launched by APT actors. Recent advance in provenance-based IDS (PIDS) shows promises by exposing malicious system activities in causal attack graphs. However, existing approaches are restricted to intra-machine tracing, and unable to reveal the scope of attackers' traversal inside a network. We propose HADES, the first PIDS capable of performing accurate causality-based cross-machine tracing by leveraging a novel concept called logon session based execution partitioning to overcome several challenges in cross-machine tracing. We design HADES as an efficient on-demand tracing system …",IEEE,,2025
1798,"Rethinking Tamper-Evident Logging: A High-Performance, Co-Designed Auditing System",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09SohzcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=09SohzcAAAAJ:hC7cP41nSMkC,"Existing tamper-evident logging systems suffer from high overhead and severe data loss in high-load settings, yet only provide coarse-grained tamper detection. Moreover, installing such systems requires recompiling kernel code. To address these challenges, we present Nitro, a high-performance, tamper-evident audit logging system that supports fine-grained detection of log tampering. Even better, our system avoids kernel recompilation by using the eBPF technology. To formally justify the security of Nitro, we provide a new definitional framework for logging systems, and give a practical cryptographic construction meeting this new goal. Unlike prior work that focus only on the cryptographic processing, we codesign the cryptographic part with the pre- and post-processing of the logs to exploit all system-level optimizations. Our evaluations demonstrate Nitro's superior performance, achieving 10X-25X improvements in high-stress conditions and 2X-10X in real-world scenarios while maintaining near-zero data loss. We also provide an advanced variant, Nitro-R that introduces in-kernel log reduction techniques to reduce runtime overhead even further.",,,2025
1799,PROVSYN: Synthesizing Provenance Graphs for Data Augmentation in Intrusion Detection Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09SohzcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=09SohzcAAAAJ:IWHjjKOFINEC,"Provenance graph analysis plays a vital role in intrusion detection, particularly against Advanced Persistent Threats (APTs), by exposing complex attack patterns. While recent systems combine graph neural networks (GNNs) with natural language processing (NLP) to capture structural and semantic features, their effectiveness is limited by class imbalance in real-world data. To address this, we introduce PROVSYN, an automated framework that synthesizes provenance graphs through a three-phase pipeline: (1) heterogeneous graph structure synthesis with structural-semantic modeling, (2) rule-based topological refinement, and (3) context-aware textual attribute synthesis using large language models (LLMs). PROVSYN includes a comprehensive evaluation framework that integrates structural, textual, temporal, and embedding-based metrics, along with a semantic validation mechanism to assess the correctness of generated attack patterns and system behaviors. To demonstrate practical utility, we use the synthetic graphs to augment training datasets for downstream APT detection models. Experimental results show that PROVSYN produces high-fidelity graphs and improves detection performance through effective data augmentation.",,,2025
1800,A Principled Approach for Detecting APTs in Massive Networks via Multi-Stage Causal Analytics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09SohzcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=09SohzcAAAAJ:dhFuZR0502QC,"Detecting Advanced Persistent Threats (APTs) in large enterprise networks with conventional Network Intrusion Detection Systems (NIDS) is challenging due to the stealthy, multi-stage, and long-running nature of APTs. This paper introduces Netguardian, a novel NIDS utilizing a comprehensive methodology to correlate anomalies across APT stages. By merging real traffic with simulated APT scenarios, Netguardian creates a detailed training dataset for enhanced anomaly detection. Netguardian implements custom models for each APT stage, extracting specific traffic features, such as periodicity and failed connections, to identify anomalies. These anomalies are then correlated to reconstruct attack paths. Our system leverages these paths to assign threat scores based on interconnected anomalies matching known APT progression, effectively prioritizing suspicious paths. Evaluation on a large dataset of enterprise …",IEEE,,2025
1801,Are We There Yet? Unraveling the State-of-the-Art Graph Network Intrusion Detection Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=09SohzcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=09SohzcAAAAJ:L8Ckcad2t8MC,"Network Intrusion Detection Systems (NIDS) are vital for ensuring enterprise security. Recently, Graph-based NIDS (GIDS) have attracted considerable attention because of their capability to effectively capture the complex relationships within the graph structures of data communications. Despite their promise, the reproducibility and replicability of these GIDS remain largely unexplored, posing challenges for developing reliable and robust detection systems. This study bridges this gap by designing a systematic approach to evaluate state-of-the-art GIDS, which includes critically assessing, extending, and clarifying the findings of these systems. We further assess the robustness of GIDS under adversarial attacks. Evaluations were conducted on three public datasets as well as a newly collected large-scale enterprise dataset. Our findings reveal significant performance discrepancies, highlighting challenges related to dataset scale, model inputs, and implementation settings. We demonstrate difficulties in reproducing and replicating results, particularly concerning false positive rates and robustness against adversarial attacks. This work provides valuable insights and recommendations for future research, emphasizing the importance of rigorous reproduction and replication studies in developing robust and generalizable GIDS solutions.",,arXiv preprint arXiv:2503.20281,2025
1802,Photolithographic patterning of polyethylene glycol hydrogels,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=N0HYl_0AAAAJ&citation_for_view=N0HYl_0AAAAJ:_kc_bZDykSQC,"A simple, inexpensive photolithographic method for surface patterning deformable, solvated substrates is demonstrated using photoactive poly(ethylene glycol) (PEG)-diacrylate hydrogels as model substrates. Photolithographic masks were prepared by printing the desired patterns onto transparencies using a laser jet printer. Precursor solutions containing monoacryloyl-PEG-peptide and photoinitiator were layered onto hydrogel surfaces. The acrylated moieties in the precursor solution were then conjugated in monolayers to specific hydrogel regions by exposure to UV light through the transparency mask. The effects of UV irradiation time and precursor solution concentration on the levels of immobilized peptide were characterized, demonstrating that bound peptide concentration can be controlled by tuning these parameters. Multiple peptides can be immobilized to a single hydrogel surface in distinct patterns by …",Elsevier,,2006
1803,Decellularized matrices in regenerative medicine,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=N0HYl_0AAAAJ&citation_for_view=N0HYl_0AAAAJ:UeHWp8X0CEIC,"Of all biologic matrices, decellularized extracellular matrix (dECM) has emerged as a promising tool used either alone or when combined with other biologics in the fields of tissue engineering or regenerative medicine – both preclinically and clinically. dECM provides a native cellular environment that combines its unique composition and architecture. It can be widely obtained from native organs of different species after being decellularized and is entitled to provide necessary cues to cells homing. In this review, the superiority of the macro- and micro-architecture of dECM is described as are methods by which these unique characteristics are being harnessed to aid in the repair and regeneration of organs and tissues. Finally, an overview of the state of research regarding the clinical use of different matrices and the common challenges faced in using dECM are provided, with possible solutions to help translate …",Elsevier,Acta biomaterialia,2018
1804,Nitric oxide‐releasing polyurethane–PEG copolymer containing the YIGSR peptide promotes endothelialization with decreased platelet adhesion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=N0HYl_0AAAAJ&citation_for_view=N0HYl_0AAAAJ:5nxA0vEk-isC,"Thrombosis and intimal hyperplasia are the principal causes of small‐diameter vascular graft failure. To improve the long‐term patency of polyurethane vascular grafts, we have incorporated both poly(ethylene glycol) and a diazeniumdiolate nitric oxide (NO) donor into the backbone of polyurethane to improve thromboresistance. Additionally, we have incorporated the laminin‐derived cell adhesive peptide sequence YIGSR to encourage endothelial cell adhesion and migration, while NO release encourages endothelial cell proliferation. NO production by polyurethane films under physiological conditions demonstrated biphasic release, in which an initial burst of 70% of the incorporated NO was released within 2 days, followed by sustained release over 2 months. Endothelial cell proliferation in the presence of the NO‐releasing material was increased as compared to control polyurethane, and platelet adhesion to …","Wiley Subscription Services, Inc., A Wiley Company",,2008
1805,Nitric oxide-producing polyurethanes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=N0HYl_0AAAAJ&citation_for_view=N0HYl_0AAAAJ:YOwf2qJgpHMC,"Thrombus formation and eventual intimal hyperplasia are the leading causes of small-diameter synthetic vascular graft failure. To combat these issues, we have incorporated a diazeniumdiolate-modified nitric oxide (NO)-producing peptide into a polyurethane to improve the thromboresistance of this biocompatible polymer. NO production by polyurethane films occurred for approximately 2 months under physiological conditions, and mechanical properties of the material were suitable for vascular graft applications. Platelet adhesion to NO-releasing polyurethane was dramatically decreased compared to control polyurethane. Furthermore, endothelial cell growth was stimulated in the presence of the NO-releasing polyurethane, while smooth muscle cell growth was greatly inhibited. The ability of this bioactive material to inhibit platelet adhesion and smooth muscle cell proliferation while encouraging …",American Chemical Society,,2005
1806,Temperature-and pH-responsive polymer compositions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=N0HYl_0AAAAJ&citation_for_view=N0HYl_0AAAAJ:d1gkVwhDpl0C,"2007-06-11 Assigned to WASHINGTON, UNIVERSITY OF reassignment WASHINGTON, UNIVERSITY OF ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS). Assignors: STAYTON, PATRICK S., YIN, XIANGCHUN, TAITE, LAKESHIA J., HOFFMAN, ALLAN S., GARBERN, JESSICA",,,2010
1807,A Poly (ethylene glycol) Diacrylate Hydrogel Angiogenesis Platform for Idiopathic Pulmonary Fibrosis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=N0HYl_0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=N0HYl_0AAAAJ:9ZlFYXVOiuMC,,AIChE,,2024
1808,Multiscale computational model predicts how environmental changes and drug treatments affect microvascular remodeling in fibrotic disease,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=N0HYl_0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=N0HYl_0AAAAJ:mVmsd5A6BfQC,"Investigating the molecular, cellular, and tissue-level changes caused by disease, and the effects of pharmacological treatments across these biological scales, necessitates the use of multiscale computational modeling in combination with experimentation. Many diseases dynamically alter the tissue microenvironment in ways that trigger microvascular network remodeling, which leads to the expansion or regression of microvessel networks. When microvessels undergo remodeling in idiopathic pulmonary fibrosis (IPF), functional gas exchange is impaired due to loss of alveolar structures and lung function declines. Here, we integrated a multiscale computational model with independent experiments to investigate how combinations of biomechanical and biochemical cues in IPF alter cell fate decisions leading to microvascular remodeling. Our computational model predicted that extracellular matrix (ECM) stiffening …",,,2024
1809,Multi–Scale Computational Model of Microvascular Remodeling in Idiopathic Pulmonary Fibrosis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=N0HYl_0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=N0HYl_0AAAAJ:Wp0gIr-vW9MC,"In idiopathic pulmonary fibrosis (IPF), progressive extracellular matrix (ECM) stiffening and dysregulated levels of growth factors, such as vascular endothelial growth factor A (VEGF-A), disrupt endothelial cell (EC) to pericyte cell communication. The physical coupling of ECs with pericytes in the microcirculation is necessary for maintaining microvessel homeostasis and function, and their uncoupling can lead to both angiogenesis and microvessel regression–, the two main processes that dictate microvessel density and tissue perfusion. However, the effects of EC-pericyte uncoupling on microvascular homeostasis in IPF have not been thoroughly investigated, despite the fact that microvessel homeostasis is necessary for lung capillaries to perform their critical role of facilitating gas exchange for the body. Understanding how dysregulated biochemical and biomechanical signals impact EC-pericyte coupling in IPF necessitates the use of a computational model where the effects of these signals can be explored both in isolation and in combination. In this work, we present a multi-scale computational model that integrates EC and pericyte intracellular signaling networks, represented by logic-based network models, with a multi-cell, agent-based model of the IPF lung microenvironment. We used the multi-scale computational model to investigate how combinations of biomechanical and biochemical cues regulate microvascular remodeling. Our multi-scale computational model predicted that ECM stiffness decreased vessel area which was associated with a reduction of EC-pericyte coupling in mature fibrosis (20 kPa). The loss of vessel area and EC …",Cold Spring Harbor Laboratory,,2024
1810,Integrated environmental modeling: a vision and roadmap for the future,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=M9aKXDwAAAAJ&citation_for_view=M9aKXDwAAAAJ:iH-uZ7U-co4C,"Integrated environmental modeling (IEM) is inspired by modern environmental problems, decisions, and policies and enabled by transdisciplinary science and computer capabilities that allow the environment to be considered in a holistic way. The problems are characterized by the extent of the environmental system involved, dynamic and interdependent nature of stressors and their impacts, diversity of stakeholders, and integration of social, economic, and environmental considerations. IEM provides a science-based structure to develop and organize relevant knowledge and information and apply it to explain, explore, and predict the behavior of environmental systems in response to human and natural sources of stress. During the past several years a number of workshops were held that brought IEM practitioners together to share experiences and discuss future needs and directions. In this paper we organize …",Elsevier,,2013
1811,Multi-decadal synthesis of benthic–pelagic coupling in the western arctic: role of cross-shelf advective processes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=M9aKXDwAAAAJ&citation_for_view=M9aKXDwAAAAJ:u5HHmVD_uO8C,"Using geographic information systems (GIS) software and geostatistical techniques, we utilized three decades of water-column chlorophyll a data to examine the relative importance of autochthonous versus allochthonous sources of reduced carbon to benthic communities that occur from the northern Bering to the eastern Beaufort Sea shelf. Spatial trend analyses revealed areas of high benthic biomass (>300gm−2) and chlorophyll (>150mgm−2) on both the southern and northern Chukchi shelf; both areas are known as depositional centers for reduced organic matter that originates on the Bering Sea shelf and is advected northward in Anadyr and Bering shelf water masses. We found a significant correlation between biomass and chlorophyll a in the Chukchi Sea, reflective of the strong benthic–pelagic coupling in a system that is utilized heavily by benthic-feeding marine mammals. In contrast, there was no …",Pergamon,,2005
1812,Models as web services using the open geospatial consortium (ogc) web processing service (wps) standard,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=M9aKXDwAAAAJ&citation_for_view=M9aKXDwAAAAJ:k_IJM867U9cC,"Environmental modeling often requires the use of multiple data sources, models, and analysis routines coupled into a workflow to answer a research question. Coupling these computational resources can be accomplished using various tools, each requiring the developer to follow a specific protocol to ensure that components are linkable. Despite these coupling tools, it is not always straight forward to create a modeling workflow due to platform dependencies, computer architecture requirements, and programming language incompatibilities. A service-oriented approach that enables individual models to operate and interact with others using web services is one method for overcoming these challenges. This work advances the idea of service-oriented modeling by presenting a design for a modeling service that builds from the Open Geospatial Consortium (OGC) Web Processing Service (WPS) protocol. We …",Elsevier,,2013
1813,Toward the Geoscience Paper of the Future: Best practices for documenting and sharing research from data to software to provenance,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=M9aKXDwAAAAJ&citation_for_view=M9aKXDwAAAAJ:htyGaKyDgHMC,"Geoscientists now live in a world rich with digital data and methods, and their computational research cannot be fully captured in traditional publications. The Geoscience Paper of the Future (GPF) presents an approach to fully document, share, and cite all their research products including data, software, and computational provenance. This article proposes best practices for GPF authors to make data, software, and methods openly accessible, citable, and well documented. The publication of digital objects empowers scientists to manage their research products as valuable scientific assets in an open and transparent way that enables broader access by other scientists, students, decision makers, and the public. Improving documentation and dissemination of research will accelerate the pace of scientific discovery by improving the ability of others to build upon published work.",,Earth and Space Science,2016
1814,A first approach to web services for the National Water Information System,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=M9aKXDwAAAAJ&citation_for_view=M9aKXDwAAAAJ:u-x6o8ySG0sC,"A wealth of freely available hydrologic data are provided by governmental organizations including in situ observations, geospatial data sets, remote sensing products, and simulation model output. Despite having access to this information, much of the data remain underutilized in the hydrologic sciences due in part to the time required to access, obtain, and integrate data from different sources. Web services offer a means for sharing hydrologic data more openly by providing a standard protocol for machine-to-machine communication. We have used this new technology to create a machine accessible interface for the National Water Information System (NWIS), an online repository of historical and real-time streamflow, water-quality, and ground water level observations maintained by the United States Geological Survey (USGS). These services provide a middle-layer of abstraction between the NWIS database and …",Elsevier,,2008
1815,Understanding Long-Term Stormwater Best Management Practice Maintenance Challenges: Insights from the Virginia Department of Transportation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=M9aKXDwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=M9aKXDwAAAAJ:WTQy_8Ay2UsC,"Best management practices (BMPs) are designed to manage stormwater and reduce pollution, but their effectiveness and compliance with regulatory requirements depend on consistent maintenance. Despite their importance, there is limited research on how stormwater practitioners allocate resources and navigate operational challenges to maintain BMPs under regulatory and budgetary constraints. To address this knowledge gap, this study conducted an open-ended survey of stormwater professionals across eight districts of the Virginia Department of Transportation (VDOT). Paired with a review of 17,874 BMP inspection records from 2020 to 2024, the survey data provided insights into how reported maintenance issues from surveys align with inspection-based observations of BMP conditions, how resource constraints shape maintenance priorities, and which strategies may improve long-term maintenance …",American Society of Civil Engineers,,2026
1816,Forecasting Multi-Step-Ahead Street-Scale Nuisance Flooding using a seq2seq LSTM Surrogate Model for Real-Time Application in a Coastal-Urban City,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=M9aKXDwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=M9aKXDwAAAAJ:2_BaaiyHPJIC,"In urban-coastal cities facing an elevated risk of nuisance flooding (by rain and tide) due to increased heavy rainfall, sea level rise, urbanization, and aging drainage systems, real-time flood forecasting at the street-scale can provide useful information to transportation decision-makers. Physics-Based Models (PBMs) that offer high accuracy come with high computational runtimes and costs that limit their application for real-time flood forecasting. To address this challenge, Machine Learning (ML) surrogate models trained from PBMs have been proposed to provide street-scale flood forecasts. Previous related studies have focused on using Long Short-Term Memory (LSTM) architectures to model hourly flood depth on streets. While LSTM models can capture input sequences effectively, they fall short in accurately preserving output sequences, limiting their suitability for multi-step-ahead forecasts. The seq2seq LSTM …",Elsevier,,2025
1817,"Quantifying the impact of nuisance flooding on urban coastal communities under present and future climatic conditions: Norfolk, Virginia as a case study",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=M9aKXDwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=M9aKXDwAAAAJ:xIusEVNJREcC,"Study region Norfolk, Virginia, United States Study focus Nuisance flooding, characterized by frequent but minor floods, has been on the rise and the trend is expected to continue due to climate change. Utilizing a two-dimensional surface flow / one-dimensional pipe hydrodynamic model, this study presents a methodology for simulating flooding from low return period tidal and rainfall events to quantify the impact of nuisance flooding on urban coastal communities under present and future climatic conditions. Applying the methodology, the results show the impact of nuisance flooding from tidal alone and compound (i.e., rainfall and tide) events. New hydrologic insights for the region Using 2020 as a base year, the model suggests tidal nuisance flooding (TNF) impacts approximately 4 % (1.87 km2) of the study area. With a projected 1-meter sea-level rise by 2100, the TNF extent is projected to increase to …",Elsevier,,2025
1818,Soil moisture retrieval from AMSR-E,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vbNdSy0AAAAJ&citation_for_view=vbNdSy0AAAAJ:u5HHmVD_uO8C,"The Advanced Microwave Scanning Radiometer (AMSR-E) on the Earth Observing System (EOS) Aqua satellite was launched on May 4, 2002. The AMSR-E instrument provides a potentially improved soil moisture sensing capability over previous spaceborne radiometers such as the Scanning Multichannel Microwave Radiometer and Special Sensor Microwave/Imager due to its combination of low frequency and higher spatial resolution (approximately 60 km at 6.9 GHz). The AMSR-E soil moisture retrieval approach and its implementation are described in this paper. A postlaunch validation program is in progress that will provide evaluations of the retrieved soil moisture and enable improved hydrologic applications of the data. Key aspects of the validation program include assessments of the effects on retrieved soil moisture of variability in vegetation water content, surface temperature, and spatial heterogeneity …",IEEE,,2003
1819,"IAHS Decade on Predictions in Ungauged Basins (PUB), 2003–2012: Shaping an exciting future for the hydrological sciences",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vbNdSy0AAAAJ&citation_for_view=vbNdSy0AAAAJ:u-x6o8ySG0sC,"Les bassins versants de drainage de nombreuses régions du monde sont peu ou pas du tout jaugés, et dans certains cas les réseaux de mesures existants sont en déclin. Le problème est compliqué par les impacts des changements induits par l'homme aux surfaces continentales et au climat, changements qui se produisent au niveau local, régional ou global. Les prévisions pour des bassins peu ou pas jaugés dans ces conditions sont fortement incertaines. La décennie de l'AISH sur les prévisions sur les bassins non jaugés (PBNJ) est une nouvelle initiative lancée par l'Association Internationale des Sciences Hydrologiques. Elle a pour objectif de développer et de mettre en application des programmes scientifiques appropriés pour engager et activer la communauté scientifique, d'une façon coordonnée, vers la réalisation d'avancées majeures dans la capacité de faire des prévisions pour des bassins non …",Taylor & Francis Group,,2003
1820,Thriving on our changing planet: A decadal strategy for Earth observation from space,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vbNdSy0AAAAJ&citation_for_view=vbNdSy0AAAAJ:LXmCCkuhhTsC,"We live on a dynamic Earth shaped by both natural processes and the impacts of humans on their environment. It is in our collective interest to observe and understand our planet, and to predict future behavior to the extent possible, in order to effectively manage resources, successfully respond to threats from natural and human-induced environmental change, and capitalize on the opportunities â€"" social, economic, security, and more â€"" that such knowledge can bring. By continuously monitoring and exploring Earth, developing a deep understanding of its evolving behavior, and characterizing the processes that shape and reshape the environment in which we live, we not only advance knowledge and basic discovery about our planet, but we further develop the foundation upon which benefits to society are built. Thriving on Our Changing Planet presents prioritized science, applications, and observations, along with related strategic and programmatic guidance, to support the US civil space Earth observation program over the coming decade.",National Academies Press,,2019
1821,"Advancing process‐based watershed hydrological research using near‐surface geophysics: A vision for, and review of, electrical and magnetic geophysical methods",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vbNdSy0AAAAJ&citation_for_view=vbNdSy0AAAAJ:2osOgNQ5qMEC,"We want to develop a dialogue between geophysicists and hydrologists interested in synergistically advancing process based watershed research. We identify recent advances in geophysical instrumentation, and provide a vision for the use of electrical and magnetic geophysical instrumentation in watershed scale hydrology. The focus of the paper is to identify instrumentation that could significantly advance this vision for geophysics and hydrology during the next 3–5 years. We acknowledge that this is one of a number of possible ways forward and seek only to offer a relatively narrow and achievable vision. The vision focuses on the measurement of geological structure and identification of flow paths using electrical and magnetic methods. The paper identifies instruments, provides examples of their use, and describes how synergy between measurement and modelling could be achieved. Of specific interest are …","John Wiley & Sons, Ltd.",,2008
1822,Soil moisture remote sensing: State‐of‐the‐science,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vbNdSy0AAAAJ&citation_for_view=vbNdSy0AAAAJ:3s1wT3WcHBgC,"Core Ideas Satellites, particularly at L‐band frequency, can globally map near‐surface soil moisture. Near‐surface moisture is extended to the root zone using models and data assimilation. Validation uses core monitoring sites, monitoring networks, field campaigns, and multi‐satellite comparisons. Efforts are underway to associate soil moisture variability dynamics with land surface attributes. This is an update to the special section “Remote Sensing for Vadose Zone Hydrology—A Synthesis from the Vantage Point” [Vadose Zone Journal 12(3)]. Satellites (e.g., Soil Moisture Active Passive [SMAP] and Soil Moisture and Ocean Salinity [SMOS]) using passive microwave techniques, in particular at L‐band frequency, have shown good promise for global mapping of near‐surface (0–5‐cm) soil moisture at a spatial resolution of 25 to 40 km and temporal resolution of 2 to 3 d. C‐ and X‐band soil moisture records date …","The Soil Science Society of America, Inc.",,2017
1823,A novel soil moisture evaluation framework incorporating brightness temperature and a high-resolution 1 km summer brightness temperature dataset,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vbNdSy0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vbNdSy0AAAAJ:oXKBmVzQOggC,"Accurate estimation of soil moisture (SM) is essential for various hydrological, meteorological, agricultural, and ecological applications. However, evaluating SM on a global scale remains challenging due to the limited availability of in-situ observations and the spatial heterogeneity of SM. Coarser resolution SM products, although beneficial for broader area coverage, often struggle to capture fine-scale variations influenced by local hydrological processes, land use, vegetation cover, and microclimates. To address these challenges, this study presents two contributions: a new 1 km brightness temperature (TB) dataset for the summer season and a two-step SM evaluation method. The 1 km TB dataset, developed by integrating SMAP’s 9 km SM product with radiative transfer modeling (RTM) and Mironov model, provides enhanced spatial resolution and is focused on areas where vegetation water content (VWC) is …",Taylor & Francis,,2025
1824,Witherspoon Lecture Presented by Lixin Wang,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vbNdSy0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vbNdSy0AAAAJ:9o6PfxSMcEIC,,AGU,,2025
1825,Evaluating SMAP 400 m Soil Moisture Accuracy Across Diverse South Indian Micro-Watersheds: Insights from the REWARD Program,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vbNdSy0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vbNdSy0AAAAJ:E2bRg1zSkIsC,,AGU,,2025
1826,"Advances in Remote Sensing, AI, and Modeling for Hydrology and the Terrestrial Water Cycle III Oral",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vbNdSy0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vbNdSy0AAAAJ:wgKq3sYidysC,,AGU,,2025
1827,Walter B. Langbein Lecture Presented by Chris Soulsby,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vbNdSy0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=vbNdSy0AAAAJ:3WNXLiBY60kC,,AGU,,2025
1828,Fe-based bulk metallic glasses with diameter thickness larger than one centimeter,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cVHCVr8AAAAJ&citation_for_view=cVHCVr8AAAAJ:u-x6o8ySG0sC,"Fe–Cr–Mo–(Y,Ln)–C–B bulk metallic glasses (Ln are lanthanides) with maximum diameter thicknesses reaching 12 mm have been obtained by casting. The high glass formability is attained despite a low reduced glass transition temperature of 0.58. The inclusion of Y/Ln is motivated by the idea that elements with large atomic sizes can destabilize the competing crystalline phase, enabling the amorphous phase to be formed. It is found that the role of Y/Ln as a fluxing agent is relatively small in terms of glass formability enhancement. The obtained bulk metallic glasses are non-ferromagnetic and exhibit high elastic moduli of approximately 180–200 GPa and microhardness of approximately 13 GPa.",Cambridge University Press,,2004
1829,Synthesis and properties of metallic glasses that contain aluminum,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cVHCVr8AAAAJ&citation_for_view=cVHCVr8AAAAJ:u5HHmVD_uO8C,The synthesis and properties of a class of metallic glasses containing up to 90 atomic percent aluminum are reported. The unusual formability of the glasses and their structural features are pointed out. Mechanical properties including tensile fracture strength and Young's modulus are reported along with crystallization temperatures. The unusually high strengths of the aluminum glasses can be of significant importance in obtaining high-strength low-density materials.,American Association for the Advancement of Science,,1988
1830,Recent developments in bulk thermoelectric materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cVHCVr8AAAAJ&citation_for_view=cVHCVr8AAAAJ:7eciy3tyNvQC,"Good thermoelectric materials possess low thermal conductivity while maximizing electric carrier transport. This article looks at various classes of materials to understand their behavior and determine methods to modify or “tune” them to optimize their thermoelectric properties. Whether it is the use of “rattlers” in cage structures such as skutterudites, or mixed-lattice atoms such as the complex half-Heusler alloys, the ability to manipulate the thermal conductivity of a material is essential in optimizing its properties for thermoelectric applications.",Cambridge Core,,2006
1831,Deformation-induced nanocrystal formation in shear bands of amorphous alloys,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cVHCVr8AAAAJ&citation_for_view=cVHCVr8AAAAJ:d1gkVwhDpl0C,"AMORPHOUS alloys formed by rapid solidification of a metallic melt are of considerable technological interest as high-strength materials1–8. As they are not in thermodynamic equilibrium, these materials tend to crystallize on heating9,10. A high degree of crystallization leads to embrittlement, but if it can be arrested when the crystallites are of only nanometre dimensions, the resulting amorphous–nanocrystalline composite actually has greater strength than the original amorphous material11. There is consequently much interest in understanding the mechanisms of crystallization. Previous studies have suggested that mechanical deformation can induce crystallization12–16. Here we report the direct observation of crystallization within the shear bands of aluminium-based amorphous alloys induced by bending. The crystals are face-centred cubic aluminium, 7–10 nm in diameter, and seem to form as a …",Nature Publishing Group UK,,1994
1832,Machine Learning Phase Classification of Thermoelectric Materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cVHCVr8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=cVHCVr8AAAAJ:gM-ZYMRJdBUC,"In this study, we employ a Support Vector Machine (SVM) model to efficiently classify the phases of thermoelectric (TE) alloys. While ab initio calculations and experiments have explored the phases of functional TE materials, the large variety of alloys makes these explorations time-consuming and expensive. Therefore, there is a critical need for time-efficient methods to accelerate the discovery and development of new TE materials. Recently, machine learning (ML) classification models have been applied to predict material phases, including those of multi-principal element alloys. Using an SVM to classify phases of TE alloys, our results demonstrate that the model achieves prediction accuracies ranging from 77% to 92%. Additionally, cross-validation across various TE phases is performed to demonstrate the model’s robustness in phase differentiation. This work offers a time-efficient computational approach to distinguish TE material phases, offering valuable insights that can aid in the evaluation and design of high-performance thermoelectric materials.",MDPI,,2025
1833,Reexamining Machine Learning Models on Predicting Thermoelectric Properties,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cVHCVr8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=cVHCVr8AAAAJ:-WH5uU-2cuwC,"Thermoelectric materials can generate clean energy by transforming waste heat into electricity. The effectiveness of thermoelectric materials is measured by the dimensionless figure of merit, ZT. The quest for high ZT materials has drawn extensive research experimentally and theoretically. However, due to the vast material space, finding high ZT materials is time-consuming and costly. To improve the efficiency of discovering new thermoelectric materials, recent studies have employed machine learning with databases to search for high ZT candidates. In this work, we examine the effects of adding various physical concepts on the performance of machine learning models in predicting TE properties. The objective is to improve the model ability to capture the underlying physics in designing TE materials. These concepts include short range order and crystal structure class. Results show some improvements in accuracy. However, the current models do not distinguish between dilute alloys and concentrated alloys, rendering them inadequate in predicting doping effects. To better capture the electronic band structure effect from doping, we included various dopant properties as features. This increases the prediction accuracy in doped materials. Furthermore, we used a genetic algorithm to rank features for various thermoelectric properties to provide physical insight into key parameters in designing thermoelectric materials.",,,2025
1834,Comparing machine learning models for strength and ductility in high-entropy alloys,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cVHCVr8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=cVHCVr8AAAAJ:eA5wQj470iYC,"We compare several machine learning (ML) models that predict the yield strength and plasticity of high-entropy alloys (HEAs) for achieving high-accuracy with notably low root mean square errors (RMSE). Our models, developed using a comprehensive database of single-phase body-centered cubic (BCC) HEAs and BCC + B2 HEAs (where B2 is ordered BCC), integrate advanced feature engineering reflecting the current understanding of electronic factors, atomic ordering informed by mixing enthalpy, and the D parameter associated with stacking fault energy in HEAs. This approach enables systematic comparisons of different ML models, providing deep insights into the mechanical properties of BCC and related alloys. By leveraging genetic algorithms for feature selection and meticulous hyperparameter optimization, our ML framework excels in both predictive power and interpretability. The rigorous validation …",Springer US,,2025
1835,Integrated design of aluminum-enriched high-entropy refractory B2 alloys with synergy of high strength and ductility,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cVHCVr8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=cVHCVr8AAAAJ:NrcdxztAscQC,"Refractory high-entropy alloys (RHEAs) are promising high-temperature structural materials. Their large compositional space poses great design challenges for phase control and high strength-ductility synergy. The present research pioneers using integrated high-throughput machine learning with Monte Carlo simulations supplemented by ab initio calculations to effectively navigate phase selection and mechanical property predictions, developing single-phase ordered B2 aluminum-enriched RHEAs (Al-RHEAs) demonstrating high strength and ductility. These Al-RHEAs achieve remarkable mechanical properties, including compressive yield strengths up to 1.7 gigapascals, fracture strains exceeding 50%, and notable high-temperature strength retention. They also demonstrate a tensile yield strength of 1.0 gigapascals with a ductility of 9%, albeit with B2 ordering. Furthermore, we identify valence electron count …",American Association for the Advancement of Science,,2024
1836,Variation of the Passive Film on Compositionally Concentrated Dual-Phase Al0.3Cr0.5Fe2Mn0.25Mo0.15Ni1.5Ti0.3 and Implications for Corrosion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cVHCVr8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=cVHCVr8AAAAJ:xvKSgulxyWUC,"The passive film on a dual-phase Al0.3Cr0.5Fe2Mn0.25Mo0.15Ni1.5Ti0.3 FCC + Heusler (L21) compositionally concentrated alloy formed during extended exposure to an applied potential in the passive range in dilute chloride solution was characterized. Each phase, with its own distinct composition of passivating elements, formed unique passive films separated by a heterophase interface. High-resolution, surface sensitive characterization enabled chemical analysis of the passive film formed over individual phases. The film formed over the L21 phase had a higher concentration of Al, Ni, and Ti, while the film formed over FCC phase was of similar thickness but contained comparatively higher Cr, Fe, and Mo concentrations, consistent with the differences in bulk microstructure composition. The passive film was continuous across phase boundaries and the distribution of passivating elements (Al, Cr, and Ti …",Springer US,,2024
1837,Experimental study of a dual-mode scramjet isolator,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Plgy-iAAAAAJ&citation_for_view=Plgy-iAAAAAJ:u5HHmVD_uO8C,"INTEREST in single-stage-to-orbit and two-stage-to-orbit vehicles has motivated research and development of ramjet and scramjet engines. Dual-mode scramjets (DMSJ), in particular, are promising propulsion systems for these vehicles because they integrate the advantageous capabilities of both ramjets and scramjets into a single fixed-geometry combustor [1, 2]. This combination may enable a vehicle to operate from Mach 3 to Mach numbers approaching 20 with only minor engine geometry changes. At the lower limit of this envelope, the DMSJ operates in ramjet mode and combustion occurs at subsonic speeds. In this mode, the addition of heat can be used to drive the supersonic inflow to sonic conditions and achieve a thermal choke. However, at speeds approaching Mach 7, pressure losses associated with choking the flow increase and operational efficiency decreases [3]. Transition from subsonic to …",,,2008
1838,Experimental study of test-medium vitiation effects on dual-mode scramjet performance,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Plgy-iAAAAAJ&citation_for_view=Plgy-iAAAAAJ:IjCSPb-OGe4C,"An experimental study was performed to characterize the effects of vitiation due to combustion-air preheating on dual-mode scramjet combustion. Major combustion vitiation species (H2O and CO2) were added to the freestream of an electrical-resistance-heated, direct-connect facility simulating Mach 5 flight enthalpy. With clean, dry air, the combustor operated in the supersonic mode at fuel equivalence ratios below 0.22, and in the subsonic mode for equivalence ratios above 0.26. Hysteresis was observed in the dual-mode transition region between 0.22 and 0.26, as the mode of combustion was dependent on whether the fuel rate was increasing or decreasing. Adding increasing amounts of water vapor and carbon dioxide to the freestream decreased combustor pressures by 10 to 30% for the same fuel equivalence ratio. Vitiation also caused transition between supersonic and subsonic combustion to occur at a …",,,2011
1839,Velocity profile measurements in hypersonic flows using sequentially imaged fluorescence-based molecular tagging,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Plgy-iAAAAAJ&citation_for_view=Plgy-iAAAAAJ:Y0pCki6q_DkC,"THE ability to perform quantitative velocity measurements in a hypersonic flow can be complicated by the extreme dynamic and thermodynamic conditions present in hypersonic test facilities and the limited optical access to the test section. Nevertheless, these measurements are needed to validate computational modeling efforts aimed at improved understanding of the physical characteristics of such flows. Recent experimental hypersonic wind-tunnel measurement work at NASA Langley Research Center (Langley) has been focused on providing quantitative velocity data. The Langley 31 in. Mach 10 blowdown air tunnel is frequently used for both fundamental and project-related testing (ie, Space Shuttle orbiter [1], Hyper-X [2], etc.), for which quantitative measurements are Presented as Paper 2010-1404 at the 48th AIAA Aerospace Sciences Meeting, Orlando, FL, 4–7 January 2010; received 15 June 2010 …",,,2011
1840,Shock train leading-edge detection in a dual-mode scramjet,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Plgy-iAAAAAJ&citation_for_view=Plgy-iAAAAAJ:qjMakFHDy7sC,"THE dual-mode scramjet (DMSJ) is a particularly attractive hypersonic airbreathing propulsion system because it combines the operational capabilities of a ramjet and a scramjet into one flowpath [1–3]. At Mach numbers below approximately 4, the DMSJ operates in ram mode whereby combustion occurs at subsonic conditions. This is achieved by managing the heat release in the combustor such that a thermal choke is achieved and a precombustion shock train forms in the DMSJ isolator. The shock train consists of a series of normal or oblique shocks, which terminate with a normal shock that drives the flow to subsonic conditions. However, at high Mach numbers, forcing the flow to subsonic conditions results in increased pressure losses and decreased operational efficiency [3]. This can be averted by allowing theflow to remain supersonic. At a fixed Mach number, the transition from subsonic to supersonic …",,,2008
1841,"Dual-mode combustion of hydrogen in a Mach 5, continuous-flow facility",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Plgy-iAAAAAJ&citation_for_view=Plgy-iAAAAAJ:u-x6o8ySG0sC,"THE concept of a dual-mode scramjet has considerablepotential for transatmospheric vehicle applications. 1 The dual mode of operation provides the capability of using a single-engine owpath over a broad range of ight Mach numbers. At speeds of Mach 5 and above, the engine is operated as a scramjet, and the heat-releaseprocess in the combustor remains predominantly supersonic. At lower speeds however, the requirement of high thermal effi ciency prescribes that the combustion process remain subsonic. 2 This ramjet mode can be achieved, using the same engine geometry, by matching the owpath area ratio and combustion heat release such that a thermal choke is produced downstream of the point of fuel injection. Provided the associated pressure rise upstream of this choke can be effectively isolated from the engine’s supersonic inlet, the dual-mode scramjet will operate at low supersonic ight speeds in …",,,2001
1842,Enhancement of Dual-Mode Scramjet Flowpath Control With an Optical Emission Spectroscopy Sensor,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Plgy-iAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Plgy-iAAAAAJ:NJ774b8OgUMC,The objective of this work is to investigate the utility of an optical emission spectroscopy sensor for improving control performance in a dual-mode scramjet flowpath. The sensor utilizes a multi-anode photomultiplier tube detector and uses a transmission grating to spectrally disperse chemiluminescence emitted from the reacting gases within the combustor of a dual-mode scramjet flowpath. Closed-loop shock train control is demonstrated in a direct-connect dual-mode scramjet facility utilizing wall pressure measurements for shock train location estimation. Various combinations of optical emission and pressure signals measured in the combustor are used to create best-fit calibration functions to estimate shock location. Performance of the calibrated functions and closed-loop shock control using the function outputs as feedback was analyzed with root-mean-squared-error statistics. Analysis showed that both pressure …,,,2025
1843,Wavelet-Based Optical Flow Velocimetry Using High Repetition-Rate OH-PLIF in Dual-Mode Scramjet,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Plgy-iAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Plgy-iAAAAAJ:kzcrU_BdoSEC,"Wavelet-based optical flow velocimetry (wOFV) is applied to high-speed planar laser induced fluorescence (PLIF) measurements for determining velocity in a supersonic combustion environment. 100 kHz PLIF imaging of hydroxyl (OH) radicals was completed to study a scramjet combustor flowpath at the University of Virginia Supersonic Combustion Facility (UVASCF). The wOFV analysis yields two-dimensional velocity fields in a high-speed reacting flow environment over a limited spatial domain without introducing seed particles or non-native tracer gases. These measurements represent the first demonstration of 100 kHzOHPLIF applied in a supersonic combustion system, offering insights into instantaneous and time-averaged flow behavior and turbulent structures. Velocity fields derived from wOFV are compared with prior particle image velocimetry (PIV) measurements in the same facility. The results …",,,2025
1844,Propagation of Uncertainty in Experimental Dynamic Coefficients of Fluid Film Journal Bearings,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Plgy-iAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Plgy-iAAAAAJ:_Ybze24A_UAC,"The stiffness and damping coefficients of fluid film bearings play a key role in predicting levels of vibration and stability margins in high-performance industrial rotating machinery. However, variability in the coefficients calculated by numerical bearing codes creates inaccuracies in the rotodynamic predictions. Therefore, there is a strong need for accurate experimental measurement of bearing coefficients for validation purposes. This work examines new propagation uncertainty strategies in bearing coefficients estimation, and for the first time examines the effect of the nonlinearity of the dynamic coefficients on the experimental uncertainty estimated by the Taylor Series Method. The Montecarlo method is presented as a more accurate approach to estimating experimental uncertainty. The results of the analyses are compared to published values from previously reported studies. This paper also proposes a novel …",American Society of Mechanical Engineers,,2024
1845,Control of a dual-mode scramjet flow path utilizing optical emission spectroscopy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Plgy-iAAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Plgy-iAAAAAJ:W5xh706n7nkC,"Shock train leading edge (STLE) location control within a Dual-Mode Scramjet (DMSJ) flow path was demonstrated using an optical emission spectroscopy (OES) sensor for control feedback. Emission from electronically excited chemical species, OH⁎ and C 2⁎, was observed within the combustor and used for feedback to control the STLE within the DMSJ isolator. An optical emission sensor was used to experimentally demonstrate STLE control using a Proportional-Integral (PI) controller. Feedback using this sensor was compared the traditional approach of using wall pressure sensors. Utilizing an OES sensor for feedback proved to be an effective method to estimate and control the STLE location and provided a smoother response than when utilizing discrete wall-based pressure measurements that tended to discretize the estimated STLE location. Characteristic Model-Based All-Coefficient Adaptive Control …",Elsevier Masson,,2024
1846,Follow the water: emerging issues of climate change and conflict in Peru,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-oPiDkMAAAAJ&citation_for_view=-oPiDkMAAAAJ:zYLM7Y9cAGgC,"In 2007, the Fourth Assessment Report of the Intergovernmental Panel on Climate Change (IPCC) predicted that rising global temperatures will contribute to an upsurge in severe storms, floods, droughts, glacier melt, and sea level rise. Soon thereafter, a number of policy studies concluded that there is a strong likelihood that the natural hazards and environmental stresses associated with climate change will trigger or amplify conflict, especially in vulnerable or unstable areas of the developing world. 1 Among the projected scenarios were severe resource scarcity, dramatic increases in internal and external migration, disease outbreaks, and a host of destabilizing social and political effects.",,,2012
1847,Guía para el desarrollo de proyectos de energía renovable en Costa Rica,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-oPiDkMAAAAJ&citation_for_view=-oPiDkMAAAAJ:Y0pCki6q_DkC,,,https://areca.bcie.org/fileadmin/areca/espanol/archivos/informacion-sector-energetico/guias/851758449.pdf,2010
1848,Issue and Challenges for Accelerating Energy Access in the Central American Region: A Discussion Towards Enhancing Advocacy and Cooperation Among Civil Society Organizations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-oPiDkMAAAAJ&citation_for_view=-oPiDkMAAAAJ:IjCSPb-OGe4C,"This work has been sponsored by Hivos, as part of its “Program on Climate Change and 100% Renewables”. In the Central American region, Hivos is implementing different types of activities together with partner organizations in order to promote the discussion as well as to foster the participation of different stakeholders with the objective of accelerating the provision of cleaner energy services for the poor. This document aims at providing information relevant to the discussion of improvements and advocacy aspects related to policies and funding on access to energy. A brief description of the energy situation in the targeted Central American countries of Guatemala, Honduras, El Salvador and Nicaragua is presented from the perspectives of energy system indicators as well as important poverty conditions of segments of the population, in order to highlight the dimensions of the energy access issue in the region. The …",,,2012
1849,How social movements engage with public deliberation: A multifaceted approach,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-oPiDkMAAAAJ&citation_for_view=-oPiDkMAAAAJ:0EnyYjriUFMC,"This thesis empirically examines how a social movement as a plural, multifaceted body, engages with an ample range of spaces for deliberation. The study centers on the social movement's practices and aspirations when engaging with a variety of spaces for public expression and involvement in decision-making, ranging from Municipal Councils, to Technical Advisory Commissions, to Community Agricultural Festivals. It examines the questions how do social movements engage with public deliberation?, and what are the implications of this engagement for the theory and practice of deliberative democracy?. The empirical research in this thesis is based on an interpretive study of the Costa Rican Movement Against Genetically Modified Organisms (or Movement Against Transgenics MaT) and its practices of engagement with deliberative spaces at the national and local levels between 1999 and 2015. The research project examines this case as an information-rich, revelatory and extreme case of social movement engagement with formal local government decision-making on complex and divisive issues. This thesis proposes three contributions to bridge the study of social movements and public deliberation. First, it takes a broad situated approach to studying how social movements make sense of their practices of engagement with public deliberation, without a restricting it to a pre-conceived role. Second, my analysis expressly recognizes that the activists within the movement do not have a unified perspective about the movement's engagement with public deliberation, or a singular approach for how to relate to outsiders and antagonists. Hence, I …",,,2022
1850,Beyond experts and conciliators: Envisioning engineers as multi-faceted peacebuilders in Costa Rica,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-oPiDkMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=-oPiDkMAAAAJ:LkGwnXOMwfcC,"There is a rich precedent in implementing Peace Engineering at a national scale in Costa Rica, particularly in the evolving dynamics of regulating professional conduct. However, there are also considerable obstacles to the recognition of the value and urgency of this interdisciplinary undertaking. This paper outlines the strengths and examines the barriers to the growth of this novel endeavor. It is argued that building the field of practice for Peace Engineering requires greater reflection and deliberative democratization of disciplinary boundaries, particularly in civil service and academia. To conclude, a tentative plan of action is outlined for leaders in the country's engineering profession to become peace entrepreneurs and deliberative practitioners.",,,2021
1851,Water purification by membranes: the role of polymer science,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pR8eT_sAAAAJ&citation_for_view=pR8eT_sAAAAJ:u5HHmVD_uO8C,"Two of the greatest challenges facing the 21st century involve providing sustainable supplies of clean water and energy, two highly interrelated resources, at affordable costs. Membrane technology is expected to continue to dominate the water purification technologies owing to its energy efficiency. However, there is a need for improved membranes that have higher flux, are more selective, are less prone to various types of fouling, and are more resistant to the chemical environment, especially chlorine, of these processes. This article summarizes the nature of the global water problem and reviews the state of the art of membrane technology. Existing deficiencies of current membranes and the opportunities to resolve them with innovative polymer chemistry and physics are identified. Extensive background is provided to help the reader understand the fundamental issues involved. © 2010 Wiley Periodicals, Inc. J …","Wiley Subscription Services, Inc., A Wiley Company",,2010
1852,Water permeability and water/salt selectivity tradeoff in polymers for desalination,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pR8eT_sAAAAJ&citation_for_view=pR8eT_sAAAAJ:u-x6o8ySG0sC,"Polymer membrane-based desalination (e.g., reverse osmosis (RO) and nanofiltration (NF)) has been extensively developed since the 1960s and is a well-established process. The separation performance of desalination membranes is usually described in terms of water flux (or permeance) and salt rejection. Based on a survey of available data, water permeance and NaCl rejection are often inversely correlated, and there may be an upper bound, similar to that observed in gas separation membranes, beyond which there are very few data points. However, water permeance and salt rejection are not intrinsic material properties since they are influenced by sample size (i.e., membrane thickness in the case of permeance) and measurement variables (e.g., pressure and salt concentration in the case of salt rejection). Use of water permeability, rather than water flux or permeance, and water/salt permeability selectivity …",Elsevier,,2011
1853,Fundamental water and salt transport properties of polymeric materials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pR8eT_sAAAAJ&citation_for_view=pR8eT_sAAAAJ:Se3iqnhoufwC,"Fundamental water and salt transport properties of polymers are critical for applications such as reverse osmosis (RO), nanofiltration (NF), forward osmosis (FO), pressure-retarded osmosis (PRO), and membrane capacitive deionization (MCDI) that require controlled water and salt transport. Key developments in the field of water and salt transport in polymer membranes are reviewed, and a survey of polymers considered for such applications is provided. Many polymers considered for such applications contain charged functional groups, such as sulfonate groups, that can dissociate in the presence of water. Water and ion transport data from the literature are reviewed to highlight the similarities and differences between charged and uncharged polymers. Additionally, the influence of other polymer structure characteristics, such as cross-linking and morphology in phase separated systems, on water and salt transport …",Pergamon,Progress in Polymer Science,2014
1854,"Polyamide interfacial composite membranes prepared from m-phenylene diamine, trimesoyl chloride and a new disulfonated diamine",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pR8eT_sAAAAJ&citation_for_view=pR8eT_sAAAAJ:2osOgNQ5qMEC,"The influence of synthesis conditions (e.g., monomer concentration and membrane preparation protocol) on transport properties of polyamide thin-film composite (TFC) membranes prepared using m-phenylenediamine (MPD) and trimesoyl chloride (TMC) via interfacial polymerization is reported. For example, at 25°C, NaCl rejection and permeate flux combinations of 99.6±0.1% and 42±3L/(m2h), respectively, were achieved in crossflow filtration using a 2000ppm aqueous solution of NaCl and a transmembrane pressure difference of 225psi (15.5bar). Additionally, a sulfone diamine, disulfonated bis[4-(3-aminophenoxy)phenyl]sulfone (S-BAPS), was used in place of MPD to prepare TFC membranes. The resulting membranes had low NaCl rejection but somewhat higher permeate flux than MPD/TMC membranes. These membranes had reduced chlorine tolerance compared to those prepared using MPD as the …",Elsevier,,2012
1855,Assembling a natural small molecule into a supramolecular network with high structural order and dynamic functions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pR8eT_sAAAAJ&citation_for_view=pR8eT_sAAAAJ:r0BpntZqJG4C,"Programming the hierarchical self-assembly of small molecules has been a fundamental topic of great significance in biological systems and artificial supramolecular systems. Precise and highly programmed self-assembly can produce supramolecular architectures with distinct structural features. However, it still remains a challenge how to precisely control the self-assembly pathway in a desirable way by introducing abundant structural information into a limited molecular backbone. Here we disclose a strategy that directs the hierarchical self-assembly of sodium thioctate, a small molecule of biological origin, into a highly ordered supramolecular layered network. By combining the unique dynamic covalent ring-opening-polymerization of sodium thioctate and an evaporation-induced interfacial confinement effect, we precisely direct the dynamic supramolecular self-assembly of this simple small molecule in a …",American Chemical Society,,2019
1856,Dissecting the multicellular ecosystem of metastatic melanoma by single-cell RNA-seq,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-syB4jwAAAAJ&citation_for_view=-syB4jwAAAAJ:pAkWuXOU-OoC,"To explore the distinct genotypic and phenotypic states of melanoma tumors, we applied single-cell RNA sequencing (RNA-seq) to 4645 single cells isolated from 19 patients, profiling malignant, immune, stromal, and endothelial cells. Malignant cells within the same tumor displayed transcriptional heterogeneity associated with the cell cycle, spatial context, and a drug-resistance program. In particular, all tumors harbored malignant cells from two distinct transcriptional cell states, such that tumors characterized by high levels of the MITF transcription factor also contained cells with low MITF and elevated levels of the AXL kinase. Single-cell analyses suggested distinct tumor microenvironmental patterns, including cell-to-cell interactions. Analysis of tumor-infiltrating T cells revealed exhaustion programs, their connection to T cell activation and clonal expansion, and their variability across patients. Overall, we begin to …",American Association for the Advancement of Science,,2016
1857,Highly multiplexed imaging of single cells using a high-throughput cyclic immunofluorescence method,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-syB4jwAAAAJ&citation_for_view=-syB4jwAAAAJ:KNjnJ3z-R6IC,"Single-cell analysis reveals aspects of cellular physiology not evident from population-based studies, particularly in the case of highly multiplexed methods such as mass cytometry (CyTOF) able to correlate the levels of multiple signalling, differentiation and cell fate markers. Immunofluorescence (IF) microscopy adds information on cell morphology and the microenvironment that are not obtained using flow-based techniques, but the multiplicity of conventional IF is limited. This has motivated development of imaging methods that require specialized instrumentation, exotic reagents or proprietary protocols that are difficult to reproduce in most laboratories. Here we report a public-domain method for achieving high multiplicity single-cell IF using cyclic immunofluorescence (CycIF), a simple and versatile procedure in which four-colour staining alternates with chemical inactivation of fluorophores to progressively build a …",Nature Publishing Group UK,,2015
1858,The library of integrated network-based cellular signatures NIH program: system-level cataloging of human cells response to perturbations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-syB4jwAAAAJ&citation_for_view=-syB4jwAAAAJ:An6A6Jpfc1oC,"The Library of Integrated Network-Based Cellular Signatures (LINCS) is an NIH Common Fund program that catalogs how human cells globally respond to chemical, genetic, and disease perturbations. Resources generated by LINCS include experimental and computational methods, visualization tools, molecular and imaging data, and signatures. By assembling an integrated picture of the range of responses of human cells exposed to many perturbations, the LINCS program aims to better understand human disease and to advance the development of new therapies. Perturbations under study include drugs, genetic perturbations, tissue micro-environments, antibodies, and disease-causing mutations. Responses to perturbations are measured by transcript profiling, mass spectrometry, cell imaging, and biochemical methods, among other assays. The LINCS program focuses on cellular physiology shared among …",Elsevier,Cell systems,2018
1859,Metrics other than potency reveal systematic variation in responses to cancer drugs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-syB4jwAAAAJ&citation_for_view=-syB4jwAAAAJ:YsMSGLbcyi4C,"Large-scale analysis of cellular response to anticancer drugs typically focuses on variation in potency (half-maximum inhibitory concentration, (IC50)), assuming that it is the most important difference between effective and ineffective drugs or sensitive and resistant cells. We took a multiparametric approach involving analysis of the slope of the dose-response curve, the area under the curve and the maximum effect (Emax). We found that some of these parameters vary systematically with cell line and others with drug class. For cell-cycle inhibitors, Emax often but not always correlated with cell proliferation rate. For drugs targeting the Akt/PI3K/mTOR pathway, dose-response curves were unusually shallow. Classical pharmacology has no ready explanation for this phenomenon, but single-cell analysis showed that it correlated with significant and heritable cell-to-cell variability in the extent of target inhibition. We …",Nature Publishing Group US,,2013
1860,Adaptive resistance of melanoma cells to RAF inhibition via reversible induction of a slowly dividing de‐differentiated state,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-syB4jwAAAAJ&citation_for_view=-syB4jwAAAAJ:kzcSZmkxUKAC,"Treatment of BRAF‐mutant melanomas with MAP kinase pathway inhibitors is paradigmatic of the promise of precision cancer therapy but also highlights problems with drug resistance that limit patient benefit. We use live‐cell imaging, single‐cell analysis, and molecular profiling to show that exposure of tumor cells to RAF/MEK inhibitors elicits a heterogeneous response in which some cells die, some arrest, and the remainder adapt to drug. Drug‐adapted cells up‐regulate markers of the neural crest (e.g., NGFR), a melanocyte precursor, and grow slowly. This phenotype is transiently stable, reverting to the drug‐naïve state within 9 days of drug withdrawal. Transcriptional profiling of cell lines and human tumors implicates a c‐Jun/ECM/FAK/Src cascade in de‐differentiation in about one‐third of cell lines studied; drug‐induced changes in c‐Jun and NGFR levels are also observed in xenograft and human tumors …",,,2017
1861,Multivariate analysis of metabolic state vulnerabilities across diverse cancer contexts reveals synthetically lethal associations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-syB4jwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=-syB4jwAAAAJ:SIv7DqKytYAC,"Targeting the distinct metabolic needs of tumor cells has recently emerged as a promising strategy for cancer therapy. The heterogeneous, context-dependent nature of cancer cell metabolism, however, poses challenges to identifying effective therapeutic interventions. Here, we utilize various unsupervised and supervised multivariate modeling approaches to systematically pinpoint recurrent metabolic states within hundreds of cancer cell lines, elucidate their association with tumor lineage and growth environments, and uncover vulnerabilities linked to their metabolic states across diverse genetic and tissue contexts. We validate key findings via analysis of data from patient-derived tumors and pharmacological screens and by performing genetic and pharmacological experiments. Our analysis uncovers synthetically lethal associations between the tumor metabolic state (e.g., oxidative phosphorylation), driver …",Elsevier,,2024
1862,"Protocol for iterative indirect immunofluorescence imaging in cultured cells, tissue sections, and metaphase chromosome spreads",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-syB4jwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=-syB4jwAAAAJ:QsaTk4IG4EwC,"We present a protocol to generate highly multiplexed spatial data at cellular and subcellular resolutions using iterative indirect immunofluorescence imaging (4i). We describe streamlined steps for using 4i across fixed cultured cells, formalin-fixed paraffin-embedded (FFPE) tissue sections, and metaphase chromosome spreads. We detail procedures for sample preparation, antibody and DNA staining, immunofluorescence imaging, antibody elution, and image processing. This protocol is adapted for high-throughput analysis of fixed cultured cells and addresses sample-specific challenges such as intrinsic tissue autofluorescence and chromosome fragility. For complete details on the use and execution of this protocol for fixed cultured cells, please refer to Comandante-Lou et al.1",Elsevier,,2024
1863,Characterization of driver oncogenic mutations of in-transit melanoma metastases.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-syB4jwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=-syB4jwAAAAJ:LXmCCkuhhTsC,"9586 Background: In-transit melanoma (ITM) is a distinctive form of melanoma metastasis, marked by aggressive locoregional progression and characterized by the entrapment of tumor cells within the lymphatic channels before reaching regional lymph nodes (LN). The mechanisms leading to lymphatic trapping rather than progression to distant metastasis are not well-understood. Previous research indicates a clonal origin for ITM, suggesting specific early-stage genetic alterations may drive this clinical phenotype. In this study, we sought to identify driver oncogenic mutations specific to ITM that may serve as potential targets. Methods: We analyzed data from the MSK-IMPACT database, which includes targeted sequencing of 341-468 genes for patients with cutaneous melanoma. Patients were stratified into four groups based on the type of sample sequenced: in-transit, primary tumor, regional LN, and distant …",American Society of Clinical Oncology,Journal of Clinical Oncology,2024
1864,Defining and Targeting Novel Epigenetic Vulnerabilities in Heterogeneous Drug-Resistant Melanomas,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-syB4jwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=-syB4jwAAAAJ:sA9dB-pw3HoC,"In this study, we perform a targeted kinase inhibitor screen and identify a tool compound, named MTX-216, to be highly effective in blocking NF1-LoF melanoma cells. Single-cell analysis links drug-induced cytotoxicity to effective co-suppression of proliferation markerKi-67 and the ribosomal S6 phosphorylation. We find the anti-tumor efficacy of MTX-216 to be dependent on its ability to inhibit not only PI3K but also SYK and suppression of a group of genes that regulate mitochondrial electron transport chain. Furthermore, combinations of inhibitors targeting either MEK or PI3K/mTOR with an independent SYK kinase inhibitor or SYK knockdown show favorable effects. These studies provide a path to exploit SYK dependency to selectively block NF1-LoF melanoma cells. In parallel, through systematic experimental measurements, single-cell analysis, and long-duration live-cell microscopy experiments, we have identified potentially novel effective drugs or drug combinations that overcome cell-to cell variability responsible for incomplete efficacy of currently available MAPK inhibitor treatments across genetically diverse BRAF-mutant melanoma contexts.",,,2023
1865,Loss of NF1 in melanoma confers sensitivity to SYK kinase inhibition,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-syB4jwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=-syB4jwAAAAJ:UuEBAcK4md4C,"Neurofibromin 1 (NF1) loss of function (LoF) mutations are frequent in melanoma and drive hyperactivated RAS and tumor growth. NF1LoF melanoma cells, however, do not show consistent sensitivity to individual MEK, ERK, or PI3K/mTOR inhibitors. To identify more effective therapeutic strategies for treating NF1LoF melanoma, we performed a targeted kinase inhibitor screen. A tool compound named MTX-216 was highly effective in blocking NF1LoF melanoma growth in vitro and in vivo. Single-cell analysis indicated that drug-induced cytotoxicity was linked to effective cosuppression of proliferation marker Ki-67 and ribosomal protein S6 phosphorylation. The antitumor efficacy of MTX-216 was dependent on its ability to inhibit not only PI3K, its nominal target, but also SYK. MTX-216 suppressed expression of a group of genes that regulate mitochondrial electron transport chain and are associated …",American Association for Cancer Research,,2023
1866,Patterned electroconvection under AC and DC voltages with strong unipolar charge injection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PMFpSwwAAAAJ&citation_for_view=PMFpSwwAAAAJ:9yKSN-GCB0IC,"The phenomenon of electroconvection has attracted attention because it has the potential to improve ion transport on polarized surfaces, reducing the plateau region of limiting current. Previous observations for DC voltages indicate that patterned surfaces or unipolar charge injection significantly enhance ion transport through electroconvection. However, creating and maintaining the convection cells crucial for electroconvection is challenging under AC voltages due to the alternating direction of the electric field, which can cause instabilities. In this article, we explore how electroconvection can be induced using a patterned membrane and strong unipolar charge injection with both DC and AC voltages. We use a flow simulation with a specialized adaptive time-stepping algorithm to simulate electroconvection and find the best pattern ratio (⁠ R⁠) for achieving the highest time-averaged current density. The system’s …",AIP Publishing,,2025
1867,Developing Numerical Methods and Optimal Boundary Conditions for Enhancing Electroconvection Under AC Voltage,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PMFpSwwAAAAJ&citation_for_view=PMFpSwwAAAAJ:u-x6o8ySG0sC,"Electroconvection has garnered significant attention due to its potential to enhance ion transport on polarized surfaces, thereby reducing the plateau region of the limiting current vs voltage curve. This dissertation explores the induction of electroconvection under both alternating current (AC) and direct current (DC) voltages, emphasizing the effects of surface patterning under the constraint of unipolar charge injection. While DC voltages significantly enhance ion transport by way of the electroconvection mechanism, facilitated by patterned surfaces, AC voltages present unique challenges. The alternating direction of the electric field under AC conditions complicates the creation and maintenance of stable convection cells, essential for effective electroconvection. This study examines how various pattern designs influence the dynamics of electroconvection across different AC frequency settings. Our analysis has …",,,2024
1868,Numerical Simulation of Pattern Accelerated Electroconvection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PMFpSwwAAAAJ&citation_for_view=PMFpSwwAAAAJ:u5HHmVD_uO8C,"Electroconvection is an emerging topic of interest for engineers due to its great potential in industrial applications such as separation, desalination, fuel cells and, more recently by nanofluidic channels. Research has shown that Electroconvection can enhance ion transport at polarized surfaces and thereby shorten the plateau region of limiting current. The patterned surfaces with alternating permeable and impermeable regions can increase the ion transport and Electroconvection process. In this work, numerical simulation has been used to investigate and optimized patterned accelerated Electroconvection. An iterative algorithm is used for the robust treatment of the coupling of concentration and momentum. Linearization of electromigration fluxes helps in decreasing the complexity and faster convergence. The effect of patterned and homogeneous boundary on mean ion transport and current density will be …",,,2021
1869,Impact of Surface Patterning on Electroconvection with Unipolar Charge Injection under AC and DC Voltages,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PMFpSwwAAAAJ&citation_for_view=PMFpSwwAAAAJ:d1gkVwhDpl0C,,AMS,,
1870,Diameter-selective Raman scattering from vibrational modes in carbon nanotubes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PbfBJx8AAAAJ&citation_for_view=PbfBJx8AAAAJ:MXK_kJrjxJIC,"Single wall carbon nanotubes (SWNTs) that are found as close-packed arrays in crystalline ropes have been studied by using Raman scattering techniques with laser excitation wavelengths in the range from 514.5 to 1320 nanometers. Numerous Raman peaks were observed and identified with vibrational modes of armchair symmetry (n, n) SWNTs. The Raman spectra are in good agreement with lattice dynamics calculations based on C-C force constants used to fit the two-dimensional, experimental phonon dispersion of a single graphene sheet. Calculated intensities from a nonresonant, bond polarizability model optimized for sp2 carbon are also in qualitative agreement with the Raman data, although a resonant Raman scattering process is also taking place. This resonance results from the one-dimensional quantum confinement of the electrons in the nanotube.",American Association for the Advancement of Science,,1997
1871,Carbon nanotubes with DNA recognition,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PbfBJx8AAAAJ&citation_for_view=PbfBJx8AAAAJ:u5HHmVD_uO8C,"Since the discovery of their one-dimensional electronic band structure, the leading candidate that has emerged for nanodevice applications is single-walled carbon nanotubes (SWNTs) . Here we unite their unique properties with the specific molecular-recognition features of DNA by coupling SWNTs to peptide nucleic acid (PNA, an uncharged DNA analogue) and hybridizing these macromolecular wires with complementary DNA. Our findings provide a new, versatile means of incorporating SWNTs into larger electronic devices by recognition-based assembly, and of using SWNTs as probes in biological systems by sequence-specific attachment.",Nature Publishing Group UK,,2002
1872,Purification of single-wall carbon nanotubes by microfiltration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PbfBJx8AAAAJ&citation_for_view=PbfBJx8AAAAJ:3fE2CSJIrl8C,"A purification procedure for single-wall carbon nanotubes (SWNTs) prepared by pulsed laser ablation is discussed, which separates coexisting carbon nanospheres (CNS), metal nanoparticles, polyaromatic carbons, and fullerenes from the SWNT fraction. The process involves the suspension of CNS, metal nanoparticles, and SWNTs in an aqueous solution using a cationic surfactant and the subsequent trapping of SWNTs on a membrane filter. No oxidative treatment is required. Scanning/transmission electron microscopy and Raman scattering were used to evaluate the purification process and the vibrational features of SWNTs. Purity of SWNTs at the final stage sample is in excess of 90% by weight, and no evidence of impurity carbon phases was revealed in the Raman spectrum of the SWNT fraction.",American Chemical Society,,1997
1873,Monte Carlo simulations of H2 physisorption in finite-diameter carbon nanotube ropes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PbfBJx8AAAAJ&citation_for_view=PbfBJx8AAAAJ:u-x6o8ySG0sC,"We report the results of classical, grand canonical Monte Carlo simulations of the physisorption of H2 in finite-diameter `ropes' of parallel single-walled carbon nanotubes. The strong dependence of the gravimetric adsorption on the diameter of the rope is correlated with computed values of the specific surface area. The grooves on the external surfaces of the ropes are shown to provide a high binding-energy adsorption site, comparable in strength to those in the endohedral pores. Our results suggest that delamination of nanotube ropes should increase the gravimetric storage capacity.",North-Holland,,2000
1874,Individual single-walled carbon nanotubes as nanoelectrodes for electrochemistry,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PbfBJx8AAAAJ&citation_for_view=PbfBJx8AAAAJ:d1gkVwhDpl0C,"We demonstrate the use of individual single-walled carbon nanotubes (SWNTs) as nanoelectrodes for electrochemistry. SWNTs were contacted by nanolithography, and cyclic voltammetry was performed in aqueous solutions. Interestingly, metallic and semiconducting SWNTs yielded similar steady-state voltammetric curves. We clarify this behavior through a model that considers the electronic structure of the SWNTs. Interfacial electron transfer to the SWNTs is observed to be very fast but can nonetheless be resolved due to the nanometer critical dimension of SWNTs. These studies demonstrate the potential of using a SWNT as a model carbon nanoelectrode for electrochemistry.",American Chemical Society,,2005
1875,"Work in Progress: A Novel Two-Semester Course Sequence that Integrates Engineering Design, Sociotechnical Skills, Career Development, and Academic Advising",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PbfBJx8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=PbfBJx8AAAAJ:bFI3QPDXJZMC,"We present our work in progress of the design and implementation of a new first-year introductory design course sequence in the School of Engineering at the University of Virginia, replacing two long-standing required courses for first-year students–one that introduced the field of engineering, and another that focused on sociotechnical principles and communication. In developing this new course sequence, a task force first generated a set of guiding principles to drive the curriculum redesign, gathered feedback on needed technical and professional proficiencies from alumni, faculty, and employers, and sought information about what engineering looked like at peer institutions before defining a vision the curriculum. Among the recommendations was the creation of a new two course “Engineering Foundations” sequence to integrate engineering design, communication, ethical reasoning, sociotechnical thinking, develop students’ professional competence, and embed academic advising and career development. The sequence has since been deployed and is taught by purpose-hired faculty who serve a dual role as the student’s professor and academic advisor, meaning that every student has regular, face-to-face interaction with their advisor. This increased contact promotes a supportive environment for students as they navigate the beginnings of their college careers. Learning objectives are consistent across sections of the courses taught by the different faculty, and evidence-based pedagogies are consistently employed. Importantly, the interwoven technical and sociotechnical approach to engineering is supported by guidance, materials, and …",,,2024
1876,"Gd2@C79N: Isolation, Characterization, and Monoadduct Formation of a Very Stable Heterofullerene with a Magnetic Spin State of S = 15/2",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PbfBJx8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=PbfBJx8AAAAJ:UeHWp8X0CEIC,"The dimetallic endohedral heterofullerene (EHF), Gd2@C79N, was prepared and isolated in a relatively high yield when compared with the earlier reported heterofullerene, Y2@C79N. Computational (DFT), chemical reactivity, Raman, and electrochemical studies all suggest that the purified Gd2@C79N, with the heterofullerene cage, (C79N)5- has comparable stability with other better known isoelectronic metallofullerene (C80)6- cage species (e.g., Gd3N@C80). These results describe an exceptionally stable paramagnetic molecule with low chemical reactivity with the unpaired electron spin density localized on the internal diatomic gadolinium cluster and not on the heterofullerene cage. EPR studies confirm that the spin state of Gd2@C79N is characterized by a half-integer spin quantum number of S = 15/2. The spin (S = 1/2) on the N atom of the fullerene cage and two octet spins (S = 7/2) of two encapsulated …",American Chemical Society,,2011
1877,Vibrational spectrum of the endohedral C@C fullerene by Raman spectroscopy: Evidence for tunneling of the diatomic molecule,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PbfBJx8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=PbfBJx8AAAAJ:Y0pCki6q_DkC,"The structure and vibrational spectrum of the novel endohedral fullerene C@C was studied by Raman spectroscopy, with particular emphasis on the rotational transitions of the diatomic unit in the low-energy Raman spectrum. We report evidence for tunneling of this unit through the rotation plane and observe anomalous narrowing in a hindered rotational mode. We also report complementary density functional theory calculations that support our conclusions and discuss potential applications to quantum computing and nonvolatile memory devices.",American Physical Society,,2011
1878,Raman study of Fano interference in p‐type doped silicon,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PbfBJx8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=PbfBJx8AAAAJ:W7OEmFMy1HYC,"As the silicon industry continues to push the limits of device dimensions, tools such as Raman spectroscopy are ideal to analyze and characterize the doped silicon channels. The effect of inter‐valence band transitions on the zone center optical phonon in heavily p‐type doped silicon is studied by Raman spectroscopy for a wide range of excitation wavelengths extending from the red (632.8 nm) into the ultra‐violet (325 nm). The asymmetry in the one‐phonon Raman lineshape is attributed to a Fano interference involving the overlap of a continuum of electronic excitations with a discrete phonon state. We identify a transition above and below the one‐dimensional critical point (E = 3.4 eV) in the electronic excitation spectrum of silicon. The relationship between the anisotropic silicon band structure and the penetration depth is discussed in the context of possible device applications. Copyright © 2010 John Wiley & …","John Wiley & Sons, Ltd.",,2010
1879,Noise analysis of carbon nanotube field effect transistors irradiated by electron beam,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=PbfBJx8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=PbfBJx8AAAAJ:qUcmZB5y_30C,"Using current noise measurement techniques, the authors have studied the effects of electron beam exposure on field effect transistors based on carbon nanotube channels. In the case of p-type semiconducting nanotubes, the authors find that high doses induce a potential barrier along the channel, and transport is dominated by the tunneling events across this barrier. The authors suggest that the barrier is induced by charges trapped in the underlying SiO 2 barrier. Complementary studies on metallic nanotubes do not exhibit this behavior.",AIP Publishing,,2010
1880,Accelerated search for materials with targeted properties by adaptive design,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IpNOR80AAAAJ&citation_for_view=IpNOR80AAAAJ:TGkaJS32XoUC,"Finding new materials with targeted properties has traditionally been guided by intuition, and trial and error. With increasing chemical complexity, the combinatorial possibilities are too large for an Edisonian approach to be practical. Here we show how an adaptive design strategy, tightly coupled with experiments, can accelerate the discovery process by sequentially identifying the next experiments or calculations, to effectively navigate the complex search space. Our strategy uses inference and global optimization to balance the trade-off between exploitation and exploration of the search space. We demonstrate this by finding very low thermal hysteresis (ΔT) NiTi-based shape memory alloys, with Ti 50.0 Ni 46.7 Cu 0.8 Fe 2.3 Pd 0.2 possessing the smallest ΔT (1.84 K). We synthesize and characterize 36 predicted compositions (9 feedback loops) from a potential space of∼ 800,000 compositions. Of these, 14 had …",Nature Publishing Group,,2016
1881,Active learning in materials science with emphasis on adaptive sampling using uncertainties for targeted design,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IpNOR80AAAAJ&citation_for_view=IpNOR80AAAAJ:5bfplxN71z4C,"One of the main challenges in materials discovery is efficiently exploring the vast search space for targeted properties as approaches that rely on trial-and-error are impractical. We review how methods from the information sciences enable us to accelerate the search and discovery of new materials. In particular, active learning allows us to effectively navigate the search space iteratively to identify promising candidates for guiding experiments and computations. The approach relies on the use of uncertainties and making predictions from a surrogate model together with a utility function that prioritizes the decision making process on unexplored data. We discuss several utility functions and demonstrate their use in materials science applications, impacting both experimental and computational research. We summarize by indicating generalizations to multiple properties and multifidelity data, and identify challenges …",Nature Publishing Group UK,npj Computational Materials,2019
1882,Accelerated Discovery of Large Electrostrains in BaTiO3‐Based Piezoelectrics Using Active Learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IpNOR80AAAAJ&citation_for_view=IpNOR80AAAAJ:IExZWSxeYXUC,"A key challenge in guiding experiments toward materials with desired properties is to effectively navigate the vast search space comprising the chemistry and structure of allowed compounds. Here, it is shown how the use of machine learning coupled to optimization methods can accelerate the discovery of new Pb‐free BaTiO3 (BTO‐) based piezoelectrics with large electrostrains. By experimentally comparing several design strategies, it is shown that the approach balancing the trade‐off between exploration (using uncertainties) and exploitation (using only model predictions) gives the optimal criterion leading to the synthesis of the piezoelectric (Ba0.84Ca0.16)(Ti0.90Zr0.07Sn0.03)O3 with the largest electrostrain of 0.23% in the BTO family. Using Landau theory and insights from density functional theory, it is uncovered that the observed large electrostrain is due to the presence of Sn, which allows for the ease of …",,,2018
1883,Experimental search for high-temperature ferroelectric perovskites guided by two-step machine learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IpNOR80AAAAJ&citation_for_view=IpNOR80AAAAJ:I2jIoRS3jIgC,"Experimental search for high-temperature ferroelectric perovskites is a challenging task due to the vast chemical space and lack of predictive guidelines. Here, we demonstrate a two-step machine learning approach to guide experiments in search of xBi\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$[ {{\mathrm{Me}}_y' {\mathrm{Me}}_{(1 - y)}'' } ]$$\end{document}O3–(1 − x)PbTiO3-based perovskites with high ferroelectric Curie temperature. These involve classification learning to screen for compositions in the perovskite structures, and regression coupled to active learning to identify promising perovskites for synthesis and feedback. The problem is challenging because the search space is …",Nature Publishing Group UK,,2018
1884,An informatics approach to transformation temperatures of NiTi-based shape memory alloys,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IpNOR80AAAAJ&citation_for_view=IpNOR80AAAAJ:AFXcoJnoRH0C,"The martensitic transformation serves as the basis for applications of shape memory alloys (SMAs). The ability to make rapid and accurate predictions of the transformation temperature of SMAs is therefore of much practical importance. In this study, we demonstrate that a statistical learning approach using three features or material descriptors related to the chemical bonding and atomic radii of the elements in the alloys, provides a means to predict transformation temperatures. Together with an adaptive design framework, we show that iteratively learning and improving the statistical model can accelerate the search for SMAs with targeted transformation temperatures. The possible mechanisms underlying the dependence of the transformation temperature on these features is discussed based on a Landau-type phenomenological model.",Pergamon,,2017
1885,Type-1.5 SNSPD: Interacting vortex theory of two bandgap superconducting single photon detectors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IpNOR80AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=IpNOR80AAAAJ:71d7Y1FijdoC,"Photon detectors based on type-2 superconductors have found widespread applications from on-chip quantum computing to quantum remote sensing. Here, we develop the theory for a new class of type-1.5 superconducting nanowire single photon detectors (SNSPDs) based on two bandgap superconductors with high transition temperatures such as MgB2 (Tc ~38.6K). We show that vortex-vortex interactions in two component condensates lead to a unique operating regime where single photons can seed multiple vortices within a hotspot. We also show that dark counts are suppressed in the type-1.5 regime compared to the widely studied type-2 SNSPDs. Our work opens the door for exploring the unique vortex physics of two-gap superconductors for quantum device applications.",,,2025
1886,"Large‐Scale Interlaboratory Study Along the Entire Process Chain of Laser Powder Bed Fusion: Bridging Variability, Standards, and Optimization across Metals and Polymers",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IpNOR80AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=IpNOR80AAAAJ:rDsFeusoTZkC,"Laser powder bed fusion is a cornerstone technology for additive manufacturing (AM) of metals and polymers, yet challenges in achieving consistent reproducibility and process optimization persist. Addressing these requires a systematic understanding of the interactions between feedstock, process parameters, and final part characteristics throughout the entire production chain. This study presents results from a comprehensive interlaboratory investigation conducted by 32 research institutions, evaluating six feedstock, including nanoparticle‐modified aluminum alloy and polyamide powders, under standardized protocols. Data analysis encompasses 69 powder properties, 15 process parameters per print, and 78 part features, culminating in a dataset of over 1.2 million correlations. Advanced statistical methods and machine learning are employed to identify critical variability drivers, such as the impact of …",,,2025
1887,Broadband optical phonon scattering reduces the thermal conductivity of multi-cation oxides,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IpNOR80AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=IpNOR80AAAAJ:i8eIfGGcn98C,"Multicomponent oxides, such as many minerals and high entropy oxides, show promise as materials for protection in extreme environments. Similar to other phononically dominated materials, the spectrum of vibrational carriers and phonon scattering heavily influences thermal transport in multi-cation oxides. In this work, we experimentally and computationally investigate the nature of phonon scattering and thermal transport in a series of single and multi-cation rare earth sesquioxides and zirconates. A reduction in thermal conductivity was observed from the single to multi-cation oxides, which is directly correlated to measured optical mode lifetimes. Via spectroscopic ellipsometry, we observe red shifting of the optical modes from local bonding distortion. Density functional theory calculation was used to evaluate how bonding distortions influence the phononic scattering rate observed through modal broadening and …",Nature Publishing Group UK,,2025
1888,"Towards"" on-demand"" van der Waals epitaxy with hpc-driven online ensemble sampling",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IpNOR80AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=IpNOR80AAAAJ:Dmoar05iI2YC,"Traditional approaches to achieve targeted epitaxial growth involves exploring a vast parameter space of thermodynamical and kinetic drivers (e.g., temperature, pressure, chemical potential etc). This tedious and time-consuming approach becomes particularly cumbersome to accelerate synthesis and characterization of novel materials with complex dependencies on local chemical environment, temperature and lattice-strains, specifically nanoscale heterostructures of layered 2D materials. We combine the strength of next generation supercomputers at the extreme scale, machine learning and classical molecular dynamics simulations within an adaptive real time closed-loop virtual environment steered by Bayesian optimization to enable asynchronous ensemble sampling of the synthesis space, and apply it to the recrystallization phenomena of amorphous transition-metal dichalcogenide (TMDC) bilayer to form stack moir\'e heterostructures under various growth parameters. We show that such asynchronous ensemble sampling frameworks for materials simulations can be promising towards achieving on-demand epitaxy of van der Waals stacked moir\'e devices, paving the way towards a robust autonomous materials synthesis pipeline to enable unprecedented discovery of new functionalities.",,,2025
1889,An interactive web-based dashboard to track COVID-19 in real time,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rBkH7h0AAAAJ&citation_for_view=rBkH7h0AAAAJ:u-x6o8ySG0sC,"In December, 2019, a local outbreak of pneumonia of initially unknown cause was detected in Wuhan (Hubei, China), and was quickly determined to be caused by a novel coronavirus, 1 namely severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The outbreak has since spread to every province of mainland China as well as 27 other countries and regions, with more than 70 000 confirmed cases as of Feb 17, 2020. 2 In response to this ongoing public health emergency, we developed an online interactive dashboard, hosted by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University, Baltimore, MD, USA, to visualise and track reported cases of coronavirus disease 2019 (COVID-19) in real time. The dashboard, first shared publicly on Jan 22, illustrates the location and number of confirmed COVID-19 cases, deaths, and recoveries for all affected countries. It was developed …",Elsevier,,2020
1890,Association between mobility patterns and COVID-19 transmission in the USA: a mathematical modelling study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rBkH7h0AAAAJ&citation_for_view=rBkH7h0AAAAJ:9yKSN-GCB0IC,"Background Within 4 months of COVID-19 first being reported in the USA, it spread to every state and to more than 90% of all counties. During this period, the US COVID-19 response was highly decentralised, with stay-at-home directives issued by state and local officials, subject to varying levels of enforcement. The absence of a centralised policy and timeline combined with the complex dynamics of human mobility and the variable intensity of local outbreaks makes assessing the effect of large-scale social distancing on COVID-19 transmission in the USA a challenge. Methods We used daily mobility data derived from aggregated and anonymised cell (mobile) phone data, provided by Teralytics (Zürich, Switzerland) from Jan 1 to April 20, 2020, to capture real-time trends in movement patterns for each US county, and used these data to generate a social distancing metric. We used epidemiological data to compute …",Elsevier,,2020
1891,"The Johns Hopkins University Center for Systems Science and Engineering COVID-19 Dashboard: data collection process, challenges faced, and lessons learned",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rBkH7h0AAAAJ&citation_for_view=rBkH7h0AAAAJ:ULOm3_A8WrAC,"On Jan 22, 2020, a day after the USA reported its first COVID-19 case, the Johns Hopkins University Center for Systems Science and Engineering (JHU CSSE) launched the first global real-time coronavirus surveillance system: the JHU CSSE COVID-19 Dashboard. As of June 1, 2022, the dashboard has served the global audience for more than 30 consecutive months, totalling over 226 billion feature layer requests and 3·6 billion page views. The highest daily record was set on March 29, 2020, with more than 4·6 billion requests and over 69 million views. This Personal View reveals the fundamental technical details of the entire data system underlying the dashboard, including data collection, data fusion logic, data curation and sharing, anomaly detection, data corrections, and the human resources required to support such an effort. The Personal View also covers the challenges, ranging from data visualisation to …",Elsevier,The lancet infectious diseases,2022
1892,COVID-19 Dashboard by the center for systems science and engineering (CSSE) at Johns Hopkins University (JHU),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rBkH7h0AAAAJ&citation_for_view=rBkH7h0AAAAJ:iH-uZ7U-co4C,,,,2020
1893,"An interactive web-based dashboard to track COVID-19 in real time (vol 20, pg 533, 2020)",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rBkH7h0AAAAJ&citation_for_view=rBkH7h0AAAAJ:dfsIfKJdRG4C,,ELSEVIER SCI LTD,,2020
1894,SafeTraffic Copilot: adapting large language models for trustworthy traffic safety assessments and decision interventions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rBkH7h0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rBkH7h0AAAAJ:f2IySw72cVMC,"Predicting expected traffic crashes and designing targeted interventions are highly challenging due to the inherent complexity of crash data and persistent concerns over the prediction trustworthiness. We introduce SafeTraffic Copilot that adapts Large Language Models (LLMs) to perform expected crash prediction as a text-reasoning task, then attribute critical features for targeted safety interventions. Within the Copilot, SafeTraffic LLM is customized then fine-tuned on the textualized SafeTraffic Event dataset, which consists of 66,205 real-world crash cases with 14.5 million words from five U.S. states. Across multiple prediction tasks including crash type, severity, and number of injuries, SafeTraffic LLM demonstrates a 33.3% to 45.8% improvement in average F1-score over existing works. To interpret these results and inform safety interventions, we introduce SafeTraffic Attribution, a sentence-level feature-attribution …",Nature Publishing Group UK,,2025
1895,Improving policy design and epidemic response using integrated models of economic choice and disease dynamics with behavioral feedback,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rBkH7h0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rBkH7h0AAAAJ:pyW8ca7W8N0C,"Human behavior plays a crucial role in infectious disease transmission, yet traditional models often overlook or oversimplify this factor, limiting predictions of disease spread and the associated socioeconomic impacts. Here we introduce a feedback-informed epidemiological model that integrates human behavior with disease dynamics in a credible, tractable, and extendable manner. From economics, we incorporate a dynamic decision-making model where individuals assess the trade-off between disease risks and economic consequences, and then link this to a risk-stratified compartmental model of disease spread taken from epidemiology. In the unified framework, heterogeneous individuals make choices based on current and future payoffs, influencing their risk of infection and shaping population-level disease dynamics. As an example, we model disease-decision feedback during the early months of the COVID-19 pandemic, when the decision to participate in paid, in-person work was a major determinant of disease risk. Comparing the impacts of stylized policy options representing mandatory, incentivized/compensated, and voluntary work abstention, we find that accounting for disease-behavior feedback has a significant impact on the relative health and economic impacts of policies. Including two crucial dimensions of heterogeneity—health and economic vulnerability—the results highlight how inequities between risk groups can be exacerbated or alleviated by disease control measures. Importantly, we show that a policy of more stringent workplace testing can potentially slow virus spread and, surprisingly, increase labor supply since …",Public Library of Science,,2025
1896,From Data to Decisions: Engineering Pathways to Equitable and Resilient Public Health Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rBkH7h0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rBkH7h0AAAAJ:yD5IFk8b50cC,"Infectious diseases represent one of the most significant threats to human well-being, capable of causing immense loss of life, disrupting economies, and deepening social inequities. To combat these threats, societies depend on robust infectious disease modeling to guide public health responses. However, creating models that are both accurate and equitable requires a collaborative effort across diverse fields, including epidemiology, computer science, economics, and social science. In this complex landscape, engineering provides the essential bridge, offering systematic approaches to translate interdisciplinary insights into functional, data-driven solutions. This dissertation embodies engineering approaches through two interrelated thrusts. The first research thrust advances short-term infectious disease forecasting by developing multimodal machine learning frameworks. These include a deep-learning model that integrates diverse disease-relevant data streams (Chapter 2), such as epidemiological and mobility data, alongside a Large Language Model-based architecture (PandemicLLM) that reframes forecasting as a text-reasoning task (Chapter 3). Recognizing that real-world human behavior often drives disease dynamics, the second research thrust moves beyond forecasting to model human behavior in complex systems. This is accomplished first by using large-scale mobility data to empirically measure widening behavioral inequities between socioeconomic groups since the COVID-19 pandemic (Chapter 4) and second by developing a Feedback-Informed Epidemiological Model (FIEM) to simulate how individual health-wealth trade …",,,2025
1897,Advancing real-time infectious disease forecasting using large language models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rBkH7h0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rBkH7h0AAAAJ:cFHS6HbyZ2cC,"Forecasting the short-term spread of an ongoing disease outbreak poses a challenge owing to the complexity of contributing factors, some of which can be characterized through interlinked, multi-modality variables, and the intersection of public policy and human behavior. Here we introduce PandemicLLM, a framework with multi-modal large language models (LLMs) that reformulates real-time forecasting of disease spread as a text-reasoning problem, with the ability to incorporate real-time, complex, non-numerical information. This approach, through an artificial intelligence–human cooperative prompt design and time-series representation learning, encodes multi-modal data for LLMs. The model is applied to the COVID-19 pandemic, and trained to utilize textual public health policies, genomic surveillance, spatial and epidemiological time-series data, and is tested across all 50 states of the United States for a …",Nature Publishing Group US,,2025
1898,Can A Society of Generative Agents Simulate Human Behavior and Inform Public Health Policy? A Case Study on Vaccine Hesitancy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rBkH7h0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rBkH7h0AAAAJ:RYcK_YlVTxYC,"Can we simulate a sandbox society with generative agents to model human behavior, thereby reducing the over-reliance on real human trials for assessing public policies? In this work, we investigate the feasibility of simulating health-related decision-making, using vaccine hesitancy, defined as the delay in acceptance or refusal of vaccines despite the availability of vaccination services (MacDonald, 2015), as a case study. To this end, we introduce the VacSim framework with 100 generative agents powered by Large Language Models (LLMs). VacSim simulates vaccine policy outcomes with the following steps: 1) instantiate a population of agents with demographics based on census data; 2) connect the agents via a social network and model vaccine attitudes as a function of social dynamics and disease-related information; 3) design and evaluate various public health interventions aimed at mitigating vaccine hesitancy. To align with real-world results, we also introduce simulation warmup and attitude modulation to adjust agents' attitudes. We propose a series of evaluations to assess the reliability of various LLM simulations. Experiments indicate that models like Llama and Qwen can simulate aspects of human behavior but also highlight real-world alignment challenges, such as inconsistent responses with demographic profiles. This early exploration of LLM-driven simulations is not meant to serve as definitive policy guidance; instead, it serves as a call for action to examine social simulation for policy development.",,,2025
1899,Adverse events in robotic surgery: a retrospective study of 14 years of FDA data,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sXpmLxUAAAAJ&citation_for_view=sXpmLxUAAAAJ:z_wVstp3MssC,"Background Use of robotic systems for minimally invasive surgery has rapidly increased during the last decade. Understanding the causes of adverse events and their impact on patients in robot-assisted surgery will help improve systems and operational practices to avoid incidents in the future. Methods By developing an automated natural language processing tool, we performed a comprehensive analysis of the adverse events reported to the publicly available MAUDE database (maintained by the U.S. Food and Drug Administration) from 2000 to 2013. We determined the number of events reported per procedure and per surgical specialty, the most common types of device malfunctions and their impact on patients, and the potential causes for catastrophic events such as patient injuries and deaths. Results During the study period, 144 deaths (1.4% of the 10,624 reports), 1,391 patient injuries (13.1%), and 8,061 device malfunctions (75.9%) were reported. The numbers of injury and death events per procedure have stayed relatively constant (mean = 83.4, 95% confidence interval (CI), 74.2–92.7 per 100,000 procedures) over the years. Surgical specialties for which robots are extensively used, such as gynecology and urology, had lower numbers of injuries, deaths, and conversions per procedure than more complex surgeries, such as cardiothoracic and head and neck (106.3 vs. 232.9 per 100,000 procedures, Risk Ratio = 2.2, 95% CI, 1.9–2.6). Device and instrument malfunctions, such as falling of burnt/broken pieces of instruments into the patient (14.7%), electrical arcing of instruments (10.5%), unintended operation of instruments (8.6 …",Public Library of Science,,2016
1900,Targeted Attacks on Teleoperated Surgical Robots: Dynamic Model-based Detection and Mitigation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sXpmLxUAAAAJ&citation_for_view=sXpmLxUAAAAJ:AXPGKjj_ei8C,"This paper demonstrates targeted cyber-physical attacks on teleoperated surgical robots. These attacks exploit vulnerabilities in the robot's control system to infer a critical time during surgery to drive injection of malicious control commands to the robot. We show that these attacks can evade the safety checks of the robot, lead to catastrophic consequences in the physical system (e.g., sudden jumps of robotic arms or system's transition to an unwanted halt state), and cause patient injury, robot damage, or system unavailability in the middle of a surgery. We present a model-based analysis framework that can estimate the consequences of control commands through real-time computation of robot's dynamics. Our experiments on the RAVEN II robot demonstrate that this framework can detect and mitigate the malicious commands before they manifest in the physical system with an average accuracy of 90%.",,,2016
1901,"On the safety of machine learning: Cyber-physical systems, decision sciences, and data products",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sXpmLxUAAAAJ&citation_for_view=sXpmLxUAAAAJ:eq2jaN3J8jMC,"Machine learning algorithms increasingly influence our decisions and interact with us in all parts of our daily lives. Therefore, just as we consider the safety of power plants, highways, and a variety of other engineered socio-technical systems, we must also take into account the safety of systems involving machine learning. Heretofore, the definition of safety has not been formalized in a machine learning context. In this article, we do so by defining machine learning safety in terms of risk, epistemic uncertainty, and the harm incurred by unwanted outcomes. We then use this definition to examine safety in all sorts of applications in cyber-physical systems, decision sciences, and data products. We find that the foundational principle of modern statistical machine learning, empirical risk minimization, is not always a sufficient objective. We discuss how four different categories of strategies for achieving safety in engineering …","Mary Ann Liebert, Inc.",,2017
1902,Analysis of safety-critical computer failures in medical devices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sXpmLxUAAAAJ&citation_for_view=sXpmLxUAAAAJ:ufrVoPGSRksC,"Malfunctioning medical devices are one of the leading causes of serious injury and death in the US. Between 2006 and 2011, 5,294 recalls and approximately 1.2 million adverse events were reported to the US Food and Drug Administration (FDA). Almost 23 percent of these recalls were due to computer-related failures, of which approximately 94 percent presented medium to high risk of severe health consequences (such as serious injury or death) to patients. This article investigates the causes of failures in computer-based medical devices and their impact on patients by analyzing human-written descriptions of recalls and adverse event reports obtained from public FDA databases. The authors characterize computer-related failures by deriving fault classes, failure modes, recovery actions, and number of devices affected by the recalls. This analysis is used as a basis for identifying safety issues in life-critical …",IEEE,,2013
1903,"A review of cognitive assistants for healthcare: Trends, prospects, and future directions",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sXpmLxUAAAAJ&citation_for_view=sXpmLxUAAAAJ:4MWp96NkSFoC,"Healthcare cognitive assistants (HCAs) are intelligent systems or agents that interact with users in a context-aware and adaptive manner to improve their health outcomes by augmenting their cognitive abilities or complementing a cognitive impairment. They assist a wide variety of users ranging from patients to their healthcare providers (e.g., general practitioner, specialist, surgeon) in several situations (e.g., remote patient monitoring, emergency response, robotic surgery). While HCAs are critical to ensure personalized, scalable, and efficient healthcare, there exists a knowledge gap in finding the emerging trends, key challenges, design guidelines, and state-of-the-art technologies suitable for developing HCAs. This survey aims to bridge this gap for researchers from multiple domains, including but not limited to cyber-physical systems, artificial intelligence, human-computer interaction, robotics, and smart health. It …",ACM,ACM Computing Surveys (CSUR),2021
1904,Knowsafe: Combined knowledge and data driven hazard mitigation in artificial pancreas systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sXpmLxUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=sXpmLxUAAAAJ:_axFR9aDTf0C,"Significant progress has been made in anomaly detection and run-time monitoring to improve the safety and security of cyber-physical systems (CPS). However, less attention has been paid to hazard mitigation. This paper proposes a combined knowledge and data driven approach, KnowSafe, for the design of safety engines that can predict and mitigate safety hazards resulting from safety-critical malicious attacks or accidental faults targeting a CPS controller. We integrate domain-specific knowledge of safety constraints and context-specific mitigation actions with machine learning (ML) techniques to estimate system trajectories in the far and near future, infer potential hazards, and generate optimal corrective actions to keep the system safe. Experimental evaluation on two realistic closed-loop testbeds for artificial pancreas systems (APS) and two real-world datasets for diabetes treatment demonstrates that …",IEEE,,2025
1905,Systems-Theoretic and Data-Driven Security Analysis in ML-enabled Medical Devices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sXpmLxUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=sXpmLxUAAAAJ:DJbcl8HfkQkC,"The integration of AI/ML into medical devices is rapidly transforming healthcare by enhancing diagnostic and treatment facilities. However, this advancement also introduces serious cybersecurity risks due to the use of complex and often opaque models, extensive interconnectivity, interoperability with third-party peripheral devices, Internet connectivity, and vulnerabilities in the underlying technologies. These factors contribute to a broad attack surface and make threat prevention, detection, and mitigation challenging. Given the highly safety-critical nature of these devices, a cyberattack on these devices can cause the ML models to mispredict, thereby posing significant safety risks to patients. Therefore, ensuring the security of these devices from the time of design is essential. This paper underscores the urgency of addressing the cybersecurity challenges in ML-enabled medical devices at the pre-market phase. We begin by analyzing publicly available data on device recalls and adverse events, and known vulnerabilities, to understand the threat landscape of AI/ML-enabled medical devices and their repercussions on patient safety. Building on this analysis, we introduce a suite of tools and techniques designed by us to assist security analysts in conducting comprehensive premarket risk assessments. Our work aims to empower manufacturers to embed cybersecurity as a core design principle in AI/ML-enabled medical devices, thereby making them safe for patients.",,,2025
1906,Safety Interventions against Adversarial Patches in an Open-Source Driver Assistance System,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sXpmLxUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=sXpmLxUAAAAJ:QYdC8u9Cj1oC,"Drivers are becoming increasingly reliant on advanced driver assistance systems (ADAS) as autonomous driving technology becomes more popular and developed with advanced safety features to enhance road safety. However, the increasing complexity of the ADAS makes autonomous vehicles (AVs) more exposed to attacks and accidental faults. In this paper, we evaluate the resilience of a widely used ADAS against safety-critical attacks that target perception inputs. Various safety mechanisms are simulated to assess their impact on mitigating attacks and enhancing ADAS resilience. Experimental results highlight the importance of timely intervention by human drivers and automated safety mechanisms in preventing accidents in both driving and lateral directions and the need to resolve conflicts among safety interventions to enhance system resilience and reliability.",,,2025
1907,Runtime Stealthy Perception Attacks against DNN-based Adaptive Cruise Control Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sXpmLxUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=sXpmLxUAAAAJ:Ri6SYOTghG4C,"Adaptive Cruise Control (ACC) is a widely used driver assistance technology for maintaining desired speed and safe distance to the leading vehicle. This paper evaluates the security of the deep neural network (DNN) based ACC systems under runtime stealthy perception attacks that strategically inject perturbations into camera data to cause forward collisions. We present a context-aware strategy for the selection of the most critical times for triggering the attacks and a novel optimization-based method for the adaptive generation of image perturbations at runtime. We evaluate the effectiveness of the proposed attack using an actual vehicle, a publicly available driving dataset, and a realistic simulation platform with the control software from a production ACC system, a physical-world driving simulator, and interventions by the human driver and safety features such as Advanced Emergency Braking System (AEBS …",,,2025
1908,SAM: Foreseeing Inference-Time False Data Injection Attacks on ML-enabled Medical Devices,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=sXpmLxUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=sXpmLxUAAAAJ:IUKN3-7HHlwC,"The increasing use of machine learning (ML) in medical systems necessitates robust security measures to mitigate potential threats. Current research often overlooks the risk of adversaries injecting false inputs through peripheral devices at inference time, leading to mispredictions in patients' conditions. These risks are hard to foresee and mitigate during the design phase since the system is assembled by end users at the time of use. To address this gap, we introduce SAM, a technique that enables security analysts to perform System Theoretic Process Analysis for Security (STPA-Sec) on ML-enabled medical devices during the design phase. SAM models the medical system as a control structure, with the ML engine as the controller and peripheral devices as potential points for false data injection. It interfaces with state-of-the-art vulnerability databases and Large Language Models (LLMs) to automate the …",,,2024
1909,Overview of the fundamental reactions and degradation mechanisms of NOx storage/reduction catalysts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swrz9nMAAAAJ&citation_for_view=swrz9nMAAAAJ:u5HHmVD_uO8C,"Over the last several years, nitrogen oxide(s) (NOx) storage/reduction (NSR) catalysts, also referred to as NOx adsorbers or lean NOx traps, have been developed as an aftertreatment technology to reduce NOx emissions from lean‐burn power sources. NSR operation is cyclic: during the lean part of the cycle, NOx are trapped on the catalyst; intermittent rich excursions are used to reduce the NOx to N2 and restore the original catalyst surface; and lean operation then resumes. This review will describe the work carried out in characterizing, developing, and understanding this catalyst technology for application in mobile exhaust‐gas aftertreatment. The discussion will first encompass the reaction process fundamentals, which include five general steps involved in NOx reduction to N2 on NSR catalysts; NO oxidation, NO2 and NO sorption leading to nitrite and nitrate species, reductant evolution, NOx release, and …",Taylor & Francis Group,,2004
1910,Interaction of molecular oxygen with the vacuum-annealed TiO2 (110) surface: molecular and dissociative channels,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swrz9nMAAAAJ&citation_for_view=swrz9nMAAAAJ:u-x6o8ySG0sC,"We have examined the interaction of molecular oxygen with the TiO2(110) surface using temperature-programmed desorption (TPD), isotopic labeling studies, sticking probability measurements, and electron energy loss spectroscopy (ELS). Molecular oxygen does not adsorb on the TiO2(110) surface in the temperature range between 100 and 300 K unless surface oxygen vacancy sites are present. These vacancy defects are generated by annealing the crystal at 850 K, and can be quantified reliably using water TPD. Adsorption of O2 at 120 K on a TiO2(110) surface with 8% oxygen vacancies (about 4 × 1013 sites/cm2) occurs with an initial sticking probability of 0.5−0.6 that diminishes as the surface is saturated. The saturation coverage at 120 K, as estimated by TPD uptake measurements, is approximately three times the surface vacancy population. Coverage-dependent TPD shows little or no O2 desorption …",American Chemical Society,,1999
1911,Review of methane catalytic cracking for hydrogen production,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swrz9nMAAAAJ&citation_for_view=swrz9nMAAAAJ:WF5omc3nYNoC,"Methane catalytic cracking is a process by which carbon monoxide-free hydrogen can be produced. Despite the fact that hydrogen produced from methane cracking is a pure form of hydrogen, methane cracking is not used on an industrial scale for producing hydrogen since it is not economically competitive with other hydrogen production processes. However, pure hydrogen demand is increasing annually either in amount or in number of applications that require carbon monoxide-free hydrogen. Currently, hydrogen is produced primarily via catalytic steam reforming, partial oxidation, and auto-thermal reforming of natural gas. Although these processes are mature technologies, CO is formed as a by-product, and in order to eliminate it from the hydrogen stream, complicated and costly separation processes are required. To improve the methane catalytic cracking economics, extensive research to improve different …",Pergamon,International Journal of Hydrogen Energy,2011
1912,Diesel oxidation catalysts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swrz9nMAAAAJ&citation_for_view=swrz9nMAAAAJ:Tyk-4Ss8FVUC,"The diesel oxidation catalyst (DOC) has been part of diesel exhaust systems since regulations were introduced to limit the amount of harmful emissions released to the environment from diesel engines. The DOC primary functions are oxidation of CO, unburned hydrocarbons, and NO, while active hydrocarbon oxidation can also be used to generate exotherms required for downstream components. This review will describe work that has attempted to understand the reactions, both desired and undesired, that occur over the catalyst. First, the history, configuration, and components of the DOC will be discussed, followed by in-depth coverage of the fundamental reactions that occur over a DOC, including reaction mechanisms, reaction inhibition, and other reactivity effects. Finally, DOC deactivation mechanisms and their effects on the DOC are described. While there is a lot of research literature regarding Pt- and Pd …",Taylor & Francis Group,,2011
1913,Insights into photoexcited electron scavenging processes on TiO2 obtained from studies of the reaction of O2 with OH groups adsorbed at electronic defects on TiO2 (110),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swrz9nMAAAAJ&citation_for_view=swrz9nMAAAAJ:d1gkVwhDpl0C,"In this study we show that molecular oxygen reacts with bridging OH (OHbr) groups formed as a result of water dissociation at oxygen vacancy defects on the surface of rutile TiO2(110). The electronic structure of an oxygen vacancy defect on TiO2(110) is essentially the same as that of electron trap states detected on photoexcited or sensitized TiO2 photocatalysts, being Ti3+ in nature. Electron energy loss spectroscopy (EELS) measurements, in agreement with valence band photoemission results in the literature, indicate that water dissociation at oxygen vacancy sites has little or no impact on the electronic structure of these sites. Temperature programmed desorption (TPD) measurements show that O2 adsorbed at 120 K reacts with near unity reaction probability with OHbr groups on TiO2(110) to form an unidentified intermediate that decomposes to generate terminal OH groups at nondefect sites. Commensurate …",American Chemical Society,,2003
1914,Forced dynamic operation for acrylonitrile manufacture,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swrz9nMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=swrz9nMAAAAJ:5icHVeHT4IsC,"In one aspect, the disclosure relates to a process for acrylonitrile manufacture using forced dynamic operation over transition metal promoted bismuth molybdate-based catalysts. The forced dynamic operation leverages catalyst lattice oxygen in ammoxidation of propene to improved acrylonitrile productivity and yield. This abstract is intended as a scanning tool for purposes of searching in the particular art and is not intended to be limiting of the present disclosure.",,,2025
1915,Impact of Sulfur and Hydrothermal Aging on NOx Reduction over Cu-CHA Catalysts,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swrz9nMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=swrz9nMAAAAJ:_OXeSy2IsFwC,,AIChE,,2025
1916,Modeling of Cu/SSZ-13 SCR Catalyst Sulfation and HTA-Induced Changes in ZCuOH and Z 2 Cu Site Distribution,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swrz9nMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=swrz9nMAAAAJ:Ehil0879vHcC,"Selective catalytic reduction (SCR) with Cu/SSZ-13 catalysts is the leading approach for reducing nitrogen oxides (NOx) emissions from diesel engines. Within the catalyst, various active sites exist, including mono-and multinuclear framework copper sites and extraframework CuO nanoparticles [1]. The literature primarily discusses two framework sites: ZCuOH and Z2Cu. The main mechanisms of Cu/SSZ-13 catalyst deactivation are hydrothermal aging (HTA) and sulfur poisoning. Mild HTA, at temperatures below 750 C, preserves the zeolite structure but promotes the transformation of ZCuOH sites to Z2Cu, affecting catalyst performance [2]. Recently we developed a kinetic model that describes the transformation of the Cu sites during mild HTA and quantified different activity of ZCuOH and Z2Cu sites in NO, CO, NH3 and SO2 oxidation reactions [3]. This work utilizes an integrated experimental and kinetic modeling approach to examine the effect of combined HTA and sulfur poisoning on the standard SCR reaction rate.",AIChE,,2025
1917,Impact of Cu Speciation in Cu/SSZ-13 on Oxidation Reactions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swrz9nMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=swrz9nMAAAAJ:Aul-kAQHnToC,,AIChE,,2025
1918,Effects of Sulfur Exposure on Cu Speciation and NH3 Storage in SSZ-13,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=swrz9nMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=swrz9nMAAAAJ:ZzlSgRqYykMC,,AIChE,,2025
1919,TracKnee: Knee angle measurement using stretchable conductive fabric sensors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2UFPsQYAAAAJ&citation_for_view=2UFPsQYAAAAJ:YOwf2qJgpHMC,"Knee injuries are common and can be costly for a patient in terms of recovery time and monetary contribution. Wearable technology can be used to help monitor a patient's progress and their adherence to rehabilitation protocols. Further, estimating joint angles can help medical professionals treat their patients effectively. In this paper, we propose three models that can be used in succession to calculate knee angles from a voltage reading from a conductive fabric sensor. These models take an input of voltage, calculate the resistance of our conductive fabric sensor, then calculate the change in length across the front of the knee, and finally calculate the angle of the knee. We present TracKnee, a sensing knee sleeve designed and fabricated to unobtrusively measure knee angles. We evaluated our model and our device by conducting a user study with six participants where we collected 240 ground truth angles and …",Elsevier,,2020
1920,Parkinson's disease action tremor detection with supervised-leaning models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2UFPsQYAAAAJ&citation_for_view=2UFPsQYAAAAJ:d1gkVwhDpl0C,"People with Parkinson's Disease (PD) have multiple symptoms, such as freezing of gait (FoG), hand tremors, speech difficulties, and balance issues, in different stages of the disease. Among these symptoms, hand tremors are present across all stages of the disease. PD hand tremors have critical consequences and negatively impact the quality of PD patients' everyday lives. Researchers have proposed a variety of wearable devices to mitigate PD tremors. However, these devices require accurate tremor detection technology to work effectively while the tremor occurs. This paper introduces a PD action tremor detection method to recognize PD tremors from regular activities. We used a dataset from 30 PD patients wearing accelerometers and gyroscope sensors on their wrists. We selected time-domain and frequency-domain hand-crafted features. Also, we compared our hand-crafted features with existing CNN data …",,,2023
1921,MobiGesture: Mobility-aware hand gesture recognition for healthcare,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2UFPsQYAAAAJ&citation_for_view=2UFPsQYAAAAJ:W7OEmFMy1HYC,"Accurate recognition of hand gestures while moving is still a significant challenge, which prevents the wide use of existing gesture recognition technology. In this paper, we propose a novel mobility-aware hand gesture segmentation algorithm to detect and segment hand gestures. We also propose a Convolutional Neural Network (CNN) to classify hand gestures with mobility noises. Based on the segmentation and classification algorithms, we develop MobiGesture, a mobility-aware hand gesture recognition system for healthcare. For the leave-one-subject-out cross-validation test, experiments with human subjects show that the proposed segmentation algorithm achieves 94.0% precision, and 91.2% recall when the user is moving. The proposed hand gesture classification algorithm is 16.1%, 15.3%, and 14.4% more accurate than state-of-the-art work when the user is standing, walking and jogging, respectively.",Elsevier,,2018
1922,TremorSense: Tremor Detection for Parkinson's Disease Using Convolutional Neural Network,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2UFPsQYAAAAJ&citation_for_view=2UFPsQYAAAAJ:Zph67rFs4hoC,"Parkinson's Disease (PD) hand tremors are common symptoms in all stages of PD. PD tremors have a severe influence on patients' daily quality of life. Wearable technology can be used to help detect, quantify, and mitigate these PD tremors. Among the wearable technology, PD tremor detection is the primary step for further analysis and treatment using wearable devices. Some researchers have explored PD rest tremor detection. However, less research has been done concerning postural tremor and action tremor detection, which are difficult to classify only using frequency-domain features. In this paper, we propose TremorSense, a PD tremor detection system to classify Parkinson's Disease hand tremors. TremorSense utilizes accelerometers and gyroscopes as wearable sensors on patients' wrists to collect data from 30 PD patients. We develop the TremorSense Android application that connects the sensors via …",IEEE,,2021
1923,Microsleep prediction using an EKG capable heart rate monitor,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2UFPsQYAAAAJ&citation_for_view=2UFPsQYAAAAJ:3fE2CSJIrl8C,"Microsleep is an involuntary episode of sleep which lasts for a fraction of a second or up to one minute where an individual fails to respond to their environment and becomes unconscious. Because of the lapsed time, microsleep can create dangerous situations, for example when a user is driving a car, any microsleep can result in unsafe situations or even death. In this paper, we design a system that detects and predicts microsleep using data gathered from an EKG capable heart rate monitor. The results of our study show that we detect microsleep correctly 96% of the time and we can predict the time period in which the next microsleep will occur 83% of the time. These predictions occur between 15 seconds and 5 minutes before the next microsleep. After a microsleep is detected or predicted, the system alerts the subject, allowing the shortening of current and prevention of future microsleeps.",IEEE,,2016
1924,"DermaGlow: Objective Quantification of Melanin, Erythema and Skin-tone Using Wearable Optical Spectroscopy",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2UFPsQYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2UFPsQYAAAAJ:L8Ckcad2t8MC,"Accurate characterization of the skin is essential for optimizing diagnostic and therapeutic dermatological tools, as well as technologies like pulse oximetry that rely on skin perfusion. Traditionally, optical spectroscopy has been used for skin assessments through devices like commercial colorimeters, which are high-cost instruments that, while precise, only provide single measurements rather than continuous data. Additionally, medical wearable devices that use this technology often show variable accuracy based on skin tone. The limitations of existing devices demonstrate the need for a solution that can provide low-cost, accurate, and continuous skin monitoring across varying skin tones in a wearable form-factor. This paper introduces DermaGlow, a novel wearable optical spectroscopy framework designed for low-cost, non-invasive monitoring of melanin, erythema, and skin tone. DermaGlow utilizes an off-the …",ACM,,2025
1925,A Multi-Wavelength Optical Sensing Framework for Calibration-Free Wearable Blood Pressure Monitoring,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2UFPsQYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2UFPsQYAAAAJ:QIV2ME_5wuYC,"Blood pressure (BP) is a key indicator of cardiovascular health, with hypertension leading to significant morbidity and mortality worldwide. Continuous monitoring of BP is essential for early detection of cardiovascular disease, however current tools are either cumbersome, unreliable, or not suited for long-term use. Traditional cuff-based BP measurement, while reliable, is impractical for continuous monitoring. Recent advances using photoplethysmography (PPG) waveforms offer an alternative, but they face challenges such as limited interpretability, high computational complexity, and susceptibility to motion artifacts. In this paper, we introduce a novel multi-wavelength optical sensing framework designed for calibration-free wearable blood pressure monitoring. Our system utilizes a broad spectrum of wavelengths and interpretable features, combined with machine learning, to estimate systolic (SBP), diastolic (DBP …",IEEE,,2025
1926,Precision Rehabilitation After Youth Anterior Cruciate Ligament Reconstruction: Individualized Reinjury Risk Stratification and Modifiable Risk Factor Identification to Guide …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2UFPsQYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2UFPsQYAAAAJ:dhFuZR0502QC,"Background After anterior cruciate ligament (ACL) reconstruction, adolescent athletes have a high risk of second ACL injuries, and revision ACL reconstruction is associated with increased medical costs, reduced activity levels, chronic knee pain, and higher rates of knee osteoarthritis, making the prevention of a reinjury a priority. While athlete clearance protocols and algorithms exist, the current methods of identifying the reinjury risk have limited predictive accuracy and are largely based on nonmodifiable risk factors, which limit their clinical application. Purpose The goal of this study was to develop an ACL reinjury risk prediction (ACL-RRP) model capable of accurately classifying an individual patient’s risk, identifying modifiable risk factors, and ranking these factors in the order of importance and ability to be modified. Study Design Cohort study (Diagnosis); Level of evidence, 2. Methods A clinician-informed approach …",SAGE Publications,,2025
1927,Supporting interruption management and multimodal interface design: Three meta-analyses of task performance as a function of interrupting task modality,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ALjgMAoAAAAJ&citation_for_view=ALjgMAoAAAAJ:IjCSPb-OGe4C,"Objective The aim of this study was to integrate empirical data showing the effects of interrupting task modality on the performance of an ongoing visual-manual task and the interrupting task itself. The goal is to support interruption management and the design of multimodal interfaces. Background Multimodal interfaces have been proposed as a promising means to support interruption management. To ensure the effectiveness of this approach, their design needs to be based on an analysis of empirical data concerning the effectiveness of individual and redundant channels of information presentation. Method Three meta-analyses were conducted to contrast performance on an ongoing visual task and interrupting tasks as a function of interrupting task modality (auditory vs. tactile, auditory vs. visual, and single modality vs. redundant auditory-visual). In total, 68 studies were included and six moderator variables were …",Sage Publications,,2013
1928,Extending Fitts’ law in three-dimensional virtual environments with current low-cost virtual reality technology,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ALjgMAoAAAAJ&citation_for_view=ALjgMAoAAAAJ:MAUkC_7iAq8C,"Virtual reality (VR) interfaces require users to perform three-dimensional reaching and pointing movements to interact with objects positioned within the user's arm's reach. However, there has been limited work that has evaluated the applicability of established models of human motor control to model performance of these tasks in 3D virtual reality environments using current low-cost technologies. In this study, a 3D discrete pointing task using the Oculus Rift system was used to explore potential influences on movement in VR and to account for these influences in a new formulation of Fitts’ law. Target size and distance from the starting point of movement were systematically varied to generate a broad range of index of difficulty (ID) values. Target locations were specified using a spherical coordinate system in which inclination angle corresponded to the pitch of the movement axis with respect to the starting point of …",Academic Press,,2020
1929,Informing the design of multimodal displays: A meta-analysis of empirical studies comparing auditory and tactile interruptions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ALjgMAoAAAAJ&citation_for_view=ALjgMAoAAAAJ:2osOgNQ5qMEC,"The expected air traffic growth will introduce new tasks and automation technologies. As a result, the amount of mostly visual cockpit information will increase significantly, leading to more interruptions and risk of data overload. One promising means of addressing this challenge is through the use of multimodal interfaces which distribute information across sensory channels. To inform the design of such interfaces, a meta-analysis was conducted on the effectiveness and performance effects of auditory versus tactile interruption signals. From the 23 studies, ratio scores were computed to compare performance between the two modalities. The impact of 6 moderator variables was also examined. Overall, this analysis shows faster responses to tactile interruptions. However, more complex and very urgent interruption signals are better presented via the auditory modality. The findings add to our knowledge base in …",SAGE Publications,,2011
1930,Effects of workload and workload transitions on attention allocation in a dual-task environment: Evidence from eye tracking metrics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ALjgMAoAAAAJ&citation_for_view=ALjgMAoAAAAJ:Dem6FJhTUoYC,"High mental workload, in addition to changes in workload, can negatively affect operators, but it is not clear how sudden versus gradual workload transitions influence performance and visual attention allocation. This knowledge is important as sudden shifts in workload are common in multitasking domains. The objective of this study was to investigate, using performance and eye tracking metrics, how constant versus variable levels of workload affect operators in the context of a dual-task paradigm. An unmanned aerial vehicle command and control simulation varied task load between low, high, gradually transitioning from low to high, and suddenly transitioning from low to high. Performance on a primary and secondary task and several eye tracking measures were calculated. There was no significant difference between sudden and gradual workload transitions in terms of performance or attention allocation overall …",Sage Publications,,2020
1931,Crossmodal matching: A critical but neglected step in multimodal research,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ALjgMAoAAAAJ&citation_for_view=ALjgMAoAAAAJ:k8Z6L05lTy4C,"Research on multimodal information processing has seen a surge in recent years. Most of this research suffers from a significant shortcoming: the failure to perform crossmodal matching. Crossmodal matching refers to equating perceived intensities of stimuli across two sensory modalities. This step is critical for avoiding that modality is confounded with other signal properties. Very few studies include this step, and there is no agreed-upon matching technique. An experiment comparing two different approaches shows that even minor variations can lead to significant differences in match values and intraindividual match variability. Our findings highlight the need for developing and employing a valid crossmodal matching procedure for future studies.",IEEE,,2015
1932,Deep learning-assisted system improves practical effect in cervical cytopathology diagnosis: A comparative study of reading modes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ALjgMAoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ALjgMAoAAAAJ:z6xuaG2dYH0C,"Deep learning (DL) has significantly improved the diagnostic accuracy and efficiency of cytopathologists. However, current DL-assisted reading modes have yet to be fully evaluated, and there is limited evidence regarding cytopathologists' preferences and experiences. This study employs a randomized, controlled, four-way crossover design to assess the effectiveness of four different reading modes in cervical cytopathology readings. This study included retrospectively collected 1620 cervical slides between 2021 and 2022. These slides were read by 108 certified cytopathologists with varying expertise using the four reading modes: unassisted, concurrent, second, and triage mode. A questionnaire survey was conducted to gather the cytopathologists' adoption of each mode, including mode score and their confidence and preferences. Compared to unassisted, all DL-assisted modes improved the cytopathologists …",Elsevier,,2025
1933,A Survey on Tactile Change Blindness,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ALjgMAoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ALjgMAoAAAAJ:D_tqNUsBuKoC,"While vibrotactile displays continue to gain popularity, it remains that the phenomenon of tactile change blindness negatively impacts the human ability to detect changes between and within tactile signals. This paper surveys the research literature on tactile change detection and blindness under various parameters, including the number of tactors used, the intensity and length of the stimulus, and whether distractors between stimuli (i.e., transients) were used during experimentation, among others. The goal of this survey is to summarize what has been done in an attempt to better understand the parameters that exacerbate tactile change blindness and identify potential areas of future research. When such an understanding is reached, the design of haptic and multimodal displays may ideally be improved.",IEEE,IEEE Transactions on Haptics,2025
1934,Intensity-Based Tactile Changes are Detected Faster Than Location-Based Tactile Changes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ALjgMAoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ALjgMAoAAAAJ:T_ojBgVMvoEC,"Haptic and multimodal displays fundamentally rely on a user's ability to accurately detect when a change occurs within the display. The present study compared change detection performance between tactile stimuli defined by featural (i.e., intensity) and spatial (i.e., location) properties using a two-alternative forced choice (2AFC) paradigm to determine whether they can be considered equivalent. Electroencephalography (EEG) and the event-related potential (ERP) technique were used to complement behavioral data by providing a view into the neural characteristics and time course of tactile information processing. Results indicate that feature-based and space-based tactile stimuli do not significantly differ in sensitivity as signal detection theory defines. Despite this, behavioral responses to feature-based stimuli are nearly 100 ms faster than space-based stimuli. Participants also displayed a more conservative …",IEEE,,2025
1935,Predicting Mental Demand of Teammates Using Eye Tracking Metrics: A Machine Learning Approach,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ALjgMAoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ALjgMAoAAAAJ:2ywjKiB__4kC,"Analyzing eye tracking data using machine learning (ML) offers new insights into cognitive states such as mental workload. However, most research has focused on individuals rather than teams, where workload emerges from shared attention and coordination. Additionally, traditional workload assessment methods like the NASA Task Load Index (NASA-TLX) face limitations in aggregating subscales, raising concerns about their accuracy. This study explores the feasibility of using gaze-based ML models to classify mental demand in Unmanned Aerial Vehicle (UAV) command-and-control (C2) teams. Eye tracking and workload data were collected from four experimental studies involving UAV C2 tasks. Using eight ML classifiers, we evaluated whether gaze features could predict workload levels. k-Nearest Neighbors (kNN) achieved the highest accuracy (81%) and precision (90%), outperforming other models …",,,2025
1936,Smart textiles for personalized healthcare,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Xtx_WC4AAAAJ&citation_for_view=Xtx_WC4AAAAJ:qxL8FJ1GzNcC,"Incorporating sensing and therapeutic capabilities into everyday textiles could be a powerful approach in the development of personalized healthcare. The creation of such smart textiles has been driven by the fabrication of various miniaturized platform technologies, and has led to the construction of compact, autonomous and interconnected functional textiles. Here we review the development of smart textiles for application in personalized healthcare. We examine the different platform technologies, the various fabrication strategies and the range of clinical scenarios in which they are used. We also explore the current commercial and regulatory landscapes, and consider issues of data management. Finally, we highlight the key steps required to transition these technological platforms to commercial applications.",Nature Publishing Group UK,Nature Electronics,2022
1937,Electronic textiles for wearable point-of-care systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Xtx_WC4AAAAJ&citation_for_view=Xtx_WC4AAAAJ:KlAtU1dfN6UC,"Traditional public health systems are suffering from limited, delayed, and inefficient medical services, especially when confronted with the pandemic and the aging population. Fusing traditional textiles with diagnostic, therapeutic, and protective medical devices can unlock electronic textiles (e-textiles) as point-of-care platform technologies on the human body, continuously monitoring vital signs and implementing round-the-clock treatment protocols in close proximity to the patient. This review comprehensively summarizes the research advances on e-textiles for wearable point-of-care systems. We start with a brief introduction to emphasize the significance of e-textiles in the current healthcare system. Then, we describe textile sensors for diagnosis, textile therapeutic devices for medical treatment, and textile protective devices for prevention, by highlighting their working mechanisms, representative materials, and …",American Chemical Society,Chemical Reviews,2021
1938,Nanogenerators for smart cities in the era of 5G and Internet of Things,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Xtx_WC4AAAAJ&citation_for_view=Xtx_WC4AAAAJ:W7OEmFMy1HYC,"5G has taken off at a brisk speed over the years, bringing significant benefits to the Internet of Things (IoT) devices and wireless sensor nodes. The launching of 5G technology provides an excellent opportunity for the faster development of smart cities. Nanogenerators (NGs) have been widely demonstrated as sustainable power sources and self-powered active sensors. The last 15 years of research on NGs have revealed that it can contribute to the digitalization of smart city services, such as localized renewable energy supplies, intelligent transportation, smart vehicles, and digital healthcare applications. The integration of novel NG technology in smart cities will solve problems pertinent to sustainable power sources for decentralized IoT devices and provide pathways for realizing self-powered active sensing systems. In this review, we will provide a comprehensive review of current research on NGs' applications in …",Elsevier,Joule,2021
1939,Giant magnetoelastic effect in soft systems for bioelectronics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Xtx_WC4AAAAJ&citation_for_view=Xtx_WC4AAAAJ:hqOjcs7Dif8C,"The magnetoelastic effect—the variation of the magnetic properties of a material under mechanical stress—is usually observed in rigid alloys, whose mechanical modulus is significantly different from that of human tissues, thus limiting their use in bioelectronics applications. Here, we observed a giant magnetoelastic effect in a soft system based on micromagnets dispersed in a silicone matrix, reaching a magnetomechanical coupling factor indicating up to four times more enhancement than in rigid counterparts. The results are interpreted using a wavy chain model, showing how mechanical stress changes the micromagnets’ spacing and dipole alignment, thus altering the magnetic field generated by the composite. Combined with liquid-metal coils patterned on polydimethylsiloxane working as a magnetic induction layer, the soft magnetoelastic composite is used for stretchable and water-resistant magnetoelastic …",Nature Publishing Group UK,,2021
1940,Muscle fibers inspired high‐performance piezoelectric textiles for wearable physiological monitoring,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Xtx_WC4AAAAJ&citation_for_view=Xtx_WC4AAAAJ:zYLM7Y9cAGgC,"The next‐generation wearable biosensors with highly biocompatible, stretchable, and robust features are expected to enable the change of the current reactive and disease‐centric healthcare system to a personalized model with a focus on disease prevention and health promotion. Herein, a muscle‐fiber‐inspired nonwoven piezoelectric textile with tunable mechanical properties for wearable physiological monitoring is developed. To mimic the muscle fibers, polydopamine (PDA) is dispersed into the electrospun barium titanate/polyvinylidene fluoride (BTO/PVDF) nanofibers to enhance the interfacial‐adhesion, mechanical strength, and piezoelectric properties. Such improvements are both experimentally observed via mechanical characterization and theoretically verified by the phase‐field simulation. Taking the PDA@BTO/PVDF nanofibers as the building blocks, a nonwoven light‐weight piezoelectric textile is …",,,2021
1941,A soft magnetoelastic sensor to decode levels of fatigue,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Xtx_WC4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Xtx_WC4AAAAJ:35N4QoGY0k4C,"Fatigue is a complex condition characterized by a decline in a person’s mental or physical performance. Methods to gauge fatigue include self-reported questionnaires, electroencephalography and camera-based technologies. However, these methods are typically restricted to laboratory settings, which limits their wider accessibility. Here we report a soft on-eyelid magnetoelastic sensor that can capture eye-blink parameters in real time and quantitatively decode fatigue levels. The sensor, which works in a self-powered manner, comprises a magnetomechanical coupling layer formed from a silicone rubber matrix embedded with micromagnets and a conductive gold coil patterned onto a thin thermoplastic elastomer layer. This design allows the conversion of eye movements into high-fidelity electrical signals. The sensor exhibits a Young’s modulus of 200 kPa, a stretchability of up to 530% and a pressure sensitivity …",Nature Publishing Group UK,,2025
1942,Neural network-assisted personalized handwriting analysis for Parkinson’s disease diagnostics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Xtx_WC4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Xtx_WC4AAAAJ:J_g5lzvAfSwC,"Diagnosing Parkinson’s disease (PD) promptly, accessibly and effectively is crucial for improving patient outcomes, yet reaching this goal remains a challenge. Here we developed a diagnostic pen featuring a soft magnetoelastic tip and ferrofluid ink, capable of sensitively and quantitatively converting both on-surface and in-air writing motions into high-fidelity, analyzable signals for self-powered PD diagnostics. The diagnostic pen’s working mechanism is based on the magnetoelastic effect in its magnetoelastic tip and the dynamic movement of the ferrofluid ink. To validate the clinical potential, a pilot human study was conducted, incorporating both patients with PD and healthy participants. The diagnostic pen accurately recorded handwriting signals, and a one-dimensional convolutional neural network-assisted analysis successfully distinguished patients with PD with an average accuracy of 96.22%. Our …",Nature Publishing Group US,,2025
1943,Advances in 2D materials for wearable biomonitoring,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Xtx_WC4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Xtx_WC4AAAAJ:lSLTfruPkqcC,"Over the past two decades, the discovery of graphene has sparked a significant increase in research on two-dimensional (2D) materials These materials exhibit exceptional properties, including a large surface area, flexibility, and tunable electrical conductivity, making them ideal for building up wearable biosensors. Such biosensors offer rapid response times, high sensitivity, biocompatibility, and outstanding mechanical strength. This review provides a comprehensive overview of wearable biosensors based on 2D materials, highlighting their unique properties, synthesis methods, and integration into flexible electronic systems. Significant advancements, existing challenges, and commercialization prospects are explored. The development of these biosensors promises to revolutionize health monitoring and advance personalized medicine by enabling continuous, real-time monitoring of physiological parameters.",Elsevier,Materials Science and Engineering: R: Reports,2025
1944,Leveraging giant magnetoelasticity in soft matter for acoustic energy harvesting,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Xtx_WC4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Xtx_WC4AAAAJ:NaGl4SEjCO4C,"To address the challenge of recycling energy from low-density acoustic waves found in everyday sounds such as speech and music, we developed a soft acoustic energy harvester based on the giant magnetoelastic effect. This harvester efficiently captures energy from various environmental sound sources. It operates by combining the giant magnetoelastic effect with a spray-coating and magnetic pre-orientation process, enabling it to convert multi-directional acoustic waves into electrical energy across a wide frequency range (0–900 Hz). The magnetoelastic generator achieves a short-circuit current density of 98 μA cm−2 at a low internal impedance of 300 Ω, representing a significant improvement in current output that achieves a 100-fold increase compared to existing counterparts for acoustic energy harvesting. With inherent waterproofness and dustproofness, it can function effectively in humid or dusty …",Elsevier,,2025
1945,Diagnosing Parkinson’s disease via behavioral biometrics of keystroke dynamics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Xtx_WC4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Xtx_WC4AAAAJ:RGFaLdJalmkC,"Parkinson’s disease (PD) is one of the rapidly growing neurodegenerative diseases, affecting more than 10 million people worldwide. Early and accurate diagnosis of PD is highly desirable for therapeutic interventions but remains a substantial challenge. We developed a soft, portable intelligent keyboard leveraging magnetoelasticity to detect subtle pressure variations in keystroke dynamics by converting continuous keystrokes into high-fidelity electrical signals, thus enabling the quantitative analysis of PD motor symptoms using machine learning. Relying on a fundamental working mechanism, the intelligent keyboard demonstrates highly sensitive, intrinsically waterproof, and biocompatible properties, with the successful demonstration in a pilot study on patients with PD. To facilitate the potential continuous monitoring of PD, a customized cellphone application was developed to integrate the intelligent keyboard …",American Association for the Advancement of Science,,2025
1946,Fighting traffic: the dawn of the motor age in the American city,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iWK7deIAAAAJ&citation_for_view=iWK7deIAAAAJ:u5HHmVD_uO8C,"The fight for the future of the city street between pedestrians, street railways, and promoters of the automobile between 1915 and 1930. Before the advent of the automobile, users of city streets were diverse and included children at play and pedestrians at large. By 1930, most streets were primarily a motor thoroughfares where children did not belong and where pedestrians were condemned as “jaywalkers.” In Fighting Traffic, Peter Norton argues that to accommodate automobiles, the American city required not only a physical change but also a social one: before the city could be reconstructed for the sake of motorists, its streets had to be socially reconstructed as places where motorists belonged. It was not an evolution, he writes, but a bloody and sometimes violent revolution. Norton describes how street users struggled to define and redefine what streets were for. He examines developments in the crucial transitional years from the 1910s to the 1930s, uncovering a broad anti-automobile campaign that reviled motorists as “road hogs” or “speed demons” and cars as “juggernauts” or “death cars.” He considers the perspectives of all users—pedestrians, police (who had to become “traffic cops”), street railways, downtown businesses, traffic engineers (who often saw cars as the problem, not the solution), and automobile promoters. He finds that pedestrians and parents campaigned in moral terms, fighting for “justice.” Cities and downtown businesses tried to regulate traffic in the name of “efficiency.” Automotive interest groups, meanwhile, legitimized their claim to the streets by invoking “freedom”—a rhetorical stance of particular power in the United …",Mit Press,,2011
1947,Street rivals: Jaywalking and the invention of the motor age street,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iWK7deIAAAAJ&citation_for_view=iWK7deIAAAAJ:u-x6o8ySG0sC,"Before the American city could be physically reconstructed to accommodate automobiles, its streets had to be socially reconstructed as places where cars belong. Until then, streets were regarded as public spaces, where practices that endangered or obstructed others (including pedestrians) were disreputable. Motorists' claim to street space was therefore fragile, subject to restrictions that threatened to negate the advantages of car ownership. Epithets—especially joy rider—reflected and reinforced the prevailing social construction of the street. Automotive interest groups (motordom) recognized this obstacle and organized in the teens and 1920s to overcome it. One tool in this effort was jaywalker. Motordom discovered this obscure colloquialism in the teens, reinvented it, and introduced it to the millions. It ridiculed once-respectable street uses and cast doubt on pedestrians' legitimacy in most of the street. Though …",Johns Hopkins University Press,,2007
1948,Four Paradigms: Traffic Safety in the Twentieth-Century United States,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iWK7deIAAAAJ&citation_for_view=iWK7deIAAAAJ:zYLM7Y9cAGgC,"Traffic safety, once neglected within the larger history of the automobile in the United States, has finally been getting the attention it always deserved. Nevertheless, historians still sometimes misappraise traffic safety in one era by the standards of another. Ahistorical assumptions have contributed to misinterpretations—for example, that Americans of the 1920s were extraordinarily tolerant of traffic casualties because they did not respond to them as more recent traffic-safety paradigms would prescribe. As a corrective, four paradigms, approximately sequential, are proposed: Safety First, Control, Crashworthiness, and Responsibility. Historians are invited to borrow, modify, or replace them, and to consider their applicability to other countries. Whether these particular paradigms survive review or not, historians who are alert to safety paradigms will produce more reliable scholarship on the history of traffic safety.",Johns Hopkins University Press,,2015
1949,Autonorama: the illusory promise of high-tech driving,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iWK7deIAAAAJ&citation_for_view=iWK7deIAAAAJ:qUcmZB5y_30C,"“The foundation has been laid for fully autonomous,” Elon Musk announced in 2016, when he assured the world that Tesla would have a driverless fleet on the road in 2017.“It’s twice as safe as a human, maybe better.” Promises of technofuturistic driving utopias have been ubiquitous wherever tech companies and carmakers meet. In Autonorama: The Illusory Promise of High-Tech Driving, technology historian Peter Norton argues that driverless cars cannot be the safe, sustainable, and inclusive “mobility solutions” that tech companies and automakers are promising us. The salesmanship behind the driverless future is distracting us from investing in better ways to get around that we can implement now. Unlike autonomous vehicles, these alternatives are inexpensive, safe, sustainable, and inclusive. Norton takes the reader on an engaging ride—from the GM Futurama exhibit to “smart” highways and vehicles—to show how we are once again being sold car dependency in the guise of mobility. He argues that we cannot see what tech companies are selling us except in the light of history. With driverless cars, we’re promised that new technology will solve the problems that car dependency gave us—zero crashes! zero emissions! zero congestion! But these are the same promises that have kept us on a treadmill of car dependency for 80 years. Autonorama is hopeful, advocating for wise, proven, humane mobility that we can invest in now, without waiting for technology that is forever just out of reach. Before intelligent systems, data, and technology can serve us, Norton suggests, we need wisdom. Rachel Carson warned us that when we seek …",Island Press,,2021
1950,Fighting traffic,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iWK7deIAAAAJ&citation_for_view=iWK7deIAAAAJ:_kc_bZDykSQC,"Fighting Traffic Page 1 Fighting Traffic The Dawn of the Motor Age in the American City Peter D. Norton The MIT Press Cambridge, Massachusetts London, England Page 2 © 2008 Massachusetts Institute of Technology All rights reserved. No part of this book may be reproduced in any form by any electronic or mechanical means (including photocopying, recording, or information storage and retrieval) without permission in writing from the publisher. For information on quantity discounts, email special_sales@mitpress.mit.edu. Set in Stone serif and Stone sans by SNP Best-set Typesetter Ltd., Hong Kong. Printed and bound in the United States of America. Library of Congress Cataloging-in-Publication Data Norton, Peter D. Fighting traffic : the dawn of the motor age in the American city / Peter Norton. p. cm. Includes bibliographical references and index. ISBN 978-0-262-14100-0 (hardcover : alk. paper) 1. Transportation…",,,2008
1951,The Mismeasure of the American Street.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iWK7deIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iWK7deIAAAAJ:hMod-77fHWUC,"The urban ground floor of the typical American city is comparatively privatized, exclusive, and unconducive to diverse local purposes. Proponents of more versatile and inviting urban environments are likely to hear that their proposals face insuperable cultural obstacles. In fact, these obstacles themselves began as contested, heterodox, and farfetched innovations. In the twentieth century, the typical American city street was radically transformed. Novel standards, initially controversial, legitimized and ostensibly necessitated the changes. The new measures were prescriptive, mandating vehicular storage, speed, and throughput over other important urban functions. Valuable street uses that were inconsistent with these criteria were either redefined as nuisances or, more often, omitted from calculations entirely, thereby mismeasuring their value at zero. The effects included privatization of public space and public …",,,2025
1952,"Normalising fast driving: the radical revision of traffic safety in the United States, 1920–1940",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iWK7deIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iWK7deIAAAAJ:JV2RwH3_ST0C,"The ‘radical revision’in public policy that Mehren called for lies at the origin of the cardependent world most Americans inhabit today. In 1922 pedestrians far outnumbered motorists, and their right to the safe and convenient use of streets was settled law. As fast motor vehicles proliferated, however, the mix proved deadly. Both law and policy assigned the burden of responsibility to motorists. They were in the minority, and they had introduced a new hazard. Because streets were for all, motorists would have to conform. Mehren proposed to redefine streets as motor thoroughfares. Instead of safety from motorists, he proposed safety for motorists. In 1922 this was a fringe position; Mehren himself called it ‘radical.’But within a year, motordom united behind Mehren’s appeal. By the middle of the decade the radical revision was well underway in legislation and administrative practice. Today this policy legacy also …",Edward Elgar Publishing,,2025
1953,"Book Review: Justice and the Interstates: The Racist Truth about Urban Highways by Ryan Reft, Amanda K. Phillips de Lucas and Rebecca C. Retzlaff (eds)",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iWK7deIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iWK7deIAAAAJ:maZDTaKrznsC,"In their conception, execution, and effects, urban highways in the United States reflected and reinforced systemic racial injustices. At least among historians, this assessment is neither new nor controversial. By 1967, highway project opponents in Washington, DC were denouncing “White men’s roads through black men’s homes”. 1 In 1969, when bulldozers were still clearing whole city blocks to make room for new segments of the interstate highways, Whitney Young, executive director of the National Urban League, condemned highway projects and their planners for “destroying black neighborhoods to make commuting faster and easier for white suburbanites”. 2 Young presented his assertion as a statement of self-evident fact. It is therefore striking that more than 50 years later, an anthology of articles on the history of urban highways in the USA would be subtitled The Racist Truth about Urban Highways—as if this …",SAGE Publications,The Journal of Transport History,2023
1954,"Book Review: No Bicycle, No Bus, No Job: The Making of Workers’ Mobility in the Netherlands, 1920–1990 by Patrick Bek",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iWK7deIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iWK7deIAAAAJ:isC4tDSrTZIC,"At work, a lunch break is typically taken on the employer’s time. After all, a meal is essential to the working day. Equally essential is the journey to and from work. Like the workday, these trips are time away from home life and personal obligations, and in both time and money they are likely to cost more than lunch. Somehow, however, few workers can even ever hope for an employer who will accept any responsibility for these journeys. Some can expect free parking; otherwise, for most employers, this demanding work obligation is the employees’ responsibility. There is of course a history behind this inconsistency, but despite the flourishing of mobility studies, it has received only limited attention. Labor historians have examined workplace power struggles, and mobility historians have studied daily journeys, but power struggles over responsibility for daily journeys to work have been inconspicuous. In No Bicycle, No …",SAGE Publications,The Journal of Transport History,2023
1955,Consuming Landscapes: What We See When We Drive and Why It Matters by Thomas Zeller,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=iWK7deIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=iWK7deIAAAAJ:M3NEmzRMIkIC,"By Thomas Zeller. Baltimore: Johns Hopkins University Press, 2022. Pp. 264. Driving is a visual experience. Even today, despite astonishing technology, the only sense a driver must have is still the sense of sight. In Consuming Landscapes, Thomas Zeller examines driving as a constructed visual experience. In selecting a scenic route, drivers choose their vistas, but such views are also chosen for them, and often contrived for them, by the road designers. Setting aside the proverbial “Point A” and “Point B,” which often pass as the only places that are supposed to matter in a trip, Zeller investigates the line segment between the two, reminding us that drivers’ experiences are never limited to the roadway and the others on it. Drivers do not just drive through landscapes; they drive in them. This fact was road designers’ opportunity, and that of those who commissioned them. For themselves and their clients, road …",Johns Hopkins University Press,,2023
1956,Sub-threshold design for ultra low-power systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=I7a8pr0AAAAJ&citation_for_view=I7a8pr0AAAAJ:u-x6o8ySG0sC,"Current microprocessor and digital signal processors heavily utilize register files and memories for high speed computing. Register files are needed for local buffering and load-store operations. SRAMs providing local and global caches are starting to occupy a significant fraction of microprocessor chip area. For example, in the state-of-the-art Texas Instruments C64x Very-Long Instruction Word (VLIW) DSP processor, there is more than 1MB of memory and two 32-entry 32-bit register files [126]. The latest 0MAP2 application processor contains more than 5Mb of internal RAM [127]. As processor complexity increases and transistor widths decrease, Systems on a Chip (SoCs) are adding more and more on-chip memory to the design. In deep sub-micron technologies, large memories can dissipate a lot of leakage energy because they cannot be shutdown when idling. The information in the memories must be held …",Springer,,2006
1957,Body area sensor networks: Challenges and opportunities,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=I7a8pr0AAAAJ&citation_for_view=I7a8pr0AAAAJ:UeHWp8X0CEIC,"Body area sensors can enable novel applications in and beyond healthcare, but research must address obstacles such as size, cost, compatibility, and perceived value before networks that use such sensors can become widespread.",IEEE,Computer,2009
1958,Modeling and sizing for minimum energy operation in subthreshold circuits,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=I7a8pr0AAAAJ&citation_for_view=I7a8pr0AAAAJ:u5HHmVD_uO8C,"This paper examines energy minimization for circuits operating in the subthreshold region. Subthreshold operation is emerging as an energy-saving approach to many energy-constrained applications where processor speed is less important. In this paper, we solve equations for total energy to provide an analytical solution for the optimum V/sub DD/ and V/sub T/ to minimize energy for a given frequency in subthreshold operation. We show the dependence of the optimum V/sub DD/ for a given technology on design characteristics and operating conditions. This paper also examines the effect of sizing on energy consumption for subthreshold circuits. We show that minimum sized devices are theoretically optimal for reducing energy. A fabricated 0.18-/spl mu/m test chip is used to compare normal sizing and sizing to minimize operational V/sub DD/ and to verify the energy models. Measurements show that existing …",IEEE,,2005
1959,A 256-kb 65-nm sub-threshold SRAM design for ultra-low-voltage operation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=I7a8pr0AAAAJ&citation_for_view=I7a8pr0AAAAJ:IjCSPb-OGe4C,"Low-voltage operation for memories is attractive because of lower leakage power and active energy, but the challenges of SRAM design tend to increase at lower voltage. This paper explores the limits of low-voltage operation for traditional six-transistor (6T) SRAM and proposes an alternative bitcell that functions too much lower voltages. Measurements confirm that a 256-kb 65-nm SRAM test chip using the proposed bitcell operates into sub-threshold to below 400 mV. At this low voltage, the memory offers substantial power and energy savings at the cost of speed, making it well-suited to energy-constrained applications. The paper provides measured data and analysis on the limiting effects for voltage scaling for the test chip.",IEEE,,2007
1960,A Batteryless 19 W MICS/ISM-Band Energy Harvesting Body Sensor Node SoC for ExG Applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=I7a8pr0AAAAJ&citation_for_view=I7a8pr0AAAAJ:bFI3QPDXJZMC,"This paper presents an ultra-low power batteryless energy harvesting body sensor node (BSN) SoC fabricated in a commercial 130 nm CMOS technology capable of acquiring, processing, and transmitting electrocardiogram (ECG), electromyogram (EMG), and electroencephalogram (EEG) data. This SoC utilizes recent advances in energy harvesting, dynamic power management, low voltage boost circuits, bio-signal front-ends, subthreshold processing, and RF transmitter circuit topologies. The SoC is designed so the integration and interaction of circuit blocks accomplish an integrated, flexible, and reconfigurable wireless BSN SoC capable of autonomous power management and operation from harvested power, thus prolonging the node lifetime indefinitely. The chip performs ECG heart rate extraction and atrial fibrillation detection while only consuming 19 μW, running solely on harvested energy. This chip is the …",IEEE,,2012
1961,"EveractiveSelf-Powered SoC with Energy Harvesting, Wakeup Receiver, and Energy-Aware Subsystem",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=I7a8pr0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=I7a8pr0AAAAJ:2l5NCbZemmgC,"EveractiveSelf-Powered SoC with Energy Harvesting, Wakeup Receiver, and Energy-Aware Subsystem Toggle navigation IEEE Computer Society Digital Library Jobs Tech News Resource Center Press Room Advertising About Us IEEE IEEE Computer Society IEEE Computer Society Digital Library My Subscriptions Magazines Journals Conference Proceedings Institutional Subscriptions IEEE IEEE Computer Society More Jobs Tech News Resource Center Press Room Advertising About Us Cart All Advanced Search Conference Cover Image Download 1.Home 2.Proceedings 3.hcs 2025 EveractiveSelf-Powered SoC with Energy Harvesting, Wakeup Receiver, and Energy-Aware Subsystem 2025, pp. 1-31, DOI Bookmark: 10.1109/HCS66204.2025.11154389 Keywords Receivers, Energy Harvesting, Wake Up Receiver, Authors Benton H. Calhoun , Everactive,Charlottesville,VA David D. Wentzloff , Everactive,Ann …",IEEE Computer Society,,2025
1962,"A Compact, Power-Efficient, and On-the-Fly I2C-to-SPI Converter for Distributed E-Textile Systems",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=I7a8pr0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=I7a8pr0AAAAJ:An6A6Jpfc1oC,"This paper presents a 0.36-mm2 I2C-to-SPI converter chip designed for electronic textile (E-textile) applications, featuring an on-the-fly conversion scheme that eliminates the need for on-chip data buffers and internal clock generation. By leveraging the synchronous nature of both I2C and SPI protocols, the proposed design forwards each incoming I2C data bit, SDA (Serial Data Line) directly to the SPI output using the I2C serial clock line (SCL), thereby reducing both area and power consumption. Two versions of the chip are proposed: a ‘full’ die and a ‘compact’ die. The converter enables seamless integration into distributed in-textile architectures by minimizing silicon overhead. The ‘full’ die implementation achieves a area reduction compared to commercially available I2C-to-SPI converters, while the ‘compact’ version further reduces the footprint by through the use of a small corner seal-ring and a linear …",IEEE,,2025
1963,A 0.36 mm2 On-the-Fly I2C-to-SPI Converter for E-Textile Applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=I7a8pr0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=I7a8pr0AAAAJ:5bg8sr1QxYwC,"This paper presents a 0.36-mm2 I2C-to-SPI converter chip with on-the-fly conversion for E-textile applications. The on-the-fly operation eliminates the need for on-chip data buffers and clock generation, improving the area and power efficiency versus prior works. The die area is 7.33× smaller than commercially-available off-the-shelf (COTS) I2Cto-SPI converters, enabling it to integrate unobtrusively into E-textile applications. The chip supports conversion at ultra-fast I2C operating frequency up to 5 MHz while consuming only 0.379 mW of power. At the standard I2C speed of 400 kHz, it consumes 0.145 mW, which is 48× more power-efficient than commercially available I2C-to-SPI converters.",IEEE,,2025
1964,Characterization of Stacked PV Cell Configurations in a Deep N-Well 65nm CMOS Technology,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=I7a8pr0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=I7a8pr0AAAAJ:kzcSZmkxUKAC,"The selection of a suitable photovoltaic (PV) design for emerging energy harvesting applications remains challenging, as PV cell performance is highly dependent on design variables and environmental setup. These factors vary widely across existing studies, making direct comparisons complex and increasing uncertainty in predicting expected PV cell output characteristics for a given use case. To address this, our paper presents a comparison of various on-chip PV cell configurations, implemented using a 0.6mm x 0.6mm test chip realized in 65nm deep-nwell (DNW) CMOS technology. The experimental results demonstrate that, depending on diode arrangements, separate configurations achieve a maximum open-circuit voltage of 0.54V and a peak power density of 1.18 µW/mm2 at 20 klux illumination. This characterization work, therefore, enables designers to select an optimal configuration tailored to specific …",IEEE,,2025
1965,Sustainable colloidal-silver-impregnated ceramic filter for point-of-use water treatment,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dnu0nSEAAAAJ&citation_for_view=dnu0nSEAAAAJ:MXK_kJrjxJIC,"Cylindrical colloidal-silver-impregnated ceramic filters for household (point-of-use) water treatment were manufactured and tested for performance in the laboratory with respect to flow rate and bacteria transport. Filters were manufactured by combining clay-rich soil with water, grog (previously fired clay), and flour, pressing them into cylinders, and firing them at 900 °C for 8 h. The pore-size distribution of the resulting ceramic filters was quantified by mercury porosimetry. Colloidal silver was applied to filters in different quantities and ways (dipping and painting). Filters were also tested without any colloidal-silver application. Hydraulic conductivity of the filters was quantified using changing-head permeability tests. [3H]H2O water was used as a conservative tracer to quantify advection velocities and the coefficient of hydrodynamic dispersion. Escherichia coli (E. coli) was used to quantify bacterial transport through the …",American Chemical Society,,2008
1966,Toward Understanding the Efficacy and Mechanism of Opuntia spp. as a Natural Coagulant for Potential Application in Water Treatment,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dnu0nSEAAAAJ&citation_for_view=dnu0nSEAAAAJ:hMod-77fHWUC,"Historically, there is evidence to suggest that communities in the developing world have used plant-based materials as one strategy for purifying drinking water. In this study, the coagulant properties of Opuntia spp., a species of cactus, are quantitatively evaluated for the first time. Opuntia spp. was evaluated for turbidity removal from synthetic water samples, and steps were made toward elucidating the underlying coagulation mechanism. In model turbid water using kaolin clay particles at pH 10, Opuntia spp. reduced turbidity by 98% for a range of initial turbidities. This is similar to the observed coagulation activities previously described for Moringa oleifera, a widely studied natural coagulant. Although it has been reported that Moringa oleifera predominantly operates through charge neutralization, comparison of zeta potential measurements and transmission electron microscopy images of flocs formed by Opuntia …",American Chemical Society,,2008
1967,Effect of ten quaternary ammonium cations on tetrachloromethane sorption to clay from water,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dnu0nSEAAAAJ&citation_for_view=dnu0nSEAAAAJ:u5HHmVD_uO8C,"The mineral surface of Wyoming bentonite (clay) was modified by replacing inorganic ions by each of 10 qua-ternary ammonium compounds, and tetrachloromethane sorption to the modified sorbents from water was studied. Tetrachloromethane sorption from solution to clay mod-ified with tetramethyl-, tetraethyl-, benzyltrimethyl-, or benzyltriethylammonium cations generally is characterized by relatively high solute uptake, isotherm nonlinearity, and competitive sorption (with trichloroethene as the com-peting sórbate). For these sorbents, the ethyl functional groups yield reduced sorptive capacity relative to methyl groups, whereas the benzyl group appears to have a similar effect on sorbent capacity as the methyl group. Sorption of tetrachloromethaneto clay modified with dodecyldimethyl (2-phenoxyethyl)-, dodecyltrimethyl-, tetradecyl-trimethyl-, hexadecyltrimethyl-, or benzyldimethylhexa-decylammonium bromide …",American Chemical Society,,1990
1968,Sorption of nonionic organic contaminants to single and dual organic cation bentonites from water,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dnu0nSEAAAAJ&citation_for_view=dnu0nSEAAAAJ:u-x6o8ySG0sC,"(CH3) 3-N+-R where R is a 10-, 12-, 14-, 16-, or 18-carbon alkyl chain. Nonionic solute sorption to bentonite exchanged with cations from the first class (in an amount equal to 40% of cation-exchange capacity) is caused primarily by adsorption. When a second organic cation from the second class is also exchanged onto this sorbent in an amount equal to 20, 40, or 60% of cation-exchange capacity, the longchain alkyl functional groups cause two effects. First, the alkyl chains interfere with nonionic solute adsorption to the bentonite mineral surface modified by the tetramethyl-, tetraethyl-, or benzyltriethylammonium cations. Second, the alkyl chains create a partition medium for sorption of the nonionic solutes. Solute uptake by adsorption decreases, and solute uptake by partition increases as the amount of organic cations from the second class exchanged onto the bentonite increases from 0 to 60% of cation …",American Chemical Society,,1995
1969,Global stressors on water quality and quantity,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dnu0nSEAAAAJ&citation_for_view=dnu0nSEAAAAJ:BwyfMAYsbu0C,"This inequality is especially critical for Asia, which has 60% of the world’s population but only 36% of the world’s water. Water quality in terms of pollutant loading also is not distributed equally and is related to the type of use and a country’s level of development (Figure 2). Developing countries often have less capacity to improve water quality and depend on lower-quality water for a variety of uses, including drinking water.",American Chemical Society,Environmental science & technology,2008
1970,"Associations Between Point-of-Use Water Treatment Interventions and Cognitive Scores among Children 5 Years of Age and Younger in Limpopo, South Africa",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dnu0nSEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dnu0nSEAAAAJ:WKZfnVNUP7sC,"For children in low-resource settings, repeated exposure to enteric pathogens, including through unsafe water, can have long-term effects and is potentially associated with impaired cognitive development. Access to effective, low-cost point-of-use (POU) water treatment technologies may therefore improve cognitive function. A community-based randomized controlled trial of two POU water treatment technologies was conducted in rural Limpopo, South Africa. In total, 404 households with a primary study child younger than 3 years were randomly assigned to one of four groups: 1) a silver-impregnated ceramic filter and a silver-impregnated ceramic tablet group, 2) a silver-impregnated ceramic tablet only group, 3) a safe-storage water container group, or 4) a no-intervention group. Follow-up surveys were conducted every quarter for the following 2 years. Approximately 2 years after the baseline assessment, 236 of …",,,2025
1971,"Combined Efficacy of Silver, Copper, and Hypochlorite Ions for Vector Control of Juvenile Aedes aegypti in Household Water Storage Containers",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dnu0nSEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dnu0nSEAAAAJ:-lDlBIcJJzsC,"This study evaluates the larvicidal effects of three common water disinfectants, silver (AgNO3), copper (CuSO4·5H2O), and hypochlorite (NaOCl) ions. The treatments were combined at 40–50% of their recommended drinking water guidelines and tested against late first instar and third instar Ae. aegypti larvae. The findings demonstrate that the combined application of water disinfectants yields greater efficacy in suppressing the emergence of Aedes aegypti compared to the use of the individual disinfectants alone. The silver (Ag) and copper (Cu) combination treatment (40 ppb Ag + 600 ppb Cu) showed the greatest efficacy, achieving nearly complete inhibition of emergence of the older instar larvae (98.52% [96.50, 99.47]). All treatments demonstrated high efficacy against late 1st instar Ae. aegypti larvae, with the combined copper and chlorine (Cl) treatment yielding the lowest survival rates, though individual disinfectants also produced substantial mortality. The results of this study provide critical insights to inform the design and implementation of point-of-use water treatment technologies for household water storage containers that both ensure safe drinking water and also strategically target mosquito breeding within household storage containers, thus supporting integrated vector management approaches essential for controlling neglected tropical diseases.",MDPI,,2025
1972,Optimization of Shigella and Campylobacter Detection from Milk and Water and Differentiation of Viable Organisms Using Viability PCR,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dnu0nSEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dnu0nSEAAAAJ:WEZ36b6n6v0C,"Campylobacter and Shigella are leading causes of enteric infections, especially in low-resource settings, and are transmitted through contaminated food, milk, and water. Detecting these pathogens in environmental samples and differentiating between viable and nonviable bacteria is critical for understanding their transmission and for risk assessment. This study optimized and evaluated laboratory methods for detecting viable Campylobacter and Shigella in water and raw cow milk using viability polymerase chain reaction (PCR). To optimize sample processing and extraction, seven water concentration methods, two water DNA extraction protocols, eight milk concentration methods, and nine milk DNA extraction protocols were compared. Water and milk were spiked with known amounts of bacteria, concentrated, and then subjected to DNA extraction and quantitative polymerase chain reaction (qPCR). For concentrating milk …",American Society of Civil Engineers,,2025
1973,"Effectiveness of the upscaled use of a silver-ceramic (silver ionization) technology to disinfect drinking water in tanks at schools in rural India (vol 22, pg 2233, 2024)",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dnu0nSEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dnu0nSEAAAAJ:nLH0p24aEWsC,,IWA PUBLISHING,,2025
1974,"Analyzing the Efficacy of Water Treatment Disinfectants as Vector Control: The Larvicidal Effects of Silver Nitrate, Copper Sulfate Pentahydrate, and Sodium Hypochlorite on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dnu0nSEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=dnu0nSEAAAAJ:p-RlQlBqj_YC,"For communities without access to uninterrupted, piped water, household water storage (HWS) practices can lead to adverse public health outcomes caused by water degradation and mosquito proliferation. With over 700,000 deaths caused by vector-borne diseases annually, the objective of this study was to determine whether water disinfectants, at concentrations deemed safe for human consumption and beneficial for water treatment, are effective in reducing the emergence of adult mosquitoes that transmit disease. Laboratory bioassays, designed to resemble the context of treating HWS containers, were conducted to assess the larvicidal effects of chemicals at concentrations below regulatory limits for drinking water: silver (20, 40, 80 μg/L Ag), copper (300, 600, 1200 μg/L Cu), and chlorine (500, 1000, 2000 ug/L free chlorine). The water disinfectants demonstrated the ability to significantly reduce the population of juvenile Ae. aegypti. Sodium hypochlorite was found to be the most effective in decreasing the survival rate of late first instar larvae, while silver nitrate exhibited the highest effectiveness in inhibiting the emergence of late third instar larvae. Ultimately, this study highlights the potential of an integrated approach to Water, Sanitation, and Health (WASH) solutions with vector control management.",MDPI,,2025
1975,Recent advances of lanthanum-based perovskite oxides for catalysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sr5dIXkAAAAJ&citation_for_view=Sr5dIXkAAAAJ:Tyk-4Ss8FVUC,"There is a need to reduce the use of noble metal elementsespecially in the field of catalysis, where noble metals are ubiquitously applied. To this end, perovskite oxides, an important class of mixed oxide, have been attracting increasing attention for decades as potential replacements. Benefiting from the extraordinary tunability of their compositions and structures, perovskite oxides can be rationally tailored and equipped with targeted physical and chemical propertiesfor example, redox behavior, oxygen mobility, and ionic conductivityfor enhanced catalysis. Recently, the development of highly efficient perovskite oxide catalysts has been extensively studied. This perspective article summarizes the recent development of lanthanum-based perovskite oxides as advanced catalysts for both energy conversion applications and traditional heterogeneous reactions.",American Chemical Society,,2015
1976,"Monodisperse MxFe3–xO4 (M = Fe, Cu, Co, Mn) Nanoparticles and Their Electrocatalysis for Oxygen Reduction Reaction",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sr5dIXkAAAAJ&citation_for_view=Sr5dIXkAAAAJ:eQOLeE2rZwMC,"Sub-10 nm nanoparticles (NPs) of M(II)-substituted magnetite MxFe3–xO4 (MxFe1–xO•Fe2O3) (M = Mn, Fe, Co, Cu) were synthesized and studied as electrocatalysts for oxygen reduction reaction (ORR) in 0.1 M KOH solution. Loaded on commercial carbon support, these MxFe3–xO4 NPs showed the M(II)-dependent ORR catalytic activities with MnxFe3–xO4 being the most active followed by CoxFe3–xO4, CuxFe3–xO4, and Fe3O4. The ORR activity of the MnxFe3–xO4 was further tuned by controlling x and MnFe2O4 NPs were found to be as efficient as the commercial Pt in catalyzing ORR. The MnFe2O4 NPs represent a new class of highly efficient non-Pt catalyst for ORR in alkaline media.",American Chemical Society,,2013
1977,FePt and CoPt nanowires as efficient catalysts for the oxygen reduction reaction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sr5dIXkAAAAJ&citation_for_view=Sr5dIXkAAAAJ:LkGwnXOMwfcC,"The oxygen reduction reaction (ORR) is an important cathode reaction used in fuel cells and metal–air batteries for renewable energy applications.[1–3] Platinum has been studied extensively as an essential catalytic component to reduce undesired overpotentials observed in the ORR.[4] Previous computational and experimental investigations have revealed that once alloyed with first-row transition metals, such as Fe, Co, and Ni, Pt alloy thin films and nanoparticles (NPs) can show dramatic activity enhancement in ORR catalysis,[5, 6] especially when the Pt-skin structure is formed on the surface of MPt.[7] This enhancement is believed to originate from the downshift of the d-band center of Pt in the alloy structure; this downshift results in a decrease of the bonding strength between Pt and the oxygenated species (often called blocking species or spectators) and an increased number of available Pt sites for oxygen …",WILEY‐VCH Verlag,,2013
1978,New approach to fully ordered fct-FePt nanoparticles for much enhanced electrocatalysis in acid,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sr5dIXkAAAAJ&citation_for_view=Sr5dIXkAAAAJ:5nxA0vEk-isC,Fully ordered face-centered tetragonal (fct) FePt nanoparticles (NPs) are synthesized by thermal annealing of the MgO-coated dumbbell-like FePt-Fe3O4 NPs followed by acid washing to remove MgO. These fct-FePt NPs show strong ferromagnetism with room temperature coercivity reaching 33 kOe. They serve as a robust electrocatalyst for the oxygen reduction reaction (ORR) in 0.1 M HClO4 and hydrogen evolution reaction (HER) in 0.5 M H2SO4 with much enhanced activity (the most active fct-structured alloy NP catalyst ever reported) and stability (no obvious Fe loss and NP degradation after 20 000 cycles between 0.6 and 1.0 V (vs RHE)). Our work demonstrates a reliable approach to FePt NPs with much improved fct-ordering and catalytic efficiency for ORR and HER.,American Chemical Society,,2015
1979,Hard-magnet L10-CoPt nanoparticles advance fuel cell catalysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sr5dIXkAAAAJ&citation_for_view=Sr5dIXkAAAAJ:9ZlFYXVOiuMC,"Stabilizing transition metals (M) in MPt alloy under acidic conditions is challenging, yet crucial to boost Pt catalysis toward oxygen reduction reaction (ORR). We synthesized ∼9 nm hard-magnet core/shell L10-CoPt/Pt nanoparticles with 2–3 atomic layers of strained Pt shell for ORR. At 60°C in acid, the hard-magnet L10-CoPt better stabilizes Co (5% loss after 24 hr) than soft-magnet A1-CoPt (34% loss in 7 hr). L10-CoPt/Pt achieves mass activities (MA) of 0.56 A/mgPt initially and 0.45 A/mgPt after 30,000 voltage cycles in the membrane electrode assembly at 80°C, exceeding the DOE 2020 targets on Pt activity and durability (0.44 A/mgPt in MA and <40% loss in MA after 30,000 cycles). Density functional theory calculations suggest that the ligand effect of Co and the biaxial strain (−4.50%/−4.25%) of the Pt shell weaken the binding of oxygenated species, leading to enhanced ORR performance in fuel cells.",Elsevier,,2019
1980,Sustainable synthesis of polymer-grade ethylene via electrified acetylene semihydrogenation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sr5dIXkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Sr5dIXkAAAAJ:CHSYGLWDkRkC,"The electrocatalytic semihydrogenation of acetylene (C2H2), powered by renewable electricity, provides an energy- and cost-efficient alternative to conventional thermocatalytic methods for purifying crude ethylene (C2H4) streams. This approach provides a more sustainable route to polymer-grade C2H4 by reducing greenhouse gas emissions, yet its commercial potential remains limited by the scarcity of high-performance catalysts and the absence of comprehensive techno-economic analyses for large-scale implementation. In this study, we conduct an extensive screening and evaluation of monodisperse metal nanoparticle (NP) catalysts (Cu, Ag, Au, Pd, Bi) with tunable particle sizes and morphologies for the electrocatalytic semihydrogenation of C2H2 in flow reactors. Among these candidates, 45 nm Cu nanocubes and 8 nm Ag NPs exhibited the highest performance. In a simulated crude ethylene stream (C2H …",National Academy of Sciences,,2025
1981,Strain relaxation enhances ammonia electrosynthesis from nitrate on Cu/CuAu core/shell nanocrystals with ordered intermetallic layers,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sr5dIXkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Sr5dIXkAAAAJ:EUQCXRtRnyEC,"Recycling ammonia (NH3) via the electrocatalytic nitrate reduction reaction (NO3RR) offers a sustainable, energy-efficient solution for closing the nitrogen cycle while simultaneously treating nitrate-rich wastewater. In this work, we synthesized core/shell Cu/CuAu nanocubes with precisely controlled ordered intermetallic layers using a facile seed-mediated method. The compressive surface strain of the nanocrystals was finely regulated by adjusting the layers of the CuAu shell. Specifically, the strain-relaxed Cu/CuAu catalysts exhibit high NO3RR performance for NH3 production, achieving a Faradic efficiency of 89.9% at −0.5 V vs. the reversible hydrogen electrode (RHE) and an exceedingly high yield rate of 11.3 mol h−1 g−1 at −0.6 V vs. RHE. Furthermore, Cu/CuAu catalysts show catalytic stability over 10 consecutive cycles and 12-h electrolysis. This atomic-level control of thickness allows precise tuning of the …",Elsevier,,2025
1982,Electrocatalytic C N Coupling: Advances in Urea Synthesis and Opportunities for Alternative Products,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sr5dIXkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Sr5dIXkAAAAJ:_xSYboBqXhAC,"Urea is an essential fertilizer produced through the industrial synthesis of ammonia (NH3) via the Haber–Bosch process, which contributes ≈1.2% of global annual CO2 emissions. Electrocatalytic urea synthesis under ambient conditions via CN coupling from CO2 and nitrogen species such as nitrate (NO3−), nitrite (NO2−), nitric oxide (NO), and nitrogen gas (N2) has gained interest as a more sustainable route. However, challenges remain due to the unclear reaction pathways for urea formation, competing reactions, and the complexity of the resulting product matrix. This review highlights recent advances in catalyst design, urea quantification, and intermediate identification in the CN coupling reaction for electrocatalytic urea synthesis. Furthermore, this review explores future prospects for industrial CN coupling, considering potential nitrogen and carbon sources and examining alternative CN coupling …",,ChemSusChem,2025
1983,Single-atom molybdenum doping induces nickel oxide-to-hydroxide transformation for enhanced alkaline hydrogen evolution,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sr5dIXkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Sr5dIXkAAAAJ:xtRiw3GOFMkC,"NiMoOx compounds are widely regarded as among the most efficient non-noble metal catalysts for the hydrogen evolution reaction (HER). Nevertheless, understanding the structural evolution under in situ conditions and further enhancing their performance remain key challenges. Herein, we report that single-atom Mo doping in NiO significantly enhances its HER activity, reducing the overpotential to 131 mV at 10 mA cm−2 compared to undoped NiO. In situ X-ray absorption spectroscopy and Raman spectroscopy reveal that under catalytic conditions, Mo single atoms remain structurally stable, while Ni2+ species in NiO are converted to Ni(OH)2 in alkaline media under the applied working potential for HER. Notably, this transformation is absent in undoped NiO, indicating that Mo doping promotes the formation of active Ni(OH)2 sites, which, in turn, accelerate the rate-limiting water dissociation step. These findings …",Royal Society of Chemistry,,2025
1984,Cathodic Corrosion-Induced Structural Evolution of CuNi Electrocatalysts for Enhanced CO2 Reduction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sr5dIXkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Sr5dIXkAAAAJ:b0M2c_1WBrUC,"The electrochemical CO 2 reduction reaction (CO 2 RR) has attracted significant attention as a promising strategy for storing intermittent energy in chemical bonds while sustainably producing value-added chemicals and fuels. Copper-based bimetallic catalysts are particularly appealing for CO 2 RR due to their unique ability to generate multi-carbon products. While substantial effort has been devoted to developing new catalysts, the evolution of bimetallic systems under operational conditions remains underexplored. In this work, we synthesized a series of Cu x Ni 1− x nanoparticles and investigated their structural evolution during CO 2 RR. Due to the higher oxophilicity of Ni compared to Cu, the particles tend to become Ni-enriched at the surface upon air exposure, promoting the competing hydrogen evolution reaction (HER). At negative activation potentials, cathodic corrosion has been observed in Cu x Ni 1− x nanoparticles, leading to the significant Ni loss and the formation of irregularly shaped Cu nanoparticles with increased defects. This structural evolution, driven by cathodic corrosion, shifts the electrolysis from HER toward CO 2 reduction, significantly enhancing the Faradaic efficiency of multi-carbon products (C 2+).",,,2024
1985,Beyond the dichotomy of students-as-consumers and personal transformation: what students want from their degrees and their engagement with knowledge,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yNW7R7QAAAAJ&citation_for_view=yNW7R7QAAAAJ:u5HHmVD_uO8C,"There is widespread concern that students are increasingly becoming passive consumers of education who primarily attend university to obtain the credentials they need for the labour market. To interrogate this view, a longitudinal qualitative study examined what 47 students in three countries wanted to get out of studying for their degree (their personal projects) and how these developed over the course of their undergraduate studies. Our analysis showed that whilst most students had instrumental reasons for studying, they tended to be personally committed to the knowledge they were studying and had a clear sense of the role it would play in their future lives. Where students did not see knowledge as having a key role in helping them to realise their personal projects, they were less likely to value their studies. Also, students who were committed to the knowledge they were studying but did not have a sense of …",Routledge,,2024
1986,Disciplinary socialization in first-year STEM students,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yNW7R7QAAAAJ&citation_for_view=yNW7R7QAAAAJ:qjMakFHDy7sC,"Whether knowingly or not, students choose to become part of a disciplinary community when they choose their major. This membership comes alongside a set of written and unwritten rules, expectations, and responsibilities. The process by which students learn these membership requirements, referred to as socialization, is a socially driven affair. Students may gain this knowledge from peers, senior students, mentors, or faculty, all of whom constitute socializing agents. For many students, this process can begin before they even arrive at school through interactions with their parents, teachers, or college faculty. The purpose of this qualitative study is to investigate the role of interaction with socializing agents for first-year STEM students at a large research-intensive institution in the Southeast United States. Fifteen interviews from firstyear undergraduate students from three STEM disciplines were analyzed to explore and compare experiences with disciplinary socializers. We found that there was a pattern of low engagement within the discipline across all three of the majors involved in the study, particularly with respect to professional organizations. The primary socialization that had impacted student decisions occurred prior to their enrollment in their major of choice. Having identified these patterns, further work must be conducted to understand the way forwards to foster effective socialization in the first year across all of the identified STEM majors.",,,2020
1987,The Journey of Becoming and Belonging: A Longitudinal Exploration of Socialization's Impact on STEM Students' Sense of Belonging,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yNW7R7QAAAAJ&citation_for_view=yNW7R7QAAAAJ:9yKSN-GCB0IC,"Persistently high attrition rates from STEM majors present a stubborn challenge for researchers, administrators, and faculty alike. To approach this problem, my dissertation examined the socialization processes by which students develop a sense of belonging to both their institution and their discipline. Previously identified as an important factor in students' persistence and overall satisfaction with their undergraduate experience, belonging is a critical piece of the retention puzzle. However, not every student experiences or develops belonging in the same way. This dissertation applied the theoretical lens of socialization to deepen the understanding of how social interactions help or hinder students' belonging to their university and chosen major alike. My dissertation work was grounded in the synthesis of two theoretical frameworks: Conrad et al.'s (2006) model of socialization and Strayhorn's (2018e) conceptualization of sense of belonging. The study took the form of an embedded case study of two similar disciplinary contexts within a large public land-grant Research 1 institution, with four students from each context for a total of eight participants. By leveraging four years of interview data from each participant, supported by institutional documentation, I addressed the question: In what ways does a student's socialization experience influence, if at all, their sense of belonging to both their chosen discipline and their university? Data analysis included qualitative coding, trajectory mapping, and thematic analysis. Trajectories were produced for each participant before expanding the analysis to examine patterns across and between the contexts. My …",Virginia Tech,,2023
1988,Interdisciplinary collaboration in capstone courses,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yNW7R7QAAAAJ&citation_for_view=yNW7R7QAAAAJ:d1gkVwhDpl0C,"Senior capstone classes are unique and crucial experiences for undergraduate students, in that they provide long-term, often synthesis-based projects in a collaborative environment. Yet, an overwhelming majority of programs do not provide students with the chance to work cooperatively across disciplinary lines. Those that do typically only allow for interaction between groups within the same overarching discipline such as Mechanical or Electrical Engineering. Ideally, the capstone experience is meant to foreshadow the type of interaction and work that a student will engage in, easing their transition into the work environment following graduation. In industry, engineers are expected to work collaboratively with experts in several technical and non-technical domains. Subsequently, capstone classes are lacking the ability to prepare undergraduate students for membership on the interdisciplinary teams that exist in workplaces within the United States and abroad. As such, the purpose of this paper is to describe the process of creating and subsequent plans for implementation of an interdisciplinary capstone course at a large research-intensive institution in the Southeast US. The challenges associated with developing a course that meets the need of each disciplinary capstone experience and spans the boundary of different approaches to pedagogy, knowledge structure and learning will be explored as well.",,,2019
1989,GIFTS: Creative Reflection to Close the Semester,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yNW7R7QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=yNW7R7QAAAAJ:LkGwnXOMwfcC,"This GIFT describes a creative reflection assignment to be given at the end of engineering students’ first year. Motivation Reflection is a powerful tool for students to evaluate their own learning and growth. It allows students to synthesize learning across lectures, assignments, and classes, as well as giving them a means to connect their past, present, and future selves with their experiences in a project or course. First Year Engineering (FYE) courses are a prime opportunity for students to engage in reflective assessments. Though they are still early in their academic careers, the first year is a pivotal period for making decisions around major selection, on-campus engagement, personal values, and more. As a result, intentionally incorporating reflection into assessments can help to support students as they make these choices that will influence the next four years and beyond. This assignment particularly emphasizes the connections between students’ personal hobbies and values and the engineering work they have completed. Furthermore, reflection provides an exceptional opportunity for faculty to connect with students. It offers faculty a chance to connect with students in a less restrictive, less academic context than simply providing feedback on an assignment, report, or project. Student-faculty connections are essential for student outcomes including both academic and personal satisfaction, as well as academic performance. Objectives At the end of a semester, as final projects wrap up and final exams near, there is a final reflection assignment for FYE students to complete. The course does not have a final exam, so the reflection is a final sendoff …",,,2025
1990,"WIP: Using Challenge Essential Questions to Connect Technical, Social, and Ethical Content in a First-Year Engineering Program",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yNW7R7QAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=yNW7R7QAAAAJ:_FxGoFyzp5QC,"This Work-In-Progress paper will describe a specific intervention to help beginning engineering students make connections between technical and sociotechnical content. Foundational engineering courses are designed to introduce new undergraduates to the discipline of engineering and help them develop the skills and knowledge to succeed throughout their studies. Students are introduced to technical content (eg, CAD, programming, fabrication, the design process) as well as sociotechnical content (eg, STS frameworks, engineering ethics, sustainability, professional development, teamwork, and communication). These two knowledge bases serve students best when clearly connected, yet students often struggle to establish that connection for themselves, and instructors’ attempts to emphasize their interrelated nature are not always successful. Poor connection between technical and sociotechnical content risks students perceiving sociotechnical concepts as secondary or separate from technical design. If students are not sufficiently skilled at integrating both aspects of engineering work, then they will not be prepared to navigate the complex challenges they will be asked to take on in their careers. Additionally, when equipped with a sociotechnical framework and lens through which to address engineering problems, students develop greater empathy and social responsibility.",,,2025
1991,Control systems with actuator saturation: analysis and design,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n4fG76YAAAAJ&citation_for_view=n4fG76YAAAAJ:u5HHmVD_uO8C,"Saturation nonlinearities are ubiquitous in engineering systems. In control systems, every physical actuator or sensor is subject to saturation owing to its maximum and minimum limits. A digital filter is subject to saturation if it is implemented in a finite word length format. Saturation nonlinearities are also purposely introduced into engineering systems such as control sys tems and neural network systems. Regardless of how saturation arises, the analysis and design of a system that contains saturation nonlinearities is an important problem. Not only is this problem theoretically challenging, but it is also practically imperative. This book intends to study control systems with actuator saturation in a systematic way. It will also present some related results on systems with state saturation or sensor saturation. Roughly speaking, there are two strategies for dealing with actuator sat uration. The first strategy is to neglect the saturation in the first stage of the control design process, and then to add some problem-specific schemes to deal with the adverse effects caused by saturation. These schemes, known as anti-windup schemes, are typically introduced using ad hoc modifications and extensive simulations. The basic idea behind these schemes is to intro duce additional feedbacks in such a way that the actuator stays properly within its limits. Most of these schemes lead to improved performance but poorly understood stability properties.",Springer Science & Business Media,,2001
1992,Flocking of multi-agents with a virtual leader,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n4fG76YAAAAJ&citation_for_view=n4fG76YAAAAJ:Tyk-4Ss8FVUC,"All agents being informed and the virtual leader traveling at a constant velocity are the two critical assumptions seen in the recent literature on flocking in multi-agent systems. Under these assumptions, Olfati-Saber in a recent IEEE Transactions on Automatic Control paper proposed a flocking algorithm which by incorporating a navigational feedback enables a group of agents to track a virtual leader. This paper revisits the problem of multi-agent flocking in the absence of the above two assumptions. We first show that, even when only a fraction of agents are informed, the Olfati-Saber flocking algorithm still enables all the informed agents to move with the desired constant velocity, and an uninformed agent to also move with the same desired velocity if it can be influenced by the informed agents from time to time during the evolution. Numerical simulation demonstrates that a very small group of the informed agents can …",IEEE,,2009
1993,A survey of distributed optimization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n4fG76YAAAAJ&citation_for_view=n4fG76YAAAAJ:bJZ_LSxkz4EC,"In distributed optimization of multi-agent systems, agents cooperate to minimize a global function which is a sum of local objective functions. Motivated by applications including power systems, sensor networks, smart buildings, and smart manufacturing, various distributed optimization algorithms have been developed. In these algorithms, each agent performs local computation based on its own information and information received from its neighboring agents through the underlying communication network, so that the optimization problem can be solved in a distributed manner. This survey paper aims to offer a detailed overview of existing distributed optimization algorithms and their applications in power systems. More specifically, we first review discrete-time and continuous-time distributed optimization algorithms for undirected graphs. We then discuss how to extend these algorithms in various directions to handle …",Pergamon,Annual Reviews in Control,2019
1994,An analysis and design method for linear systems subject to actuator saturation and disturbance,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n4fG76YAAAAJ&citation_for_view=n4fG76YAAAAJ:u-x6o8ySG0sC,"We present a method for estimating the domain of attraction of the origin for a system under a saturated linear feedback. A simple condition is derived in terms of an auxiliary feedback matrix for determining if a given ellipsoid is contractively invariant. This condition is shown to be less conservative than the existing conditions which are based on the circle criterion or the vertex analysis. Moreover, the condition can be expressed as linear matrix inequalities (LMIs) in terms of all the varying parameters and hence can easily be used for controller synthesis. This condition is then extended to determine the invariant sets for systems with persistent disturbances. LMI based methods are developed for constructing feedback laws that achieve disturbance rejection with guaranteed stability requirements. The effectiveness of the developed methods is illustrated with examples.",Pergamon,,2002
1995,Low gain feedback,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n4fG76YAAAAJ&citation_for_view=n4fG76YAAAAJ:UeHWp8X0CEIC,"We consider the class of multi-input multi-output input output linearizable systems,{~=/(x, c~), x~ l~', c~ R~,~= A~+ B [G (x,~, d (t)) u+ g (x,~, d (t))],~ eI~ n,, fir m,(9.1. 1) y= D~, y ER p, where y is the only available measurement on the system, u is the control input, d (t) is any continuous disturbance assumed to belong to a compact set DC tt q, f and g are C x vector functions, G is a C 1 matrix function which is invertible for all (x,~, d) fi R txl~"" x D, and finally, A, B, C and D are constant matrices of appropriate dimensions such that the pairs (A, B) and (A, D) are stabilizable and detectable respectively. For such a class of systems, the dynamical system~=. f (x, 0) is referred to as zero dynamics (eg,[4-6]). Moreover, the system (9.1. 1) is said to be of minimum-phase if its zero dynamics has x= 0 as a globally asymptotically stable equilibrium point.",springer London,,1999
1996,Distributed Semiglobal Nash Equilibrium Seeking for Robotic Systems Subject to Unknown Disturbances,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n4fG76YAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=n4fG76YAAAAJ:brChLMnLtjYC,"This article investigates distributed Nash equilibrium (NE) seeking for multirobot systems with nonlinear dynamics, time-varying disturbances, and individual inequality constraints under switching communication topologies. A novel control architecture is developed by integrating adaptive radial basis function (RBF) neural networks with projection-based pseudogradient dynamics. The proposed method enables each robot to estimate and track its local NE strategy in a fully distributed manner, without requiring global information or prior knowledge of the disturbances. Unlike existing methods that rely on static graphs or known disturbance bounds, our approach ensures constraint satisfaction and disturbance rejection simultaneously under a jointly strongly connected switching network. Numerical simulations involving five 2-degrees of freedom robotic manipulators demonstrate the effectiveness of the proposed …",IEEE,,2025
1997,Distributed secondary control of energy storage units in a droop-controlled DC microgrid,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n4fG76YAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=n4fG76YAAAAJ:t6hKUfryX1MC,"In the control and management of an energy storage system consisting of multiple energy storage units, bus voltage regulation, load power sharing, and energy level balancing are important objectives. To achieve these objectives, we propose a distributed secondary control scheme for each energy storage unit in a droop-controlled multi-bus DC microgrid. This control scheme is composed of two auxiliary control inputs. By constructing a distributed voltage observer based on the dynamic average consensus algorithm of a first-order multi-agent system, we design the first auxiliary control input such that global voltage regulation is achieved. Moreover, based on the leaderless consensus algorithm of a second-order multi-agent system, we design the second auxiliary control input such that proportional power sharing and state-of-energy balancing are simultaneously achieved. Through simulation studies in MATLAB …",Elsevier,,2025
1998,New Conditions and Controllers for State-of-Charge Balancing in Battery Energy Storage Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n4fG76YAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=n4fG76YAAAAJ:d7BmB2BcYiwC,"We investigate the state-of-charge (SoC) balancing control problem for a battery energy storage system, which consists of multiple battery units. These battery units are allowed to have heterogeneous battery parameters and are connected in parallel to deliver a desired total power. Existing power allocating controllers have been developed to achieve SoC balancing without taking balancing speed into consideration. Motivated by this observation, we aim to design new power allocating controllers such that accelerated SoC balancing is achieved. To facilitate our control design, we first introduce a new concept, the powered SoC, and establish new sufficient conditions that guarantee SoC balancing among battery units in the discharging and the charging modes. Based on these new sufficient conditions, we design a power allocating controller for each battery unit. It is shown that the proposed power allocating …",IEEE,,2025
1999,Privacy-Preserving Distributed Control for a Networked Battery Energy Storage System,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n4fG76YAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=n4fG76YAAAAJ:CLQ-NLsb8zAC,"The increasing deployment of distributed Battery Energy Storage Systems (BESSs) in modern power grids necessitates effective coordination strategies to ensure state-of-charge (SoC) balancing and accurate power delivery. While distributed control frameworks offer scalability and resilience, they also raise significant privacy concerns due to the need for inter-agent information exchange. This paper presents a novel privacy-preserving distributed control algorithm for SoC balancing in a networked BESS. The proposed framework includes distributed power allocation law that is designed based on two privacy-preserving distributed estimators, one for the average unit state and the other for the average desired power. The average unit state estimator is designed via the state decomposition method without disclosing sensitive internal states. The proposed power allocation law based on these estimators ensures asymptotic SoC balancing and global power delivery while safeguarding agent privacy from external eavesdroppers. The effectiveness and privacy-preserving properties of the proposed control strategy are demonstrated through simulation results.",,,2025
2000,Oscillator Potts machines: An overdamped Langevin model for low-energy sampling of the standard Potts model,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=n4fG76YAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=n4fG76YAAAAJ:Fx7lCCP36QIC,"The standard Potts model is a fundamental model in statistical physics that generalizes the Ising model. Although Ising machines, as Langevin models, have been widely studied for sampling the Ising model, studies of Langevin models for sampling the standard Potts model are still lacking. In this work, we present a compact and physically realizable Langevin model that serves as a sampler for sampling the low-energy spin configurations of the standard Potts model.",,,2025
2001,Temperature-aware microarchitecture,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5DLZvlMAAAAJ&citation_for_view=5DLZvlMAAAAJ:u-x6o8ySG0sC,"With power density and hence cooling costs rising exponentially, processor packaging can no longer be designed for the worst case, and there is an urgent need for runtime processor-level techniques that can regulate operating temperature when the package's capacity is exceeded. Evaluating such techniques, however, requires a thermal model that is practical for architectural studies.This paper describes HotSpot, an accurate yet fast model based on an equivalent circuit of thermal resistances and capacitances that correspond to microarchitecture blocks and essential aspects of the thermal package. Validation was performed using finite-element simulation. The paper also introduces several effective methods for dynamic thermal management (DTM): ""temperature-tracking"" frequency scaling, localized toggling, and migrating computation to spare hardware units. Modeling temperature at the microarchitecture …",ACM,,2003
2002,Bus-invert coding for low-power I/O,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5DLZvlMAAAAJ&citation_for_view=5DLZvlMAAAAJ:u5HHmVD_uO8C,"Technology trends and especially portable applications drive the quest for low-power VLSI design. Solutions that involve algorithmic, structural or physical transformations are sought. The focus is on developing low-power circuits without affecting too much the performance (area, latency, period). For CMOS circuits most power is dissipated as dynamic power for charging and discharging node capacitances. This is why many promising results in low-power design are obtained by minimizing the number of transitions inside the CMOS circuit. While it is generally accepted that because of the large capacitances involved much of the power dissipated by an IC is at the I/O little has been specifically done for decreasing the I/O power dissipation. We propose the bus-invert method of coding the I/O which lowers the bus activity and thus decreases the I/O peak power dissipation by 50% and the I/O average power dissipation …",IEEE,,2002
2003,HotSpot: A compact thermal modeling methodology for early-stage VLSI design,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5DLZvlMAAAAJ&citation_for_view=5DLZvlMAAAAJ:IjCSPb-OGe4C,"This paper presents HotSpot-a modeling methodology for developing compact thermal models based on the popular stacked-layer packaging scheme in modern very large-scale integration systems. In addition to modeling silicon and packaging layers, HotSpot includes a high-level on-chip interconnect self-heating power and thermal model such that the thermal impacts on interconnects can also be considered during early design stages. The HotSpot compact thermal modeling approach is especially well suited for preregister transfer level (RTL) and presynthesis thermal analysis and is able to provide detailed static and transient temperature information across the die and the package, as it is also computationally efficient.",IEEE,,2006
2004,Temperature-aware microarchitecture: Modeling and implementation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5DLZvlMAAAAJ&citation_for_view=5DLZvlMAAAAJ:d1gkVwhDpl0C,"With cooling costs rising exponentially, designing cooling solutions for worst-case power dissipation is prohibitively expensive. Chips that can autonomously modify their execution and power-dissipation characteristics permit the use of lower-cost cooling solutions while still guaranteeing safe temperature regulation. Evaluating techniques for this dynamic thermal management (DTM), however, requires a thermal model that is practical for architectural studies.This paper describes HotSpot, an accurate yet fast and practical model based on an equivalent circuit of thermal resistances and capacitances that correspond to microarchitecture blocks and essential aspects of the thermal package. Validation was performed using finite-element simulation. The paper also introduces several effective methods for DTM: ""temperature-tracking"" frequency scaling, ""migrating computation"" to spare hardware units, and a ""hybrid"" …",ACM,,2004
2005,Control-theoretic techniques and thermal-RC modeling for accurate and localized dynamic thermal management,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5DLZvlMAAAAJ&citation_for_view=5DLZvlMAAAAJ:9yKSN-GCB0IC,"This paper proposes the use of formal feedback control theory as a way to implement adaptive techniques in the processor architecture. Dynamic thermal management (DTM) is used as a test vehicle, and variations of a PID controller (Proportional-Integral-Differential) are developed and tested for adaptive control of fetch ""toggling."" To accurately test the DTM mechanism being proposed, this paper also develops a thermal model based on lumped thermal resistances and thermal capacitances. This model is computationally efficient and tracks temperature at the granularity of individual functional blocks within the processor. Because localized heating occurs much faster than chip-wide heating, some parts of the processor are more likely, to be ""hot spots"" than others. Experiments using Wattch and the SPEC2000 benchmarks show that the thermal trigger threshold can be set within 0.2/spl deg/ of the maximum …",IEEE,,2002
2006,Unlocking High-Performance Low-Power Adiabatic Logic Computing with Modern FinFET Technology Node,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5DLZvlMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=5DLZvlMAAAAJ:8-xnCJp56iQC,"The rapid advancement in technology has led to increased demand for battery-powered portable electronic devices, but, as integrated circuits (ICs) feature sizes shrink, the power consumption of these ICs becomes comparatively more significant. This impacts the battery life and thermal management of Internet of Things (IoT) devices, making it essential yet challenging to develop ultra-low power ICs. Adiabatic logic (AL) circuits have been proposed decades ago to reduce active power losses by using AC power supplies, but they had to operate at very low clock rates in order to achieve their power savings due to the relatively slow transistor technology of the era and the required peripheral circuits. Modern FinFET technologies are intrinsically much faster but the corresponding integrated circuits (ICs) built using these advanced nodes are generally limited in speed not by the circuit delay but rather by power delivery …",,,2025
2007,Virtualized Computational RFID (VCRFID) Solution for Industry 4.0 Applications,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5DLZvlMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=5DLZvlMAAAAJ:RVsengBWOnMC,"This paper presents a Virtualized Computational Radio Frequency Identification (VCRFID) solution that utilizes far-field UHF RF for sensing, computing, and self-powering at the edge. A standard UHF RFID system is asymmetric as it consists of a relatively large, complex “reader”, which acts as an RF transmitter and controller for a number of small simple battery-less “tags”, which work in passive mode as they communicate and harvest RF energy from the reader. Previously proposed Computational RFID (CRFID) solutions enhance the standard RFID tags with microcontrollers and sensors in order to gain enhanced functionality, but they end up requiring a relatively high level of power, and thus ultimately reduced range, which limits their use for many Internet-of-Things (IoT) application scenarios. Our VCRFID solution instead keeps the functionality of the tags minimalistic by only providing a sensor interface to be able to capture desired environmental data (temperature, humidity, vibration, etc.), and then transmit it to the RFID reader, which then performs all the computational load usually carried out by a microcontroller on the tag in prior work. This virtualization of functions enables the design of a circuit without a microcontroller, providing greater flexibility and allowing for wireless reconfiguration of tag functions over RF for a 97% reduction in energy consumption compared to prior energy-harvesting RFID tags with microcontrollers. The target application is Industry 4.0 where our VCRFID solution enables battery-less fine-grain monitoring of vibration and temperature data for pumps and motors for predictive maintenance scenarios.",MDPI,,2025
2008,Cool-3D: An End-to-End Thermal-Aware Framework for Early-Phase Design Space Exploration of Microfluidic-Cooled 3DICs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5DLZvlMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=5DLZvlMAAAAJ:Uha2Xg-6WXIC,"The rapid advancement of three-dimensional integrated circuits (3DICs) has heightened the need for early-phase design space exploration (DSE) to minimize design iterations and unexpected challenges. Emphasizing the pre-register-transfer level (Pre-RTL) design phase is crucial for reducing trial-and-error costs. However, 3DIC design introduces additional complexities due to thermal constraints and an expanded design space resulting from vertical stacking and various cooling strategies. Despite this need, existing Pre-RTL DSE tools for 3DICs remain scarce, with available solutions often lacking comprehensive design options and full customization support. To bridge this gap, we present Cool-3D, an end-to-end, thermal-aware framework for 3DIC design that integrates mainstream architectural-level simulators, including gem5, McPAT, and HotSpot 7.0, with advanced cooling models. Cool-3D enables broad and fine-grained design space exploration, built-in microfluidic cooling support for thermal analysis, and an extension interface for non-parameterizable customization, allowing designers to model and optimize 3DIC architectures with greater flexibility and accuracy. To validate the Cool-3D framework, we conduct three case studies demonstrating its ability to model various hardware design options and accurately capture thermal behaviors. Cool-3D serves as a foundational framework that not only facilitates comprehensive 3DIC design space exploration but also enables future innovations in 3DIC architecture, cooling strategies, and optimization techniques. The entire framework, along with the experimental data, is in the process of …",,,2025
2009,Design and Modeling for Very High-sensitivity UHF RF Energy Harvesting Circuit,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5DLZvlMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=5DLZvlMAAAAJ:0UEtxawf5sEC,"The increasing demand for wearable and portable IoT devices necessitates alternatives to traditional battery-powered systems, leading to the emergence of RF energy harvesting as a viable solution. However, long-distance charging poses challenges due to diminishing RF power and increased losses with distance, highlighting the critical importance of improving the sensitivity of the harvesting circuit. In this work, we propose a highly sensitive UHF RF energy harvesting circuit by optimizing a combined RF-DC rectifier (RDR) with a DC-DC converted (DDC) based on a commercial 22-nm fully-depleted silicon on insulator (FDSOI) technology. Flipped well transistors and feedback self-body biasing are used to design the RDR to adaptively tune threshold voltages while an ultra-low power frequency-adjustable feed-forward dynamic leakage suppression (FFDLS) two-phase clock generator is used for pumping the …",IEEE,,2025
2010,Modern electroplating,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2JwR8V0AAAAJ&citation_for_view=2JwR8V0AAAAJ:rHJHxKgnXwkC,"The definitive resource for electroplating, now completely up to date With advances in information-age technologies, the field of electroplating has seen dramatic growth in the decade since the previous edition of Modern Electroplating was published. This expanded new edition addresses these developments, providing a comprehensive, one-stop reference to the latest methods and applications of electroplating of metals, alloys, semiconductors, and conductive polymers. With special emphasis on electroplating and electrochemical plating in nanotechnologies, data storage, and medical applications, the Fifth Edition boasts vast amounts of new and revised material, unmatched in breadth and depth by any other book on the subject. It includes: Easily accessible, self-contained contributions by over thirty experts Five completely new chapters and hundreds of additional pages A cutting-edge look at applications in nanoelectronics Coverage of the formation of nanoclusters and quantum dots using scanning tunneling microscopy (STM) An important discussion of the physical properties of metal thin films Chapters devoted to methods, tools, control, and environmental issues And much more A must-have for anyone in electroplating, including technicians, platers, plating researchers, and metal finishers, Modern Electroplating, Fifth Edition is also an excellent reference for electrical engineers and researchers in the automotive, data storage, and medical industries.",John Wiley & Sons,,2011
2011,Theory and practice of metal electrodeposition,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2JwR8V0AAAAJ&citation_for_view=2JwR8V0AAAAJ:T_ojBgVMvoEC,"The authors provide new insights into the theoretical and applied aspects of metal electrodeposition. The theory largely focuses on the electrochemistry of metals. Details on the practice discuss the selection and use of metal coatings, the technology of deposition of metals and alloys, including individual peculiarities, properties and structure of coatings, control and investigations. This book aims to acquaint advanced students and researchers with recent advances in electrodeposition while also being an excellent reference for the practical electrodeposition of metals and alloys.",Springer Science & Business Media,,2011
2012,Advanced alkaline water electrolysis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2JwR8V0AAAAJ&citation_for_view=2JwR8V0AAAAJ:k8Z6L05lTy4C,"A short review on the fundamental and technological issues relevant to water electrolysis in alkaline and proton exchange membrane (PEM) devices is given. Due to price and limited availability of the platinum group metal (PGM) catalysts they currently employ, PEM electrolyzers have scant possibilities of being employed in large-scale hydrogen production. The importance and recent advancements in the development of catalysts without PGMs are poised to benefit more the field of alkaline electrolysis rather than that of PEM devices. This paper presents our original data which demonstrate that an advanced alkaline electrolyzer with performances rivaling those of PEM electrolyzers can be made without PGM and with catalysts of high stability and durability. Studies on the advantages/limitations of electrolyzers with different architectures do show how a judicious application of pressure differentials in a recirculating …",Pergamon,,2012
2013,Corrosion resistance of ternary Ni P based alloys in sulfuric acid solutions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2JwR8V0AAAAJ&citation_for_view=2JwR8V0AAAAJ:u-x6o8ySG0sC,"NiP based alloy films were prepared by autocatalytic deposition and their structure, chemistry and corrosion behaviors in sulfuric acid solutions were studied as a function of their composition. The as-prepared Ni-based alloys are nanocrystalline, and their grain size decreases with increasing P content. Addition of a third element (W or Mo) influences the observed grain size. At low anodic overpotential NiP based alloys present a lower exchange current and lower reactivity than Ni, both improving with increasing P content. Contrary to Ni however, the NiP based alloys do not passivate at higher anodic overpotentials. Addition of W to NiP alloys can improve their corrosion resistance, while addition of Mo has little or no beneficial effects on corrosion properties.",Pergamon,,2002
2014,Magnetic nanowires in hexagonally ordered pores of alumina,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2JwR8V0AAAAJ&citation_for_view=2JwR8V0AAAAJ:u5HHmVD_uO8C,"Acid-anodized aluminum forms amorphous alumina with long and columnar nanopores with approximately hexagonal ordering (""alumite""). Excellent hexagonal ordering of these nanopores has been achieved by 24 hours of anodization, but with restricted domain size (2-4 /spl mu/m/sup 2/), which can be increased to 100 /spl mu/m/sup 2/ with longer anodization. We have deposited Fe in disordered pores and Co in ordered pores; we can control the average length and diameter of these nanowires, but there is still a distribution of nanowire lengths. Previously, we described Fe nanowires with diameters down to 11 nm in disordered pores. Here we focus on longer (770 nm) and shorter (64 nm) Co nanowires with diameters of 25 nm in ordered pores with 100 nm pore-to-pore separation. The longer wires have an easy axis out-of-plane, with squareness >0.9, coercivity=1900 Oe, and a fluctuation field of 5.3 Oe. The …",IEEE,,2000
2015,Exploration of the Electrodeposition of Smooth Near-Equiatomic CoCuFeNi from Glycine-Citrate Electrolytes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2JwR8V0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2JwR8V0AAAAJ:EBV337fEn3EC,,ECS,,2025
2016,"Electroplating, Electrodeposition Combined with Vapor Deposition PVD for Advanced Manufacturing",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2JwR8V0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2JwR8V0AAAAJ:i_7YvbSbtFEC,"The world of fashion, clothing and automation increasingly requires thin films of metal and alloys with increasingly sustainable and low environmental impact processes. In this field, much remains to be done in the field of electrodeposition, physical vapor deposition, PVD, and also in the combination of the two processes. The possibility of obtaining metal accessories with high resistance to corrosion without color variation with time, wear and the increasingly aggressive atmospheres in which we live. In this presentation we will see some cases of industrial applications of deposition of metals or alloys on clothes and accessories of various types with coupled techniques of electrodeposition-PVD. In the last case, it is highlighted how electrodeposition is used to level or smooth surfaces and PVD to finish surfaces with coatings that can have particular characteristics of resistance to corrosion or surface colors. The …","The Electrochemical Society, Inc.",,2025
2017,Electrodeposition of Near-Equiatomic CoCuFeNi Multi-Principal Element Alloys from an Acidic Glycine-Citrate-Triton X100 Aqueous Electrolyte,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2JwR8V0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=2JwR8V0AAAAJ:u3T1itk59dMC,"Understanding the composition and morphology control of electrodeposited CoCuFeNi is the first step to finding a general strategy for developing electrodeposition processes of unconventional alloys with large redox potential differences and complicated deposition mechanisms. In this work, we have successfully synthesized the near-equiatomic (< 5 at% error) CoCuFeNi films with∼ 200nm thickness by electrodeposition from glycine-citrate-Triton X-100 acidic electrolytes. This system generally follows Principle II in Brenner’s paradigm on alloy composition control in electrodeposition. X-ray diffraction (XRD) profiles show that the films only consist of one crystalline phase, different from the deposit from ammonia-citrate-boric acid electrolytes and the equilibrium phases predicted by CALPHAD. The near-equiatomic deposits at Ru substrates were successfully annealed at 400∘ C without significant intermixing …",Pergamon,,2025
2018,Determinants of resistance to engineered T cell therapies targeting CD19 in large B cell lymphomas,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ll8q58oAAAAJ&citation_for_view=Ll8q58oAAAAJ:dhFuZR0502QC,"Most relapsed/refractory large B cell lymphoma (r/rLBCL) patients receiving anti-CD19 chimeric antigen receptor (CAR19) T cells relapse. To characterize determinants of resistance, we profiled over 700 longitudinal specimens from two independent cohorts (n = 65 and n = 73) of r/rLBCL patients treated with axicabtagene ciloleucel. A method for simultaneous profiling of circulating tumor DNA (ctDNA), cell-free CAR19 (cfCAR19) retroviral fragments, and cell-free T cell receptor rearrangements (cfTCR) enabled integration of tumor and both engineered and non-engineered T cell effector-mediated factors for assessing treatment failure and predicting outcomes. Alterations in multiple classes of genes are associated with resistance, including B cell identity (PAX5 and IRF8), immune checkpoints (CD274), and those affecting the microenvironment (TMEM30A). Somatic tumor alterations affect CAR19 therapy at multiple …",Elsevier,,2023
2019,Applications of focused ultrasound-mediated blood-brain barrier opening,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ll8q58oAAAAJ&citation_for_view=Ll8q58oAAAAJ:9ZlFYXVOiuMC,"The blood brain barrier (BBB) plays a critically important role in the regulation of central nervous system (CNS) homeostasis, but also represents a major limitation to treatments of brain pathologies. In recent years, focused ultrasound (FUS) in conjunction with gas-filled microbubble contrast agents has emerged as a powerful tool for transiently and non-invasively disrupting the BBB in a targeted and image-guided manner, allowing for localized delivery of drugs, genes, or other therapeutic agents. Beyond the delivery of known therapeutics, FUS-mediated BBB opening also demonstrates the potential for use in neuromodulation and the stimulation of a range of cell- and tissue-level physiological responses that may prove beneficial in disease contexts. Clinical trials investigating the safety and efficacy of FUS-mediated BBB opening are well underway, and offer promising non-surgical approaches to treatment of …",Elsevier,Advanced drug delivery reviews,2022
2020,Barriers to immune cell infiltration in tumors,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ll8q58oAAAAJ&citation_for_view=Ll8q58oAAAAJ:IWHjjKOFINEC,"Increased immune cell infiltration into tumors is associated with improved patient survival and predicts response to immune therapies. Thus, identification of factors that determine the extent of immune infiltration is crucial, so that methods to intervene on these targets can be developed. T cells enter tumor tissues through the vasculature, and under control of interactions between homing receptors on the T cells and homing receptor ligands (HRLs) expressed by tumor vascular endothelium and tumor cell nests. HRLs are often deficient in tumors, and there also may be active barriers to infiltration. These remain understudied but may be crucial for enhancing immune-mediated cancer control. Multiple intratumoral and systemic therapeutic approaches show promise to enhance T cell infiltration, including both approved therapies and experimental therapies. This review highlights the intracellular and extracellular …",,Journal for immunotherapy of cancer,2023
2021,Focused ultrasound immunotherapy for central nervous system pathologies: challenges and opportunities,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ll8q58oAAAAJ&citation_for_view=Ll8q58oAAAAJ:u5HHmVD_uO8C,"Immunotherapy is rapidly emerging as the cornerstone for the treatment of several forms of metastatic cancer, as well as for a host of other pathologies. Meanwhile, several new high-profile studies have uncovered remarkable linkages between the central nervous and immune systems. With these recent developments, harnessing the immune system for the treatment of brain pathologies is a promising strategy. Here, we contend that MR image-guided focused ultrasound (FUS) represents a noninvasive approach that will allow for favorable therapeutic immunomodulation in the setting of the central nervous system. One obstacle to effective immunotherapeutic drug delivery to the brain is the blood brain barrier (BBB), which refers to the specialized structure of brain capillaries that prevents transport of most therapeutics from the blood into brain tissue. When applied in the presence of circulating microbubbles, FUS …",,Theranostics,2017
2022,Perspectives on recent progress in focused ultrasound immunotherapy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ll8q58oAAAAJ&citation_for_view=Ll8q58oAAAAJ:2osOgNQ5qMEC,"Immunotherapy holds tremendous promise as a strategy for eradicating solid tumors. However, poor T cell infiltration and persistence within most solid tumor microenvironments, as well as mechanisms of adaptive resistance, continue to severely limit the accessibility of most immunotherapies to a broad patient population. This limitation perpetuates the demand for allied therapeutic strategies. Among such strategies is focused ultrasound (FUS), a non-invasive, non-ionizing technique for precisely targeted acoustic energy deposition into tissues. FUS has gained remarkable attention over recent years as a modality for elicitation of immune mechanisms in cancer and other pathologies. In 2017, we published a comprehensive review paper detailing existing evidence for immune modulation and therapy with FUS, as well as impending challenges and opportunities of consideration for the field. Over the last two years, a …",,Theranostics,2019
2023,Evaluation of a PET Insert for Trimodal Imaging: A Step Towards PET/MRI-Guided Focused Ultrasound,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ll8q58oAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ll8q58oAAAAJ:isC4tDSrTZIC,"Combining Positron Emission Tomography (PET) with Magnetic Resonance Imaging (MRI) and Focused Ultrasound (FUS) has emerged as a promising hybrid technique in the medical imaging field. Despite the potential benefits of using simultaneous PET and MRI acquisitions to monitor therapeutic effects and ensure precision and safety during FUS applications, no commercial or academic PET/MRI-guided FUS system (referred in the following as trimodal PET-MRI-FUS) exists. This work presents the design and evaluation of a preclinical PET insert for simultaneous operation with MRI and FUS systems. The proposed PET insert is based on monolithic LYSO crystals arranged in two octagonal rings that define inner and outer diameters of 72 mm and 114 mm, respectively, with an axial length of 67 mm. The system performance was evaluated according to the NEMA NU 4 2008 protocol. It achieves a uniform …",IEEE,,2025
2024,Abstract A038: Overcoming myeloid-mediated immunosuppression and enhancing blood-brain barrier access to advance B7H3 CAR T cell therapy in high-risk Medulloblastoma,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ll8q58oAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ll8q58oAAAAJ:TFP_iSt0sucC,"Background Group 3 medulloblastoma (G3MB) is the most aggressive medulloblastoma subgroup. Although CAR T-cell therapy is promising, it has shown limited efficacy in G3MB due to poor T-cell persistence, largely driven by the immunosuppressive tumor microenvironment (TME) and an intact blood–brain barrier (BBB). M2-like tumor-associated macrophages (TAMs) are major contributors to this immunosuppression, whereas inflammatory TAMs can support CAR T-cell function. We identified Resiquimod, a Toll-like receptor (TLR) 7/8 agonist, as a potent immunomodulator capable of reprogramming TAMs toward a pro-inflammatory phenotype. In parallel, low-intensity focused ultrasound (LIFU) provides a noninvasive method to transiently disrupt the BBB, potentially enhancing both immunomodulatory effects and CAR T-cell infiltration. The objective of this study is to improve the efficacy of B7-H3-directed …",American Association for Cancer Research,,2025
2025,CAR-T cell therapy in brain malignancies: obstacles in the face of cellular trafficking and persistence,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ll8q58oAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ll8q58oAAAAJ:iH-uZ7U-co4C,"Chimeric Antigen Receptor T (CAR-T) cell therapy offers substantial promise for the treatment of brain malignancies, yet its clinical translation remains limited. Tumors such as Glioblastoma Multiforme (GBM), Diffuse Intrinsic Pontine Glioma (DIPG), and Medulloblastoma (MB) are associated with poor prognoses and exhibit limited responsiveness to conventional treatment modalities, including radiotherapy, chemotherapy, and surgical resection. The application of CAR-T cell therapy in these contexts faces significant challenges, primarily in terms of efficient cellular trafficking into the tumor microenvironment and access to heterogeneous tumor regions. Furthermore, CAR-T cell persistence, defined by the long-term survival and functionality of infused cells, remains a critical hurdle in achieving durable therapeutic responses and preventing tumor relapses. This review aims to address the two predominant barriers, trafficking and persistence, by discussing the underlying mechanisms that limit CAR-T cell efficacy in brain tumors, reviewing current strategies aimed at overcoming these challenges, and evaluating novel approaches to enhance the effectiveness of CAR-T therapies in this setting.",Frontiers Media SA,Frontiers in Immunology,2025
2026,Therapeutic Ultrasound for Multimodal Cancer Treatment: A Spotlight on Breast Cancer,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ll8q58oAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ll8q58oAAAAJ:j3f4tGmQtD8C,"Cancer remains a leading cause of mortality worldwide, and the demand for improved efficacy, precision, and safety of management options has never been greater. Focused ultrasound (FUS) is a rapidly emerging strategy for nonionizing, noninvasive intervention that holds promise for the multimodal treatment of solid cancers. Owing to its versatile array of bioeffects, this technology is now being evaluated across preclinical and clinical oncology trials for tumor ablation, therapeutic delivery, radiosensitization, sonodynamic therapy, and enhancement of tumor-specific immune responses. Given the breadth of this burgeoning domain, this review places a spotlight on recent advancements in breast cancer care to exemplify the multifaceted role of FUS technology for oncology indications—outlining physical principles of FUS-mediated thermal and mechanical bioeffects, giving an overview of results from recent …",Annual Reviews,Annual Review of Biomedical Engineering,2025
2027,Abstract C030: Timing of melanoma brain metastasis seeding dictates the immunomodulatory effect and efficacy of systemic anti-CD40 agonist therapy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ll8q58oAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ll8q58oAAAAJ:RHpTSmoSYBkC,"Introduction: Melanoma brain metastasis (MBM) affects nearly 50% of patients with advanced melanoma. Despite progress in systemic therapies, particularly immune checkpoint inhibitors, intracranial responses remain highly variable. The CD40/CD40L axis and its pleiotropic effects on the anti-tumoral immune response has the potential to improve MBM treatment. Our aim was to investigate whether the timing of MBM seeding, in a two-site mouse model of MBM, impacts the intracranial efficacy of anti-CD40 agonism (aCD40). Methods: 2 x 105 B16F1-cOVA murine melanoma cells were subcutaneously (s.c.) injected in the right flank in C57BL/6 mice (5F, 5M). After 3 days, 1 x 105 B16F1-cOVA cells were intracerebrally (i.c.) injected into the right striatum under stereotaxic guidance (early MBM’ cohort). A separate cohort of C57BL/6 mice (5F, 5M) had s.c. injection of B16F1-cOVA cells, followed by an i.c. injection of …",American Association for Cancer Research,,2024
2028,Speckle reducing anisotropic diffusion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1HVnbCYAAAAJ&citation_for_view=1HVnbCYAAAAJ:iH-uZ7U-co4C,"This paper provides the derivation of speckle reducing anisotropic diffusion (SRAD), a diffusion method tailored to ultrasonic and radar imaging applications. SRAD is the edge-sensitive diffusion for speckled images, in the same way that conventional anisotropic diffusion is the edge-sensitive diffusion for images corrupted with additive noise. We first show that the Lee and Frost filters can be cast as partial differential equations, and then we derive SRAD by allowing edge-sensitive anisotropic diffusion within this context. Just as the Lee (1980, 1981, 1986) and Frost (1982) filters utilize the coefficient of variation in adaptive filtering, SRAD exploits the instantaneous coefficient of variation, which is shown to be a function of the local gradient magnitude and Laplacian operators. We validate the new algorithm using both synthetic and real linear scan ultrasonic imagery of the carotid artery. We also demonstrate the …",IEEE,,2002
2029,Functional aspects of meningeal lymphatics in ageing and Alzheimer’s disease,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1HVnbCYAAAAJ&citation_for_view=1HVnbCYAAAAJ:jSAVyFp_754C,"Ageing is a major risk factor for many neurological pathologies, but its mechanisms remain unclear. Unlike other tissues, the parenchyma of the central nervous system (CNS) lacks lymphatic vasculature and waste products are removed partly through a paravascular route. (Re)discovery and characterization of meningeal lymphatic vessels has prompted an assessment of their role in waste clearance from the CNS. Here we show that meningeal lymphatic vessels drain macromolecules from the CNS (cerebrospinal and interstitial fluids) into the cervical lymph nodes in mice. Impairment of meningeal lymphatic function slows paravascular influx of macromolecules into the brain and efflux of macromolecules from the interstitial fluid, and induces cognitive impairment in mice. Treatment of aged mice with vascular endothelial growth factor C enhances meningeal lymphatic drainage of macromolecules from the …",Nature Publishing Group UK,,2018
2030,Active contour external force using vector field convolution for image segmentation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1HVnbCYAAAAJ&citation_for_view=1HVnbCYAAAAJ:JV2RwH3_ST0C,"Snakes, or active contours, have been widely used in image processing applications. Typical roadblocks to consistent performance include limited capture range, noise sensitivity, and poor convergence to concavities. This paper proposes a new external force for active contours, called vector field convolution (VFC), to address these problems. VFC is calculated by convolving the edge map generated from the image with the user-defined vector field kernel. We propose two structures for the magnitude function of the vector field kernel, and we provide an analytical method to estimate the parameter of the magnitude function. Mixed VFC is introduced to alleviate the possible leakage problem caused by choosing inappropriate parameters. We also demonstrate that the standard external force and the gradient vector flow (GVF) external force are special cases of VFC in certain scenarios. Examples and comparisons with …",IEEE,,2007
2031,Image enhancement using a contrast measure in the compressed domain,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1HVnbCYAAAAJ&citation_for_view=1HVnbCYAAAAJ:k_IJM867U9cC,"An image enhancement algorithm for images compressed using the JPEG standard is presented. The algorithm is based on a contrast measure defined within the discrete cosine transform (DCT) domain. The advantages of the psychophysically motivated algorithm are 1) the algorithm does not affect the compressibility of the original image because it enhances the images in the decompression stage and 2) the approach is characterized by low computational complexity. The proposed algorithm is applicable to any DCT-based image compression standard, such as JPEG, MPEG 2, and H. 261.",IEEE,,2003
2032,Peripherally derived macrophages can engraft the brain independent of irradiation and maintain an identity distinct from microglia,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1HVnbCYAAAAJ&citation_for_view=1HVnbCYAAAAJ:BrOSOlqYqPUC,"Peripherally derived macrophages infiltrate the brain after bone marrow transplantation and during central nervous system (CNS) inflammation. It was initially suggested that these engrafting cells were newly derived microglia and that irradiation was essential for engraftment to occur. However, it remains unclear whether brain-engrafting macrophages (beMφs) acquire a unique phenotype in the brain, whether long-term engraftment may occur without irradiation, and whether brain function is affected by the engrafted cells. In this study, we demonstrate that chronic, partial microglia depletion is sufficient for beMφs to populate the niche and that the presence of beMφs does not alter behavior. Furthermore, beMφs maintain a unique functional and transcriptional identity as compared with microglia. Overall, this study establishes beMφs as a unique CNS cell type and demonstrates that therapeutic engraftment of beMφs …",Rockefeller University Press,,2018
2033,A dynamic predictive transformer with temporal relevance regression for action detection,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1HVnbCYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1HVnbCYAAAAJ:rCNdntzdTkkC,"This paper introduces a novel transformer network tailored to skeleton-based action detection in untrimmed long video streams. Our approach centers around three innovative mechanisms that collectively enhance the network’s temporal analysis capabilities. First, a new predictive attention mechanism incorporates future frame data into the sequence analysis during the training phase. This mechanism addresses the essential issue of the current action detection models: incomplete temporal modeling in long action sequences, particularly for boundary frames that lie outside the network’s immediate temporal receptive field, while maintaining computational efficiency. Second, we integrate a new adaptive weighted temporal attention system that dynamically evaluates the importance of each frame within an action sequence. In contrast to the existing approaches, the proposed weighting strategy is both adaptive and …",Pergamon,,2025
2034,PSF-SRDN: Point Spread Function-Aware Speckle Reducing Diffusion Network,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1HVnbCYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1HVnbCYAAAAJ:RMgMIBzvq-4C,"Ultrasound images are corrupted by signal-dependent speckle, degrading the image quality and presenting challenges for downstream tasks such as segmentation and classification. The ultrasound transducer, as modeled by the point spread function (PSF), further distorts the speckle and the signal. The PSF has different lateral and axial distortions which should be considered in the design of efficient speckle removal methods. To this end, we propose a novel lateral and axial distortion-aware diffusion network that encodes the spectrum of lateral and axial distortions, thus enabling adaptive denoising of images corrupted with speckle. The distortions have been modeled in the forward and reverse processes of a multiplicative noise-based diffusion model. Extensive experiments on two datasets establish the efficiency of the proposed model over state-of-the-art methods. The code and data are available at https …",IEEE,,2025
2035,Why instructional activities within classroom activity structures matter and how teacher dashboards can support advancements in instruction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1HVnbCYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1HVnbCYAAAAJ:QoJ_w57xiyAC,"Research developments in deep learning indicate that it is feasible to train computers (eg, neural networks) to classify classroom activity structures in recorded observations of mathematics and reading/language arts instruction such as whole-group instruction, small-group instruction, individual student work, and transitions (Foster et al., 2024; Korban et al., 2023; Wang et al., 2014). In addition, researchers have used audio and transcript data from elementary and secondary classrooms to train neural networks to classify instructional activities such as teacher questioning, use of academic language, student explanation and justification, and teacher feedback and uptake of students’ contributions (Dale et al., 2022; Demszky et al., 2023; Demszky et al., in press; Hunkins et al., 2022; Jacobs et al., 2022; Suresh et al., 2021). Thus, we are at a point where educators can potentially use artificial intelligence (AI) tools to …",Edward Elgar Publishing,,2025
2036,Dynamic Average Consensus for Improving Classifier Accuracy for Multi-Camera Video Sequences,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1HVnbCYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1HVnbCYAAAAJ:EaFouW7jFu4C,"Dynamically tracking time-varying signals find applications in several computer vision-enabled tasks such as object tracking and autonomous vehicle navigation. Such tasks are often characterized by a graph that defines the network topology and how the information is distributed throughout the network, where each node of the graph represents an agent. In contrast to centralized systems, distributed networks do not rely on a centralized server to process the signals acquired from all nodes within the network. The dynamic average consensus problem entails each agent tracking the average of all signals in the network based on the information it receives from its neighboring agents. In this paper, we study the application of the dynamic average consensus algorithm in an object detection framework. In a first-of-its-kind study, we show that the latent features extracted from an object detection network can be …",IEEE,,2024
2037,Student Engagement Assessment in Classrooms Using a Novel 3D Eye-Gaze Estimation and Evaluation Algorithm,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1HVnbCYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1HVnbCYAAAAJ:x21FZCSn4ZoC,"Student attentiveness within the classroom can be assessed by observing student attention toward the teacher or whiteboard, which may be inferred through eye-gaze direction. This paper introduces a novel technique for evaluating student attentiveness by analyzing the direction of their eye gaze derived from their 3D skeletal pose in a reconstructed 3D environment. As for the contributions, the paper suggests a novel 3D head pose estimation algorithm that, unlike other works, does not need frontal face information. As a result, the method is highly effective in uncontrolled environments such as classrooms, where frontal face data is often unavailable. Moreover, a new algorithm was developed to evaluate student attentiveness based on 3D eye gaze information interpreted from the 3D head pose. The proposed method has been validated using a set of instructional videos collected at the University of Virginia.",IEEE,,2024
2038,Structural and material changes in the aging thorax and their role in crash protection for older occupants,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5T1IsfwAAAAJ&citation_for_view=5T1IsfwAAAAJ:u5HHmVD_uO8C,"The human body undergoes a variety of changes as it ages through adulthood. These include both morphological (structural) changes (eg, increased thoracic kyphosis) and material changes (eg, osteoporosis). The purpose of this study is to evaluate structural changes that occur in the aging bony thorax and to assess the importance of these changes relative to the well-established material changes. The study involved two primary components. First, full-thorax computed tomography (CT) scans of 161 patients, age 18 to 89 years, were analyzed to quantify the angle of the ribs in the sagittal plane. A significant association between the angle of the ribs and age was identified, with the ribs becoming more perpendicular to the spine as age increased (0.08 degrees/year, p= 0.012). Next, a finite element model of the thorax was used to evaluate the importance of this rib angle change relative to other factors associated …",SAE Technical Paper,,2005
2039,Spherical indentation load-relaxation of soft biological tissues,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5T1IsfwAAAAJ&citation_for_view=5T1IsfwAAAAJ:u-x6o8ySG0sC,"Elastic-viscoelastic correspondence was used to generate displacement–time solutions for spherical indentation testing of soft biological materials with time-dependent mechanical behavior. Boltzmann hereditary integral operators were used to determine solutions for indentation load-relaxation following a constant displacement rate ramp. A “ramp correction factor” approach was used for routine analysis of experimental load-relaxation data. Experimental load-relaxation tests were performed on rubber, as well as kidney tissue and costal cartilage, two hydrated soft biological tissues with vastly different mechanical responses. The experimental data were fit to the spherical indentation ramp-relaxation solutions to obtain values of short- and long-time shear modulus and of material time constants. The method is used to demonstrate linearly viscoelastic responses in rubber, level-independent indentation results for …",Cambridge University Press,,2006
2040,Fatality risk and the presence of rib fractures,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5T1IsfwAAAAJ&citation_for_view=5T1IsfwAAAAJ:ufrVoPGSRksC,"Rib fractures may be dismissed as clinically insignificant, or of secondary importance in a patient presenting with other serious injuries, especially if the patient is young. This study assesses the effect of concomitant rib injuries on fatality risk following a car crash, and compares the effect as a function of patient age. The National Trauma Databank was sampled to identify 181,331 adults that were in motor vehicle crashes and had complete data available. Characteristics among several populations were compared, including the association between rib fractures and fatality risk in two age groups (18 to 45 years old and over 64 years old). Descriptive statistics were compiled to contrast the injury patterns and outcomes. Propensity scores were then generated using logistic regression, where the “treatment group” was those patients with rib fractures of at least an abbreviated injury scale (AIS) 3. Covariates for generating …",,,2008
2041,Impact response of restrained PMHS in frontal sled tests: skeletal deformation patterns under seat belt loading,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5T1IsfwAAAAJ&citation_for_view=5T1IsfwAAAAJ:9yKSN-GCB0IC,"This study evaluated the response of restrained post-mortem human subjects (PMHS) in 40 km/h frontal sled tests. Eight male PMHS were restrained on a rigid planar seat by a custom 3-point shoulder and lap belt. A video motion tracking system measured three-dimensional trajectories of multiple skeletal sites on the torso allowing quantification of ribcage deformation. Anterior and superior displacement of the lower ribcage may have contributed to sternal fractures occurring early in the event, at displacement levels below those typically considered injurious, suggesting that fracture risk is not fully described by traditional definitions of chest deformation. The methodology presented here produced novel kinematic data that will be useful in developing biofidelic human models. Additional analysis of the data produced by the reported tests as well as additional tests with a variety of loading conditions are required to …",SAE Technical Paper,,2009
2042,Spinal injury rates and specific causation in motor vehicle collisions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5T1IsfwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=5T1IsfwAAAAJ:OxQqgzTNpSoC,"Motor vehicle collisions (MVCs) are a leading cause of acute spinal injuries. Chronic spinal pathologies are common in the population. Thus, determining the incidence of different types of spinal injuries due to MVCs and understanding biomechanical mechanism of these injuries is important for distinguishing acute injuries from chronic degenerative disease. This paper describes methods for determining causation of spinal pathologies from MVCs based on rates of injury and analysis of the biomechanics require to produce these injuries. Rates of spinal injuries in MVCs were determined using two distinct methodologies and interpreted using a focused review of salient biomechanical literature. One methodology used incidence data from the Nationwide Emergency Department Sample and exposure data from the Crash Report Sample System supplemented with a telephone survey to estimate total national …",Pergamon,Accident Analysis & Prevention,2023
2043,STAPP CAR CRASH,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5T1IsfwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=5T1IsfwAAAAJ:yM8WYnMLviIC,"Credits Credits Full Text STAPP CAR CRASH JOURNAL VOLUME 64 Editorial Review Board Kristy B. Arbogast Children's Hospital of Philadelphia Saeed Barbat Ford Motor Company Philippe Beillas Université de Lyon; IFSTTAR, LBMC; Université Lyon 1, France Farid Bendjellal Britax Childcare Limited John H. Bolte IV The Ohio State University John M. Cavanaugh Wayne State University Dainius J. Dalmotas DJ Dalmotas Consulting Inc. Warren N. Hardy Virginia Tech Center for Injury Biomechanics Annette L. Irwin General Motors LLC Richard W. Kent University of Virginia David F. Meaney University of Pennsylvania Harold J. Mertz General Motors Corporation, ret. Barry S. Myers Duke University Guy S. Nusholtz Fiat Chrysler Automobiles US LLC Frank A. Pintar Medical College of Wisconsin Priya Prasad Prasad Engineering, LLC Stephen W. Rouhana Vehicle Safety Sciences, LLC Jonathan D. Rupp Emory …",,,2022
2044,The development of mandatory practices for the testing and maintenance of synthetic turf fields in the National Football League,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5T1IsfwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=5T1IsfwAAAAJ:bZUHSELkOu4C,"Synthetic turf has become an increasingly common playing surface in athletics. Synthetic turf maintenance and athlete health are related and are important considerations at all levels of play. As part of the development of testing practices for the National Football League (NFL) game‐day surfaces, a literature search of MEDLINE and PubMed between the years 1990 and 2018 was conducted. Additionally, a taskforce was convened, and expert opinion was solicited from members through systematic interviews regarding synthetic turf design and maintenance practices in the NFL. All game‐day synthetic turf manufacturers were routinely solicited for input during development and implementation of the mandatory practices. Appropriate maintenance practices can improve the consistency of a synthetic playing surface. Methods for evaluating surface hardness and other aspects of synthetic turf have been developed …",,,2022
2045,Automated turf testing apparatus and system for using same,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5T1IsfwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=5T1IsfwAAAAJ:tCoNjB6AT50C,"(57) ABSTRACT A mobile apparatus that is automated to measure controlled and applied forces and moments to sport surfaces allowing for performance and safety assessment of athletic apparel and athletic surfaces, such as natural or artificial turf. The apparatus is capable of using not only shear and compressive forces, but also rotational moments, and all prescribed forces and moments in combination at the same or different times.",,,2022
2046,"The interplay of fibroblasts, the extracellular matrix, and inflammation in scar formation",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AGJx9cYAAAAJ&citation_for_view=AGJx9cYAAAAJ:YOwf2qJgpHMC,"Various forms of fibrosis, comprising tissue thickening and scarring, are involved in 40% of deaths across the world. Since the discovery of scarless functional healing in fetuses prior to a certain stage of development, scientists have attempted to replicate scarless wound healing in adults with little success. While the extracellular matrix (ECM), fibroblasts, and inflammatory mediators have been historically investigated as separate branches of biology, it has become increasingly necessary to consider them as parts of a complex and tightly regulated system that becomes dysregulated in fibrosis. With this new paradigm, revisiting fetal scarless wound healing provides a unique opportunity to better understand how this highly regulated system operates mechanistically. In the following review, we navigate the four stages of wound healing (hemostasis, inflammation, repair, and remodeling) against the backdrop of adult …",Elsevier,Journal of Biological Chemistry,2022
2047,Lactate is a metabolic mediator that shapes immune cell fate and function,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AGJx9cYAAAAJ&citation_for_view=AGJx9cYAAAAJ:Zph67rFs4hoC,"Lactate and the associated H+ ions are still introduced in many biochemistry and general biology textbooks and courses as a metabolic by-product within fast or oxygen-independent glycolysis. However, the role of lactate as a fuel source has been well-appreciated in the field of physiology, and the role of lactate as a metabolic feedback regulator and distinct signaling molecule is beginning to gain traction in the field of immunology. We now know that while lactate and the associated H+ ions are generally immunosuppressive negative regulators, there are cell, receptor, mediator, and microenvironment-specific effects that augment T helper (Th)17, macrophage (M)2, tumor-associated macrophage, and neutrophil functions. Moreover, we are beginning to uncover how lactate and H+ utilize different transporters and signaling cascades in various immune cell types. These immunomodulatory effects may have a substantial impact in cancer, sepsis, autoimmunity, wound healing, and other immunomodulatory conditions with elevated lactate levels. In this article, we summarize the known effects of lactate and H+ on immune cells to hypothesize potential explanations for the divergent inflammatory vs. anti-inflammatory effects.",Frontiers Media SA,Frontiers in Physiology,2021
2048,Lactic acid suppresses IL-33–mediated mast cell inflammatory responses via hypoxia-inducible factor-1α–dependent miR-155 suppression,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AGJx9cYAAAAJ&citation_for_view=AGJx9cYAAAAJ:_FxGoFyzp5QC,"Lactic acid (LA) is present in tumors, asthma, and wound healing, environments with elevated IL-33 and mast cell infiltration. Although IL-33 is a potent mast cell activator, how LA affects IL-33–mediated mast cell function is unknown. To investigate this, mouse bone marrow–derived mast cells were cultured with or without LA and activated with IL-33. LA reduced IL-33–mediated cytokine and chemokine production. Using inhibitors for monocarboxylate transporters (MCT) or replacing LA with sodium lactate revealed that LA effects are MCT-1–and pH-dependent. LA selectively altered IL-33 signaling, suppressing TGF-β–activated kinase-1, JNK, ERK, and NF-κB phosphorylation, but not p38 phosphorylation. LA effects in other contexts have been linked to hypoxia-inducible factor (HIF)-1α, which was enhanced in bone marrow–derived mast cells treated with LA. Because HIF-1α has been shown to regulate the …",American Association of Immunologists,,2016
2049,Lactic acid inhibits lipopolysaccharide-induced mast cell function by limiting glycolysis and ATP availability,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AGJx9cYAAAAJ&citation_for_view=AGJx9cYAAAAJ:roLk4NBRz8UC,"Sepsis has a well-studied inflammatory phase, with a less-understood secondary immunosuppressive phase. Elevated blood lactate and slow lactate clearance are associated with mortality; however, regulatory roles are unknown. We hypothesized that lactic acid (LA) contributes to the late phase and is not solely a consequence of bacterial infection. No studies have examined LA effects in sepsis models in vivo or a mechanism by which it suppresses LPS-induced activation in vitro. Because mast cells can be activated systemically and contribute to sepsis, we examined LA effects on the mast cell response to LPS. LA significantly suppressed LPS-induced cytokine production and NF-κB transcriptional activity in mouse bone marrow–derived mast cells and cytokine production in peritoneal mast cells. Suppression was MCT-1 dependent and reproducible with sodium lactate or formic acid. Further, LA significantly …",American Association of Immunologists,,2019
2050,Crosstalk between T cells and fibroblasts in biomaterial-mediated fibrosis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AGJx9cYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=AGJx9cYAAAAJ:9ZlFYXVOiuMC,"Biomaterial implants are a critical aspect of our medical therapies and biomedical research and come in various forms: stents, implantable glucose sensors, orthopedic implants, silicone implants, drug delivery systems, and tissue engineered scaffolds. Their implantation triggers a series of biological responses that often times lead to the foreign body response and subsequent fibrotic encapsulation, a dense ECM-rich capsule that isolates the biomaterial and renders it ineffective. These responses lead to the failure of biomaterials and is a major hurdle to overcome and in promoting their success. Much attention has been given to macrophage populations for the inflammatory component of these responses to biomaterials but recent work has identified an important role of T cells and their ability to modulate fibroblast activity and vice versa. In this review, we focus on T cell-fibroblast crosstalk by exploring T cell subsets …",Elsevier,Matrix Biology Plus,2025
2051,A Thy-1–negative immunofibroblast population emerges as a key determinant of fibrotic outcomes to biomaterials,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AGJx9cYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=AGJx9cYAAAAJ:4DMP91E08xMC,"Fibrosis-associated fibroblasts have been identified across various fibrotic disorders, but not in the context of biomaterials, fibrotic encapsulation, and the foreign body response. In other fibrotic disorders, a fibroblast subpopulation defined by Thy-1 loss is strongly correlated with fibrosis yet we do not know what promotes Thy-1 loss. We have previously shown that Thy-1 is an integrin regulator enabling normal fibroblast mechanosensing, and here, leveraging nonfibrotic microporous annealed particle (MAP) hydrogels versus classical fibrotic bulk hydrogels, we demonstrate that Thy1−/− mice mount a fibrotic response to MAP gels that includes inflammatory signaling. We found that a distinct and cryptic α–smooth muscle actin–positive Thy-1− fibroblast population emerges in response to interleuklin-1β (IL-1β) and tumor necrosis factor–α (TNFα). Furthermore, IL-1β/TNFα-induced Thy-1− fibroblasts consist of two …",American Association for the Advancement of Science,,2024
2052,IL-33 induces cellular and exosomal miR-146a expression as a feedback inhibitor of mast cell function,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AGJx9cYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=AGJx9cYAAAAJ:aqlVkmm33-oC,"IL-33 is an inflammatory cytokine that promotes allergic disease by activating group 2 innate lymphoid cells, Th2 cells, and mast cells. IL-33 is increased in asthmatics, and its blockade suppresses asthma-like inflammation in mouse models. Homeostatic control of IL-33 signaling is poorly understood. Because the IL-33 receptor, ST2, acts via cascades used by the TLR family, similar feedback mechanisms may exist. MicroRNA (miR)-146a is induced by LPS-mediated TLR4 signaling and serves as a feedback inhibitor. Therefore, we explored whether miR-146a has a role in IL-33 signaling. IL-33 induced cellular and exosomal miR-146a expression in mouse bone marrow–derived mast cells (BMMCs). BMMCs transfected with a miR-146a antagonist or derived from miR-146a knockout mice showed enhanced cytokine expression in response to IL-33, suggesting that miR-146a is a negative regulator of IL-33–ST2 …",American Association of Immunologists,,2024
2053,High-dimensional comparison of monocytes and T cells in post-COVID and idiopathic pulmonary fibrosis,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AGJx9cYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=AGJx9cYAAAAJ:qxL8FJ1GzNcC,"Introduction Up to 30% of hospitalized COVID-19 patients experience persistent sequelae, including pulmonary fibrosis (PF). Methods We examined COVID-19 survivors with impaired lung function and imaging worrisome for developing PF and found within six months, symptoms, restriction and PF improved in some (Early-Resolving COVID-PF), but persisted in others (Late-Resolving COVID-PF). To evaluate immune mechanisms associated with recovery versus persistent PF, we performed single-cell RNA-sequencing and multiplex immunostaining on peripheral blood mononuclear cells from patients with Early- and Late-Resolving COVID-PF and compared them to age-matched controls without respiratory disease. Results and discussion Our analysis showed circulating monocytes were significantly reduced in Late-Resolving COVID-PF patients compared to Early-Resolving COVID-PF and non-diseased controls. Monocyte abundance correlated with pulmonary function forced vital capacity and diffusion capacity. Differential expression analysis revealed MHC-II class molecules were upregulated on the CD8 T cells of Late-Resolving COVID-PF patients but downregulated in monocytes. To determine whether these immune signatures resembled other interstitial lung diseases, we analyzed samples from Idiopathic Pulmonary Fibrosis (IPF) patients. IPF patients had a similar marked decrease in monocyte HLA-DR protein expression compared to Late-Resolving COVID-PF patients. Our findings indicate decreased circulating monocytes are associated with decreased lung function and uniquely distinguish Late-Resolving COVID-PF from Early …",Frontiers Media SA,,2024
2054,Inferring causal molecular networks: empirical assessment through a community-based effort,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=roFM8XsAAAAJ&citation_for_view=roFM8XsAAAAJ:qjMakFHDy7sC,"It remains unclear whether causal, rather than merely correlational, relationships in molecular networks can be inferred in complex biological settings. Here we describe the HPN-DREAM network inference challenge, which focused on learning causal influences in signaling networks. We used phosphoprotein data from cancer cell lines as well as in silico data from a nonlinear dynamical model. Using the phosphoprotein data, we scored more than 2,000 networks submitted by challenge participants. The networks spanned 32 biological contexts and were scored in terms of causal validity with respect to unseen interventional data. A number of approaches were effective, and incorporating known biology was generally advantageous. Additional sub-challenges considered time-course prediction and visualization. Our results suggest that learning causal relationships may be feasible in complex settings such as …",Nature Publishing Group US,,2016
2055,Transformers learn to implement preconditioned gradient descent for in-context learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=roFM8XsAAAAJ&citation_for_view=roFM8XsAAAAJ:L8Ckcad2t8MC,"Several recent works demonstrate that transformers can implement algorithms like gradient descent. By a careful construction of weights, these works show that multiple layers of transformers are expressive enough to simulate iterations of gradient descent. Going beyond the question of expressivity, we ask:\emph {Can transformers learn to implement such algorithms by training over random problem instances?} To our knowledge, we make the first theoretical progress on this question via an analysis of the loss landscape for linear transformers trained over random instances of linear regression. For a single attention layer, we prove the global minimum of the training objective implements a single iteration of preconditioned gradient descent. Notably, the preconditioning matrix not only adapts to the input distribution but also to the variance induced by data inadequacy. For a transformer with attention layers, we prove certain critical points of the training objective implement iterations of preconditioned gradient descent. Our results call for future theoretical studies on learning algorithms by training transformers.",,,2023
2056,Escaping saddles with stochastic gradients,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=roFM8XsAAAAJ&citation_for_view=roFM8XsAAAAJ:WF5omc3nYNoC,"We analyze the variance of stochastic gradients along negative curvature directions in certain non-convex machine learning models and show that stochastic gradients indeed exhibit a strong component along these directions. Furthermore, we show that-contrary to the case of isotropic noise-this variance is proportional to the magnitude of the corresponding eigenvalues and not decreasing in the dimensionality. Based upon this bservation we propose a new assumption under which we show that the injection of explicit, isotropic noise usually applied to make gradient descent escape saddle points can successfully be replaced by a simple SGD step. Additionally-and under the same condition-we derive the first convergence rate for plain SGD to a second-order stationary point in a number of iterations that is independent of the problem dimension.",PMLR,,2018
2057,Exponential convergence rates for batch normalization: The power of length-direction decoupling in non-convex optimization,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=roFM8XsAAAAJ&citation_for_view=roFM8XsAAAAJ:Se3iqnhoufwC,"Normalization techniques such as Batch Normalization have been applied very successfully for training deep neural networks. Yet, despite its apparent empirical benefits, the reasons behind the success of Batch Normalization are mostly hypothetical. We here aim to provide a more thorough theoretical understanding from a classical optimization perspective. Our main contribution towards this goal is the identification of various problem instances in the realm of machine learning where Batch Normalization can provably accelerate optimization. We argue that this acceleration is due to the fact that Batch Normalization splits the optimization task into optimizing length and direction of the parameters separately. This allows gradient-based methods to leverage a favourable global structure in the loss landscape that we prove to exist in Learning Halfspace problems and neural network training with Gaussian inputs. We thereby turn Batch Normalization from an effective practical heuristic into a provably converging algorithm for these settings. Furthermore, we substantiate our analysis with empirical evidence that suggests the validity of our theoretical results in a broader context.",PMLR,,2019
2058,"Estimating diffusion network structures: Recovery conditions, sample complexity & soft-thresholding algorithm",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=roFM8XsAAAAJ&citation_for_view=roFM8XsAAAAJ:u-x6o8ySG0sC,"Information spreads across social and technological networks, but often the network structures are hidden from us and we only observe the traces left by the diffusion processes, called cascades. Can we recover the hidden network structures from these observed cascades? What kind of cascades and how many cascades do we need? Are there some network structures which are more difficult than others to recover? Can we design efficient inference algorithms with provable guarantees? Despite the increasing availability of cascade data and methods for inferring networks from these data, a thorough theoretical understanding of the above questions remains largely unexplored in the literature. In this paper, we investigate the network structure inference problem for a general family of continuous-time diffusion models using an l1-regularized likelihood maximization framework. We show that, as long as the cascade sampling process satisfies a natural incoherence condition, our framework can recover the correct network structure with high probability if we observe O (d^ 3 log N) cascades, where d is the maximum number of parents of a node and N is the total number of nodes. Moreover, we develop a simple and efficient soft-thresholding inference algorithm, which we use to illustrate the consequences of our theoretical results, and show that our framework outperforms other alternatives in practice.",PMLR,,2014
2059,Linear Transformers Implicitly Discover Unified Numerical Algorithms,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=roFM8XsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=roFM8XsAAAAJ:_Qo2XoVZTnwC,"We train a linear attention transformer on millions of masked-block matrix completion tasks: each prompt is masked low-rank matrix whose missing block may be (i) a scalar prediction target or (ii) an unseen kernel slice of Nystr\""om extrapolation. The model sees only input-output pairs and a mean-squared loss; it is given no normal equations, no handcrafted iterations, and no hint that the tasks are related. Surprisingly, after training, algebraic unrolling reveals the same parameter-free update rule across three distinct computational regimes (full visibility, rank-limited updates, and distributed computation). We prove that this rule achieves second-order convergence on full-batch problems, cuts distributed iteration complexity, and remains accurate with rank-limited attention. Thus, a transformer trained solely to patch missing blocks implicitly discovers a unified, resource-adaptive iterative solver spanning prediction, estimation, and Nystr\""om extrapolation, highlighting a powerful capability of in-context learning.",,,2025
2060,Data Generation without Function Estimation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=roFM8XsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=roFM8XsAAAAJ:TQgYirikUcIC,"Estimating the score function (or other population-density-dependent functions) is a fundamental component of most generative models. However, such function estimation is computationally and statistically challenging. Can we avoid function estimation for data generation? We propose an estimation-free generative method: A set of points whose locations are deterministically updated with (inverse) gradient descent can transport a uniform distribution to arbitrary data distribution, in the mean field regime, without function estimation, training neural networks, and even noise injection. The proposed method is built upon recent advances in the physics of interacting particles. We show, both theoretically and experimentally, that these advances can be leveraged to develop novel generative methods.",,,2025
2061,Transformers can learn temporal difference methods for in-context reinforcement learning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=roFM8XsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=roFM8XsAAAAJ:HDshCWvjkbEC,"Traditionally, reinforcement learning (RL) agents learn to solve new tasks by updating their neural network parameters through interactions with the task environment. However, recent works demonstrate that some RL agents, after certain pretraining procedures, can learn to solve unseen new tasks without parameter updates, a phenomenon known as in-context reinforcement learning (ICRL). The empirical success of ICRL is widely attributed to the hypothesis that the forward pass of the pretrained agent neural network implements an RL algorithm. In this paper, we support this hypothesis by showing, both empirically and theoretically, that when a transformer is trained for policy evaluation tasks, it can discover and learn to implement temporal difference learning in its forward pass.",International Conference on Learning Representations,,2025
2062,Provable optimal transport with transformers: The essence of depth and prompt engineering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=roFM8XsAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=roFM8XsAAAAJ:mB3voiENLucC,"Can we establish provable performance guarantees for transformers? Establishing such theoretical guarantees is a milestone in developing trustworthy generative AI. In this paper, we take a step toward addressing this question by focusing on optimal transport, a fundamental problem at the intersection of combinatorial and continuous optimization. Leveraging the computational power of attention layers, we prove that a transformer with fixed parameters can effectively solve the optimal transport problem in Wasserstein-2 with entropic regularization for an arbitrary number of points. Consequently, the transformer can sort lists of arbitrary sizes up to an approximation factor. Our results rely on an engineered prompt that enables the transformer to implement gradient descent with adaptive stepsizes on the dual optimal transport. Combining the convergence analysis of gradient descent with Sinkhorn dynamics, we establish an explicit approximation bound for optimal transport with transformers, which improves as depth increases. Our findings provide novel insights into the essence of prompt engineering and depth for solving optimal transport. In particular, prompt engineering boosts the algorithmic expressivity of transformers, allowing them implement an optimization method. With increasing depth, transformers can simulate several iterations of gradient descent.",,,2024
2063,"You watch, you give, and you engage: a study of live streaming practices in China",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7r0_F0kAAAAJ&citation_for_view=7r0_F0kAAAAJ:4MWp96NkSFoC,"Despite gaining traction in North America, live streaming has not reached the popularity it has in China, where live- streaming has a tremendous impact on the social behaviors of users. To better understand this socio-technological phenomenon, we conducted a mixed methods study of live streaming practices in China. We present the results of an online survey of 527 live streaming users, focusing on their broadcasting or viewing practices and the experiences they find most engaging. We also interviewed 14 active users to explore their motivations and experiences. Our data revealed the different categories of content that was broadcasted and how varying aspects of this content engaged viewers. We also gained insight into the role reward systems and fan group-chat play in engaging users, while also finding evidence that both viewers and streamers desire deeper channels and mechanisms for interaction in …",,,2018
2064,Thor's hammer: An ungrounded force feedback device utilizing propeller-induced propulsive force,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7r0_F0kAAAAJ&citation_for_view=7r0_F0kAAAAJ:BwyfMAYsbu0C,"We present a new handheld haptic device, Thor's Hammer, which uses propeller propulsion to generate ungrounded, 3-DOF force feedback. Thor's Hammer has six motors and propellers that generates strong thrusts of air without the need for physical grounding or heavy air compressors. With its location and orientation tracked by an optimal tracking system, the system can exert forces in arbitrary directions regardless of the device's orientation. Our technical evaluation shows that Thor's Hammer can apply up to 4 N of force in arbitrary directions with less than 0.11 N and 3.9° of average magnitude and orientation errors. We also present virtual reality applications that can benefit from the force feedback provided by Thor's Hammer. Using these applications, we conducted a preliminary user study and participants felt the experience more realistic and immersive with the force feedback.",,,2018
2065,Pre-Touch Sensing for Mobile Interaction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7r0_F0kAAAAJ&citation_for_view=7r0_F0kAAAAJ:nrtMV_XWKgEC,"Touchscreens continue to advance including progress towards sensing fingers proximal to the display. We explore this emerging pre-touch modality via a self-capacitance touchscreen that can sense multiple fingers above a mobile device, as well as grip around the screen's edges. This capability opens up many possibilities for mobile interaction. For example, using pre-touch in an anticipatory role affords an ""ad-lib interface"" that fades in a different UI--appropriate to the context--as the user approaches one-handed with a thumb, two-handed with an index finger, or even with a pinch or two thumbs. Or we can interpret pre-touch in a retroactive manner that leverages the approach trajectory to discern whether the user made contact with a ballistic vs. a finely-targeted motion. Pre-touch also enables hybrid touch + hover gestures, such as selecting an icon with the thumb while bringing a second finger into range to …",,,2016
2066,SplitBoard: A simple split soft keyboard for wristwatch-sized touch screens,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7r0_F0kAAAAJ&citation_for_view=7r0_F0kAAAAJ:z_wVstp3MssC,"Text entry on a smartwatch is a challenging problem due to the device's limited screen area. In this paper, we introduce the SplitBoard, which is a soft keyboard designed for a smartwatch. As the user flicks left or right on the keyboard, it switches between the left and right halves of a QWERTY keyboard. We report the results of two user experiments where the SplitBoard was compared to an ordinary QWERTY keyboard, the ZoomBoard, SlideBoard, and Qwerty-like keypad. We measured the initial performance with new users for each method. The SplitBoard outperformed all other techniques in the experiments. The SplitBoard is expected to be a viable option for smartwatch text entry because of its light processing requirements, good performance, and immediate learnability.",,,2015
2067,ThingMoji: User-Captured Cut-Outs For In-Stream Visual Communication,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7r0_F0kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7r0_F0kAAAAJ:8d8msizDQcsC,"Live streaming has become increasingly popular, driven by the desire for direct and real-time interactions between streamers and viewers. However, current text-based interactions and pre-defined emojis limit expressiveness, especially when referring to specific stream moments. We propose ThingMoji, a type of user-captured cut-outs to enhance user expression and foster more effective communication between streamers and their audience in the comment section. ThingMojis are unique digital icons created by users by capturing snapshots and annotating specific areas at any point during the stream. We developed StreamThing, a live-streaming platform integrated with ThingMojis, to explore their use during object-focused live streaming contexts. In a user study with three in-the-wild deployments reveals the expressive use of ThingMojis in diverse live-streaming scenarios with rich visual contents. Our findings …",ACM,,2025
2068,SpaceShare: Leveraging Multimodal Context for Fluid Sharing of Spaces in Video Meetings,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7r0_F0kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7r0_F0kAAAAJ:FAceZFleit8C,"In video meetings, people not only talk but also share objects and their environments. However, conventional video calls offer limited support for spatial sharing, typically relying on a live video feed. We present SpaceShare, a system that integrates real-time 3D space reconstruction into video meetings and leverages multi-modal context to fluidly support shared spatial understanding. The reconstructed 3D environment enables users to independently explore the space, while avatar visualization and shared views convey each participant’s location and viewpoints. SpaceShare also stores conversation content and contextual metadata, such as where the conversation took place. This allows users to retrieve spatial features using both physical attributes and conversational context.",,,2025
2069,CustomSight: Enhancing LLM-Powered Visual Assistance for Blind Individuals using Goal-Directed Dynamic Filters,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7r0_F0kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7r0_F0kAAAAJ:_FM0Bhl9EiAC,"LLM-powered assistive technologies (ATs) have enabled blind and visually impaired (BVI) users to query personalized, goal-oriented information about their visual environment. However, the accuracy of system responses depends heavily on well-framed, query-relevant images, which can be difficult for BVI users to capture. We present CustomSight, an LLM-powered AT that helps BVI users effectively query visual information by providing task-aware, real-time guidance to frame the camera and automatically capture images when relevant content is in view. When a user issues a query, CustomSight generates a Dynamic Filter—a custom pipeline that encodes logic tied to the user’s intent, monitors the live feed, and triggers context-aware feedback and image capture. The captured image is sent to the LLM to fetch accurate visual information.",,,2025
2070,Thing2Reality: Enabling Spontaneous Creation of 3D Objects from 2D Content using Generative AI in XR Meetings,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7r0_F0kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7r0_F0kAAAAJ:GtLg2Ama23sC,"During remote communication, participants often share both digital and physical content, such as product designs, digital assets, and environments, to enhance mutual understanding. Recent advances in augmented communication have facilitated users to swiftly create and share digital 2D copies of physical objects from video feeds into a shared space. However, conventional 2D representations of digital objects limits spatial referencing in immersive environments. To address this, we propose Thing2Reality, an Extended Reality (XR) meeting platform that facilitates spontaneous discussions of both digital and physical items during remote sessions. With Thing2Reality, users can quickly materialize ideas or objects in immersive environments and share them as conditioned multiview renderings or 3D Gaussians. Thing2Reality enables users to interact with remote objects or discuss concepts in a collaborative …",,,2025
2071,"DialogLab: Authoring, Simulating, and Testing Dynamic Human-AI Group Conversations",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7r0_F0kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=7r0_F0kAAAAJ:9pM33mqn1YgC,"Designing compelling multi-party conversations involving both humans and AI agents presents significant challenges, particularly in balancing scripted structure with emergent, human-like interactions. We introduce DialogLab, a prototyping toolkit for authoring, simulating, and testing hybrid human-AI dialogues. DialogLab provides a unified interface to configure conversational scenes, define agent personas, manage group structures, specify turn-taking rules, and orchestrate transitions between scripted narratives and improvisation. Crucially, DialogLab allows designers to introduce controlled deviations from the script—through configurable agents that emulate human unpredictability—to systematically probe how conversations adapt and recover. DialogLab facilitates rapid iteration and evaluation of complex, dynamic multi-party human-AI dialogues. An evaluation with both end users and domain experts …",,,2025
2072,A parallel solution–adaptive method for three-dimensional turbulent non-premixed combusting flows,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ui8val8AAAAJ&citation_for_view=Ui8val8AAAAJ:u-x6o8ySG0sC,"A parallel adaptive mesh refinement (AMR) algorithm is proposed and applied to the prediction of steady turbulent non-premixed compressible combusting flows in three space dimensions. The parallel solution-adaptive algorithm solves the system of partial-differential equations governing turbulent compressible flows of reactive thermally perfect gaseous mixtures using a fully coupled finite-volume formulation on body-fitted multi-block hexahedral meshes. The compressible formulation adopted herein can readily accommodate large density variations and thermo-acoustic phenomena. A flexible block-based hierarchical data structure is used to maintain the connectivity of the solution blocks in the multi-block mesh and to facilitate automatic solution-directed mesh adaptation according to physics-based refinement criteria. For calculations of near-wall turbulence, an automatic near-wall treatment readily …",Academic Press,,2010
2073,A parallel adaptive mesh refinement algorithm for predicting turbulent non-premixed combusting flows,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ui8val8AAAAJ&citation_for_view=Ui8val8AAAAJ:u5HHmVD_uO8C,"A parallel adaptive mesh refinement (AMR) algorithm is proposed for predicting turbulent non-premixed combusting flows characteristic of gas turbine engine combustors. The Favre-averaged Navier–Stokes equations governing mixture and species transport for a reactive mixture of thermally perfect gases in two dimensions, the two transport equations of the k–ω turbulence model, and the time-averaged species transport equations, are all solved using a fully coupled finite-volume formulation. A flexible block-based hierarchical data structure is used to maintain the connectivity of the solution blocks in the multi-block mesh and facilitate automatic solution-directed mesh adaptation according to physics-based refinement criteria. This AMR approach allows for anisotropic mesh refinement and the block-based data structure readily permits efficient and scalable implementations of the algorithm on multi-processor …",Taylor & Francis,,2006
2074,Properties of lean turbulent methane-air flames with significant hydrogen addition,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ui8val8AAAAJ&citation_for_view=Ui8val8AAAAJ:UeHWp8X0CEIC,"We examine the combustion of mixed H2–CH4–air fuels using two-dimensional simulations that incorporate detailed kinetics and a mixture-averaged model for differential species transport. The mixtures range from lean H2–air at ϕ=0.37 to lean CH4–air at ϕ=0.7. For each mixture, we compute the quasi-steady propagation of a flame into flow with superimposed low-level turbulent fluctuations, so that the resulting flames are in the laminar flamelet regime. We examine the resulting global flame characteristics, and quantify how the chemistry depends on local flame curvature. We then examine in more detail how the methane chemistry is modulated by the presence of hydrogen. In particular, we find that the local methane burning speed shows a strong positive correlation with local flame curvature when sufficient hydrogen is added to the mixture. Moreover, for higher hydrogen concentrations, the mixtures exhibit …",Elsevier,,2011
2075,Parallel solution-adaptive method for two-dimensional non-premixed combusting flows,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ui8val8AAAAJ&citation_for_view=Ui8val8AAAAJ:d1gkVwhDpl0C,A parallel Adaptive Mesh Refinement (AMR) algorithm is proposed and applied to the predictions of both laminar and turbulent steady non-premixed compressible combusting flows. The parallel solution-adaptive algorithm solves the system of partial-differential equations governing two-dimensional axisymmetric laminar and turbulent compressible flows for reactive thermally perfect gaseous mixtures using a fully coupled finite-volume formulation on body-fitted multi-block quadrilateral mesh. Numerical results for co-flow laminar and turbulent diffusion flames are described and compared to available experimental data. The numerical results demonstrate the validity and potential of the parallel AMR approach for predicting both fine-scale features of laminar and complex turbulent non-premixed flames.,Inderscience Publishers,,2011
2076,Numerical simulation of nitrogen oxide formation in lean premixed turbulent H2/O2/N2 flames,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ui8val8AAAAJ&citation_for_view=Ui8val8AAAAJ:IjCSPb-OGe4C,"Lean premixed hydrogen flames are thermodiffusively unstable and burn in cellular structures. Within these cellular structures the flame is locally enriched by preferential diffusion of hydrogen, leading to local hotspots that burn more intensely than an idealized flat steady flame at comparable inlet conditions. We investigate the impact of this local enrichment on the formation of nitrogen oxides. We consider a two dimensional configuration in which lean premixed hydrogen–air flames interact with a weakly turbulent velocity field for a range of equivalence ratios. The simulations show that although peak temperatures remain well below 1800K (where thermal NOx traditionally is thought to become significant), these localized hot spots lead to significant production of nitric oxides, and the relative enhancement becomes increasingly significant with lower fuel equivalence ratios. A detailed examination of the reaction …",Elsevier,,2011
2077,Towards a Quantum Algorithm for the Incompressible Nonlinear Navier-Stokes Equations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ui8val8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ui8val8AAAAJ:bFI3QPDXJZMC,"In this work, we present novel concepts for quantum algorithms to solve transient, nonlinear partial differential equations (PDEs). The challenge lies in how to effectively represent, encode, process, and evolve the nonlinear system of PDEs on quantum computers. We will discuss the new techniques using the incompressible Navier-Stokes equations as an example, because it represents the fundamental nonlinear feature and yet removes certain complexity in physics, allowing us to focus on the design of quantum algorithms. Previous attempts solving nonlinear PDEs in quantum computation have often involved storing multiple copies of solutions or employing linearizations. Neither is practical due to exponential scaling with evolution time or insufficient solution accuracy. We propose a new framework based on matrix product states (MPSs) and matrix product operators (MPOs), in addition to the Krylov subspace methods. For example, the solution variables of the Navier-Stokes equations are represented by MPSs, and the linear and nonlinear terms are processed by MPOs. The time evolution of the operators is attained by a fast-forwarding algorithm using Krylov subspace methods. Furthermore, we discuss various techniques for efficient encoding of MPSs, measurement reduction for MPOs, and use of tensor operations to treat multi-variate, multi-physics characteristics of Navier-Stokes.","Oak Ridge National Laboratory (ORNL), Oak Ridge, TN (United States)",,2025
2078,On the Parallel Performance of a Novel Brick-Based Hash-Table CFD Library for Distributed Computing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ui8val8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ui8val8AAAAJ:yD5IFk8b50cC,"The performance of a brick-based and hash-table-based framework, HashBrick, supporting distributed structured-grid calculations on heterogeneous architectures, is evaluated with a fourth-order accurate finite-volume algorithm in space and time. HashBrick is implemented with brick data structures and hash tables to provide performance portability across CPUs and GPUs on distributed parallel architectures. It is optimized for CFD algorithms characterized by local clusters of structured-grid data that are otherwise sparsely distributed in the domain. A simple acoustic Gaussian pulse problem is solved to primarily stress memory bandwidth and latency. A weak-scaling study was performed to demonstrate HashBrick's performance on multiple computing nodes. The performance of HashBrick is assessed by comparing wall-clock time and energy against a CPU-only CFD solver, for the same power budget. Two …",,,2025
2079,Overlapping domain decomposition methods for finite volume discretizations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ui8val8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ui8val8AAAAJ:SeFeTyx0c_EC,"Two-level additive overlapping domain decomposition methods are applied to solve the linear system arising from the cell-centered finite volume discretization methods (FVMs) for the elliptic problems. The conjugate gradient (CG) methods are used to accelerate the convergence. To analyze the preconditioned CG algorithm, a discrete L 2 norm, an H 1 norm, and an H 1 semi-norm are introduced to connect the matrices resulting from the FVMs and related bilinear forms. It has been proved that, with a small overlap, the condition number of the preconditioned systems does not depend on the number of the subdomains. The result is similar to that for the conforming finite element. Numerical experiments confirm the theory.",Pergamon,,2024
2080,Application of a fourth-order accurate finite-volume method with adaptive refinement in space and time to multifluid plasma simulations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ui8val8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ui8val8AAAAJ:f2IySw72cVMC,"A novel multifluid plasma model is developed, based on the finite-volume method, with a fourth-order accurate algorithm and solution-adaptive mesh refinement in space and time. Previously, the order of accuracy of the multifluid plasma model was verified and the solutions to common plasma test cases were demonstrated. In the present work, the multifluid plasma model is applied to solve complex test cases involving discontinuities and shocks. Discussion is thus focused on methods of numerical stabilization and strategies with adaptive mesh refinement. The results show improvements to solution stability and as much as an order of magnitude improvement in compute time due to adaptive mesh refinement.",Mathematical Sciences Publishers,,2024
2081,Angular momentum of walking at different speeds,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LITDTDwAAAAJ&citation_for_view=LITDTDwAAAAJ:d1gkVwhDpl0C,"Recently, researchers in robotics have used regulation of the angular momentum of body segments about the total body center of mass (CoM) to develop control strategies for bipedal gait. This work was spurred by reports finding that for a “large class” of human movement tasks, including standing, walking, and running the angular momentum is conserved about the CoM. However, there is little data presented to justify this position. This paper describes an analysis of 11 male adults walking overground at 0.7, 1.0, and 1.3 times their comfortable walking speed (CWS). The normalized angular momenta about the body CoM of 12 body segments were computed about all three coordinate axes. The normalized angular momenta were both small (<0.03) and highly regulated for all subjects and walking speed with extrema that negatively correlated with walking speeds. It was found that the angular momentum of the body …",North-Holland,,2010
2082,Angular momentum synergies during walking,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LITDTDwAAAAJ&citation_for_view=LITDTDwAAAAJ:u-x6o8ySG0sC,"We studied the coordination of body segments during treadmill walking. Specifically, we used the uncontrolled manifold hypothesis framework to quantify the segmental angular momenta (SAM) synergies that stabilize (i.e., reduce the across trials variability) the whole body angular momentum (WBAM). Seven male subjects were asked to walk over a treadmill at their comfortable walking speed. A 17-segment model, fitted to the subject’s anthropometry, was used to reconstruct their kinematics and to compute the SAM and WBAM in three dimensions. A principal component analysis was used to represent the 17 SAM by the magnitudes of the first five principal components. An index of synergy (ΔV) was used to quantify the co-variations of these principal components with respect to their effect on the WBAM. Positive values of ΔV were observed in the sagittal plane during the swing phase. They reflected the synergies …",Springer-Verlag,,2009
2083,Improvements in lower-extremity function following a rehabilitation program with patterned electrical neuromuscular stimulation in females with patellofemoral pain: A …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LITDTDwAAAAJ&citation_for_view=LITDTDwAAAAJ:4TOpqqG69KYC,"Context : Patellofemoral pain (PFP) is a challenging condition, with altered kinematics and muscle activity as 2 common impairments. Single applications of patterned electrical neuromuscular stimulation (PENS) have improved both kinematics and muscle activity in females with PFP; however, the use of PENS in conjunction with a rehabilitation program has not been evaluated. Objective : To determine the effects of a 4-week rehabilitation program with PENS on lower-extremity biomechanics and electromyography (EMG) during a single-leg squat (SLS) and a step-down task (SDT) in individuals with PFP. Study Design : Double-blinded randomized controlled trial. Setting : Laboratory. Patients of Other Participants : Sixteen females …",Human Kinetics,,2019
2084,The effects of ankle foot orthoses on energy recovery and work during gait in children with cerebral palsy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LITDTDwAAAAJ&citation_for_view=LITDTDwAAAAJ:IjCSPb-OGe4C,"BACKGROUND Studies suggest that 50% of children with cerebral palsy are prescribed ankle foot orthoses. One of the aims of ankle foot orthosis use is to aid in walking. This research examined the effects that ankle foot orthoses have on the energy recovery and the mechanical work performed by children with cerebral palsy during walking. METHODS Twenty-one children with spastic diplegia walked with and without their prescribed bilateral ankle foot orthoses. Ten of the subjects wore articulated (hinged) orthoses and 11 subjects wore solid orthoses. Three dimensional kinematic data were collected and between and within group repeated measures ANOVAs were applied to the dependent measures. FINDINGS The results were similar for both groups. There was an increase in stride length, energy recovery, and potential energy and the kinetic energy variation. There was no change in the mechanical work …",Elsevier,,2012
2085,Landing stiffness between individuals with and without a history of low back pain,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LITDTDwAAAAJ&citation_for_view=LITDTDwAAAAJ:KlAtU1dfN6UC,"Context : Reduced spinal stabilization, delayed onset of muscle activation, and increased knee joint stiffness have been reported in individuals with a history of low back pain (LBP). Biomechanical adaptations resulting from LBP may increase the risk for future injury due to suboptimal loading of the lower-extremity or lumbar spine. Assessing landing mechanics in these individuals could help identify which structures might be susceptible to future injury. Objective : To compare vertical and joint stiffness of the lower-extremity and lumbar spine between individuals with and without a previous history of LBP. Design : Cross-sectional study. Setting : Research laboratory. Participants : There were 45 participants (24 without a previous history …",Human Kinetics,,2020
2086,An Augmented Full-Body Model that Improves Upper Body Tracking and Reduces Dynamic Inconsistency in Complex Motion: X. Hu et al.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LITDTDwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=LITDTDwAAAAJ:ZeXyd9-uunAC,"Purpose In recent years, the applications of musculoskeletal simulations have been expanded from simple walking to complex movements in various kinds of sports. The goal of this study was to augment the capability of the currently widely used full-body model (Rajagopal (2016) IEEE Trans. Biomed. Eng. 63:2068–2079) to improve the tracking of the kinematics of the head, shoulder, arms, and torso during complex full-body motion. Methods Based on the testing of different modeling choices of neck, shoulder, and torso segments, the original Rajagopal full-body model was augmented by adding three joints in the spine and two sternoclavicular joints. The inverse kinematics and inverse dynamics of sports-related movements from 16 collegiate athletes were compared between the original Rajagopal and augmented full-body model. Results Our results showed that the augmented full-body model had significant …",Springer International Publishing,,2025
2087,Coin Test: A Complementary Examination for Assessing Upper Extremity Function in Cervical Myelopathy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LITDTDwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=LITDTDwAAAAJ:L8Ckcad2t8MC,"Study Design A prospective observational study. Objectives To explore the potential utility of the Coin Test as a valuable tool for assessing and diagnosing cervical spondylotic myelopathy (CSM). Methods In the first cohort, 36 patients with balance issues were assessed for CSM using the new Coin Test. In the second cohort, the Coin Test and mJOA scores were compared in 36 CSM patients before and 6 weeks after surgery. Results Among the 36 patients with balance problems who failed tandem gait test, 15 out of 16 (94%) CSM patients failed the Coin Test. The other 20 patients (56%) without CSM completed the Coin Test successfully but failed the tandem gait test for various reasons. The Coin Test demonstrated high specificity (100%) and sensitivity (94%) for diagnosing CSM in patients who failed tandem gait test. In the second cohort, the mJOA score improved significantly from 12 to 15 6 weeks postoperatively …",SAGE Publications,,2025
2088,Torque complexity of maximal knee extensor isometric contraction in individuals following anterior cruciate ligament reconstruction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LITDTDwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=LITDTDwAAAAJ:7PzlFSSx8tAC,"Background Current rehabilitation goals following anterior cruciate ligament reconstruction are structured around the maximal force generating capabilities of the muscle. Force fluctuations, an index of force control, have been observed to alter post- anterior cruciate ligament reconstruction. The temporal structure, or “complexity” of force fluctuations may provide important insight into the post-operative muscular recovery. The aims of this study were 1) to compare quadriceps torque complexity in anterior cruciate ligament reconstructed patients to the contralateral limb and to healthy, controls and 2) to assess the relationships between torque complexity to patient outcomes. Methods Data from 120 anterior cruciate ligament reconstructed participants (65 Females, 21.0 ± 8.3 years, 5.96 ± 0.48-months post-surgery) and 95 healthy controls (50 Females, 21.5 ± 2.9 years) were collected. A 30-s knee extensor maximal …",Elsevier,,2023
2089,Improvement of postural stability and gait velocity after cervical decompression surgery in patients with cervical spondylotic myelopathy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LITDTDwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=LITDTDwAAAAJ:dhFuZR0502QC,"OBJECTIVE Cervical spondylotic myelopathy (CSM) is a progressive degenerative condition that can lead to significant neurological deficits, including gait instability. Biomechanical alterations of gait and its various components are poorly understood. The goal of the current study was to determine how spatiotemporal gait parameters, as well as postural and dynamic stability, change after surgery in CSM patients. METHODS A total of 47 subjects were included, with 23 test subjects and 24 controls. Baseline measurements were made for both cohorts. In the CSM cohort, repeat measurements were made at 3 and 6 months postoperatively. To record spatiotemporal and dynamic stability parameters, subjects performed walking trials over force plates on a 15-m runway. To assess postural stability, standing balance trials were conducted on a floor-mounted force plate. Three …",American Association of Neurological Surgeons,,2023
2090,Comprehensive dynamic and kinematic analysis of the rodent hindlimb during over ground walking,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LITDTDwAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=LITDTDwAAAAJ:QIV2ME_5wuYC,"The rat hindlimb is a frequently utilized pre-clinical model system to evaluate injuries and pathologies impacting the hindlimbs. These studies have demonstrated the translational potential of this model but have typically focused on the force generating capacity of target muscles as the primary evaluative outcome. Historically, human studies investigating extremity injuries and pathologies have utilized biomechanical analysis to better understand the impact of injury and extent of recovery. In this study, we expand that full biomechanical workup to a rat model in order to characterize the spatiotemporal parameters, ground reaction forces, 3-D joint kinematics, 3-D joint kinetics, and energetics of gait in healthy rats. We report data on each of these metrics that meets or exceeds the standards set by the current literature and are the first to report on all these metrics in a single set of animals. The methodology and findings …",Nature Publishing Group UK,,2022
2091,Corrosion of additively manufactured alloys: a review,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wXpDvRYAAAAJ&citation_for_view=wXpDvRYAAAAJ:WAzi4Gm8nLoC,"Additive manufacturing (AM), often termed 3D printing, has recently emerged as a mainstream means of producing metallic components from a variety of metallic alloys. The numerous benefits of AM include net shape manufacturing, efficient use of material, suitability to low volume production runs, and the ability to explore alloy compositions not previously accessible to conventional casting. The process of AM, which is nominally performed using laser (or electron) based local melting, has a definitive role in the resultant alloy microstructure. Herein, the corrosion of alloys prepared by AM using laser and electronbased methods, relating the corrosion performance to the microstructural features influenced by AM processing, are reviewed. Such features include unique porosity, grain structures, dislocation networks, residual stress, solute segregation, and surface roughness. Correlations between reported results and …",Association for Materials Protection and Performance,Corrosion,2018
2092,In situ confocal laser scanning microscopy of AA 2024-T3 corrosion metrology: I. Localized corrosion of particles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wXpDvRYAAAAJ&citation_for_view=wXpDvRYAAAAJ:d1gkVwhDpl0C,"The morphology of attack at and around the intermetallic compounds (IMC) present on bare AA 2024-T3 was studied in situ using confocal laser scanning microscopy. Exposures were conducted in at pH 3, 6, and 10 as well as near-neutral 0.5 M NaCl. The types of attack observed could be categorized as matrix and IMC pitting, trenching adjacent to IMC, and matrix etching. The electrochemical behavior of bulk synthesized Al-Cu, Al-Cu-Mg, and Al-Cu-Fe-Mn intermetallic compounds as well as that of AA 2024-T3 was used to rationalize the observed attack metrology. The galvanic coupling between the AA2024-T3 matrix and the intermetallic particles controlled the attack rates. In Al-Cu-Mg, the strong polarization to the open-circuit potential of the alloy caused rapid dissolution (ca. 10 mA/cm 2), whereas for the Al-Cu-Fe-Mn the dissolution rates were on the order of 100 μA/cm 2. The limited dissolution rates of the Al …",IOP Publishing,,2004
2093,Passivity breakdown and pitting corrosion of binary alloys,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wXpDvRYAAAAJ&citation_for_view=wXpDvRYAAAAJ:u-x6o8ySG0sC,"PITTING corrosion—the localized dissolution of a passivated (oxide-covered) metal in the presence of a solution of certain anionic species—is a major cause of failure of metal structures. The breakdown of extremely thin (∼1 nm thick), highly stable passivating layers typically occurs in a sporadic, localized and stochastic fashion1,2, rather than as a catastrophic, global process. Using a model of a random binary iron–chromium alloy, we have shown previously3–6 that experimental observations of passivity of stainless steels can be explained by assuming that it is controlled by the selective dissolution of iron7. Thus if the chromium content is above a certain threshold (the percolation limit8), clusters of iron are finite and dissolution will proceed for a while and then stop. Oxidation of surface chromium atoms to form Cr—O—Cr linkages then creates a passive state in which the entire surface is covered with such a layer …",Nature Publishing Group UK,,1991
2094,In situ confocal laser scanning microscopy of AA 2024-T3 corrosion metrology II. Trench formation around particles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wXpDvRYAAAAJ&citation_for_view=wXpDvRYAAAAJ:2osOgNQ5qMEC,"The mechanism of trench formation next to cathodic intermetallic compound particles (IMC) on bare polished AA 2024-T3 was studied in situ using confocal laser scanning microscopy. Trenches formed at the interface between the matrix and some IMC of the Al-Cu-Mn-Fe and Al-Cu types in all electrolyte solutions studied, including with pH adjusted to 3, 6, and 10 as well as in near-neutral 0.5 M NaCl (pH 6). The trenches in the acidic solution were narrower, and not every cathodic IMC examined developed trenches. Two models for trench formation are compared in their ability to rationalize the experimental observations. The alkaline model ascribes the trenching completely to the effects of local pH increase and is unable to rationalize trenching at low pH, the dependence of trenching on particle type, and the effect of chloride ion content on trenching rate. An anodic trench model combines the influences of IMC …",The Electrochemical Society,,2004
2095,Repassivation of stainless steels: A unifying quantitative framework,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wXpDvRYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wXpDvRYAAAAJ:BJtnxTr0fRcC,"This study presents a unifying quantitative framework for understanding the repassivation process, connecting the values of E rp to key parameters such as pH,(i⋅ x) crit, anodic and cathodic kinetics, i c/i a, f, and electrode-electrolyte interfacial chemistry. The framework integrates potentiostatic, fast potentiodynamic, and galvanodynamic experiments with thermodynamic modeling using a mixed solvent thermodynamic database. Using SS316L and SS304 in 0.6 M NaCl as exemplars, the study demonstrates that repassivation potential decreases with pit depth until it plateaus, with SS316L showing a potential of-0.15 to-0.165 V vs. SCE and SS304 at-0.18 to-0.2 V vs. SCE. The differences in repassivation potential between the alloys are attributed to two roles the Mo in SS316L plays, namely suppressing anodic kinetics and accelerating cathodic kinetics. The relative rate of local cathodic kinetics within the pit are …",Pergamon,,2025
2096,From the Editor: How to Do Continuity,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wXpDvRYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wXpDvRYAAAAJ:hHIA4WEVY-EC,"From the Editor: How to Do Continuity Page 1 The Electrochemical Society Interface OPINION From the Editor: How to Do Continuity To cite this article: Robert G. Kelly 2025 Electrochem. Soc. Interface 34 3 View the article online for updates and enhancements. You may also like A framework for fault diagnosis and classifications of rolling bearings and gears in rolling mills based on RGB principal component analysis with ShuffleNetV2 introducing dual attention module Dongxiao Hou, Rongcai Cheng, Bo Zhang et al. - Hyperglycemia-induced stimulation of glucose transport in skeletal muscle measured by PET- [18F]6FDG and [18F]2FDG Hsuan-Ming Huang, Visvanathan Chandramouli, Faramarz Ismail-Beigi et al. - Validating continuous digital light processing (cDLP) additive manufacturing accuracy and tissue engineering utility of a dye-initiator package Jonathan Wallace, Martha O Wang, Paul Thompson et al. - …",IOP Publishing,,2025
2097,Leveraging Finite Element Method Modeling to Evaluate ZnNi Plating as a Mitigation Strategy for Galvanically Induced Environmental-Assisted Cracking of a P675-Anodized Titanium …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wXpDvRYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wXpDvRYAAAAJ:v_tt_AnqfNMC,"A combined experimental and computational approach was performed to assess the environmental-assisted cracking (EAC) risk of Pyrowear 675 coupled to anodized titanium in a multicomponent assembly exposed to 0.6 M NaCl. The ability of a sacrificial ZnNi layer (plated from an alkaline bath) to mitigate the cracking risk through control of the galvanic couple potential on the assembly was assessed. Experimental analyses of the electrochemical kinetics and (any inherent variability) of anodized titanium, Pyrowear 675, and electroplated ZnNi are presented. Both anodic and cathodic kinetics generated on P675 showed significant variability for the measured open-circuit potential (OCP) charge transfer kinetics between the as-received and polished surfaces. The electroplated ZnNi was shown to have variability from batch to batch in its OCP (100 mV range) and rate of anodic dissolution in its as-received state …",Association for Materials Protection and Performance,,2025
2098,From the Editor: Lessons in Chemistry,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wXpDvRYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wXpDvRYAAAAJ:M_lZXyI38BkC,"Being electrochemists, we often think we know everything about chemistry, but dealing with a pool brings challenges never addressed in P-Chem. When we moved into our current home 16 years ago, our kids were thrilled that it had an inground pool. The move was in July of that year, so they were able to enjoy it for almost two months, given the warm Septembers in central Virginia. Note the pronoun,“they.” I never had a pool growing up, so the care and management needed was all new to me. In my usual overconfidence, I thought,“How hard can it be? It’s just chemistry, and I know that, kind of.” For a moment I thought I heard the gods laughing at that, but figured it was just the crows who nest nearby. Lesson 1: Trust your first instincts. Since that first day, my battles with the pool chemistry have been such that Heather refers to the pool as my “white whale,” akin to Ahab’s obsessive pursuit of Moby Dick. From April …",IOP Publishing,,2025
2099,Experimental and Computational Comparison of Two Chromate-Free Corrosion Protection Coatings for Mitigating Galvanic Attack on AA7075 Coupled to Corrosion-Resistant Steel A286 …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wXpDvRYAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wXpDvRYAAAAJ:60iIaj97TE0C,"Overcoming galvanic corrosion, which is common in aerospace structures, is an ever-present challenge. Noble fasteners such as stainless steel and Ti-6Al-4V are often used with AA7075-T6 and AA2024-T3, inducing damage to the aluminum alloy structural components. Corrosion damage can be slowed down through the use of coatings applied to the cathode or anode in a galvanic assembly to attempt to remove one of the four galvanic corrosion requirements. This work focuses on comparing two commercially available chromate-free coatings: a sol-gel barrier coating vs. a sacrificially pigmented polymer resin coating, with respect to the robustness of their abilities to reduce galvanic corrosion with imperfections and in different environments. These two coatings were demonstrated to provide advantages in corrosion mitigation through the reduction of cathodic current supply through experimental potentiodynamic …",NACE International,,2025
2100,"Generalized stacking fault energy, ideal strength and twinnability of dilute Mg-based alloys: A first-principles study of shear deformation",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1XVWbAMAAAAJ&citation_for_view=1XVWbAMAAAAJ:d1gkVwhDpl0C,"In an effort to establish a scientific foundation for the computational development of advanced Mg-based alloys, a systematic study of the generalized stacking fault (GSF) energy curves has been undertaken. Additionally, the associated stable and unstable stacking and twinning fault energies, ideal shear strengths, and comparative twinnability have been investigated in terms of first-principles calculations for dilute Mg-based alloys of type Mg 95 X. These GSF properties are predicted using the simple and especially the pure alias shear deformations on the basal (0 0 0 1) plane and along the [1 0 1¯ 0] direction of the hexagonal close-packed (hcp) lattice. Fourteen alloying elements (X) are considered herein, namely Al, Ca, Cu, La, Li, Mn, Sc, Si, Sn, Sr, Ti, Y, Zn and Zr. The following conclusions are obtained:(i) the fault energies and the ideal shear strengths of Mg 95 X alloys decrease approximately linearly with an …",Pergamon,,2014
2101,Diffusion coefficients of alloying elements in dilute Mg alloys: A comprehensive first-principles study,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1XVWbAMAAAAJ&citation_for_view=1XVWbAMAAAAJ:ufrVoPGSRksC,"First-principles calculations based on density functional theory have been used to calculate the temperature-dependent dilute tracer diffusion coefficients for 47 substitutional alloying elements in hexagonal closed packed (hcp) Mg by combining transition state theory and an 8-frequency model. The minimum energy pathways and the saddle point configurations during solute migration are calculated with the climbing image nudged elastic band method. Vibrational properties are obtained using the quasi-harmonic Debye model with inputs from first-principles calculations. An improved generalized gradient approximation of PBEsol is used in the present first-principles calculations, which is able to well describe both vacancy formation energies and vibrational properties. It is found that the solute diffusion coefficients in hcp Mg are roughly inversely proportional to the bulk modulus of the dilute alloys, which reflects the …",Pergamon,,2016
2102,Adsorption-controlled growth of La-doped BaSnO3 by molecular-beam epitaxy,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1XVWbAMAAAAJ&citation_for_view=1XVWbAMAAAAJ:OR75R8vi5nAC,"Epitaxial La-doped BaSnO 3 films were grown in an adsorption-controlled regime by molecular-beam epitaxy, where the excess volatile SnO x desorbs from the film surface. A film grown on a (001) DyScO 3 substrate exhibited a mobility of 183 cm 2 V− 1 s− 1 at room temperature and 400 cm 2 V− 1 s− 1 at 10 K despite the high concentration (1.2× 10 11 cm− 2) of threading dislocations present. In comparison to other reports, we observe a much lower concentration of (BaO) 2 Ruddlesden-Popper crystallographic shear faults. This suggests that in addition to threading dislocations, other defects—possibly (BaO) 2 crystallographic shear defects or point defects—significantly reduce the electron mobility.",AIP Publishing,,2017
2103,A comprehensive first-principles study of pure elements: Vacancy formation and migration energies and self-diffusion coefficients,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1XVWbAMAAAAJ&citation_for_view=1XVWbAMAAAAJ:IUKN3-7HHlwC,"A vast number of materials properties and phenomena are regulated by diffusion. However, diffusion coefficients from experiments and calculations are far from complete. Here, we report a compilation of vacancy formation energies (H Va F), vacancy migration energies (H Va M), vacancy activation energies (H Va Q), vacancy concentrations (C Va), and vacancy-mediated self-diffusion coefficients (D Va) as a function of temperature for 82 pure elements in bcc, fcc, and hcp structures by means of a comprehensive first-principles study. We assess the accuracy of four exchange-correlation (X–C) functionals for first-principles calculations, including the local density approximation (LDA), two generalized gradient approximations (PW91 and PBE), and PBEsol–the focus of the present work. To gain temperature-dependent diffusion properties, transition state structure searches are performed by the climbing image nudged …",Pergamon,,2016
2104,First-principles thermodynamic theory of Seebeck coefficients,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1XVWbAMAAAAJ&citation_for_view=1XVWbAMAAAAJ:F9fV5C73w3QC,"Thermoelectric effects, measured by the Seebeck coefficients, refer to the phenomena in which a temperature difference or gradient imposed across a thermoelectric material induces an electrical potential difference or gradient, and vice versa, enabling the direct conversion of thermal and electric energies. All existing first-principles calculations of Seebeck coefficients have been based on the Boltzmann kinetic transport theory. In this work, we present a fundamentally different method for the first-principles calculations of Seebeck coefficients without using any assumptions of the electron-scattering mechanism, being in contrast to the traditional theory by Cutler and Mott that shows the dependence of the Seebeck coefficient on the scattering mechanisms. It is shown that the Seebeck coefficient is a well-defined thermodynamic quantity that can be determined from the change in the chemical potential of electrons …",American Physical Society,,2018
2105,Opportunities for novel refractory alloy thermal/environmental barrier coatings using multicomponent rare earth oxides,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1XVWbAMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1XVWbAMAAAAJ:4xDN1ZYqzskC,"Opportunities are described for developing coatings for refractory alloys beyond the current state-of-the-art silicide coatings, which are inadequate for long-term application in combustion environments due to silica volatility. It is proposed that multicomponent rare earth oxides provide an ideal material system to tailor all necessary properties for environmental/thermal barrier coatings in a single layer, differing from current trends to adopt multi-layer systems that are prone to thermochemical-mechanical interface failure mechanisms. The article discusses opportunities, proof-of-concept, and challenges to accomplish these single-layer rare earth oxide coatings. Properties of interest include isotropic phase stability, processability, thermal expansion, thermal conductivity, ability to perform as a radiation barrier, stability in combustion environments, CMAS resistance, and ability to act as an oxygen diffusion barrier. Both …",Pergamon,,2024
2106,A cluster-based computational thermodynamics framework with intrinsic chemical short-range order: Part I. Configurational contribution,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1XVWbAMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1XVWbAMAAAAJ:2tRrZ1ZAMYUC,"Exploiting Chemical Short-Range Order (CSRO) is a promising avenue for manipulating the properties of alloys. However, existing modeling frameworks are not sufficient to predict CSRO in multicomponent alloys (>3 components) in an efficient and reliable manner. In this work, we developed a hybrid computational thermodynamics framework by combining unique advantages from Cluster Variation Method (CVM) and CALculation of PHAse Diagram (CALPHAD) method. The key is to decompose the cumbersome cluster variables in CVM into fewer site variables of the basic cluster using the Fowler-Yang-Li (FYL) transform, which considerably reduces the number of variables that must be minimized for multicomponent systems. CSRO is incorporated into CALPHAD with a novel cluster-based solution model called FYL-CVM. This new framework brings more physics into CALPHAD while maintaining its practicality …",Pergamon,,2024
2107,Thermodynamic modeling of the Hf-Ta-O system for the design of oxidation resistant HfC-TaC ceramics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1XVWbAMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1XVWbAMAAAAJ:jL-93Qbq4QoC,An improved understanding of the oxidation resistance of HfC-TaC ultra-high temperature ceramics (UHTCs) is developed through modeling of the phase equilibria in the Hf-Ta-O system and HfO2-Ta2O5 isoplethal section. CALculation of PHAse Diagrams (CALPHAD) thermodynamic models of the systems are developed in conjunction with experimental data from the literature and first-principles calculations. Density functional theory (DFT) calculations accurately describe thermodynamic properties of binary oxides in the Hf-Ta-O system and predict cation disorder in Hf(n-5)/2Ta2On. The ternary modeling includes revised models of the Hf–O system and existing models of the Ta–O and Hf–Ta systems. The Hf(n-5)/2Ta2On ternary oxide series is modeled as three entropically stabilized solid solutions with disordered cation sublattices that increase in stability with structure size. Hf4Ta2O13 is considered a metastable …,Elsevier,,2024
2108,Structure and formation mechanisms in tantalum and niobium oxides in superconducting quantum circuits,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1XVWbAMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=1XVWbAMAAAAJ:buQ7SEKw-1sC,"Improving the qubit’s lifetime (T1) is crucial for fault-tolerant quantum computing. Recent advancements have shown that replacing niobium (Nb) with tantalum (Ta) as the base metal significantly increases T1, likely due to a less lossy native surface oxide. However, understanding the formation mechanism and nature of both surface oxides is still limited. Using aberration-corrected transmission electron microscopy and electron energy loss spectroscopy, we found that Ta surface oxide has fewer suboxides than Nb oxide. We observed an abrupt oxidation state transition from Ta2O5 to Ta, as opposed to the gradual shift from Nb2O5, NbO2, and NbO to Nb, consistent with thermodynamic modeling. Additionally, amorphous Ta2O5 exhibits a closer-to-crystalline bonding nature than Nb2O5, potentially hindering H atomic diffusion toward the oxide/metal interface. Finally, we propose a loss mechanism arising from the …",American Chemical Society,,2024
2109,Quantitative comparison of algorithms for tracking single fluorescent particles,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6fNT0XMAAAAJ&citation_for_view=6fNT0XMAAAAJ:u5HHmVD_uO8C,"Single particle tracking has seen numerous applications in biophysics, ranging from the diffusion of proteins in cell membranes to the movement of molecular motors. A plethora of computer algorithms have been developed to monitor the sub-pixel displacement of fluorescent objects between successive video frames, and some have been claimed to have ""nanometer"" resolution. To date, there has been no rigorous comparison of these algorithms under realistic conditions. In this paper, we quantitatively compare specific implementations of four commonly used tracking algorithms: cross-correlation, sum-absolute difference, centroid, and direct Gaussian fit. Images of fluorescent objects ranging in size from point sources to 5μm were computer generated with known sub-pixel displacements. Realistic noise was added and the above four algorithms were compared for accuracy and precision. We found that cross …",Elsevier,,2001
2110,Mechanics of actomyosin bonds in different nucleotide states are tuned to muscle contraction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6fNT0XMAAAAJ&citation_for_view=6fNT0XMAAAAJ:2osOgNQ5qMEC,"Muscle contraction and many other cell movements are driven by cyclic interactions between actin filaments and the motor enzyme myosin. Conformational changes in the actin–myosin binding interface occur in concert with the binding of ATP, binding to actin, and loss of hydrolytic by-products, but the effects of these conformational changes on the strength of the actomyosin bond are unknown. The force-dependent kinetics of the actomyosin bond may be particularly important at high loads, where myosin may detach from actin before achieving its full power stroke. Here we show that over a physiological range of rapidly applied loads, actomyosin behaves as a “catch” bond, characterized by increasing lifetimes with increasing loads up to a maximum at ≈6 pN. Surprisingly, we found that the myosin–ADP bond is possessed of longer lifetimes under load than rigor bonds, although the load at which bond lifetime is …",National Academy of Sciences,,2006
2111,Smooth muscle and skeletal muscle myosins produce similar unitary forces and displacements in the laser trap,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6fNT0XMAAAAJ&citation_for_view=6fNT0XMAAAAJ:u-x6o8ySG0sC,"Purified smooth muscle myosin in the in vitro motility assay propels actin filaments at 1/10 the velocity, yet produces 3–4 times more force than skeletal muscle myosin. At the level of a single myosin molecule, these differences in force and actin filament velocity may be reflected in the size and duration of single motion and force-generating events, or in the kinetics of the cross-bridge cycle. Specifically, an increase in either unitary force or duty cycle may explain the enhanced force-generating capacity of smooth muscle myosin. Similarly, an increase in attached time or decrease in unitary displacement may explain the reduced actin filament velocity of smooth muscle myosin. To discriminate between these possibilities, we used a laser trap to measure unitary forces and displacements from single smooth and skeletal muscle myosin molecules. We analyzed our data using mean-variance analysis, which does not rely …",Elsevier,,1997
2112,Two heads of myosin are better than one for generating force and motion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6fNT0XMAAAAJ&citation_for_view=6fNT0XMAAAAJ:d1gkVwhDpl0C,"Several classes of the myosin superfamily are distinguished by their “double-headed” structure, where each head is a molecular motor capable of hydrolyzing ATP and interacting with actin to generate force and motion. The functional significance of this dimeric structure, however, has eluded investigators since its discovery in the late 1960s. Using an optical-trap transducer, we have measured the unitary displacement and force produced by double-headed and single-headed smooth- and skeletal-muscle myosins. Single-headed myosin produces approximately half the displacement and force (≈6 nm; 0.7 pN) of double-headed myosin (≈10 nm; 1.4 pN) during a unitary interaction with actin. These data suggest that muscle myosins require both heads to generate maximal force and motion.",The National Academy of Sciences,,1999
2113,Teaching peer review and the process of scientific writing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6fNT0XMAAAAJ&citation_for_view=6fNT0XMAAAAJ:IjCSPb-OGe4C,"Many undergraduate and graduate students understand neither the process of scientific writing nor the significance of peer review. In response, some instructors have created writing assignments that teach or mimic parts of the scientific publishing process. However, none fully reproduced peer review and revision of papers together with the writing and publishing process from research to final, accepted draft. In addition, most have been instituted at the graduate rather than undergraduate level. We present a detailed method for teaching undergraduate students the full scientific publishing process, including anonymous peer review, during the process of writing a “term paper.” The result is a review article in the format for submission to a major scientific journal. This method has been implemented in the course Cell and Molecular Biology for Engineers at the University of Virginia. Use of this method resulted in …",American Physiological Society,,2001
2114,Impact of a curriculum and design course redesign on student’s engineering design process knowledge,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6fNT0XMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6fNT0XMAAAAJ:LPZeul_q3PIC,"In 2023, significant changes were implemented in the first-year engineering program at the University of Virginia leading to a major redesign of courses across the curriculum. Previously, first-year students took two separate courses: one focused on the engineering design process, technical communication, and prototyping, while the other centered on sociotechnical concepts, non-technical communication, and ethics. However, starting in 2024, these courses were integrated into a single sequence taught by one instructor to eliminate artificial distinctions between technical and sociotechnical topics.",,,2025
2115,System and method for disinfection of a plumbing system associated with liquid waste,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6fNT0XMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6fNT0XMAAAAJ:XiSMed-E-HIC,"A thermal disinfection system, and related of method of use and manufacture, is implemented with a liquid-carrying conduit associated with a given plumbing system applicable with a given environment. The thermal disinfection system may include a heating device configured for thermal contact with at least a portion of the liquid-carrying conduit, thereby defining a thermal contact region of the liquid-carrying conduit. Additionally, a thermal insulating layer may disposed on the heating device. The heating device may be configured to heat (or heat and dry) a lumen defined by the liquid-carrying conduit along the thermal contact region (in whole or in part) to a specified temperature to prevent (eg, suppress) or inhibit (eg, reduce) microbial activity from advancing through the lumen defined by the liquid-carrying conduit.",,,2025
2116,Tailpiece Heating device for effective prevention of biofilm growth in sink plumbing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6fNT0XMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6fNT0XMAAAAJ:08ZZubdj9fEC,"In recent years, numerous hospitals have linked patient infections to Klebsiella pneumoniae producing Enterobacterales (KPCE) and other resistant bacterial species in their wastewater systems and handwashing sinks. Wastewater plumbing provides a reservoir for bacteria, making them incredibly difficult to eliminate through traditional disinfection methods. Data suggests that patients become infected when bacteria grow or migrate up the proximal wastewater plumbing and into the sink basin, and are subsequently dispersed onto surrounding surfaces. Therefore, a novel electronic device was developed that acts at the highest risk area, just below the sink drain, to heat and dry out the biofilm and creating a biofilm barrier and prevent upward growth from the sink trap. The efficacy of the first prototype of a tailpiece heater (TPH) in preventing drain colonization was tested using GFP-expressing Escherichia coli (GFP-E. coli) as the challenge organism. In control sinks without the TPH, GFP-E. coli biofilm grew from the p-trap upwards to colonize the drain within 7 days. Sinks with a TPH set to 75°C were found to prevent sink drain colonization. In contrast, 65°C was not adequate to prevent drain colonization. Using KPCE the TPH was more effective than no heat control in preventing drain colonization in sinks over time. Lastly, when challenged with seeding from above, the TPH also effectively prevented KPCE colonization at the drain level. Heating of the tailpiece may offer a safe, effective, and economically attractive approach to preventing the spread of resistant bacterial species from contaminated drain biofilm to patients.",Cold Spring Harbor Laboratory,,2023
2117,From theory to practice: unraveling the impact of experiential learning in biomedical engineering education,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6fNT0XMAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6fNT0XMAAAAJ:l7t_Zn2s7bgC,"Experiential education is hands-on, real-world learning that can help students develop problem-solving skills, gain practical experience, build relationships, and understand user needs. It can take many forms, including internships, coops, research projects, competitive clubs, and service learning [1]. A traditional description of experiential learning as defined by Kolb [2] includes a process where a learner has an experience, reflects on the experience, understands what they have experienced, and then applies what they have learned. Experiential learning can be viewed through a constructivist perspective which describes that the participant builds knowledge on top of previous knowledge through their experience rather than through instructor-mediated content [3]. One of the distinguishing factors in biomedical engineering (BME) is that experiential learning tends to focus on clinical and research experiences. A …",Springer International Publishing,,2023
2118,Accelerated wound healing by injectable microporous gel scaffolds assembled from annealed building blocks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BHgPA6AAAAAJ&citation_for_view=BHgPA6AAAAAJ:WF5omc3nYNoC,"Injectable hydrogels can provide a scaffold for in situ tissue regrowth and regeneration, yet gel degradation before tissue reformation limits the gels’ ability to provide physical support. Here, we show that this shortcoming can be circumvented through an injectable, interconnected microporous gel scaffold assembled from annealed microgel building blocks whose chemical and physical properties can be tailored by microfluidic fabrication. In vitro, cells incorporated during scaffold formation proliferated and formed extensive three-dimensional networks within 48 h. In vivo, the scaffolds facilitated cell migration that resulted in rapid cutaneous-tissue regeneration and tissue-structure formation within five days. The combination of microporosity and injectability of these annealed gel scaffolds should enable novel routes to tissue regeneration and formation in vivo.",Nature Publishing Group UK,,2015
2119,Activating an adaptive immune response from a hydrogel scaffold imparts regenerative wound healing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BHgPA6AAAAAJ&citation_for_view=BHgPA6AAAAAJ:qxL8FJ1GzNcC,"Microporous annealed particle (MAP) scaffolds are flowable, in situ crosslinked, microporous scaffolds composed of microgel building blocks and were previously shown to accelerate wound healing. To promote more extensive tissue ingrowth before scaffold degradation, we aimed to slow MAP degradation by switching the chirality of the crosslinking peptides from l- to d-amino acids. Unexpectedly, despite showing the predicted slower enzymatic degradation in vitro, d-peptide crosslinked MAP hydrogel (d-MAP) hastened material degradation in vivo and imparted significant tissue regeneration to healed cutaneous wounds, including increased tensile strength and hair neogenesis. MAP scaffolds recruit IL-33 type 2 myeloid cells, which is amplified in the presence of d-peptides. Remarkably, d-MAP elicited significant antigen-specific immunity against the d-chiral peptides, and an intact adaptive immune system was …",Nature Publishing Group UK,,2021
2120,Photodegradable macromers and hydrogels for live cell encapsulation and release,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BHgPA6AAAAAJ&citation_for_view=BHgPA6AAAAAJ:u-x6o8ySG0sC,"Hydrogel scaffolds are commonly used as 3D carriers for cells because their properties can be tailored to match natural extracellular matrix. Hydrogels may be used in tissue engineering and regenerative medicine to deliver therapeutic cells to injured or diseased tissue through controlled degradation. Hydrolysis and enzymolysis are the two most common mechanisms employed for hydrogel degradation, but neither allows sequential or staged release of cells. In contrast, photodegradation allows external real-time spatial and temporal control over hydrogel degradation, and allows for staged and sequential release of cells. We synthesized and characterized a series of macromers incorporating photodegradbale ortho-nitrobenzyl (o-NB) groups in the macromer backbone. We formed hydrogels from these macromers via redox polymerization and quantified the apparent rate constants of degradation (kapp) of each …",American Chemical Society,,2012
2121,Particle hydrogels based on hyaluronic acid building blocks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BHgPA6AAAAAJ&citation_for_view=BHgPA6AAAAAJ:_FxGoFyzp5QC,"The extracellular matrix (ECM) provides tissues with the mechanical support, space, and bioactive signals needed for homeostasis or tissue repair after wounding or disease. Hydrogel based scaffolds that can match the bulk mechanical properties of the target tissue have been extensively explored as ECM mimics. Although the addition of microporosity to hydrogel scaffolds has been shown to enhance cell/tissue–material integration, the introduction of microporosity often involves harsh chemical methods, which limit bioactive signal incorporation and injectability. Particle hydrogels are an emerging platform to generate in situ forming microporous scaffolds. In this approach, μgel particles are annealed to each other to form a bulk scaffold that is porous because of the void space left by the packed microgels. In the present work, we discuss the formation of hyaluronic acid-based microfluidic generated microgels for the …",American Chemical Society,,2016
2122,Photodegradable hydrogels to generate positive and negative features over multiple length scales,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BHgPA6AAAAAJ&citation_for_view=BHgPA6AAAAAJ:u5HHmVD_uO8C,"Here we present a photodegradable hydrogel as a biocompatible, nonfouling photoresist capable of presenting positive and negative features through single-photon and two-photon degradation. An ortho-nitrobenzylether (o-NBE) moiety is used as a polymerizable cap for poly(ethylene glycol) chains to create a photodegradable macromer. Positive and negative features can be patterned into/onto a hydrogel over a broad range of length scales (∼10−7 to 10−2 m (nm−cm)) in single- and two-photon photolysis. Phase contrast micrographs and profilometry data show that a partially degradable hydrogel network undergoes swelling to produce positive features with varying size (10−100 μm). Conjugation of a coumarin fluorophore to the o-NBE macromer enhances the sensitivity of the hydrogel to two-photon degradation, simultaneously incorporating fluorescence visualization with no added dye.",American Chemical Society,,2010
2123,PS17. 3: Optimizing islet transplantation with Microporous Annealed Particle MAP scaffold to improve engraftment and modulate immune responses.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BHgPA6AAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BHgPA6AAAAAJ:HoB7MX3m0LUC,"Background: Islet transplantation is a promising approach for diabetes management, but clinical application is limited by poor engraftment and immune-mediated rejection. Microporous Annealed Particle (MAP) gels are injectable, granular scaffolds formed by annealing microgels into a porous network. Unlike traditional hydrogels, MAP gels permit rapid cell infiltration and vascularization due to their interconnected microporosity, and their modular chemistry enables tunable immunomodulation. This study investigates the utility of MAP gel as a scaffold to enhance islet viability, promote engraftment, and modulate immune responses in transplantation settings. Methods: Dissociated murine islets, whole human islets, or Beta TC-6 cells were mixed with MAP gel and transplanted into diabetic syngeneic or xenogeneic recipients. Blood glucose (BG) was monitored daily. Additionally, MAP or nanoporous (NP) gels were …",LWW,,2025
2124,Microporous Annealed Particle (MAP) Gel as a Novel Scaffold for Beta-Cell Replacement Therapy: Enhancing Engraftment and Immunomodulation in a Murine Model,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BHgPA6AAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BHgPA6AAAAAJ:pqnbT2bcN3wC,"Purpose: Islet and β-cell transplantation is a promising therapy for diabetes; however, its success remains limited by poor engraftment efficiency and immune rejection and recurrent autoimmunity. This study evaluates microporous annealed particle (MAP) gel as a supportive scaffold to enhance engraftment and function of dissociated murine islets in a syngeneic model, with potential applications for stem cell-derived β-cell therapy. Methods: Dissociated islet cells from C57BL/6 mice were mixed with MAP gel and transplanted into syngeneic diabetic recipients at either the kidney capsule or epididymal fat pad sites. Blood glucose levels were monitored daily. Additionally, MAP scaffolds and nanoporous (NP) gels were transplanted into the epididymal fat pad of non-diabetic mice with or without β TC-6 cells. Cytokine profiling of implants was performed using multiplex pro-inflammatory cytokine assays at 7 and 14 days …",Elsevier,,2025
2125,Delivery of dissociated islets cells within microporous annealed particle scaffold to treat type 1 diabetes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BHgPA6AAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BHgPA6AAAAAJ:g5m5HwL7SMYC,"Provided are compositions that include single cell suspensions of pancreatic islet cells, pancreatic islet-like cells derived from iPS cells, or combinations thereof, wherein the cells are present within a MAP scaffold and/or are encapsulated by MAPs. In some embodiments, the MAP scaffold and/the MAPs have a polymer backbone that includes poly (ethyleneglycol)(PEG), hyaluronic acid, polyacrylamide, polymethacrylate, alginate, collagen, or any combination thereof. Also provided are methods for using the presently disclosed compositions for treating Type 1 diabetes, for example by administering to a subject with Type 1 diabetes such a composition via a route and in an amount effective for treating the Type 1 diabetes in the subject. In some embodiments, the administering includes injecting the composition into a kidney capsule, subcutaneously, intraperitoneally, into adipose tissue, intramuscularly …",,,2025
2126,Development of a Clinically Relevant Rabbit Model of Acute Laryngeal Injury,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BHgPA6AAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BHgPA6AAAAAJ:70eg2SAEIzsC,"Objectives Acute Laryngeal Injury (ALgI) is created as a result of endotracheal tube pressure ulcer formation leading to fibrosis and inflammation. This condition often leads to airway obstruction and voice and swallowing dysfunction. This study demonstrates a reliable animal model of ALgI to reproduce the acute wound process seen clinically, to explore the pathophysiology of this disease process, and serve as a reproducible injury suitable for the evaluation of therapeutic interventions. Methods An ALgI model was developed in New Zealand White rabbits using precise mucosal stripping of the posterior larynx, followed by intubation with an oversized 4.0 endotracheal tube for one hour to mimic intubation-associated trauma and pressure ischemia. Laryngoscopy and laryngeal harvest were performed two weeks post-injury for histologic and immunofluorescent evaluation. Results Injured rabbits demonstrated an eight-fold increase in posterior glottic thickness (1.57mm vs. 0.19mm in controls; p=0.0004) and eleven-fold increase in collagen content (1.93mm vs. 0.17mm; p=0.005). Collagen subtype analysis revealed a shift toward active collagen within the injured larynx compared to the uninjured, with increased type III collagen (69.0%% vs. 26.1%; p<0.0001) and reduced type I collagen (27.2% vs. 73.9%; p<0.0001) in the posterior glottis, consistent with the proliferative phase of wound healing. Collagen fiber alignment analysis demonstrated increased coherency in injured tissues (0.36 vs. 0.21; p=0.023), indicating early organized collagen formation consistent with scar formation within the posterior glottis. Conclusions The model offers a robust …",Cold Spring Harbor Laboratory,,2025
2127,07-4: ADVANCING ISLET AND CELL TRANSPLANTATION: MICROPOROUS ANNEALED PARTICLE (MAP) GEL AS A SCAFFOLD FOR ENHANCED ENGRAFTMENT AND IMMUNOMODULATION,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BHgPA6AAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=BHgPA6AAAAAJ:35N4QoGY0k4C,"Methods: Dissociated murine islets, whole human islets, or Beta TC-6 cells were mixed with MAP gel and transplanted into diabetic syngeneic or xenogeneic recipients. Blood glucose (BG) was monitored daily. Additionally, MAP or nanoporous (NP) gels were implanted in non-diabetic mice with or without Beta TC-6 cells. Cytokine profiling was performed at 7 and 14 days post-transplantation. Results: In diabetic C57BL/6 mice, transplantation of 100 dissociated islets with MAP gel under the kidney capsule restored normoglycemia (BG< 200 mg/dL) within 18 days and maintained control for 40 days, while islets transplanted without MAP gel failed to reverse hyperglycemia. In the epididymal fat pad, 400 dissociated islets with MAP gel sustained normoglycemia for 44 days in two mice, whereas MAP gel alone, whole islets alone, or dissociated islets alone did not.",LWW,,2025
2128,Treadmarks: Shared memory computing on networks of workstations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L1pb8GUAAAAJ&citation_for_view=L1pb8GUAAAAJ:u5HHmVD_uO8C,"Shared memory facilitates the transition from sequential to parallel processing. Since most data structures can be retained, simply adding synchronization achieves correct, efficient programs for many applications. We discuss our experience with parallel computing on networks of workstations using the TreadMarks distributed shared memory system. DSM allows processes to assume a globally shared virtual memory even though they execute on nodes that do not physically share memory. We illustrate a DSM system consisting of N networked workstations, each with its own memory. The DSM software provides the abstraction of a globally shared memory, in which each processor can access any data item without the programmer having to worry about where the data is or how to obtain its value.",IEEE,,1996
2129,Parallel metropolis coupled Markov chain Monte Carlo for Bayesian phylogenetic inference,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L1pb8GUAAAAJ&citation_for_view=L1pb8GUAAAAJ:9yKSN-GCB0IC,"Motivation: Bayesian estimation of phylogeny is based on the posterior probability distribution of trees. Currently, the only numerical method that can effectively approximate posterior probabilities of trees is Markov chain Monte Carlo (MCMC). Standard implementations of MCMC can be prone to entrapment in local optima. Metropolis coupled MCMC [(MC)3], a variant of MCMC, allows multiple peaks in the landscape of trees to be more readily explored, but at the cost of increased execution time. Results: This paper presents a parallel algorithm for (MC)3. The proposed parallel algorithm retains the ability to explore multiple peaks in the posterior distribution of trees while maintaining a fast execution time. The algorithm has been implemented using two popular parallel programming models: message passing and shared memory. Performance results indicate nearly linear speed improvement in …",Oxford University Press,,2004
2130,Treadmarks: Distributed shared memory on standard workstations and operating systems.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L1pb8GUAAAAJ&citation_for_view=L1pb8GUAAAAJ:u-x6o8ySG0sC,"TreadMarks is a distributed shared memory (DSM) system for standard Unix systems such as SunOS and Ultrix. This paper presents a performance evaluation of TreadMarks running on Ultrix using DECstation-5000/240's that are connected by a 100-Mbps switch-based ATM LAN and a 10-Mbps Ethernet. Our objective is to determine the e ciency of a user-level DSM implementation on commercially available workstations and operating systems. We achieved good speedups on the 8-processor ATM network for Jacobi (7.4), TSP (7.2), Quicksort (6.3), and ILINK (5.7). For a slightly modified version of Water from the SPLASH benchmark suite, we achieved only moderate speedups (4.0) due to the high communication and synchronization rate. Speedups decline on the 10-Mbps Ethernet (5.5 for Jacobi, 6.5 for TSP, 4.2 for Quicksort, 5.1 for ILINK, and 2.1 for Water), reflecting the bandwidth limitations of the Ethernet. These results support the contention that, with suitable networking technology, DSM is a viable technique for parallel computation on clusters of workstations. To achieve these speedups, TreadMarks goes to great lengths to reduce the amount of communication performed to maintain memory consistency. It uses a lazy implementation of release consistency, and it allows multiple concurrent writers to modify a page, reducing the impact of false sharing. Great care was taken to minimize communication overhead. In particular, on the ATM network, we used a standard low-level protocol, AAL3/4, bypassing the TCP/IP protocol stack. Unix communication overhead, however, remains the main obstacle in the way of better performance for …",,,1994
2131,Peer-to-peer information retrieval using self-organizing semantic overlay networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L1pb8GUAAAAJ&citation_for_view=L1pb8GUAAAAJ:d1gkVwhDpl0C,"Content-based full-text search is a challenging problem in Peer-to-Peer (P2P) systems. Traditional approaches have either been centralized or use flooding to ensure accuracy of the results returned.In this paper, we present pSearch, a decentralized non-flooding P2P information retrieval system. pSearch distributes document indices through the P2P network based on document semantics generated by Latent Semantic Indexing (LSI). The search cost (in terms of different nodes searched and data transmitted) for a given query is thereby reduced, since the indices of semantically related documents are likely to be co located in the network.We also describe techniques that help distribute the indices more evenly across the nodes, and further reduce the number of nodes accessed using appropriate index distribution as well as using index samples and recently processed queries to guide the search.Experiments …",,,2003
2132,Energy-efficient processor design using multiple clock domains with dynamic voltage and frequency scaling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L1pb8GUAAAAJ&citation_for_view=L1pb8GUAAAAJ:qjMakFHDy7sC,"As clock frequency increases and feature size decreases, clock distribution and wire delays present a growing challenge to the designers of singly-clocked, globally synchronous systems. We describe an alternative approach, which we call a multiple clock domain (MCD) processor, in which the chip is divided into several clock domains, within which independent voltage and frequency scaling can be performed. Boundaries between domains are chosen to exploit existing queues, thereby minimizing inter-domain synchronization costs. We propose four clock domains, corresponding to the front end , integer units, floating point units, and load-store units. We evaluate this design using a simulation infrastructure based on SimpleScalar and Wattch. In an attempt to quantify potential energy savings independent of any particular on-line control strategy, we use off-line analysis of traces from a single-speed run of each of …",IEEE,,2002
2133,JSPIM: A Skew-Aware PIM Accelerator for High-Performance Databases Join and Select Operations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L1pb8GUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=L1pb8GUAAAAJ:ziOE8S1-AIUC,"Database applications are increasingly bottlenecked by memory bandwidth and latency due to the memory wall and the limited scalability of DRAM. Join queries, central to analytical workloads, require intensive memory access and are particularly vulnerable to inefficiencies in data movement. While Processing-in-Memory (PIM) offers a promising solution, existing designs typically reuse CPU-oriented join algorithms, limiting parallelism and incurring costly inter-chip communication. Additionally, data skew, a main challenge in CPU-based joins, remains unresolved in current PIM architectures. We introduce JSPIM, a PIM module that accelerates hash join and, by extension, corresponding select queries through algorithm-hardware co-design. JSPIM deploys parallel search engines within each subarray and redesigns hash tables to achieve O(1) lookups, fully exploiting PIM's fine-grained parallelism. To mitigate skew, our design integrates subarray-level parallelism with rank-level processing, eliminating redundant off-chip transfers. Evaluations show JSPIM delivers 400x to 1000x speedup on join queries versus DuckDB. When paired with DuckDB for the full SSB benchmark, JSPIM achieves an overall 2.5x throughput improvement (individual query gains of 1.1x to 28x), at just a 7% data overhead and 2.1% per-rank PIM-enabled chip area increase.",,,2025
2134,Concurrent PIM and Load/Store Servicing in PIM-Enabled Memory,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L1pb8GUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=L1pb8GUAAAAJ:oi2SiIJ9l4AC,"Processing in-memory (PIM) has emerged as a promising approach to address the increasingly memory bound nature of modern applications like machine learning and genomics. While PIM-enabled memories offer significant performance and energy improvements over host-side execution, integration of such memories into existing systems remains an open challenge. In particular, naively replacing regular memory with a PIM-enabled one in a conventional processor could be detrimental to its performance. PIM applications are optimized to saturate the memory subsystem to maximize speedup. However, since modern processors, including CPUs and GPUs, support multi-tenancy to improve utilization, such saturation can lead to extreme unfairness and denial of service to other applications. In this paper, we characterize the performance of a PIMenabled GPU system when co-executing regular GPU kernels with …",IEEE,,2025
2135,Rollingcache: using runtime behavior to defend against cache side channel attacks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L1pb8GUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=L1pb8GUAAAAJ:3NQIlFlcGxIC,"A RollingCache system and methodology defends against contention side-channel cache attacks by dynamically changing the set of addresses contending for cache sets. Unlike prior defenses, RollingCache system does not rely on address encryption, decryption, data relocation, or cache partitioning. One or more levels of indirection are used to implement dynamic mapping controlled by the whole-cache runtime behavior. The RollingCache system does not depend on having defined security domains and can defend against an attacker running on the same or another core.",,,2024
2136,RollingCache: Using Runtime Behavior to Defend Against Cache Side Channel Attacks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L1pb8GUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=L1pb8GUAAAAJ:w1MjKQ0l0TYC,"Shared caches are vulnerable to side channel attacks through contention in cache sets. Besides being a simple source of information leak, these side channels form useful gadgets for more sophisticated attacks that compromise the security of shared systems. The fundamental design aspect that contention attacks exploit is the deterministic nature of the set of addresses contending for a cache set. In this paper, we present RollingCache, a cache design that defends against contention attacks by dynamically changing the set of addresses contending for cache sets. Unlike prior defenses, RollingCache does not rely on address encryption/decryption, data relocation, or cache partitioning. We use one level of indirection to implement dynamic mapping controlled by the whole-cache runtime behavior. Our solution does not depend on having defined security domains, and can defend against an attacker running on the same or another core. We evaluate RollingCache on ChampSim using the SPEC-2017 benchmark suite. Our security evaluation shows that our dynamic mapping removes the deterministic ability to identify the source of contention. The performance evaluation shows an impact of 1.67\% over a mix of workloads, with a corresponding",,,2024
2137,Relief: Relieving memory pressure in socs via data movement-aware accelerator scheduling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L1pb8GUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=L1pb8GUAAAAJ:wKETBy42zhYC,"Data movement latency when using on-chip accelerators in emerging heterogeneous architectures is a serious performance bottleneck. While hardware/software mechanisms such as peer-to-peer DMA between producer/consumer accelerators allow bypassing main memory and significantly reduce main memory contention, schedulers in both the hardware and software domains remain oblivious to their presence. Instead, most contemporary schedulers tend to be deadline-driven, with improved utilization and/or throughput serving as secondary or co-primary goals. This lack of focus on data communication will only worsen execution times as accelerator latencies reduce. In this paper, we present RELIEF (RElaxing Least-laxIty to Enable Forwarding), an online least laxity-driven accelerator scheduling policy that relieves memory pressure in accelerator-rich architectures via data movement-aware scheduling …",IEEE,,2024
2138,Patterns in property specifications for finite-state verification,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-ZRKCcEAAAAJ&citation_for_view=-ZRKCcEAAAAJ:u-x6o8ySG0sC,"Despite the automation, users of finite-state verification tools still must be able to specify the system requirements in the specification language of the tool. This is more challenging than it might at first appear. For example, consider the following requirement for an elevator: Between the time an elevator is called at a floor and the time it opens its doors at that floor, the elevator can arrive at that floor’at most twice. To verify this property with a linear temporal logic (LTL) model checker, a developer would have to translate this informal requirement into the following LTL formula: q ((cal1 A Oopen)+",,,1999
2139,Bandera: Extracting finite-state models from Java source code,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-ZRKCcEAAAAJ&citation_for_view=-ZRKCcEAAAAJ:u5HHmVD_uO8C,"Finite-state verification techniques, such as model checking, have shown promise as a cost-effective means for finding defects in hardware designs. To date, the application of these techniques to software has been hindered by several obstacles. Chief among these is the problem of constructing a finite-state model that approximates the executable behavior of the software system of interest. Current best-practice involves hand-construction of models which is expensive (prohibitive for all but the smallest systems), prone to errors (which can result in misleading verification results), and difficult to optimize (which is necessary to combat the exponential complexity of verification algorithms). In this paper, we describe an integrated collection of program analysis and transformation components, called Bandera, that enables the automatic extraction of safe, compact finite-state models from program source code. Bandera …",,,2000
2140,Property specification patterns for finite-state verification,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-ZRKCcEAAAAJ&citation_for_view=-ZRKCcEAAAAJ:d1gkVwhDpl0C,"Finite-state verification(eg, model checking) provides a powerful means to detect errors that are often subtle and difficult to reproduce. Nevertheless, the transition of this technology from research to practice has been slow. While there are a number of potential causes for reluctance in adopting such formal methods in practice, we believe that a primary cause rests with the fact that practitioners are unfamiliar with specification processes, notations, and strategies. Recent years have seen growing success in leveraging experience with design and coding patterns. We propose a pattern-based approach to the presentation, codification and reuse of property specifications for finite-state verification.",,,1998
2141,Constructing interaction test suites for highly-configurable systems in the presence of constraints: A greedy approach,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-ZRKCcEAAAAJ&citation_for_view=-ZRKCcEAAAAJ:M3ejUd6NZC8C,"Researchers have explored the application of combinatorial interaction testing (CIT) methods to construct samples to drive systematic testing of software system configurations. Applying CIT to highly-configurable software systems is complicated by the fact that, in many such systems, there are constraints between specific configuration parameters that render certain combinations invalid. Many CIT algorithms lack a mechanism to avoid these. In recent work, automated constraint solving methods have been combined with search-based CIT construction methods to address the constraint problem with promising results. However, these techniques can incur a non-trivial overhead. In this paper, we build upon our previous work to develop a family of greedy CIT sample generation algorithms that exploit calculations made by modern Boolean satisfiability (SAT) solvers to prune the search space of the CIT problem. We …",IEEE,,2008
2142,Differential symbolic execution,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-ZRKCcEAAAAJ&citation_for_view=-ZRKCcEAAAAJ:hqOjcs7Dif8C,"Detecting and characterizing the effects of software changes is a fundamental component of software maintenance. Version differencing information can be used to perform version merging, infer change characteristics, produce program documentation, and guide program re-validation. Existing techniques for characterizing code changes, however, are imprecise leading to unnecessary maintenance efforts. In this paper, we introduce a novel extension and application of symbolic execution techniques that computes a precise behavioral characterization of a program change. This technique, which we call differential symbolic execution (DSE), exploits the fact that program versions are largely similar to reduce cost and improve the quality of analysis results. We define the foundational concepts of DSE, describe cost-effective tool support for DSE, and illustrate its potential benefit through an exploratory study that …",,,2008
2143,LoCaL: Countering Surface Bias in Code Evaluation Metrics,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-ZRKCcEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=-ZRKCcEAAAAJ:mUJArPsKIAAC,"With the increasing popularity of large language models (LLMs) and LLM-based agents, reliable and effective code evaluation metrics (CEMs) have become crucial for progress across several software engineering tasks. While popular benchmarks often provide test cases to assess the correctness of generated code, crafting and executing test cases is expensive. Reference-based CEMs provide a cheaper alternative by scoring a candidate program based on its functional similarity to a reference. Although prior research has focused on reporting the weak correlation between these CEMs and functional correctness, the causes are only assumed, and plausible solutions remain unexplored. In this work, we critically evaluate four state-of-the-art reference-based CEMs, revealing their strong bias towards surface-level features rather than code functionality. Despite this surface bias, current evaluation datasets for these CEMs rarely include code pairs that are surface-similar yet functionally dissimilar, or functionally similar yet surface-dissimilar. To mitigate this gap, we propose LoCaL (Looks Can Lie), a CEM evaluation benchmark, with 3117 code pairs at both the method and program levels. Each pair is labeled with a functional similarity score and aims to target regions where CEMs are likely to perform poorly. The functional similarity scores are calculated through differential fuzzing, which eliminates the need for predefined test cases and, at the same time, improves the reliability of the scores by executing an order of magnitude more tests than prior work. We find that all four CEMs show significant performance degradation on LoCaL, compared to …",,,2025
2144,NeuralSAT: A High-Performance Verification Tool for Deep Neural Networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-ZRKCcEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=-ZRKCcEAAAAJ:-nhnvRiOwuoC,"Deep Neural Networks (DNNs) are increasingly deployed in critical applications, where ensuring their safety and robustness is paramount. We present NeuralSAT, a high-performance DNN verification tool that uses the DPLL(T) framework and supports a wide-range of network architectures and activation functions. Since its debut in VNN-COMP’23, in which it achieved the New Participant Award and ranked 4th overall, NeuralSAT has advanced significantly, achieving second place in VNN-COMP’24. This paper presents and evaluates the latest development of NeuralSAT, focusing on the versatility, ease of use, and competitive performance of the tool. NeuralSAT is available at: https://github.com/dynaroars/neuralsat.",Springer Nature Switzerland,,2025
2145,Instructor strategies to aid implementation of active learning: a systematic literature review,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rKcosL8AAAAJ&citation_for_view=rKcosL8AAAAJ:9yKSN-GCB0IC,"Background Despite the evidence supporting the effectiveness of active learning in undergraduate STEM courses, the adoption of active learning has been slow. One barrier to adoption is instructors’ concerns about students’ affective and behavioral responses to active learning, especially student resistance. Numerous education researchers have documented their use of active learning in STEM classrooms. However, there is no research yet that systematically analyzes these studies for strategies to aid implementation of active learning and address students’ affective and behavioral responses. In this paper, we conduct a systematic literature review and identify 29 journal articles and conference papers that researched active learning, affective and behavioral student responses, and recommended at least one strategy for implementing active learning. In this paper, we ask: (1) What are the characteristics of studies …",Springer International Publishing,International Journal of STEM Education,2021
2146,Negative student response to active learning in STEM classrooms: A systematic review of underlying reasons,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rKcosL8AAAAJ&citation_for_view=rKcosL8AAAAJ:YsMSGLbcyi4C,"Recent research has supported the use of student-centered teaching practices, such as active learning, because of its effectiveness in improving student learning and retention when compared with traditional, lecture-based teaching practices. Despite evidence supporting the effectiveness of active learning in improving STEM undergraduate education, the adoption of active learning by instructors has been slow for reasons, including negative student response to active learning. In this systematic literature review, we examine students’negative responses to active learning and reasons for the negative responses noted in 57 published STEM studies. Our findings identify three types of negative responses: affect, engagement, and evaluation. The reasons behind negative response represented six overarching categories based on student feedback: limited value, lack of time, difficulty and increased workload, lack of …",Taylor & Francis,Journal of College Science Teaching,2020
2147,Bilevel methods for image reconstruction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rKcosL8AAAAJ&citation_for_view=rKcosL8AAAAJ:UeHWp8X0CEIC,"This review discusses methods for learning parameters for image reconstruction problems using bilevel formulations. Image reconstruction typically involves optimizing a cost function to recover a vector of unknown variables that agrees with collected measurements and prior assumptions. Stateof-the-art image reconstruction methods learn these prior assumptions from training data using various machine learning techniques, such as bilevel methods.","Now Publishers, Inc.",,2022
2148,Systematic literature review of students’ affective responses to active learning: Overview of results,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rKcosL8AAAAJ&citation_for_view=rKcosL8AAAAJ:W7OEmFMy1HYC,"This full “research” paper presents an overview of results of a systematic literature review of students' affective responses to active learning in undergraduate STEM courses. We considered 2,364 abstracts of conference papers and journal articles published since 1990, and 412 studies met our inclusion criteria. The studies span the STEM disciplines and report various types of active learning. Their research designs include primarily quantitative methods (especially instructor-designed surveys and course evaluations), and they find that students' affective responses are overwhelmingly positive. Few studies excelled on our quality score metric, and there few statistically significant differences by discipline (but biology studies and chemistry studies scored significantly higher in quality than electrical engineering studies). We include several possible directions for future work.",IEEE,2018 IEEE Frontiers in Education Conference (FIE),2018
2149,Instructional factors influencing conceptual understanding of signals and systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rKcosL8AAAAJ&citation_for_view=rKcosL8AAAAJ:WF5omc3nYNoC,"This paper investigates what instructional factors influence conceptual understanding (CU) of signals and systems for senior undergraduate engineering students. Previous results show students in signals and systems courses typically gain little CU, though evidence-based instructional practices, such as active learning, can increase gains in CU. However, few studies consider CU of senior students or other instructional practices that increase CU. To explore possible factors, we interviewed two faculty members, eight undergraduate seniors, five graduate students, and four practicing engineers then analyzed the transcribed interviews using a constant comparative method. Participants identified lectures presenting CU along-side mathematical expressions; lectures emphasising purpose and connections; hands-on activities where students have control, receive immediate feedback, or where they have to apply and …",Taylor & Francis,,2022
2150,Developing an introductory machine learning course,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rKcosL8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rKcosL8AAAAJ:5nxA0vEk-isC,"This paper presents the design of the introduction to machine learning (ML) course at the [university name removed]. This course is targeted toward first and second-year undergraduate students and thus has no prerequisite courses beyond the basic introduction to programming course; notably, there are no linear algebra nor probability prerequisite. A key design feature of the course is that it is entry level but still emphasizes the mathematical perspective of ML and conceptual understanding behind ML algorithms. This course presents the basic principles behind ML to make ML feel less like a"" black box"" and covers a range of applications, focusing on applications in the electrical engineering field. Students collect and interpret data, translate between textual and mathematical descriptions of systems, gain the skills necessary to implement and test ML functions in Python, and practice presenting data in easy-to-interpret plots.",,,2025
2151,Circuit Troubleshooting Techniques in an Electrical and Computer Engineering Laboratory,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rKcosL8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rKcosL8AAAAJ:hqOjcs7Dif8C,"This research investigates troubleshooting methods undergraduate electrical engineering students employ when working with breadboarded circuits. While the literature in computer science clearly lays out many debugging strategies for coding, there are few equivalents in electrical and computer engineering (ECE) for hardware debugging strategies. The purpose of this research is thus to identify troubleshooting methods in ECE, with the goal of helping educators evaluate and eventually improve students’ self-efficacy and troubleshooting ability in an engineering laboratory.",,,2024
2152,Building Better Engineers: Teaching Chemical Engineers to Troubleshoot in the Laboratory,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rKcosL8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rKcosL8AAAAJ:Se3iqnhoufwC,"The Chemical Engineering Laboratory is a crucial training ground for students to acquire fundamental professional skills. Among these skills, troubleshooting is exceptionally valuable and significant, yet it is often underemphasized in the engineering curriculum. This study examines the efficacy of structured troubleshooting training modules in enhancing students' troubleshooting skills. Modules were integrated into laboratory lectures to introduce troubleshooting concepts, followed by a hands-on exercise to evaluate proficiency. Teaching assistants assessed student performance and recorded observations on troubleshooting approaches and strategies. Results suggest that structured training modules improve troubleshooting skills. Our findings highlight the importance of dedicated pedagogy in enhancing student troubleshooting performance.",,,2024
2153,Experimental Self-Efficacy and Troubleshooting Ability in a Chemical Engineering Laboratory,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rKcosL8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=rKcosL8AAAAJ:LkGwnXOMwfcC,"This research serves as a first step toward investigating how educators might evaluate (and eventually improve) students’ self-efficacy and troubleshooting ability in an engineering laboratory. This study uses an established survey to assess the experimental self-efficacy (ESE) of students enrolled in a fourth-year chemical engineering laboratory course at the University of Virginia. The survey measures ESE using four factors: conceptual understanding, procedural complexity, laboratory hazards, and lack of sufficient resources. Results from the ESE survey suggest that students had higher confidence in their conceptual understanding and their ability to avoid laboratory hazards. This study also analyzes students’ troubleshooting abilities using an existing chemical reactor system (a water gas shift reaction). Students were asked to use the experimental equipment to perform an activity. To succeed, students needed to identify and correct a series of challenges (eg, closed gas valves, empty reactant reservoirs). Researchers recorded their observations about students’ technical knowledge, processes, and troubleshooting strategies. Analysis of these observations suggests that students are more likely to read and follow directions or “spitball” ideas without strong use of troubleshooting strategies, though some participants successfully referenced conceptual understanding or used backtracking as troubleshooting strategies.",,,2023
2154,Rodinia: A benchmark suite for heterogeneous computing,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q-As1CEAAAAJ&citation_for_view=Q-As1CEAAAAJ:Y0pCki6q_DkC,"This paper presents and characterizes Rodinia, a benchmark suite for heterogeneous computing. To help architects study emerging platforms such as GPUs (Graphics Processing Units), Rodinia includes applications and kernels which target multi-core CPU and GPU platforms. The choice of applications is inspired by Berkeley's dwarf taxonomy. Our characterization shows that the Rodinia benchmarks cover a wide range of parallel communication patterns, synchronization techniques and power consumption, and has led to some important architectural insight, such as the growing importance of memory-bandwidth limitations and the consequent importance of data layout.",Ieee,,2009
2155,Scalable parallel programming with cuda: Is cuda the parallel programming model that application developers have been waiting for?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q-As1CEAAAAJ&citation_for_view=Q-As1CEAAAAJ:u-x6o8ySG0sC,"The advent of multicore CPUs and manycore GPUs means that mainstream processor chips are now parallel systems. Furthermore, their parallelism continues to scale with Moore’s law. The challenge is to develop mainstream application software that transparently scales its parallelism to leverage the increasing number of processor cores, much as 3D graphics applications transparently scale their parallelism to manycore GPUs with widely varying numbers of cores.",ACM,,2008
2156,PIMsynth: A Unified Compiler Framework for Bit-Serial Processing-In-Memory Architectures,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q-As1CEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Q-As1CEAAAAJ:MDX3w3dAD3YC,"Bit-serial processing-in-memory (PIM) architectures have been extensively studied, yet a standardized tool for generating efficient bit-serial code is lacking, hindering fair comparisons. We present a fully automated compiler framework, PIMsynth, for bit-serial PIM architectures, targeting both digital and analog substrates. The compiler takes Verilog as input and generates optimized micro-operation code for programmable bit-serial PIM backends. Our flow integrates logic synthesis, optimization steps, instruction scheduling, and backend code generation into a unified toolchain. With the compiler, we provide a bit-serial compilation benchmark suite designed for efficient bit-serial code generation. To enable correctness and performance validation, we extend an existing PIM simulator to support compiler-generated micro-op-level workloads. Preliminary results demonstrate that the compiler generates competitive bit-serial code …",IEEE,,2025
2157,DReX: Accurate and Scalable Dense Retrieval Acceleration via Algorithmic-Hardware Codesign,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q-As1CEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Q-As1CEAAAAJ:SpPTWFSNUtQC,"Retrieval-augmented generation (RAG) supplements large language models (LLM) with information retrieval to ensure up-to-date, accurate, factually grounded, and contextually relevant outputs. RAG implementations often employ dense retrieval methods and approximate k-nearest neighbor search (ANNS). Unfortunately, ANNS is inherently dataset-specific and prone to low recall, potentially leading to inaccuracies when irrelevant or incomplete context is passed to the LLM. Furthermore, sending numerous imprecise documents to the LLM for generation can significantly degrade performance compared to processing a smaller set of accurate documents. We propose DReX, a dataset-agnostic, accurate, and scalable Dense Retrieval Acceleration scheme enabled through a novel algorithmic-hardware co-design. We leverage in-DRAM logic to enable early filtering of embedding vectors far from the query vector. An …",,,2025
2158,Memory devices including processing-in-memory architecture configured to provide accumulation dispatching and hybrid partitioning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q-As1CEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Q-As1CEAAAAJ:rOcdG6UcVlcC,"An integrated circuit memory device can include a plurality of banks of memory, each of the banks of memory including a first pair of sub-arrays comprising first and second sub-arrays, the first pair of sub-arrays configured to store data in memory cells of the first pair of sub-arrays, a first row buffer memory circuit located in the integrated circuit memory device adjacent to the first pair of sub-arrays and configured to store first row data received from the first pair of sub-arrays and configured to transfer the row data into and/or out of the first row buffer memory circuit, and a first sub-array level processor circuit in the integrated circuit memory device adjacent to the first pair of sub-arrays and operatively coupled to the first row data, wherein the first sub-array level processor circuit is configured to perform column oriented processing a sparse matrix kernel stored, at least in-part, in the first pair of sub-arrays, with input vector …",,,2025
2159,Dynamic random access memory-based content-addressable memory (DRAM-CAM) architecture for exact pattern matching,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q-As1CEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Q-As1CEAAAAJ:wyM6WWKXmoIC,"Disclosed herein is a Dynamic Random Access Memory-Based Content-Addressable Memory (DRAM-CAM) architecture and methods relating thereto. The DRAM-CAM architecture can include a memory array, with the data organized into blocks including rows and columns. Input data can be converted into a format with first and second groups of columns. Each first group can correspond to one or more rows of the input data, and each second group can include one or more null columns. A query can be received and loaded into an available column of the second group, and pattern matching can be performed on the data to identify occurrences of elements defined by the query. The pattern matching can be performed concurrently on the first groups of columns and the available columns bit by bit. Results can include a count or location of each identified element.",,,2025
2160,"Systems, circuits, methods, and articles of manufacturer for dram-based digital bit-serial vector computing architecture",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q-As1CEAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Q-As1CEAAAAJ:RXiHnyRawswC,"Disclosed are various approaches for bit-serial computing embedded in the DRAM subarray, leveraging the massive parallelism of DRAM row operations. The present disclosure discloses digital techniques that can outperform analog charge-sharing techniques. Digital techniques can use more area but support a wider range of computing primitives, and allow a sequence of logic operations to be performed at higher clock speeds, be-tween slower subarray row reads/writes. The present disclosure describes a range of bit-serial architectures, and evaluate raw performance as well as area and energy efficiency. Results show that the digital architecture demonstrates 20× speedup over CPU, 5× over GPU, and 1.7× over SIMDRAM, an analog architecture.",,,2025
2161,"Designing for a Sustainable World: Integrating the United Nations Sustainable Development Goals into a First-year Engineering Course in Science, Technology, and Society",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YUunZDUAAAAJ&citation_for_view=YUunZDUAAAAJ:u5HHmVD_uO8C,"I am an instructor in a teaching team for a required first-year engineering course in science, technology and society (STS). The course enrolls 360-400 students each semester, and its primary learning goals are to introduce students to social and ethical aspects of engineering practice. The main deliverable in the course is a provisional patent application in which students describe a technological design they have developed in class. In previous semesters students would develop ideas for the patent application with relatively few parameters. They could generate ideas for nearly any kind of innovative technological device, process, service, or system as long as they could describe and illustrate it in 6-8 pages.",,,2020
2162,Fostering Ethical Innovation in Engineering Education and Design,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YUunZDUAAAAJ&citation_for_view=YUunZDUAAAAJ:UeHWp8X0CEIC,"Undergraduate engineering programs often emphasize technological innovation, leadership, and professional ethics. It is less clear, though, how to cultivate the kind of ethical formation that enables students to integrate technical proficiency with ethical reasoning in the technological design process. To that end, the paper describes how ethical frameworks of sustainability, justice, and care were integrated into a first-year engineering course in Science, Technology, and Society. Course material and assignments, as well as select student written reflections, illustrate how the course challenged students to apply both technical and ethical training to generate innovative designs that facilitate socially responsible, just, and sustainable practices.",,,2021
2163,Rogue Engineering: Teaching Frankenstein as a Parable of (Un) ethical Engineering Practice,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YUunZDUAAAAJ&citation_for_view=YUunZDUAAAAJ:d1gkVwhDpl0C,"Mary Shelley’s novel Frankenstein is widely regarded as a foundational work of early science fiction that cautions against misguided and unethical science and engineering. As such, the novel should be poised to help engineering undergraduates cultivate moral imagination and a commitment to socially responsible techno-science. However, despite recent critical editions of the novel that highlight its relevance for scientists and engineers, some instructors have faced difficulties successfully integrating the novel into an undergraduate engineering curriculum, and students have struggled to appreciate its value to their ethical formation as engineering professionals. Nevertheless, the novel’s potential to address ethical aspects of engineering practice calls for further attempts at integrating it into engineering education. In particular, the archetypal figure of Victor Frankenstein offers students a model of a negative “possible self” that cautions against rogue engineering practices. The paper analyzes themes from Shelley’s novel as they were used in courses in science, technology, and society (STS) to foster ethical reflection on the perils of practicing irresponsible, presumptuous, unaccountable, and biased techno-science.",,,2023
2164,Communication across Divisions: Trends Emerging from the 2019 Annual Conference of ASEE and Some Possibilities for Strategic Action,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YUunZDUAAAAJ&citation_for_view=YUunZDUAAAAJ:u-x6o8ySG0sC,"This paper extends an effort begun in 2015 to create a comprehensive and holistic view of communication as that subject is treated across the divisions of ASEE based on analysis of all of the papers on communication that were published in the proceedings of the 2019 Annual Conference. The quantitative results of the analysis reveal increases in the (1) total number of papers on communication (67 in 2019 vs. 33 in 2015),(2) number of divisions sponsoring papers on communication (20 in 2019 vs. 15 in 2015),(3) number of sessions with all or most papers focusing on communication (13 in 2019 vs. 6 in 2015). Taken together, the quantitative results demonstrate that interest in communication is both growing and dispersed across ASEE. Qualitative analysis of the papers focused on the backgrounds and institutional affiliations of the authors and trends with respect to the focus, scope, and funding of the work reported in the papers. The 2019 papers demonstrated the intensification, diversification, and evolution of four trends that were evident in 2015:(1) disciplinary and workplace communication,(2) communication tasks as a way to simultaneously develop communication competency and subject matter mastery,(3) interdisciplinary integration and multi-institutional collaboration, and (4) collecting large amounts of data about student outcomes in a single course or institution with relatively little effort devoted to synthesizing experiences across institutions. The paper concludes by enumerating strategies LEES might implement in collaboration with other divisions and ASEE headquarters to develop a Communication across Divisions Network to …",,,2020
2165,Frankenstein Lives! Teaching Mary Shelley's Novel in the Engineering Classroom,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YUunZDUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=YUunZDUAAAAJ:qjMakFHDy7sC,"Mary Shelley’s novel Frankenstein tells a terrifying cautionary tale that warns against unethical practices in science and engineering. In a previous study, I examined several ethical themes, drawn from Shelley’s novel, that are discussed in a non-technical STS course I developed for engineering undergraduates. These themes center on the novel’s critique of Victor Frankenstein’s irresponsible, presumptuous, unaccountable, and biased practice of techno-science. The present study performs a thematic analysis of a series of reflections written by students at the end of the course that address how reading Frankenstein has influenced their approach to engineering work. The reflections indicate that students were able to articulate several ethical themes that emerge from the novel’s depiction of Victor Frankenstein’s practice of rogue techno-science and, building on those themes, express their commitment to more socially responsible engineering practices.",,,2024
2166,"Learning through Play: Using LEGO® Products, Practices, and Values to Teach Social and Ethical Aspects of Engineering Design",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YUunZDUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=YUunZDUAAAAJ:9yKSN-GCB0IC,"For over twenty years college instructors have successfully integrated LEGO® products into undergraduate engineering classrooms to facilitate active learning experiences in engineering design. These experiences allow students to develop core technical proficiencies primarily related to robotics and computer programming. Despite the successful adoption of LEGO Mindstorms to teach valuable technical skills in robotics, LEGO products and practices have not been widely included in non-technical engineering classroom settings to facilitate students’ understanding of social and ethical aspects of engineering design. If LEGO products and practices could be integrated into a course in science, technology, and society (STS), as they have been into technical robotics courses, this might help students appreciate the relevance of STS and ethical concepts to engineering design challenges. With this in mind, I developed a course in STS called The LEGO Course: Engineering Design and Values. The course pairs a seminar discussion with a studio design experience to integrate the teaching of STS and ethical perspectives with authentic engineering design challenges oriented around the LEGO Group’s products, practices, and core values. Student reflections and evaluations suggest that the course effectively leverages the LEGO Group’s philosophy of “learning through play” to convey the value that social and ethical perspectives bring to engineering design.",,,2022
2167,On the mechanical performance of closed cell Al alloy foams,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IlJTlVkAAAAJ&citation_for_view=IlJTlVkAAAAJ:u5HHmVD_uO8C,"The mechanical properties of three different commercially available closed cell Al alloys all made by foam casting are examined. The objective is to assess the roles of cell morphology and of imperfections in governing the basic properties: stiffness, yield strength and fracture resistance. This assessment provides goals for manufacturing strategies that enable attainment of good mechanical performance with affordable process technologies. A prevalent role of curves and wiggles in the cell walls on stiffness and strength (anticipated by models) is affirmed by the present measurements. Systematically larger stiffnesses and yield strengths found in tension than in compression are consistent with a prominent role exerted by such imperfections. Moreover, foam casting is apparently capable of cell morphologies that impart properties approaching the best achievable values for an isotropic closed cell solid, devoid of …",Pergamon,,1997
2168,Experimental analysis of deformation mechanisms in a closed-cell aluminum alloy foam,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IlJTlVkAAAAJ&citation_for_view=IlJTlVkAAAAJ:d1gkVwhDpl0C,"The evolution of plastic deformation in a cellular Al alloy upon axial compression is monitored through a digital image correlation procedure. Three stages in the deformation response have been identified. The first involves localized plastic straining at cell nodes. It occurs uniformly and leads to a nominal loading modulus appreciably lower than the stiffness. The second comprises discrete bands of concentrated strain containing cell membranes that experience plastic buckling, elastically constrained by surrounding cells. In this phase, as the loading increases, previously formed bands harden, giving rise to new bands in neighboring regions. The localized bands exhibit a long-range correlation with neighboring bands separated by 3–4 cells along the loading direction. This length scale characterizes the continuum limit. Thirdly, coincident with a stress peak, σo, one of the bands exhibits complete plastic collapse. As …",Pergamon,,2000
2169,Compressive deformation and yielding mechanisms in cellular Al alloys determined using X-ray tomography and surface strain mapping,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IlJTlVkAAAAJ&citation_for_view=IlJTlVkAAAAJ:u-x6o8ySG0sC,"The mechanisms of compressive deformation that occur in both closed and open cell Al alloys have been established. This has been achieved by using X-ray computed tomography (CT) and surface strain mapping to determine the deformation modes and the cell morphologies that control the onset of yielding. The deformation is found to localize in narrow bands having widths of order of a cell diameter. Outside the bands, the material remains elastic. The cells within the bands that experience large permanent strains are primarily elliptical. A group of cells work collectively to allow large localized deformation. Size does not appear to be the initiator of the deformation bands. Equiaxed cells remain elastic. The implications for manufacturing materials with superior mechanical properties are discussed.",Pergamon,,1998
2170,Tuna robotics: A high-frequency experimental platform exploring the performance space of swimming fishes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IlJTlVkAAAAJ&citation_for_view=IlJTlVkAAAAJ:K3LRdlH-MEoC,"Tuna and related scombrid fishes are high-performance swimmers that often operate at high frequencies, especially during behaviors such as escaping from predators or catching prey. This contrasts with most fish-like robotic systems that typically operate at low frequencies (< 2 hertz). To explore the high-frequency fish swimming performance space, we designed and tested a new platform based on yellowfin tuna (Thunnus albacares) and Atlantic mackerel (Scomber scombrus). Body kinematics, speed, and power were measured at increasing tail beat frequencies to quantify swimming performance and to study flow fields generated by the tail. Experimental analyses of freely swimming tuna and mackerel allow comparison with the tuna-like robotic system. The Tunabot (255 millimeters long) can achieve a maximum tail beat frequency of 15 hertz, which corresponds to a swimming speed of 4.0 body lengths per …",American Association for the Advancement of Science,,2019
2171,Measurement and analysis of the structural performance of cellular metal sandwich construction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IlJTlVkAAAAJ&citation_for_view=IlJTlVkAAAAJ:9yKSN-GCB0IC,"The bending performance of sandwich construction with thin cellular metal cores has been measured and simulated. A mechanism map has been generated to characterize the predominant failure phenomena based upon collapse load criteria for face yielding, core shear and indentation. A previously developed constitutive law for the core material has been incorporated into numerical simulations. Comparisons have been made with the measured response. Initial discrepancies attributed to a core thinness effect were rectified by inputting core shear properties measured on materials having the same thickness. Analytical estimates for the stiffness, yield load and limit load are compared with the numerical simulations and experimental results.",Pergamon,,2001
2172,Development of a turning control strategy for a bio-inspired underwater vehicle,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IlJTlVkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=IlJTlVkAAAAJ:ye4kPcJQO24C,"Maneuvering in fish is complex and offers inspiration in the development of the next generation bio-inspired underwater vehicles (BUVs). Balancing desired functionality with minimal mechanical complexity is a challenge in developing a BUV. This study presents a single-actuator turning strategy for the Tunabot, a bio-inspired robotic fish, using asymmetric tail-beat timing to generate turning forces. Biological fish, such as tuna, adjust tail kinematics for maneuverability. Following this principle, the proposed control method modifies stroke duration through a single motor, synchronized by a digital encoder. Experiments were conducted in a tank, using the dorsal-view high-speed video and DeepLabCut motion tracking technology to analyze and quantify turning radius and swimming velocity. A 66% asymmetric difference in tail-beat timing resulted in a turning radius of 1.42 body lengths at a certain base frequency …",IOP Publishing,,2025
2173,Morphokinematic Impacts on Hydrodynamics and Performance of Tuna-Inspired Robots,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IlJTlVkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=IlJTlVkAAAAJ:dTyEYWd-f8wC,"Many recent developments have been made in the performance of bioinspired underwater vehicles, however, there is still a significant performance gap between the high-performing fish in nature and their engineered counterparts. A multitude of parameters govern performance in biological fish swimming, including the morphology of the fish and the kinematics of the swimming motion. In this research, we utilize computational fluid dynamics to study the effect of morphological and kinematic parameters on the performance and hydrodynamics of Tunabot Flex, a high-performance tuna-inspired robotic platform. A reconstructed virtual model is used for fluid simulations, completed with an in-house immersed boundary method-based direct numerical flow solver. Results characterize the flow of the Tunabot flex platform, including thrust generation and vortex wake analysis. The effects of the body thickness on the …",American Society of Mechanical Engineers,,2024
2174,Effects Fin Geometry and Fin Ray Stiffness on the Performance of Bio-inspired Flapping Propulsion,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IlJTlVkAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=IlJTlVkAAAAJ:Y5dfb0dijaUC,"Many examples of flexible surfaces can be found in natural propulsors. Here, we take inspiration from the spiny fin rays exhibited by real tuna fins to alter the flexibility of fin structures on the bio-inspired swimming robot platform, tunabot. This work utilizes a computational model of the tunabot featuring reconstructed body, dorsal, anal, and caudal fin surfaces. Fin geometry, stiffness, and fin ray patterns of the median fins (dorsal and anal fins) are altered to understand the effect on vortex interactions between the median fins and caudal fin, and hydrodynamic force and moment production on the surfaces. Flow information is solved using an in-house developed immersed boundary method based incompressible Navier-Stokes flow solver. Deformations of the fins due to the hydrodynamic forces are computed using Vega FEM. Iterative convergence of the fluid and structure solvers within each time step yields two-way …",,,2024
2175,"Understanding, detecting and localizing partial failures in large system software",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ogozoZUAAAAJ&citation_for_view=ogozoZUAAAAJ:2osOgNQ5qMEC,"Partial failures occur frequently in cloud systems and can cause serious damage including inconsistency and data loss. Unfortunately, these failures are not well understood. Nor can they be effectively detected. In this paper, we first study 100 real-world partial failures from five mature systems to understand their characteristics. We find that these failures are caused by a variety of defects that require the unique conditions of the production environment to be triggered. Manually writing effective detectors to systematically detect such failures is both time-consuming and error-prone. We thus propose OmegaGen, a static analysis tool that automatically generates customized watchdogs for a given program by using a novel program reduction technique. We have successfully applied OmegaGen to six large distributed systems. In evaluating 22 real-world partial failure cases in these systems, the generated watchdogs can detect 20 cases with a median detection time of 4.2 seconds, and pinpoint the failure scope for 18 cases. The generated watchdogs also expose an unknown, confirmed partial failure bug in the latest version of ZooKeeper.",,,2020
2176,Fast and concurrent {RDF} queries using {RDMA-assisted}{GPU} graph exploration,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ogozoZUAAAAJ&citation_for_view=ogozoZUAAAAJ:d1gkVwhDpl0C,"RDF graph has been increasingly used to store and represent information shared over the Web, including social graphs and knowledge bases. With the increasing scale of RDF graphs and the concurrency level of SPARQL queries, current RDF systems are confronted with inefficient concurrent query processing on massive data parallelism, which usually leads to suboptimal response time (latency) as well as throughput.",,,2018
2177,RESIN: A Holistic Service for Dealing with Memory Leaks in Production Cloud Infrastructure,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ogozoZUAAAAJ&citation_for_view=ogozoZUAAAAJ:UeHWp8X0CEIC,"Memory leak is a notorious issue. Despite the extensive efforts, addressing memory leaks in large production cloud systems remains challenging. Existing solutions incur high overhead and/or suffer from high inaccuracies.",,,2022
2178,Demystifying and Checking Silent Semantic Violations in Large Distributed Systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ogozoZUAAAAJ&citation_for_view=ogozoZUAAAAJ:qjMakFHDy7sC,"Distributed systems today offer rich features with numerous semantics that users depend on. Bugs can cause a system to silently violate its semantics without apparent anomalies. Such silent violations cause prolonged damage and are difficult to address. Yet, this problem is under-investigated.",,,2022
2179,Comprehensive and efficient runtime checking in system software through watchdogs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ogozoZUAAAAJ&citation_for_view=ogozoZUAAAAJ:9yKSN-GCB0IC,"Systems software today is composed of numerous modules and exhibits complex failure modes. Existing failure detectors focus on catching simple, complete failures and treat programs uniformly at the process level. In this paper, we argue that modern software needs intrinsic failure detectors that are tailored to individual systems and can detect anomalies within a process at finer granularity. We particularly advocate a notion of intrinsic software watchdogs and propose an abstraction for it. Among the different styles of watchdogs, we believe watchdogs that imitate the main program can provide the best combination of completeness, accuracy and localization for detecting gray failures. But, manually constructing such mimic-type watchdogs is challenging and time-consuming. To close this gap, we present an early exploration for automatically generating mimic-type watchdogs.",,,2019
2180,Verifying Computational Graphs in Production-Grade Distributed Machine Learning Frameworks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ogozoZUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ogozoZUAAAAJ:YsMSGLbcyi4C,"Modern machine learning frameworks support very large models by incorporating parallelism and optimization techniques. Yet, these very techniques add new layers of complexity, introducing silent errors that severely degrade model performance. Existing solutions are either ad hoc or too costly for production. We present Scalify, a lightweight framework that exposes silent errors by verifying semantic equivalence of computational graphs using equality saturation and Datalog-style reasoning. To scale, Scalify partitions graphs with parallel rewriting and layer memoization, reuses rewrite templates, and augments equality saturation with relational reasoning and symbolic bijection inference. It further localizes discrepancies to precise code sites, turning verification results into actionable debugging guidance. Scalify verifies models as large as Llama-3.1-405B within minutes on a commodity machine and exposed five unknown bugs in Amazon production machine learning frameworks.",,,2025
2181,Deriving semantic checkers from tests to detect silent failures in production distributed systems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ogozoZUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ogozoZUAAAAJ:W7OEmFMy1HYC,"Production distributed systems provide rich features, but various defects can cause a system to silently violate its semantics without explicit errors. Such failures cause serious consequences. Yet, they are extremely challenging to detect, as it requires deep domain knowledge and substantial manual efforts to write good checkers.",,,2025
2182,Orchestrating Cross-Layer Anomaly Detection and Mitigation to Address Gray Failures in Large-Scale Cloud Infrastructure,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ogozoZUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ogozoZUAAAAJ:Y0pCki6q_DkC,"Cloud infrastructure in production constantly experiences gray failures: a degraded state in which failures go undetected by system mechanisms, yet adversely affect end-users. Addressing the underlying anomalies on host nodes is crucial for such gray failures. However, current approaches suffer from two key limitations: first, existing detection relies solely on singulardimension signals from hosts, thus often suffering from biased views due to differential observability; second, existing mitigation actions are often insufficient, primarily consisting of host-level operations such as reboots, which leave most production issues to manual intervention. This paper presents Panacea, a holistic framework to automatically detect and mitigate host anomalies, addressing gray failures in production cloud infrastructure. PANACEA expands beyond host-level scope: it aggregates and correlates insights from VMs and application …",,,2025
2183,Verifying Semantic Equivalence of Large Models with Equality Saturation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ogozoZUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ogozoZUAAAAJ:Tyk-4Ss8FVUC,"Modern machine learning frameworks support very large models by incorporating parallelism and optimization techniques. Yet, these very techniques add new layers of complexity in ensuring the correctness of the computation. An incorrect implementation of these techniques might lead to compile-time or runtime errors that can easily be observed and fixed, but it might also lead to silent errors that will result in incorrect computations in training or inference, which do not exhibit any obvious symptom until the model is used later. These subtle errors not only waste computation resources, but involve significant developer effort to detect and diagnose. In this work, we propose Aerify, a framework to automatically expose silent errors by verifying semantic equivalence of models with equality saturation. Aerify constructs equivalence graphs (e-graphs) from intermediate representations of tensor programs, and …",,,2025
2184,ENHANCING CLOUD SYSTEM RUNTIME TO ADDRESS COMPLEX FAILURES,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ogozoZUAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=ogozoZUAAAAJ:zYLM7Y9cAGgC,"As the reliance on cloud systems intensifies in our progressively digital world, understanding and reinforcing their reliability becomes more crucial than ever. Despite impressive advancements in augmenting the resilience of cloud systems, the growing incidence of complex failures now poses a substantial challenge to the availability of these systems. With cloud systems continuing to scale and increase in complexity, failures not only become more elusive to detect but can also lead to more catastrophic consequences. Such failures question the foundational premises of conventional fault-tolerance designs, necessitating the creation of novel system designs to counteract them. This dissertation aims to enhance distributed systems’ capabilities to detect, localize, and react to complex failures at runtime. To this end, this dissertation makes contributions to address three emerging categories of failures in cloud systems. The first part delves into the investigation of partial failures, introducing OmegaGen, a tool adept at generating tailored checkers for detecting and localizing such failures. The second part grapples with silent semantic failures prevalent in cloud systems, showcasing our study findings, and introducing Oathkeeper, a tool that leverages past failures to infer rules and expose these silent issues. The third part explores solutions to slow failures via RESIN, a framework specifically designed to detect, diagnose, and mitigate memory leaks in cloud-scale infrastructures, developed in collaboration with Microsoft Azure. The dissertation concludes by offering insights into future directions for the construction of reliable cloud systems.",,,2023
2185,The gendered division of labor among STEM faculty and the effects of critical mass.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v4niKFoAAAAJ&citation_for_view=v4niKFoAAAAJ:2osOgNQ5qMEC,"This study explored whether there is a gendered division of labor for faculty in academic science, technology, engineering, and mathematics (STEM) at research universities and examined the connections between time allocation and satisfaction for STEM faculty within the context of a critical mass of women in the discipline. Using a weighted sample of 13,884 faculty from the 2004 National Study of Postsecondary Faculty (NSOPF: 04), we found a gendered division of labor that is mitigated by a critical mass of women faculty in the discipline. Results lend empirical support to theories that argue critical-mass attainment positively impacts equity in resource distribution and time allocation.(PsycINFO Database Record (c) 2016 APA, all rights reserved)",Educational Publishing Foundation,,2011
2186,Promoting gender diversity in STEM faculty through leadership development: From local and national leadership workshops to the online LEAD-it-Yourself! toolkit,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v4niKFoAAAAJ&citation_for_view=v4niKFoAAAAJ:ufrVoPGSRksC,"Purpose The advancement of equity, diversity and inclusion in higher education is dependent on institutional culture changes in academia. Faculty equity, diversity and inclusion efforts must engage departmental leadership. The purpose of this paper is to describe the growth and expansion of the ADVANCE leadership program at the University of Washington (UW) for department chairs that was designed to provide department chairs the skills, community and information needed to be agents of change within the academy. Design/methodology/approach The paper chronicles the program’s growth from a campus-based workshop program to national workshops (LEAD) to a web-based toolkit (LiY!) to support institutions in running their own UW ADVANCE-inspired leadership workshops. Findings The paper demonstrates the success of each growth stage and the expansion of program impact. Practical implications The …",Emerald Publishing Limited,,2019
2187,Majorism: Neoliberalism in Student Culture,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v4niKFoAAAAJ&citation_for_view=v4niKFoAAAAJ:Se3iqnhoufwC,"Declining support for US higher education and the corporatization of this institution shape students’ experiences. This ethnography describes a campus culture stratified by an ideology called “majorism.” Majorism, a term particular to this study’s site, is the preferential treatment of science and technology over the Liberal Arts. By understanding majorism through the lived experiences of undergraduates, we can better understand what the US academy values, its purpose, and whom it does and does not serve.",American Anthropological Association,,2021
2188,The ADVANCE mentoring-for-leadership lunch series for women faculty in STEM at the University of Washington,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v4niKFoAAAAJ&citation_for_view=v4niKFoAAAAJ:u-x6o8ySG0sC,"Given the increasingly smaller number of women in science, technology, engineering, and mathematics (STEM) fields as one progresses through the academic pipeline, it is often very difficult for women in STEM faculty positions to find a community of women and identify women mentors, especially at the upper rungs of the academic ladder. Group mentoring opportunities are one strategy to connect women STEM faculty and generate greater interest and success in academic leadership. In 2003 the University of Washington (UW) ADVANCE program introduced the Mentoring-for-Leadership lunch series to encourage women faculty to consider leadership; expose women faculty to various career paths; and build a community of women faculty in STEM. This paper describes the UW program, the literature that informs the program, and the participants' experiences. This paper also offers recommendations for …",Begel House Inc.,,2007
2189,“The Revolution Will Not Be Supervised:” Consent and Open Secrets in Data Science,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v4niKFoAAAAJ&citation_for_view=v4niKFoAAAAJ:8k81kl-MbHgC,"The social impacts of computer technology are often glorified in public discourse, but there is growing concern about its actual effects on society. In this article, we ask: how does “consent” as an analytical framework make visible the social dynamics and power relations in the capture, extraction, and labor of data science knowledge production? We hypothesize that a form of boundary violation in data science workplaces—gender harassment—may correlate with the ways humans’ lived experiences are extracted to produce Big Data. The concept of consent offers a useful way to draw comparisons between gender relations in data science and the means by which machines are trained to learn and reason. Inspired by how Big Tech leaders describe unsupervised machine learning, and the co-optation of “revolutionary” rhetoric they use to do so, we introduce a concept we call “techniques of invisibility.” Techniques of …",,,2021
2190,"Life, Liberty and the Pursuit of Convenience—on whose terms and at what costs?",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v4niKFoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=v4niKFoAAAAJ:qxL8FJ1GzNcC,,"Digital Technology for Democracy Lab, University of Virginia",,2025
2191,Cracking the Bro Code,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v4niKFoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=v4niKFoAAAAJ:YOwf2qJgpHMC,"Why dominant racial and gender groups have preferential access to jobs in computing, and how feminist labor activism in computing culture can transform the field into a force that serves democracy and social justice. Cracking the Bro Code is a bold ethnographic study of sexism and racism in contemporary computing cultures theorized through the analytical frame of the “Bro Code.” Drawing from feminist anthropology and STS, Coleen Carrigan shares in this book the direct experiences of women, nonbinary individuals, and people of color, including her own experiences in tech, to show that computing has a serious cultural problem. From senior leaders in the field to undergraduates in their first year of college, participants consistently report how sexism and harassment manifest themselves in computing via values, norms, behaviors, evaluations, and policies. While other STEM fields are making strides in recruiting, retaining, and respecting women workers, computing fails year after year to do so. Carrigan connects altruism, computing, race, and gender to advance the theory that social purpose is an important factor to consider in working toward gender equity in computing. Further, she argues that transforming computing culture from hostile to welcoming has the potential to change not only who produces computing technology but also the core values of its production, with possible impacts on social applications. Cracking the Bro Code explains how digital bosses have come to operate imperiously in our society, dodging taxes and oversight, and how some programmers who look like them are enchanted with a sense of divine right. In the …",MIT Press,,2024
2192,Sheltering: Care Tactics for Ethnography Attentive to Intersectionality and Underrepresentation in Technoscience,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v4niKFoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=v4niKFoAAAAJ:ULOm3_A8WrAC,"Designing ethnographic research on the technoscience workforce according to intersectionality theory presents both opportunities and constraints. On the one hand, the pursuit of justice in technoscience requires attending to differences between scientists who have been disenfranchised from knowledge production due to racism and sexism. On the other hand, sharing the lived experiences of severely underrepresented members of technoscience heightens the risk of harm. I introduce a practice called Sheltering, inspired by the computer science technique of “black boxing” and feminist methodology of “strong objectivity.” The opacity of the shelter in which some data resides is balanced with the transparency of the researcher’s positionality. Combining reflexivity, refusal, and performative design, Sheltering contests dominant norms in science, while minimizing risks of retaliation to collaborators. It also balances communal responsibilities with research integrity. It not only requires consideration for the researcher’s relationship with collaborators, but also attention to power in the worlds they navigate and solidarity in their struggles. Sheltering, a repertoire of care tactics to protest epistemic and social injustice in US knowledge production, can help transform who gets to produce science and reimagine other ways of knowing.","Catalyst: Feminism, Theory, Technoscience",,2023
2193,Introduction: Caring for equitable relations in interdisciplinary collaborations,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v4niKFoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=v4niKFoAAAAJ:Zph67rFs4hoC,"Collaborative research between scholars of science and technology studies (STS)and scholars of science, technology, engineering, and math (STEM) is a growing trend. The papers assembled in thisSpecial Section offer both embodied and empirical knowledge on how ethnographers negotiate our roles in integrative research when constrained by what our technoscientific collaborators value, what funders demand, what our home institutions expect, what we want to learn from the worlds we study, and the social transformations we envision in science and society. We grapple with how we as ethnographers can best balance caring for the communities we study, the ones we serve, and the ones we identify with. We take care that knowledge making is political. Race, gender, class, and ability status of scholars intersect with the organizational, institutional, and cultural contexts in which we practice science to shape and be shaped by entrenched power relations.Through a feminist politics of care, this collection transforms tensions in interdisciplinary collaborations into resources that enlarge our understandings of what these collaborations are like for STS ethnographers, make visible certain labors within them and, crucially, enrich our vision for what we want these collaborations to be.","Catalyst: Feminism, Theory, Technoscience",,2023
2194,Negotiating boundaries: an intersectional collaboration to advance women academics in engineering,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=v4niKFoAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=v4niKFoAAAAJ:KlAtU1dfN6UC,"This paper draws on data from the National Science Foundation (NSF) ADVANCE-funded LATTICE program (Launching Academics on the Tenure-Track: an Intentional Community in Engineering) to examine how a diverse group of women worked across social and professional identities to support early-career women in academic engineering. We used ethnography to elucidate the social dynamics and power relations involved in forming a coherent group identity for the LATTICE leadership team, and the boundaries we negotiated in running the LATTICE program. We identify the processes and behaviors through which we made boundaries between members salient yet porous to build a coherent community across various dimensions of difference. We offer three actionable strategies that impact change agents’ engagement and the group’s coherence across multiple dimensions of difference: (1) intentionally …",https://www.tandfonline.com/doi/full/10.1080/19378629.2023.2169613,,2023
2195,SIMPLE: a sequential immunoperoxidase labeling and erasing method,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qfy1Hr8AAAAJ&citation_for_view=qfy1Hr8AAAAJ:u5HHmVD_uO8C,"The ability to simultaneously visualize expression of multiple antigens in cells and tissues can provide powerful insights into cellular and organismal biology. However, standard methods are limited to the use of just two or three simultaneous probes and have not been widely adopted for routine use in paraffin-embedded tissue. We have developed a novel approach called sequential immunoperoxidase labeling and erasing (SIMPLE) that enables the simultaneous visualization of at least five markers within a single tissue section. Utilizing the alcohol-soluble peroxidase substrate 3-amino-9-ethylcarbazole, combined with a rapid non-destructive method for antibody-antigen dissociation, we demonstrate the ability to erase the results of a single immunohistochemical stain while preserving tissue antigenicity for repeated rounds of labeling. SIMPLE is greatly facilitated by the use of a whole-slide scanner, which can …",SAGE Publications,,2009
2196,Electrocardiographic diagnosis of acute coronary occlusion myocardial infarction in ventricular paced rhythm using the modified Sgarbossa criteria,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qfy1Hr8AAAAJ&citation_for_view=qfy1Hr8AAAAJ:Se3iqnhoufwC,"Study objective Ventricular paced rhythm is thought to obscure the electrocardiographic diagnosis of acute coronary occlusion myocardial infarction. Our primary aim was to compare the sensitivity of the modified Sgarbossa criteria (MSC) to that of the original Sgarbossa criteria for the diagnosis of occlusion myocardial infarction in patients with ventricular paced rhythm. Methods In this retrospective case-control investigation, we studied adult patients with ventricular paced rhythm and symptoms of acute coronary syndrome who presented in an emergency manner to 16 international cardiac referral centers between January 2008 and January 2018. The occlusion myocardial infarction group was defined angiographically as thrombolysis in myocardial infarction grade 0 to 1 flow or angiographic evidence of coronary thrombosis and peak cardiac troponin I ≥10.0 ng/mL or troponin T ≥1.0 ng/mL. There were 2 control …",Mosby,,2021
2197,Serial multiple antigen colocalization in paraffin-embedded tissue,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qfy1Hr8AAAAJ&citation_for_view=qfy1Hr8AAAAJ:9yKSN-GCB0IC,"BACKGROUND Visual colocalization of molecular species within sec tioned tissue can provide insights into cellular biochemistry and can serve as the basis for further study of protein-or ganelle and protein-protein interactions. Visualization of abnormal protein coexpression in neoplastic tissue may elu cidate components of oncogenic signaling pathways. Colo calization of COX2 and laminin-5, for example, has been observed at the cancer-stromal interface of lung adenocarci noma and may be associated with abnormalities in p53 expression (1). Additionally, colocalization off-catenin with compartment-specific markers revealed prognostic signifi cance that was not found using traditional single stain meth ods (2). Current colocalization methods, however, have several limitations. The most commonly used method, multi-color immunofluorescence (MCIF), is limited by the number of viable combinations of available …",,,2014
2198,Bystander intervention in out-of-hospital cardiac arrest,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qfy1Hr8AAAAJ&citation_for_view=qfy1Hr8AAAAJ:_FxGoFyzp5QC,"Out-of-hospital cardiac arrest (OHCA) remains a common medical issue in any community, with an extremely high cost in terms of morbidity and mortality; furthermore, elderly patients with OHCA generally have worse outcomes compared with younger individuals. 1 Okabayashi et al2 describe OHCA outcomes in patients aged 65 year or older in Japan by location of arrest, showing significant differences according to location (ie, residential, public area, or nursing facility). Cardiac arrests occurring in public showed the best outcomes, likely owing to higher incidence of witnessed cardiac arrests and increased availability of public-access automatic external defibrillators (AEDs). Patients experiencing arrests at nursing homes, where patients are generally likely to have a greater degree of comorbid conditions, 3 fared the worst despite the presence of health care professionals on location. Cardiac arrests in a residential …",American Medical Association,,2019
2199,Dephosphorylation of β-arrestin 1 in glioblastomas,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qfy1Hr8AAAAJ&citation_for_view=qfy1Hr8AAAAJ:u-x6o8ySG0sC,"β-Arrestins act as signal terminators for G protein-coupled receptors; they have also been implicated as scaffolding proteins for Src and mitogen-activated protein kinase signaling pathways and transactivators of receptor tyrosine kinases, suggesting their possible role in development and oncogenic signaling. Dephosphorylation of serine 412 is necessary for Src and mitogen-activated protein kinase transactivation. We hypothesized that altered β-arrestin 1 phosphorylation and activation status could play a role in gliomagenesis. Using monoclonal anti-phospho-(serine 412)- and total β-arrestin 1 antibodies, we performed immunohistochemistry on 126 human glioma samples and 7 nonneoplastic controls and Western blot analysis on 5 glioblastomas and 5 nonneoplastic controls. We found high constitutive β-arrestin 1 phosphorylation in nonneoplastic brain tissue, particularly in neurons and neuropil. Most …","American Association of Neuropathologists, Inc.",,2009
2200,"Musculoskeletal, airway, and vascular injuries in the patient with nonjudicial hanging: A narrative review for the emergency clinician",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qfy1Hr8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qfy1Hr8AAAAJ:mVmsd5A6BfQC,"Non-judicial hanging events presenting to emergency healthcare providers exhibit a wide range of severity, from cardiac arrest to minor soft tissue neck contusions, making it essential for providers to anticipate potential injuries. This review investigated the frequency of musculoskeletal, neurologic, airway, and vascular injuries to neck structures following such events. A narrative review of the PubMed database was conducted, selecting hypothesis-testing articles based on criteria including non-judicial hanging, emergency department evaluation, and consideration of at least one of the four injury areas. Two reviewers selected the final articles, analyzed the data, and investigated three questions focusing on the frequency of these injury types. The reference lists of the selected articles were also reviewed for additional relevant studies. The analysis included 30 articles (3809 patients) for musculoskeletal and …",Medknow,Turkish Journal of Emergency Medicine,2025
2201,Comparison of Deep Learning Approaches for Conversion of International Classification of Diseases Codes to the Abbreviated Injury Scale,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qfy1Hr8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=qfy1Hr8AAAAJ:Zph67rFs4hoC,"The injury severity classifications generated from the Abbreviated Injury Scale (AIS) provide information that allows for standardized comparisons in the field of trauma injury research. However, the majority of injuries are coded in International Classification of Diseases (ICD) and lack this severity information. A system to predict injury severity classifications from ICD codes would be beneficial as manually coding in AIS can be time-intensive or even impossible for some retrospective cases. It has been previously shown that the encoder-decoder-based neural machine translation (NMT) model is more accurate than a one-to-one mapping of ICD codes to AIS. The objective of this study is to compare the accuracy of two architectures, feedforward neural networks (FFNN) and NMT, in predicting Injury Severity Score (ISS) and ISS ≥16 classification. Both architectures were tested in direct conversion from ICD codes to …",,,2024
2202,Cluster analysis for gene expression data: a survey,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O8XxkE4AAAAJ&citation_for_view=O8XxkE4AAAAJ:u-x6o8ySG0sC,"DNA microarray technology has now made it possible to simultaneously monitor the expression levels of thousands of genes during important biological processes and across collections of related samples. Elucidating the patterns hidden in gene expression data offers a tremendous opportunity for an enhanced understanding of functional genomics. However, the large number of genes and the complexity of biological networks greatly increases the challenges of comprehending and interpreting the resulting mass of data, which often consists of millions of measurements. A first step toward addressing this challenge is the use of clustering techniques, which is essential in the data mining process to reveal natural structures and identify interesting patterns in the underlying data. Cluster analysis seeks to partition a given data set into groups based on specified features so that the data points within a group are more …",IEEE,,2004
2203,Wavecluster: A multi-resolution clustering approach for very large spatial databases,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O8XxkE4AAAAJ&citation_for_view=O8XxkE4AAAAJ:u5HHmVD_uO8C,"Many applications require the management of spatial data. Clustering large spatial databases is an important problem which tries to find the densely populated regions in the feature space to be used in data mining, knowledge discovery, or efficient information retrieval. A good clustering approach should be efficient and detect clusters of arbitrary shape. It must be insensitive to the outliers noise and the order of input data. We propose WaveCluster, a novel clustering approach based on wavelet transforms, which satisfies all the above requirements. Using multiresolution property of wavelet transforms, we can effectively identify arbitrary shape clusters at different degrees of accuracy. We also demonstrate that WaveCluster is highly efficient in terms of time complexity. Experimental results on very large data sets are presented which show the efficiency and effectiveness of the proposed approach compared to the other recent clustering methods.",,,1998
2204,A survey on causal inference,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O8XxkE4AAAAJ&citation_for_view=O8XxkE4AAAAJ:e7Kme7CWzzEC,"Causal inference is a critical research topic across many domains, such as statistics, computer science, education, public policy, and economics, for decades. Nowadays, estimating causal effect from observational data has become an appealing research direction owing to the large amount of available data and low budget requirement, compared with randomized controlled trials. Embraced with the rapidly developed machine learning area, various causal effect estimation methods for observational data have sprung up. In this survey, we provide a comprehensive review of causal inference methods under the potential outcome framework, one of the well-known causal inference frameworks. The methods are divided into two categories depending on whether they require all three assumptions of the potential outcome framework or not. For each category, both the traditional statistical methods and the recent …",ACM,ACM Transactions on Knowledge Discovery from Data (TKDD),2021
2205,WaveCluster: a wavelet-based clustering approach for spatial data in very large databases,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O8XxkE4AAAAJ&citation_for_view=O8XxkE4AAAAJ:2osOgNQ5qMEC,"Many applications require the management of spatial data in a multidimensional feature space. Clustering large spatial databases is an important problem, which tries to find the densely populated regions in the feature space to be used in data mining, knowledge discovery, or efficient information retrieval. A good clustering approach should be efficient and detect clusters of arbitrary shape. It must be insensitive to the noise (outliers) and the order of input data. We propose WaveCluster, a novel clustering approach based on wavelet transforms, which satisfies all the above requirements. Using the multiresolution property of wavelet transforms, we can effectively identify arbitrarily shaped clusters at different degrees of detail. We also demonstrate that WaveCluster is highly efficient in terms of time complexity. Experimental results on very large datasets are presented, which show the efficiency and effectiveness of the …",Springer-Verlag,,2000
2206,Representation learning for treatment effect estimation from observational data,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O8XxkE4AAAAJ&citation_for_view=O8XxkE4AAAAJ:5vmaGNysiqoC,"Estimating individual treatment effect (ITE) is a challenging problem in causal inference, due to the missing counterfactuals and the selection bias. Existing ITE estimation methods mainly focus on balancing the distributions of control and treated groups, but ignore the local similarity information that is helpful. In this paper, we propose a local similarity preserved individual treatment effect (SITE) estimation method based on deep representation learning. SITE preserves local similarity and balances data distributions simultaneously, by focusing on several hard samples in each mini-batch. Experimental results on synthetic and three real-world datasets demonstrate the advantages of the proposed SITE method, compared with the state-of-the-art ITE estimation methods.",,,2018
2207,Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O8XxkE4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=O8XxkE4AAAAJ:Pq77ox9vBIIC,"The capabilities of Large Vision-Language Models (LVLMs) have reached state-of-the-art on many visual reasoning tasks, including chart reasoning, yet they still falter on out-of-distribution (OOD) data, and degrade further when asked to produce their chain-of-thought (CoT) rationales, limiting explainability. We present Chart-RVR, a general framework that fine-tunes LVLMs to be more robust and explainable for chart reasoning by coupling Group Relative Policy Optimization (GRPO) with automatically verifiable rewards. Our framework comprises of three rewards that maximize: (i) correct chart-type classification, (ii) faithful chart table reconstruction, and (iii) process conformity. Applied to 3-billion-parameter LVLMs, Chart-RVR consistently outperforms standard supervised fine-tuning (SFT) on both in-distribution and out-of-distribution datasets, closing the OOD performance gap while improving rationale fidelity. The resulting models, the Chart-RVR-3B series, achieve state-of-the-art results on six chart-reasoning benchmarks spanning in-domain and OOD settings, surpassing all existing models of comparable size. Beyond accuracy, Chart-RVR yields more interpretable CoT rationales, strengthening trust and reliability - showcasing the power of verifiable rewards with GRPO for training reliable, interpretable chart-reasoning models.",,,2025
2208,COCO-Tree: COmpositional Hierarchical COncept Trees for Enhanced Reasoning in Vision Language Models,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O8XxkE4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=O8XxkE4AAAAJ:SDwcUXvf3vAC,"Compositional reasoning remains a persistent weakness of modern vision language models (VLMs): they often falter when a task hinges on understanding how multiple objects, attributes, and relations interact within an image. Multiple research works have attempted to improve compositionality performance by creative tricks such as improving prompt structure, chain of thought reasoning, etc. A more recent line of work attempts to impart additional reasoning in VLMs using well-trained Large Language Models (LLMs), which are far superior in linguistic understanding than VLMs to compensate for the limited linguistic prowess of VLMs. However, these approaches are either resource-intensive or do not provide an interpretable reasoning process. In this paper, we present 'COCO-Tree' - a novel approach that augments VLM outputs with carefully designed neurosymbolic concept trees learned from LLMs to improve VLM's linguistic reasoning. COCO-Tree's beam search-inspired reasoning process boosts compositionality performance and provides a rationale behind VLM predictions. Empirical results on four compositionality benchmarks, Winoground, EqBench, ColorSwap, and SugarCrepe, in seven different open-source VLMs with varying sizes, demonstrate that COCO-Tree significantly improves compositional generalization by 5-10% over baselines.",,,2025
2209,KDD 2025 Panel on AI for Science,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O8XxkE4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=O8XxkE4AAAAJ:Mxsl0EcrEqIC,"Artificial Intelligence (AI) is rapidly reshaping the landscape of scientific discovery by enabling the development of novel models that tackle complex, data- and computation-intensive problems. Scientific challenges, in turn, provide rich, use-inspired settings that push the boundaries of AI research. This virtuous cycle is increasingly driven by cross-disciplinary collaboration, where advances in AI and domain sciences co-evolve to accelerate innovation. In this plenary panel, we will examine the opportunities and challenges in designing cutting-edge AI models for scientific discovery, and high- light the transformative potential of cross-disciplinary partnerships in shaping the future of both AI and science.",,,2025
2210,AI and Science Day,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O8XxkE4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=O8XxkE4AAAAJ:Kcj38R9OIygC,"The past decade has been an inspiring time for artificial intelligence (AI) research. AI systems have transformed norms and practices across industries and have permeated the fabric of human society. Moreover, AI is ushering in a transformative technological age by making remarkable breakthroughs in a number of scientific fields such as protein structure prediction and medical imaging. There is increasing consensus in the wider scientific community that AI is poised to disrupt science by unlocking entirely new approaches, driving new scientific inquiry, and enabling greater scientific leaps with far-reaching social consequences. However, there are substantial barriers preventing science from realizing that potential, and addressing these barriers will require support for advances in AI methods and the adoption of these methods in routine scientific research. In this special day at KDD 2025, we host a series of talks by …",,,2025
2211,Improving Group Robustness on Spurious Correlation via Evidential Alignment,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=O8XxkE4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=O8XxkE4AAAAJ:w2iJ_PS61zAC,"Deep neural networks often learn and rely on spurious correlations, i.e., superficial associations between non-causal features and the targets. For instance, an image classifier may identify camels based on the desert backgrounds. While it can yield high overall accuracy during training, it degrades generalization on more diverse scenarios where such correlations do not hold. This problem poses significant challenges for out-of-distribution robustness and trustworthiness. Existing methods typically mitigate this issue by using external group annotations or auxiliary deterministic models to learn unbiased representations. However, such information is costly to obtain, and deterministic models may fail to capture the full spectrum of biases learned by the models. To address these limitations, we propose Evidential Alignment, a novel framework that leverages uncertainty quantification to understand the behavior of the …",,,2025
2212,The UVA/PADOVA type 1 diabetes simulator: new features,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ii2NKV4AAAAJ&citation_for_view=Ii2NKV4AAAAJ:Tiz5es2fbqcC,"Objective Recent studies have provided new insights into nonlinearities of insulin action in the hypoglycemic range and into glucagon kinetics as it relates to response to hypoglycemia. Based on these data, we developed a new version of the UVA/PADOVA Type 1 Diabetes Simulator, which was submitted to FDA in 2013 (S2013). Methods The model of glucose kinetics in hypoglycemia has been improved, implementing the notion that insulin-dependent utilization increases nonlinearly when glucose decreases below a certain threshold. In addition, glucagon kinetics and secretion and action models have been incorporated into the simulator: glucagon kinetics is a single compartment; glucagon secretion is controlled by plasma insulin, plasma glucose below a certain threshold, and glucose rate of change; and plasma glucagon stimulates with some delay endogenous glucose production. A refined statistical strategy …",SAGE Publications,,2014
2213,In Silico Preclinical Trials: A Proof of Concept in Closed-Loop Control of Type 1 Diabetes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ii2NKV4AAAAJ&citation_for_view=Ii2NKV4AAAAJ:u5HHmVD_uO8C,"Arguably, a minimally invasive system using subcutaneous (s.c.) continuous glucose monitoring (CGM) and s.c. insulin delivery via insulin pump would be a most feasible step to closed-loop control in type 1 diabetes mellitus (T1DM). Consequently, diabetes technology is focusing on developing an artificial pancreas using control algorithms to link CGM with s.c. insulin delivery. The future development of the artificial pancreas will be greatly accelerated by employing mathematical modeling and computer simulation. Realistic computer simulation is capable of providing invaluable information about the safety and the limitations of closed-loop control algorithms, guiding clinical studies, and out-ruling ineffective control scenarios in a cost-effective manner. Thus computer simulation testing of closed-loop control algorithms is regarded as a prerequisite to clinical trials of the artificial pancreas. In this paper, we present a …",SAGE Publications,Journal of diabetes science and technology,2009
2214,A randomized trial of closed-loop control in children with type 1 diabetes,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ii2NKV4AAAAJ&citation_for_view=Ii2NKV4AAAAJ:qzPvQt7yPGwC,"Background A closed-loop system of insulin delivery (also called an artificial pancreas) may improve glycemic outcomes in children with type 1 diabetes. Methods In a 16-week, multicenter, randomized, open-label, parallel-group trial, we assigned, in a 3:1 ratio, children 6 to 13 years of age who had type 1 diabetes to receive treatment with the use of either a closed-loop system of insulin delivery (closed-loop group) or a sensor-augmented insulin pump (control group). The primary outcome was the percentage of time that the glucose level was in the target range of 70 to 180 mg per deciliter, as measured by continuous glucose monitoring. Results A total of 101 children underwent randomization (78 to the closed-loop group and 23 to the control group); the glycated hemoglobin levels at baseline ranged from 5.7 to 10.1%. The mean (±SD) percentage of time that the glucose level was in the target range of 70 to …",Massachusetts Medical Society,,2020
2215,"Method, system and computer program product for real-time detection of sensitivity decline in analyte sensors",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ii2NKV4AAAAJ&citation_for_view=Ii2NKV4AAAAJ:TFP_iSt0sucC,"(54) METHOD, SYSTEMAND COMPUTER 4,036,749 A 7, 1977 Anderson PROGRAMI PRODUCT FOR REAL-TIME 4,055,175. A 10/1977 Clemens et al. DETECTION OF SENSITIVITY DECLINE IN 4,129, 128 A 12/1978 McFarlane ANALYTE SENSORS 4,245,634 A 1/1981 Albisser et al. 4,327,725 A 5, 1982 Cortese et al.",,,2012
2216,Fully integrated artificial pancreas in type 1 diabetes: modular closed-loop glucose control maintains near normoglycemia,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ii2NKV4AAAAJ&citation_for_view=Ii2NKV4AAAAJ:_FxGoFyzp5QC,"Integrated closed-loop control (CLC), combining continuous glucose monitoring (CGM) with insulin pump (continuous subcutaneous insulin infusion [CSII]), known as artificial pancreas, can help optimize glycemic control in diabetes. We present a fundamental modular concept for CLC design, illustrated by clinical studies involving 11 adolescents and 27 adults at the Universities of Virginia, Padova, and Montpellier. We tested two modular CLC constructs: standard control to range (sCTR), designed to augment pump plus CGM by preventing extreme glucose excursions; and enhanced control to range (eCTR), designed to truly optimize control within near normoglycemia of 3.9–10 mmol/L. The CLC system was fully integrated using automated data transfer CGM→algorithm→CSII. All studies used randomized crossover design comparing CSII versus CLC during identical 22-h hospitalizations including …",American Diabetes Association,,2012
2217,Capillary Ketone Monitoring–Guided Adaptation of Automated Insulin Delivery to Accommodate a Ketogenic Diet in an Individual With Type 1 Diabetes: Case Study and Literature Review,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ii2NKV4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ii2NKV4AAAAJ:UwpDZDXJMDUC,"Utilization of ketogenic diets (KDs) in people with type 1 diabetes has been limited by increased risks of hypoglycemia and ketosis (1). Conversely, improvements in glycemic control and weight management have compelled some individuals to adhere to a KD despite medical uncertainty. Herein, we report an individual with type 1 diabetes who used capillary ketone (CK) monitoring to manually adapt his closed-loop automated insulin delivery (AID) system to minimize ketosis, improve glycemic control, and enable safe utilization of a KD/very-lowcarbohydrate diet (VLCD).",American Diabetes Association,,2025
2218,Toward Personalized Decision Support Systems for Type 1 Diabetes: Integrating Psychobehavioral Factors and Glycemic Control,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ii2NKV4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ii2NKV4AAAAJ:QxtoOqDH1aQC,"Background While novel technologies have improved glycemic control in type 1 diabetes (T1D), their design is often glucose-centric and overlooks critical psychobehavioral elements such as individual treatment preferences and therapeutic goals. This article presents an algorithm development framework and study layout aimed at incorporating psychobehavioral factors into the design of technology for the management of T1D. Methods/Design A decision support system (DSS) was engineered at the University of Virginia providing therapeutic advice to individuals with T1D regarding optimal insulin dosing parameters, bolus calculation, safe undertaking of physical activity, and risk for hypoglycemia during the day as well as at bedtime. To accommodate individual preferences as to how the therapeutic advice is delivered, the DSS was designed with two possible operating modalities: prescriptive—offering optimized …",SAGE Publications,,2025
2219,Modeling Meal Absorption in Subjects Post-Roux-En-Y Gastric Bypass Surgery Leading to Post-Bariatric Hypoglycemia,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ii2NKV4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ii2NKV4AAAAJ:bXvxhPDrUX0C,"Bariatric surgery, particularly Roux-en-Y Gastric Bypass (RYGB), significantly alters postprandial physiology, including enhanced gastric emptying and increased glucose absorption. These changes can contribute to the development of post-bariatric hypoglycemia (PBH), and its associated a clinically relevant complication. As demonstrated in type 1 diabetes, the development of mathematical models and their use in simulation environments can greatly accelerate the development and testing of novel clinical approaches. This work aims to identify the most appropriate meal absorption model structure from existing models in the literature by incorporating parameters that reflect physiological alterations following RYGB surgery. Glucose rate of appearance (Ra) mean data from 12 subjects both pre- and post-surgery is fitted. The bestfitting model was selected using the Akaike Information Criterion (AIC) and Bayesian …",IEEE,,2025
2220,Miniaturized Neural Networks for Deploying Fully Closed Loop Insulin Delivery Systems: A Pilot Study Featuring Flexible Meal Announcement Options,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ii2NKV4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ii2NKV4AAAAJ:ult01sCh7k0C,"Background Automated insulin delivery (AID) has revolutionized glucose management. Next-generation AID systems focus on reducing user input, particularly for mealtime dosing, aiming for fully closed loop (FCL) control. Our goal was to assess the safety and feasibility of the next iteration of FCL control, using a miniature neural network to enable implementation within existing hardware capabilities. Methods In a randomized crossover trial, six adults with type 1 diabetes completed seven days of usual care and seven days using AIDANET in free-living conditions. AIDANET is designed to enable FCL control, but carbohydrate counting and a novel easy-bolus strategy were enabled for one day each to test the system in hybrid closed loop modalities. Results The mean glucose during usual care was 168 ± 24.3 mg/dL, compared to 161.3 ± 16.7 mg/dL using the AIDANET system. Time-in-range (TIR) 70 to 180 mg/dL …",SAGE Publications,,2025
2221,Unified platform for monitoring and control of blood glucose levels in diabetic patients,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Ii2NKV4AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=Ii2NKV4AAAAJ:lDOOmgye57wC,"A flexible system for utilizing data from different monitoring techniques and capable of providing assistance to patients with diabetes at several scalable levels, ranging from advice about long-term trends and prognosis to real-time automated closed-loop control (artificial pancreas). These scalable monitoring and treatment strategies are delivered by a unified system called the Diabetes Assistant (DiAs) platform. The system provides a foundation for implementation of various monitoring, advisory, and automated diabetes treatment algorithms or methods. The DiAs recommendations are tailored to the specifics of an individual patient, and to the patient risk assessment at any given moment.",,,2025
2222,Skin mechanical properties and modeling: A review,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6E6AzD8AAAAJ&citation_for_view=6E6AzD8AAAAJ:cFHS6HbyZ2cC,"The mechanical properties of the skin are important for various applications. Numerous tests have been conducted to characterize the mechanical behavior of this tissue, and this article presents a review on different experimental methods used. A discussion on the general mechanical behavior of the skin, including nonlinearity, viscoelasticity, anisotropy, loading history dependency, failure properties, and aging effects, is presented. Finally, commonly used constitutive models for simulating the mechanical response of skin are discussed in the context of representing the empirically observed behavior.",SAGE Publications,"Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine",2018
2223,Development of a finite element model for blast brain injury and the effects of CSF cavitation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6E6AzD8AAAAJ&citation_for_view=6E6AzD8AAAAJ:UeHWp8X0CEIC,"Blast-related traumatic brain injury is the most prevalent injury for combat personnel seen in the current conflicts in Iraq and Afghanistan, yet as a research community, we still do not fully understand the detailed etiology and pathology of this injury. Finite element (FE) modeling is well suited for studying the mechanical response of the head and brain to blast loading. This paper details the development of a FE head and brain model for blast simulation by examining both the dilatational and deviatoric response of the brain as potential injury mechanisms. The levels of blast exposure simulated ranged from 50 to 1000 kPa peak incident overpressure and 1–8 ms in positive-phase duration, and were comparable to real-world blast events. The frontal portion of the brain had the highest pressures corresponding to the location of initial impact, and peak pressure attenuated by 40–60% as the wave propagated from the …",Springer US,,2012
2224,Brain injuries from blast,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6E6AzD8AAAAJ&citation_for_view=6E6AzD8AAAAJ:zYLM7Y9cAGgC,"Traumatic brain injury (TBI) from blast produces a number of conundrums. This review focuses on five fundamental questions including: (1) What are the physical correlates for blast TBI in humans? (2) Why is there limited evidence of traditional pulmonary injury from blast in current military field epidemiology? (3) What are the primary blast brain injury mechanisms in humans? (4) If TBI can present with clinical symptoms similar to those of Post-Traumatic Stress Disorder (PTSD), how do we clinically differentiate blast TBI from PTSD and other psychiatric conditions? (5) How do we scale experimental animal models to human response? The preponderance of the evidence from a combination of clinical practice and experimental models suggests that blast TBI from direct blast exposure occurs on the modern battlefield. Progress has been made in establishing injury risk functions in terms of blast overpressure time …",Springer US,Annals of biomedical engineering,2012
2225,"C4–C5 segment finite element model development, validation, and load-sharing investigation",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6E6AzD8AAAAJ&citation_for_view=6E6AzD8AAAAJ:u5HHmVD_uO8C,"Detailed cervical spine models are necessary to better understand cervical spine response to loading, improve our understanding of injury mechanisms, and specifically for predicting occupant response and injury in auto crash scenarios. The focus of this study was to develop a C4–C5 finite element model with accurate representations of each tissue within the segment. This model incorporates more than double the number of elements of existing models, required for accurate prediction of response. The most advanced material data available were then incorporated using appropriate nonlinear constitutive models to provide accurate predictions of response at physiological levels of loading. This tissue-scale segment model was validated against a wide variety of experimental data including different modes of loading (axial rotation, flexion, extension, lateral bending, and translation), and different load levels. In …",Elsevier,,2009
2226,Cervical spine response in frontal crash,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6E6AzD8AAAAJ&citation_for_view=6E6AzD8AAAAJ:IjCSPb-OGe4C,"Predicting neck response and injury resulting from motor vehicle accidents is essential to improving occupant protection. A detailed human cervical spine finite element model has been developed, with material properties and geometry determined a priori of any validation, for the evaluation of global kinematics and tissue-level response. Model validation was based on flexion/extension response at the segment level, tension response of the whole ligamentous cervical spine, head kinematic response from volunteer frontal impacts, and soft tissue response from cadaveric whole cervical spine frontal impacts. The validation responses were rated as 0.79, assessed using advanced cross-correlation analysis, indicating the model exhibits good biofidelity. The model was then used to evaluate soft tissue response in frontal impact scenarios ranging from 8G to 22G in severity. Disc strains were highest in the C4–C5–C6 …",Elsevier,,2011
2227,Average Responses of Brain Displacement Under Rotational Loading for Computational Model Validation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6E6AzD8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6E6AzD8AAAAJ:0KyAp5RtaNEC,"Objective Computational models of the brain are typically validated using individual subjects from datasets of brain motion, but a comparison to an individual subject does not consider the biomechanical variation that naturally exists in the population. When data from multiple subjects is available, biomechanical corridors are constructed for the assessment of model biofidelity. However, a robust set of corridors for brain's biomechanical response due to applied head kinematics does not exist for model validation. The aim of this study was to create corridors based on a dataset of in situ brain displacement that included six specimens tested under a set of twelve loading conditions. Methods There were three main factors that complicated this task, including variation in head kinematics, differences in the initial position of the sensors, and the clustering of spatially scattered data. We employed various numerical and …",IEEE,,2025
2228,Cadaveric Biomechanical Comparison of Prepectoral and Submuscular Implant-based Breast Reconstruction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6E6AzD8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6E6AzD8AAAAJ:yB1At4FlUx8C,"Decreased postoperative pain and functional impact have been associated with prepectoral breast implant placement versus submuscular placement; yet no mechanical analyses have quantified this difference. Using 1 postmortem human subject, a 3-dimensional biomechanical tracking system was used to determine the impact of pocket placement on shoulder girdle dynamics for submuscular acellular dermal matrix (ADM)–assisted and prepectoral implants. Smooth silicone breast implants were placed bilaterally—one in the prepectoral plane with anterior ADM coverage and the other in the submuscular ADM-assisted plane. Using tracking nodes at the sternum, clavicles, scapulae, and humeri, each shoulder was tested through serial standardized trials of extension, flexion, lateral extension/flexion, oblique extension/flexion, and abduction using manual manipulations of the shoulder and a counter-weight …",LWW,,2025
2229,Brain injury metrics and their risk functions in frontal automotive collisions,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6E6AzD8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6E6AzD8AAAAJ:nrtMV_XWKgEC,"Objectives The objective of this study was to develop abbreviated injury scale (AIS) 1, AIS2, AIS3 and AIS4+ injury risk functions (IRFs) for traumatic brain injuries (TBIs) as estimated by the rotational kinematics of the head, in accordance with AIS1998. The effectiveness of the IRFs was investigated by comparisons with real-world accident data of frontal crash configurations. In addition, links of the IRFs developed in accordance with AIS1998 to other AIS versions were discussed. Methods AIS1, AIS2, AIS3 and AIS4+ IRFs based on finite element analysis (FEA)-based metrics in this study were developed using a TBI database used for developing mild TBI (concussion) and severe TBI (diffuse axonal injury (DAI) and intracerebral hemorrhage (ICH)) IRFs in our previous study. The TBI database includes head kinematics, clinical outcomes, and FEA-based metrics such as maximum principal strain (MPS) obtained from …",Taylor & Francis,,2025
2230,Cervical vertebral and spinal cord injuries in rollover occupants,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6E6AzD8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6E6AzD8AAAAJ:VLnqNzywnoUC,"Background Rollover crashes continue to be a substantial public health issue in North America. Previous research has shown that the cervical spine is the most injured spine segment in rollovers, but much of the past research has focused on risk factors rather than the actual cervical spine injuries. We sought to examine how different types of cervical spine injuries (vertebral and/or cord injury) vary with different occupant-related factors in rollovers and to compare these with non-rollovers. Methods We obtained crash and injury information from the National Automotive Sampling System–Crashworthiness Data System (NASS-CDS) for 2005–2015 and Crash Investigation Sampling System (CISS) for 2017–2022. Based on weighted data, we calculated relative risks to assess how occupant sex, seat belt use, ejection status, and fatal outcome relate to the rate of different cervical spine injuries in rollovers and non …",BioMed Central,,2024
2231,E-211 Surgeon perception of navigation difficulty may lay with 3D anatomical centerline features,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=6E6AzD8AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=6E6AzD8AAAAJ:z_wVstp3MssC,"Introduction Determining the ideal approach for mechanical thrombectomy is critical to the success of the procedure. Currently, an operator must decide between femoral or radial approach by evaluating preoperative vascular imaging. This choice is usually determined by the operator’s subjective experience. However, a more objective approach is possible by leveraging quantitate evaluation of the arterial anatomy. Many features that an operator qualitatively considers, such as the arch type or carotid tortuosity, can be described numerically. In this study, we evaluated a group of objective anatomical metrics to determine which correlated best with the operator’s perception of navigational difficulty. Materials and Methods We deidentified a set of 47 anterior circulation thrombectomy cases with associated CTA images and operative notes of perceived navigational difficulty and time metrics (i.e., time to first pass …",British Medical Journal Publishing Group,Journal of NeuroInterventional Surgery,2024
2232,Design and validation of a tool for neurite tracing and analysis in fluorescence microscopy images,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nsQNqnIAAAAJ&citation_for_view=nsQNqnIAAAAJ:u5HHmVD_uO8C,"Background For the investigation of the molecular mechanisms involved in neurite outgrowth and differentiation, accurate and reproducible segmentation and quantification of neuronal processes are a prerequisite. To facilitate this task, we developed a semiautomatic neurite tracing technique. This article describes the design and validation of the technique. Methods The technique was compared to fully manual delineation. Four observers repeatedly traced selected neurites in 20 fluorescence microscopy images of cells in culture, using both methods. Accuracy and reproducibility were determined by comparing the tracings to high‐resolution reference tracings, using two error measures. Labor intensiveness was measured in numbers of mouse clicks required. The significance of the results was determined by a Student t‐test and by analysis of variance. Results Both methods slightly underestimated the true …","Wiley Subscription Services, Inc., A Wiley Company",,2004
2233,MoDL: Model-based deep learning architecture for inverse problems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nsQNqnIAAAAJ&citation_for_view=nsQNqnIAAAAJ:BUYA1_V_uYcC,"We introduce a model-based image reconstruction framework with a convolution neural network (CNN)-based regularization prior. The proposed formulation provides a systematic approach for deriving deep architectures for inverse problems with the arbitrary structure. Since the forward model is explicitly accounted for, a smaller network with fewer parameters is sufficient to capture the image information compared to direct inversion approaches. Thus, reducing the demand for training data and training time. Since we rely on end-to-end training with weight sharing across iterations, the CNN weights are customized to the forward model, thus offering improved performance over approaches that rely on pre-trained denoisers. Our experiments show that the decoupling of the number of iterations from the network complexity offered by this approach provides benefits, including lower demand for training data, reduced …",IEEE,,2018
2234,Accelerated dynamic MRI exploiting sparsity and low-rank structure: kt SLR,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nsQNqnIAAAAJ&citation_for_view=nsQNqnIAAAAJ:MXK_kJrjxJIC,"We introduce a novel algorithm to reconstruct dynamic magnetic resonance imaging (MRI) data from under-sampled k-t space data. In contrast to classical model based cine MRI schemes that rely on the sparsity or banded structure in Fourier space, we use the compact representation of the data in the Karhunen Louve transform (KLT) domain to exploit the correlations in the dataset. The use of the data-dependent KL transform makes our approach ideally suited to a range of dynamic imaging problems, even when the motion is not periodic. In comparison to current KLT-based methods that rely on a two-step approach to first estimate the basis functions and then use it for reconstruction, we pose the problem as a spectrally regularized matrix recovery problem. By simultaneously determining the temporal basis functions and its spatial weights from the entire measured data, the proposed scheme is capable of …",IEEE,,2011
2235,Design of steerable filters for feature detection using canny-like criteria,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nsQNqnIAAAAJ&citation_for_view=nsQNqnIAAAAJ:u-x6o8ySG0sC,"We propose a general approach for the design of 2D feature detectors from a class of steerable functions based on the optimization of a Canny-like criterion. In contrast with previous computational designs, our approach is truly 2D and provides filters that have closed-form expressions. It also yields operators that have a better orientation selectivity than the classical gradient or Hessian-based detectors. We illustrate the method with the design of operators for edge and ridge detection. We present some experimental results that demonstrate the performance improvement of these new feature detectors. We propose computationally efficient local optimization algorithms for the estimation of feature orientation. We also introduce the notion of shape-adaptable feature detection and use it for the detection of image corners.",IEEE,,2004
2236,Blind compressive sensing dynamic MRI,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nsQNqnIAAAAJ&citation_for_view=nsQNqnIAAAAJ:3s1wT3WcHBgC,"We propose a novel blind compressive sensing (BCS) frame work to recover dynamic magnetic resonance images from undersampled measurements. This scheme models the dynamic signal as a sparse linear combination of temporal basis functions, chosen from a large dictionary. In contrast to classical compressed sensing, the BCS scheme simultaneously estimates the dictionary and the sparse coefficients from the undersampled measurements. Apart from the sparsity of the coefficients, the key difference of the BCS scheme with current low rank methods is the nonorthogonal nature of the dictionary basis functions. Since the number of degrees-of-freedom of the BCS model is smaller than that of the low-rank methods, it provides improved reconstructions at high acceleration rates. We formulate the reconstruction as a constrained optimization problem; the objective function is the linear combination of a data …",IEEE,,2013
2237,Accelerating 3D radial MPnRAGE using a self‐supervised deep factor model,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nsQNqnIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=nsQNqnIAAAAJ:2vr6o8x5NLkC,Purpose To develop a self‐supervised and memory‐efficient deep learning image reconstruction method for 4D non‐Cartesian MRI with high resolution and a large parametric dimension. Methods The deep factor model (DFM) represents a parametric series of 3D multicontrast images using a neural network conditioned by the inversion time using efficient zero‐filled reconstructions as input estimates. The model parameters are learned in a single‐shot learning (SSL) fashion from the k‐space data of each acquisition. A compatible transfer learning (TL) approach using previously acquired data is also developed to reduce reconstruction time. The DFM is compared to subspace methods with different regularization strategies in a series of phantom and in vivo experiments using the MPnRAGE acquisition for multicontrast T1$$ {T}_1 $$ imaging and quantitative T1$$ {T}_1 $$ estimation. Results DFM‐SSL improved …,,,2025
2238,Association of Contrast Enhanced Dual Energy CT-derived Pulmonary Arterial Tree-to-Lung Ratio (ArtLR) With COPD,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nsQNqnIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=nsQNqnIAAAAJ:wLxue7F8ec0C,"RATIONALE: Airway-to-lung ratio (AirLR), calculated as the mean of airway lumen diameters at standard anatomic locations divided by the cube-root of total lung volume, is associated with COPD risk regardless of smoking status, and we have previously shown an association between total-pulmonary-vascular-volume-to-lung-size relationship with AirLR. [PMCID: PMC11284327] Using dual energy computed tomography (DECT), we recently developed a deep learning-based algorithm for pulmonary arterial segmentation to compute pulmonary-arterial-to-lung ratio (ArtLR) which correlated significantly with AirLR and markers COPD. Here we automate image processing in a larger cohort to estimate ArtLR, introduce an alternative ArtLR standardization and correlate it to COPD-related measures of lung structure and function. METHODS: Using a SPIROMICS sub-cohort (110 participants), imaged via contrast …",American Thoracic Society,,2025
2239,Motion-compensated cardiac MRI using low-rank diffeomorphic flow (DMoCo),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nsQNqnIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=nsQNqnIAAAAJ:sJPMR1oEGYQC,"We introduce an unsupervised motion-compensated image reconstruction algorithm for free-breathing and ungated 3D cardiac magnetic resonance imaging (MRI). We express the image volume corresponding to each specific motion phase as the deformation of a single static image template. The main contribution of the work is the low-rank model for the compact joint representation of the family of diffeomorphisms, parameterized by the motion phases. The diffeomorphism at a specific motion phase is obtained by integrating a parametric velocity field along a path connecting the reference template phase to the motion phase. The velocity field at different phases is represented using a low-rank model. The static template and the low-rank motion model parameters are learned directly from the k-space data in an unsupervised fashion. The more constrained motion model is observed to offer improved recovery compared to current motion-resolved and motion-compensated algorithms for free-breathing 3D cine MRI.",,,2025
2240,Fast and ultra-high shot diffusion MRI image reconstruction with self-adaptive Hankel subspace,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nsQNqnIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=nsQNqnIAAAAJ:OzeSX8-yOCQC,"Multi-shot interleaved echo planar imaging is widely employed for acquiring high-resolution and low-distortion diffusion weighted images (DWI). These DWI images, however, are easily affected by motion artifacts induced by inter-shot phase variations which could be removed by enforcing the low-rankness of a huge 2D block Hankel matrix of the k-space. Successful applications have been evidenced on 4∼8 shots DWI but failure was observed on ultra-high shots, e.g. 10∼12 shots, limiting the extension to higher-resolution DWI. Moreover, the 2D Hankel matrix reconstruction is very time-consuming. Here, we propose to accelerate the reconstruction through decomposing this huge 2D matrix into small 1D lOw-raNk HAnkel (DONA) matrices from every k-space readout line. This extension encounters another problem of variant low-rankness across the k-space. To address this issue, we propose to separate signal …",Elsevier,,2025
2241,Accelerating Quantitative MRI Using Subspace Multiscale Energy Model (SS-MuSE),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nsQNqnIAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=nsQNqnIAAAAJ:pQTOvowfQioC,"Multi-contrast MRI methods acquire multiple images with different contrast weightings, which are used for the differentiation of the tissue types or quantitative mapping. However, the scan time needed to acquire multiple contrasts is prohibitively long for 3D acquisition schemes, which can offer isotropic image resolution. While deep learning-based methods have been extensively used to accelerate 2D and 2D + time problems, the high memory demand, computation time, and need for large training data sets make them challenging for large-scale volumes. To address these challenges, we generalize the plug-and-play multi-scale energy-based model (MuSE) to a regularized subspace recovery setting, where we jointly regularize the 3D multi-contrast spatial factors in a subspace formulation. The explicit energy-based formulation allows us to use variable splitting optimization methods for computationally efficient …",IEEE,,2025
2242,Episimdemics: an efficient algorithm for simulating the spread of infectious disease over large realistic social networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wuKMx_kAAAAJ&citation_for_view=wuKMx_kAAAAJ:hC7cP41nSMkC,"Preventing and controlling outbreaks of infectious diseases such as pandemic influenza is a top public health priority. We describe EpiSimdemics - a scalable parallel algorithm to simulate the spread of contagion in large, realistic social contact networks using individual-based models. EpiSimdemics is an interaction-based simulation of a certain class of stochastic reaction-diffusion processes. Straightforward simulations of such process do not scale well, limiting the use of individual-based models to very small populations. EpiSimdemics is specifically designed to scale to social networks with 100 million individuals. The scaling is obtained by exploiting the semantics of disease evolution and disease propagation in large networks. We evaluate an MPI-based parallel implementation of EpiSimdemics on a mid-sized HPC system, demonstrating that EpiSimdemics scales well. EpiSimdemics has been used in …",IEEE,,2008
2243,Extended mapping and exploration of the vanadium dioxide stress-temperature phase diagram,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wuKMx_kAAAAJ&citation_for_view=wuKMx_kAAAAJ:b1wdh0AR-JQC,"Single-crystal micro- and nanomaterials often exhibit higher yield strength than their bulk counterparts. This enhancement is widely recognized in structural materials but is rarely exploited to probe fundamental physics of electronic materials. Vanadium dioxide exhibits coupled electronic and structural phase transitions that involve different structures existing at different strain states. Full understanding of the driving mechanism of these coupled transitions necessitates concurrent structural and electrical measurements over a wide phase space. Taking advantages of the superior mechanical property of micro/nanocrystals of VO2, we map and explore its stress-temperature phase diagram over a phase space that is more than an order of magnitude broader than previously attained. New structural and electronic aspects were observed crossing phase boundaries at high-strain states. Our work shows that the actively …",American Chemical Society,,2010
2244,Generation and analysis of large synthetic social contact networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wuKMx_kAAAAJ&citation_for_view=wuKMx_kAAAAJ:u9iWguZQMMsC,"We describe ¿first principles¿ based methods for developing synthetic urban and national scale social contact networks. Unlike simple random graph techniques, these methods use real world data sources and combine them with behavioral and social theories to synthesize networks. We develop a synthetic population for the United States modeling every individual in the population including household structure, demographics and a 24-hour activity sequence. The process involves collecting and manipulating public and proprietary data sets integrated into a common architecture for data exchange and then using these data sets to generate new relations. A social contact network is derived from the synthetic population based on physical co-location of interacting persons. We use graph measures to compare and contrast the structural characteristics of the social networks that span different urban regions. We then …",IEEE,,2009
2245,"Commentary on Ferguson, et al.,“Impact of non-pharmaceutical interventions (NPIs) to reduce COVID-19 mortality and healthcare demand”",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wuKMx_kAAAAJ&citation_for_view=wuKMx_kAAAAJ:5ugPr518TE4C,"A recent manuscript (Ferguson et al. in Impact of non-pharmaceutical interventions (NPIs) to reduce COVID-19 mortality and healthcare demand, Imperial College COVID-19 Response Team, London, 2020. https://www.imperial.ac.uk/media/imperial-college/medicine/sph/ide/gida-fellowships/Imperial-College-COVID19-NPI-modelling-16-03-2020.pdf) from Imperial College modelers examining ways to mitigate and control the spread of COVID-19 has attracted much attention. In this paper, we will discuss a coarse taxonomy of models and explore the context and significance of the Imperial College and other models in contributing to the analysis of COVID-19.",Springer US,,2020
2246,The distance-2 matching problem and its relationship to the MAC-layer capacity of ad hoc wireless networks,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wuKMx_kAAAAJ&citation_for_view=wuKMx_kAAAAJ:hFOr9nPyWt4C,"We consider the problem of determining the maximum capacity of the media access (MAC) layer in wireless ad hoc networks. Due to spatial contention for the shared wireless medium, not all nodes can concurrently transmit packets to each other in these networks. The maximum number of possible concurrent transmissions is, therefore, an estimate of the maximum network capacity, and depends on the MAC protocol being used. We show that for a large class of MAC protocols based on virtual carrier sensing using RTS/CTS messages, which includes the popular IEEE 802.11 standard, this problem may be modeled as a maximum Distance-2 matching ( D2EMIS) in the underlying wireless network: Given a graph G(V,E), find a set of edges E'/spl sube/E such that no two edges in E' are connected by another edge in E. D2EMIS is NP-complete. Our primary goal is to show that it can be approximated efficiently in …",IEEE,,2004
2247,Equivalence hypergraphs: Dpo rewriting for monoidal e-graphs,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wuKMx_kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wuKMx_kAAAAJ:HbR8gkJAVGIC,"The technique of equality saturation, which equips graphs with an equivalence relation, has proven effective for program optimisation. We give a categorical semantics to these structures, called e-graphs, in terms of Cartesian categories enriched over the category of semilattices. This approach generalises to monoidal categories, which opens the door to new applications of e-graph techniques, from algebraic to monoidal theories. Finally, we present a sound and complete combinatorial representation of morphisms in such a category, based on a generalisation of hypergraphs which we call e-hypergraphs. They have the usual advantage that many of their structural equations are absorbed into a general notion of isomorphism. This new principled approach to e-graphs enables double-pushout (DPO) rewriting for these structures, which constitutes the main contribution of this paper.",IEEE,,2025
2248,Deutschland und seine Bundesländer: Spannende Materialien für einen abwechslungsreiche n Unterricht (3. und 4. Klasse),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wuKMx_kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wuKMx_kAAAAJ:EYYDruWGBe4C,"Von der Ostsee bis zur Zugspitze, von Nordrhein-Westfalen nach Brandenburg: Gehen Sie mit Ihren Grundschulkindern auf Deutschland-Tour! Was sind Stadtstaaten? Welches Bundesland liegt ganz im Norden und welche im Süden? Dieses E-Book bringt Ihren Schülerinnen und Schülern wichtiges Wissen rund um Deutschland näher! Mithilfe von abwechslungsreichen Aufgaben, Interviews, Rätseln und Spielen erfahren Ihre Schülerinnen und Schüler spielerisch und handlungsorientiert Wissenswertes über Deutschland und seine 16 Bundesländer. Die Kinder beschäftigen sich mit Gebirgen, Flüssen und Städten, lernen etwas über die deutsche Geschichte und die hiesige Politik. Jedes Bundesland wird zudem mit einem Kurzüberblick vorgestellt. Die Arbeitsblätter sind ohne Vorbereitungsaufwand sofort einsetzbar. Für die stärkeren Grundschulkinder bieten Sternchen-Aufgaben eine besondere Herausforderung. Alle Arbeitsblätter und weitere Materialien als veränderbare Word-Dateien sowie Lösungen befinden sich im Zusatzmaterial. Hier finden Sie auch interaktive Übungen zum Thema, mit denen Sie Ihren Unterricht noch abwechslungsreicher gestalten können!",Auer Verlag,,2025
2249,Towards an information-theoretic framework for multiple sequence alignment sub-sampling,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wuKMx_kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wuKMx_kAAAAJ:LI9QrySNdTsC,"In this article we develop an information-theoretic framework of multiple sequence alignments (MSAs), based on sub-sampling. The key component of this framework is an information-theoretical potential defined on pairs of sites (links) within the MSA. This potential quantifies the expected drop in variation of information between the two constituent sites. The expectation is taken with respect to all possible sub-alignments, obtained by removing a finite, fixed number of rows. We show that the potential is zero for linked sites representing columns, for which symbols are in bijective correspondence and that it is strictly positive, otherwise. It is furthermore shown that the potential assumes its unique minimum for links at which each symbol pair appears with the same multiplicity. We then show that the established drop of the variation of information exceeds finite-size effects inherent to the construction of the potential …",The Royal Society,,2024
2250,Novel multi-cluster workflow system to support real-time HPC-enabled epidemic science: Investigating the impact of vaccine acceptance on COVID-19 spread,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wuKMx_kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wuKMx_kAAAAJ:tuHXwOkdijsC,"We present MacKenzie, a HPC-driven multi-cluster workflow system that was used repeatedly to configure and execute fine-grained US national-scale epidemic simulation models during the COVID-19 pandemic. Mackenzie supported federal and Virginia policymakers, in real-time, for a large number of “what-if” scenarios during the COVID-19 pandemic, and continues to be used to answer related questions as COVID-19 transitions to the endemic stage of the disease. MacKenzie is a novel HPC meta-scheduler that can execute US-scale simulation models and associated workflows that typically present significant big data challenges. The meta-scheduler optimizes the total execution time of simulations in the workflow, and helps improve overall human productivity. As an exemplar of the kind of studies that can be conducted using Mackenzie, we present a modeling study to understand the impact of vaccine …",Academic Press,,2024
2251,The relational machine calculus,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wuKMx_kAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=wuKMx_kAAAAJ:S16KYo8Pm5AC,"This paper presents the Relational Machine Calculus (RMC): a simple, foundational model of first-order relational programming. The RMC originates from the Functional Machine Calculus (FMC), which generalizes the lambda-calculus and its standard call-by-name stack machine in two directions. One, ""locations"", introduces multiple stacks, which enable effect operators to be encoded into the abstraction and application constructs. The second, ""sequencing"", introduces the imperative notions of ""skip"" and ""sequence"", similar to kappa-calculus and concatenative programming languages. The key observation of the RMC is that the first-order fragment of the FMC exhibits a latent duality which, given a simple decomposition of the relevant constructors, can be concretely expressed as an involution on syntax. Semantically, this gives rise to a sound and complete calculus for string diagrams of Frobenius monoids …",,,2024
2252,"Subgoals, context, and worked examples in learning computing problem solving",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XXLOcBcAAAAJ&citation_for_view=XXLOcBcAAAAJ:KlAtU1dfN6UC,"Recent empirical results suggest that the instructional material used to teach computing may actually overload students' cognitive abilities. Better designed materials may enhance learning by reducing unnecessary load. Subgoal labels have been shown to be effective at reducing the cognitive load during problem solving in both mathematics and science. Until now, subgoal labels have been given to students to learn passively. We report on a study to determine if giving learners subgoal labels is more or less effective than asking learners to generate subgoal labels within an introductory CS programming task. The answers are mixed and depend on other features of the instructional materials. We found that student performance gains did not replicate as expected in the introductory CS task for those who were given subgoal labels. Computer science may require different kinds of problem-solving or may generate …",,,2015
2253,Khan academy gamifies computer science,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XXLOcBcAAAAJ&citation_for_view=XXLOcBcAAAAJ:_FxGoFyzp5QC,Gamification is the buzzword for adding gaming elements such as points or badges to learning experiences to make them more engaging and to increase motivation. In this paper we explore how Khan Academy has incorporated gaming elements into its CS learning platform. By mapping the literature on motivational processes to popular games we critically analyze how successful Khan Academy is at gamifying their site.,,,2014
2254,Measuring cognitive load in introductory CS: adaptation of an instrument,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XXLOcBcAAAAJ&citation_for_view=XXLOcBcAAAAJ:eQOLeE2rZwMC,"A student's capacity to learn a concept is directly related to how much cognitive load is used to comprehend the material. The central problem identified by Cognitive Load Theory is that learning is impaired when the total amount of processing requirements exceeds the limited capacity of working memory. Instruction can impose three different types of cognitive load on a student's working memory: intrinsic load, extraneous load, and germane load. Since working memory is a fixed size, instructional material should be designed to minimize the extraneous and intrinsic loads in order to increase the amount of memory available for the germane load. This will improve learning. To effectively design instruction to minimize cognitive load we must be able to measure the specific load components for any pedagogical intervention. This paper reports on a study that adapts a previously developed instrument to measure …",,,2014
2255,Subgoals help students solve Parsons problems,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XXLOcBcAAAAJ&citation_for_view=XXLOcBcAAAAJ:qxL8FJ1GzNcC,"We report on a study that used subgoal labels to teach students how to write while loops with a Parsons problem learning assessment. Subgoal labels were used to aid learning of programming while not overloading students' cognitive abilities. We wanted to compare giving learners subgoal labels versus asking learners to generate subgoal labels. As an assessment for learning we asked students to solve a Parsons problem -- to place code segments in the correct order. We found that students who were given subgoal labels performed statistically better than the groups that did not receive subgoal labels or were asked to generate subgoal labels. We conclude that a low cognitive load assessment, Parsons problems, can be more sensitive to student learning gains than traditional code generation problems.",,,2016
2256,Reducing withdrawal and failure rates in introductory programming with subgoal labeled worked examples,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XXLOcBcAAAAJ&citation_for_view=XXLOcBcAAAAJ:lSLTfruPkqcC,"Background Programming a computer is an increasingly valuable skill, but dropout and failure rates in introductory programming courses are regularly as high as 50%. Like many fields, programming requires students to learn complex problem-solving procedures from instructors who tend to have tacit knowledge about low-level procedures that they have automatized. The subgoal learning framework has been used in programming and other fields to breakdown procedural problem solving into smaller pieces that novices can grasp more easily, but it has only been used in short-term interventions. In this study, the subgoal learning framework was implemented throughout a semester-long introductory programming course to explore its longitudinal effects. Of 265 students in multiple sections of the course, half received subgoal-oriented instruction while the other half received typical instruction. Results Learning …",Springer International Publishing,,2020
2257,ICER 2025: Call for Attendance,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XXLOcBcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XXLOcBcAAAAJ:WbkHhVStYXYC,"Start your August off right by attending the ACM International Computing Education Research (ICER) Conference in Charlottesville, Virginia, USA! Festivities begin on Sunday, 3rd with the Doctoral Consortium and Works-In-Progress in Rice Hall. All attendees are invited to the opening reception in The Rotunda, the original library designed by Thomas Jefferson (3rd President of the United States) and centerpiece of the Academical Village on Sunday evening, 5-6:30pm. While dining on light refreshments you can reconnect with old friends while meeting new ones.",ACM,,2025
2258,ICER 2025 Call for Participation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XXLOcBcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XXLOcBcAAAAJ:p2g8aNsByqUC,"We would like to invite you to Charlottesville, Virginia, USA to attend the 21st ICER Conference. The ACM Conference on International Computing Education Research (ICER) will be held 3–6 August 2025 in the Forum Hotel on the beautiful grounds of the University of Virginia. The conference will include an in-person Doctoral Consortium on Sunday, 3 August. Attendees are invited to an opening reception in The Rotunda, the original library designed by Thomas Jefferson (third President of the United States) and centerpiece of the Academical Village on Sunday evening, 5–6:30pm.",ACM,,2025
2259,How Good are Large Language Models at Generating Subgoal Labels?,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XXLOcBcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XXLOcBcAAAAJ:SP6oXDckpogC,"The use of subgoal labels in introduction to programming classrooms has been shown to improve student performance, learning, retention, and reduce students' drop out rates. However, creating and adding subgoal labels to programming assignments is often hard to articulate and very time-intensive for instructors. In Computing Education Research, Large Language Models (LLMs) have been widely used to generate human-like outputs such as worked examples and source code. In this work, we explore whether ChatGPT could be used to generate high-quality and appropriate subgoal labels in two programming curricula. Our qualitative data analysis suggests that LLMs can assist instructors in creating subgoal labels in their classrooms, opening up directions to empower students' learning experience in programming classrooms.",,,2025
2260,Curriculum for a Comprehensive Statewide In-Service CS Teacher Training Program,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XXLOcBcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XXLOcBcAAAAJ:uWQEDVKXjbEC,"Training teachers to teach high-quality computer science courses is an important step towards increasing participation in computer science. To meet this need, our Research Practitioner Partnership (RPP) was formed with the primary goal of creating a comprehensive, graduate-level program to train in-service CS teachers with little to no prior CS coursework. Since its formation, the RPP has iteratively designed, implemented, and evaluated a five-course program to improve participants' knowledge of computer science content and pedagogy while allowing them to earn the state's grades 5-12 computer science endorsement. Our program has successfully scaled from a single-site pilot to a truly statewide, multi-site program, emphasizing educator-based, standards-based, and cohort-based instruction. Currently, the RPP serves 250 in-service participants. In this paper, we explain the curriculum development process …",,,2025
2261,Panel Session: A Vision for the Next 15 Years of Computing Education,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XXLOcBcAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=XXLOcBcAAAAJ:OU6Ihb5iCvQC,"The session will present the final report of an NSF sponsored workshop tasked with creating a vision for computing education for the next 15 years. Within several broad themes identified, the panelists were asked to probe further into where the field should be heading and what difficult questions we need to tackle. We will use the final report as a basis for discussion with the attendees and ask them the same hard questions we asked ourselves when writing this report to see how these questions shape their views of where computing education needs to be in the next 15 years.",IEEE,,2024
2262,"Identifying the best machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the BRATS challenge",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lvfWy6sAAAAJ&citation_for_view=lvfWy6sAAAAJ:RJOyoaXV5v8C,"Gliomas are the most common primary brain malignancies, with different degrees of aggressiveness, variable prognosis and various heterogeneous histologic sub-regions, i.e., peritumoral edematous/invaded tissue, necrotic core, active and non-enhancing core. This intrinsic heterogeneity is also portrayed in their radio-phenotype, as their sub-regions are depicted by varying intensity profiles disseminated across multi-parametric magnetic resonance imaging (mpMRI) scans, reflecting varying biological properties. Their heterogeneous shape, extent, and location are some of the factors that make these tumors difficult to resect, and in some cases inoperable. The amount of resected tumor is a factor also considered in longitudinal scans, when evaluating the apparent tumor for potential diagnosis of progression. Furthermore, there is mounting evidence that accurate segmentation of the various tumor sub-regions can offer the basis for quantitative image analysis towards prediction of patient overall survival. This study assesses the state-of-the-art machine learning (ML) methods used for brain tumor image analysis in mpMRI scans, during the last seven instances of the International Brain Tumor Segmentation (BraTS) challenge, i.e., 2012-2018. Specifically, we focus on i) evaluating segmentations of the various glioma sub-regions in pre-operative mpMRI scans, ii) assessing potential tumor progression by virtue of longitudinal growth of tumor sub-regions, beyond use of the RECIST/RANO criteria, and iii) predicting the overall survival from pre-operative mpMRI scans of patients that underwent gross total resection. Finally, we investigate the …",,,2018
2263,Selection of a convolution function for Fourier inversion using gridding (computerised tomography application),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lvfWy6sAAAAJ&citation_for_view=lvfWy6sAAAAJ:u-x6o8ySG0sC,"In the technique known as gridding, the data samples are weighted for sampling density and convolved with a finite kernel, then resampled on a grid preparatory to a fast Fourier transform. The authors compare the artifact introduced into the image for various convolving functions of different sizes, including the Kaiser-Bessel window and the zero-order prolate spheroidal wave function (PSWF). They also show a convolving function that improves upon the PSWF in some circumstances.<>",IEEE,,1991
2264,Fast spiral coronary artery imaging,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lvfWy6sAAAAJ&citation_for_view=lvfWy6sAAAAJ:u5HHmVD_uO8C,"A flow‐independent method for imaging the coronary arteries within a breath‐hold on a standard whole‐body MR imager was developed. The technique is based on interleaved spiral k‐space scanning and forms a cardiac‐gated image in 20 heartbeats. The spiral readouts have good flow properties and generate minimal flow artifacts. The oblique slices are positioned so that the arteries are in the plane and so that the chamber blood does not obscure the arteries. Fat suppression by a spectral‐spatial pulse improves the visualization of the arteries.© 1992 Academic Press,Inc.","Wiley Subscription Services, Inc., A Wiley Company",,1992
2265,Simultaneous spatial and spectral selective excitation,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lvfWy6sAAAAJ&citation_for_view=lvfWy6sAAAAJ:d1gkVwhDpl0C,"Using a k‐space interpretation of small‐tip excitation, a single excitation pulse has been designed that is simultaneously selective in space and resonant frequency. An analytic expression for the response of this pulse has been derived. The pulse has been implemented on a 1.5‐T imaging system. The pulse has been applied to a rapid gradient‐echo imaging sequence that forms both water and fat images within a breath‐holding interval. These rapid images are free of the chemical shift artifacts at organ boundaries that typically afflict conventional rapid images. The pulse can be applied to a variety of other sequences, such as multislice water/fat sequences and rapid k‐space scanning. © 1990 Academic Press, Inc.","Wiley Subscription Services, Inc., A Wiley Company",,1990
2266,Coronary Angiography with Magnetization‐Prepared T2 Contrast,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lvfWy6sAAAAJ&citation_for_view=lvfWy6sAAAAJ:9yKSN-GCB0IC,"A magnetization‐prepared, T2‐weighted sequence (T2 Prep) is used to suppress muscle and venous structures. When combined with lipid suppression, this technique improves the visualization of the coronary arteries. T2 Prep was designed to be robust in the presence of flow as well as B0 and B1 inho‐mogeneities and may be combined with virtually any imaging technique. Here, it is implemented with both a single‐slice spiral acquisition and a multi‐slice spiral method that acquires up to 15 slices in a single breath‐holding interval.","Wiley Subscription Services, Inc., A Wiley Company",,1995
2267,Evaluating Racial and Ethnic Disparities in Progression Assessment Patterns in Routine Clinical Practice Among Patients with Newly Diagnosed Multiple Myeloma,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lvfWy6sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=lvfWy6sAAAAJ:4n0clTBhZ78C,,Elsevier,,2025
2268,Demonstration of Interoperability Between MIDRC and N3C: A COVID-19 Severity Prediction Use Case,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lvfWy6sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=lvfWy6sAAAAJ:V_vSwabWVtYC,"Interoperability between data sources, one of the FAIR (Findability, Accessibility, Interoperability, and Reusability) principles for scientific data management, can enable multi-modality research. The purpose of our study was to investigate the potential for interoperability between an imaging resource, the Medical Imaging and Data Resource Center (MIDRC), and a clinical record resource, the National COVID Cohort Collaborative (N3C). The use case was the prediction of COVID-19 severity, defined as evidence for invasive ventilatory support, extracorporeal membrane oxygenation, death, or discharge to hospice in the N3C clinical record. Patient-level matching between MIDRC and N3C was identified using Privacy Preserving Record Linking via an honest broker. We identified positive COVID-19 tests and chest radiograph procedures in N3C and used the interval between them to identify images with matching …",Springer International Publishing,,2025
2269,Systems and methods for magnetic resonance image reconstruction with nonconvex single value decomposition,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lvfWy6sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=lvfWy6sAAAAJ:SpPTWFSNUtQC,"A computer implemented method of reconstructing magnetic resonance images (MRI) in Cartesian coordinates uses acquired magnetic resonance data and implements a Fourier transform to place the MRI data in k-space. The method allows for under-sampling the k-space and achieving an accurate output image by selecting an image model to map the sampled data and iteratively converge the model to an output that matches a region of interest subject to the MRI. The image model may be an alternating direction method of multipliers (ADMM) or an ADMM with non-convex low rank regularization algorithm. A de-noising algorithm may be at least one of a plug and play block matching and 3D filtering (PnP-BM3D), a plug and play weighted nuclear norm minimization (WNNM), or a plug and play denoising convolutional neural networks (PnP-DnCNN) algorithm. An iterative optimization of the variables of the model …",,,2025
2270,A retraced spiral strategy with semi‐automatic deblurring for volumetric thermometry,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lvfWy6sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=lvfWy6sAAAAJ:hHIA4WEVY-EC,"Purpose To develop a 3D MRI‐thermometry technique for transcranial MR‐guided focused ultrasound (MRgFUS). Methods A stack of retraced in‐out (RIO) spirals was incorporated into a 3D, RF‐spoiled, gradient recalled echo (GRE) sequence with a minimized energy deblurring strategy. Bloch simulations examined isochromat precession during RIO readout under temperature profiles matching those encountered during transcranial MRgFUS and measured the resulting effects on observed peak temperatures and FWHM of the heating patterns. The sequence then monitored temperatures in a phantom undergoing insonation from an MRgFUS device. Finally, the sequence monitored temperatures, without insonation, in four patients immediately after MRgFUS thalamotomy. For comparison, temperatures were also monitored using a frequently used, 2D, Cartesian, multi‐echo, spoiled GRE sequence. Results …",,,2025
2271,Variable‐flip‐angle 3D spiral‐in‐out turbo spin‐echo imaging using concomitant gradient compensation and echo reordering at 0.55 T,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lvfWy6sAAAAJ&pagesize=100&sortby=pubdate&citation_for_view=lvfWy6sAAAAJ:q0uBw5dMOAkC,"Purpose To develop single‐slab 3D spiral turbo spin echo (spiral SPACE) for 1‐mm3 isotropic whole‐brain T2‐weighted imaging on a high‐performance 0.55T scanner, with high scan efficiency from interleaved spiral‐in‐out trajectories, variable‐flip‐angle refocusing radiofrequency (RF) pulses, echo reordering, and concomitant‐field compensation. Methods A stack‐of‐spirals (in‐out waveforms) turbo‐spin‐echo acquisition was implemented with T2‐weighed contrast. Gradient infidelity was corrected using the gradient impulse response function (GIRF), and concomitant‐field compensation was used to correct for phase errors among echoes and during the readout windows. To maintain a long echo train (˜600 ms) within each shot, variable‐flip‐angle refocusing RF pulses were generated using extended‐phase‐graph analysis. An echo‐reordering scheme provided a smooth signal variation along the echo …",,,2025
2272,Structural vibration control using high strength and damping capacity shape memory alloys,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aKvi7Q0AAAAJ&citation_for_view=aKvi7Q0AAAAJ:zYLM7Y9cAGgC,"Designing structures to withstand dynamic environmental hazards such as earthquakes, strong winds, and hurricanes is of primary concern for civil engineers. In addition, recent advances in architectural forms, structural systems, and high performance materials have enabled the design of very slender and lightweight structures. These flexible structures are susceptible to be exposed to high levels of vibrations under strong winds and earthquakes, which may lead to structural damage and potential failure. Over the past two decades, shape memory alloys (SMAs) have emerged as a smart material that can be used in passive vibration control devices for energy dissipating and re-centering purposes. However, the quantity of equivalent viscous damping provided by superelastic NiTi SMA wires or bars is not sufficient to render the use of SMAs as the sole damping device implemented in a tall structure subjected to …",Springer International Publishing,,2017
2273,Hysteresis Identification Using Extended Preisach Neural Network,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aKvi7Q0AAAAJ&citation_for_view=aKvi7Q0AAAAJ:0EnyYjriUFMC,"Hysteresis phenomena have been observed in different branches of physics and engineering sciences. Therefore several models have been proposed for hysteresis simulation in different fields; however, almost neither can be utilized universally. This paper introduces a universal adaptive model by inspiring Preisach Neural Network, called the Extended Preisach Neural Network Model (EPNN). It enjoys two hidden layers. The first hidden layer incorporates Deteriorating Stop (DS) neurons, which their activation function follows the (DS) operator. (DS) operator can generate noncongruent hysteresis loops. The second hidden layer includes Sigmoidal neurons. Adding the second hidden layer helps the neural network learn non-Masing and asymmetric hysteresis loops very smoothly. At the input layer, besides x(t), which is input data, , the rate at which x(t) changes, is included as well in order to give (EPNN) the …",Springer US,,2022
2274,Neural network software for dam-reservoir-foundation interaction,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aKvi7Q0AAAAJ&citation_for_view=aKvi7Q0AAAAJ:u5HHmVD_uO8C,"A software has been developed to use artificial neural networks (ANNs) for the modelling of nonlinear hysteretic response of concrete gravity dams under earthquake loading when reservoir and foundation interactions are included. The neural network which is designed for a given dam has been called the"" Neuro-modeller"" of that dam. Pine flat dam has been studied as example problem. Firstly using an analysis software, the dam has been analyzed under different earthquakes to collect a large number of data for training the"" Neuro-modeller"" which has then been used for the analysis of the dam under other earthquakes. Numerical tests using other earthquakes have been done to verify the capabilities of the neuromodeller, all of which have been successful.",,,2012
2275,Universal hysteresis identification using extended Preisach neural network,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aKvi7Q0AAAAJ&citation_for_view=aKvi7Q0AAAAJ:IjCSPb-OGe4C,"Hysteresis phenomena have been observed in different branches of physics and engineering sciences. Therefore, several models have been proposed for hysteresis simulation in different fields; however, almost neither of them can be utilized universally. In this paper by inspiring of Preisach Neural Network which was inspired by the Preisach model that basically stemmed from Madelungs rules and using the learning capability of the neural networks, an adaptive universal model for hysteresis is introduced and called Extended Preisach Neural Network Model. It is comprised of input, output and, two hidden layers. The input and output layers contain linear neurons while the first hidden layer incorporates neurons called Deteriorating Stop neurons, which their activation function follows Deteriorating Stop operator. Deteriorating Stop operators can generate non-congruent hysteresis loops. The second hidden layer includes Sigmoidal neurons. Adding the second hidden layer, helps the neural network learn non-Masing and asymmetric hysteresis loops very smoothly. At the input layer, besides input data the rate at which input data changes, is included as well in order to give the model the capability of learning rate-dependent hysteresis loops. Hence, the proposed approach has the capability of the simulation of both rate-independent and rate-dependent hysteresis with either congruent or non-congruent loops as well as symmetric and asymmetric loops. A new hybridized algorithm has been adopted for training the model which is based on a combination of the Genetic Algorithm and the optimization method of sub-gradient with space dilatation …",,,2019
2276,Seismic Performance Assessment of Steel Frames Upgraded with Shape Memory Alloy Re-centering Dampers for Passive Protection of Structures Subjected to Seismic Excitations Using …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aKvi7Q0AAAAJ&citation_for_view=aKvi7Q0AAAAJ:8k81kl-MbHgC,"This study explores a super-elastic memory alloy re-centering damper device and investigates its performance in improving the response of steel frame structures subjected to multi-level seismic hazard. The configuration of the device was initially proposed by the authors in a different paper. The proposed super-elastic memory alloy re-centering damper (SMARD) counts on high-performance shape memory alloy (SMA) bars for re-centering capability and employs friction springs to augment its deformation capacity. First of all, this study explores the super-elastic response of NiTiHfPd SMAs under various conditions and illustrates their application into seismic applications. In order to collect experimental data, uniaxial tests are conducted on super-elastic NiTiHfPd SMAs in the temperature range of− 35 C–25 C and at the loading frequencies of 0.05 Hz to 1.0 Hz with four different strain amplitudes. The effects of …",IOP Publishing,,2022
2277,Exploring the Impact of Mastery Grading on Student Performance,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aKvi7Q0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=aKvi7Q0AAAAJ:YOwf2qJgpHMC,"The introduction of mastery grading in Calculus I began in the fall of 2022 in our engineering school. We found that students in the mastery-graded course experienced reduced test anxiety, achieved higher letter grades through penalty-free reattempts, and felt more confident about their math ability [1][2]. In the fall of 2023, we extended the implementation to additional sections and introduced several modifications to the grading system. Three instructors taught five sections, with three of them using the mastery grading system. To provide a more robust measure of student performance, a common mandatory final exam was also incorporated. This paper discusses the evolution of the grading design and investigates the difference in grade distribution between students in mastery-graded and traditionally graded courses, shedding light on their implications. Additionally, the paper investigates how students from mastery-graded courses perform in a subsequent Calculus II course compared to their peers in traditionally graded courses, offering insights into the enduring effect of the grading method on student success. This study, which received approval from IRB, is currently ongoing, with data collection spanning the fall of 2023 and spring of 2024. The comparison of student performance will be based on their placement test scores and results from common exams. The examination of student performance will encompass both Calculus I in fall 2023 and the subsequent Calculus II course in spring 2024. The analysis of the collected data will take place following the conclusion of the fall semester.",,,2024
2278,Exploiting a Grading Option to Measure Mathematics Confidence of Engineering Students,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aKvi7Q0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=aKvi7Q0AAAAJ:Zph67rFs4hoC,"In an earlier (separate) study (work in progress), we investigated the impact of the COVID-19 pandemic on Applied Mathematics (APMA) courses in the Engineering School at our institution. An IRB approved survey was completed by students who took at least one course in APMA during Spring 2020, Fall 2020, and Spring 2021. It was shown that students chose CR/GC/NC (credit or no-credit option as opposed to a conventional letter grade), which was offered at our institution during those semesters, more frequently for APMA courses than for Major related courses. Our hypothesis is that students were not confident in performing well in their APMA course (s) and, therefore, didn’t want to harm their GPA. We also found it plausible that they would rather spend more time studying for their major courses. Now we are extending our analysis with data received from the undergraduate registrar office regarding the students who have completed the survey. We have access to their grades, GPA, major, and demographics. Our goal is to identify patterns and correlations between data we received from the undergraduate registrar office and the survey we conducted on the same engineering school students months ago. In order to do so, we will aggregate data from the two sources (survey and registrar office), and match school records with the survey of each student participating. We will use unsupervised statistical methods to identify patterns in students' grading choices. We expect to be able to identify students with low math confidence (ie selecting credit no-credit option even when they would have got a good letter grade) so that the School can design …",,,2023
2279,Impact of Covid-19 on Applied Mathematics Courses for Engineering Students,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aKvi7Q0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=aKvi7Q0AAAAJ:kNdYIx-mwKoC,"This study investigates the impact of the COVID-19 pandemic on Applied Mathematics (APMA) courses in the Engineering School at the University of Virginia. We investigate which subset of students may have been impacted more by the changes in our instruction methods due to the pandemic, and then design and implement strategies to mitigate any negative impacts of three semesters of (mostly) online teaching, for instance by reaching out immediately with an ad-hoc recovery path. We also want to understand the level of (dis) comfort of Engineering students (possibly a subset) with online teaching as implemented by the APMA program, and revise APMA fundamental courses to mitigate/remove bias and inequity. Finally, we compare motivation, performance and outcomes between APMA courses and major-related courses (those required to graduate in a particular major), and find whether students consider (ed) APMA courses a “roadblock” on the way to their degree.",,,2022
2280,Novel computational mathematical algorithms for structural optimization using graph-theoretical methods,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aKvi7Q0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=aKvi7Q0AAAAJ:5nxA0vEk-isC,"Purpose The purpose is to reduce round-off errors in numerical simulations. In the numerical simulation, different kinds of errors may be created during analysis. Round-off error is one of the sources of errors. In numerical analysis, sometimes handling numerical errors is challenging. However, by applying appropriate algorithms, these errors are manageable and can be reduced. In this study, five novel topological algorithms were proposed in setting up a structural flexibility matrix, and five different examples were used in applying the proposed algorithms. In doing so round-off errors were reduced remarkably. Design/methodology/approach Five new algorithms were proposed in order to optimize the conditioning of structural matrices. Along with decreasing the size and duration of analyses, minimizing analytical errors is a critical factor in the optimal computer analysis of skeletal …",Emerald Publishing Limited,,2022
2281,A novel passive structural control device using high-performance NiTiHfPd material,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=aKvi7Q0AAAAJ&pagesize=100&sortby=pubdate&citation_for_view=aKvi7Q0AAAAJ:MXK_kJrjxJIC,"This study proposes a super-elastic memory alloy re-centering damper device and investigates its performance in improving the response of steel frame structures subjected to multi-level seismic hazard. The proposed super-elastic memory alloy re-centering damper (SMARD) counts on high-performance shape memory alloy (SMA) bars for recentering capability and employs friction springs to augment its deformation capacity. An analytical model of sixstory steel special moment frame buildings with installed SMARDs is developed to determine the dynamic response of the building. Then, nonlinear response time history analyses are conducted to assess the behavior of controlled and uncontrolled buildings under 44 ground motion records. Results show that SMARDs can enormously mitigate the dynamic response of steel frame structures at different seismic hazard levels and, at the same time, enhance their …",SPIE,,2022